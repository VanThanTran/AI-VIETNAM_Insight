{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fchNLGIkgoO"
   },
   "source": [
    "**3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vBnAuicQtVb",
    "outputId": "1772e0ff-d24b-49f1-e736-94e1dab452df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n",
      "Epoch 1/2500\n",
      "196/196 [==============================] - 23s 84ms/step - loss: 25.7075 - accuracy: 0.0117 - val_loss: 9.3154 - val_accuracy: 0.0100\n",
      "Epoch 2/2500\n",
      "196/196 [==============================] - 16s 78ms/step - loss: 9.1314 - accuracy: 0.0163 - val_loss: 9.4705 - val_accuracy: 0.0133\n",
      "Epoch 3/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 7.6064 - accuracy: 0.0232 - val_loss: 8.8383 - val_accuracy: 0.0105\n",
      "Epoch 4/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 7.0219 - accuracy: 0.0293 - val_loss: 8.1440 - val_accuracy: 0.0132\n",
      "Epoch 5/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 6.5347 - accuracy: 0.0353 - val_loss: 7.7260 - val_accuracy: 0.0132\n",
      "Epoch 6/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 6.1439 - accuracy: 0.0430 - val_loss: 7.4016 - val_accuracy: 0.0191\n",
      "Epoch 7/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 5.8483 - accuracy: 0.0515 - val_loss: 7.0265 - val_accuracy: 0.0226\n",
      "Epoch 8/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 5.5784 - accuracy: 0.0552 - val_loss: 6.5191 - val_accuracy: 0.0249\n",
      "Epoch 9/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 5.3557 - accuracy: 0.0662 - val_loss: 6.3999 - val_accuracy: 0.0274\n",
      "Epoch 10/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 5.1617 - accuracy: 0.0766 - val_loss: 6.1618 - val_accuracy: 0.0377\n",
      "Epoch 11/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 5.0350 - accuracy: 0.0854 - val_loss: 5.8351 - val_accuracy: 0.0282\n",
      "Epoch 12/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.8825 - accuracy: 0.0924 - val_loss: 5.6779 - val_accuracy: 0.0447\n",
      "Epoch 13/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.7821 - accuracy: 0.1046 - val_loss: 5.3258 - val_accuracy: 0.0442\n",
      "Epoch 14/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.6499 - accuracy: 0.1169 - val_loss: 5.1986 - val_accuracy: 0.0411\n",
      "Epoch 15/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.5570 - accuracy: 0.1307 - val_loss: 5.1456 - val_accuracy: 0.0489\n",
      "Epoch 16/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.4960 - accuracy: 0.1413 - val_loss: 5.0568 - val_accuracy: 0.0705\n",
      "Epoch 17/2500\n",
      "196/196 [==============================] - 16s 78ms/step - loss: 4.4149 - accuracy: 0.1603 - val_loss: 5.1519 - val_accuracy: 0.0560\n",
      "Epoch 18/2500\n",
      "196/196 [==============================] - 16s 78ms/step - loss: 4.3779 - accuracy: 0.1734 - val_loss: 4.9030 - val_accuracy: 0.0886\n",
      "Epoch 19/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2956 - accuracy: 0.1926 - val_loss: 4.8013 - val_accuracy: 0.1140\n",
      "Epoch 20/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2486 - accuracy: 0.2149 - val_loss: 4.7310 - val_accuracy: 0.1475\n",
      "Epoch 21/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 4.2396 - accuracy: 0.2307 - val_loss: 4.7724 - val_accuracy: 0.1470\n",
      "Epoch 22/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.2354 - accuracy: 0.2413 - val_loss: 4.7309 - val_accuracy: 0.1746\n",
      "Epoch 23/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2490 - accuracy: 0.2540 - val_loss: 4.7166 - val_accuracy: 0.1930\n",
      "Epoch 24/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2210 - accuracy: 0.2677 - val_loss: 4.7789 - val_accuracy: 0.1745\n",
      "Epoch 25/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2016 - accuracy: 0.2775 - val_loss: 4.6257 - val_accuracy: 0.2323\n",
      "Epoch 26/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.2478 - accuracy: 0.2827 - val_loss: 4.5369 - val_accuracy: 0.2236\n",
      "Epoch 27/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.1574 - accuracy: 0.2911 - val_loss: 4.5028 - val_accuracy: 0.2487\n",
      "Epoch 28/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.1944 - accuracy: 0.3020 - val_loss: 4.3918 - val_accuracy: 0.2635\n",
      "Epoch 29/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.0865 - accuracy: 0.3102 - val_loss: 4.3392 - val_accuracy: 0.2782\n",
      "Epoch 30/2500\n",
      "196/196 [==============================] - 16s 78ms/step - loss: 4.0674 - accuracy: 0.3248 - val_loss: 4.2743 - val_accuracy: 0.2919\n",
      "Epoch 31/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.0350 - accuracy: 0.3282 - val_loss: 4.2191 - val_accuracy: 0.3002\n",
      "Epoch 32/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.0073 - accuracy: 0.3357 - val_loss: 4.3592 - val_accuracy: 0.2967\n",
      "Epoch 33/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.0698 - accuracy: 0.3392 - val_loss: 4.0814 - val_accuracy: 0.3295\n",
      "Epoch 34/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 4.0076 - accuracy: 0.3450 - val_loss: 4.2066 - val_accuracy: 0.3150\n",
      "Epoch 35/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.9736 - accuracy: 0.3494 - val_loss: 4.3041 - val_accuracy: 0.2968\n",
      "Epoch 36/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.9638 - accuracy: 0.3584 - val_loss: 4.0845 - val_accuracy: 0.3376\n",
      "Epoch 37/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.9415 - accuracy: 0.3646 - val_loss: 4.0588 - val_accuracy: 0.3376\n",
      "Epoch 38/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.8878 - accuracy: 0.3708 - val_loss: 4.1711 - val_accuracy: 0.3251\n",
      "Epoch 39/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.9012 - accuracy: 0.3732 - val_loss: 4.0088 - val_accuracy: 0.3519\n",
      "Epoch 40/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.8712 - accuracy: 0.3800 - val_loss: 4.0013 - val_accuracy: 0.3451\n",
      "Epoch 41/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.8197 - accuracy: 0.3851 - val_loss: 3.9770 - val_accuracy: 0.3495\n",
      "Epoch 42/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.7636 - accuracy: 0.3883 - val_loss: 3.9838 - val_accuracy: 0.3589\n",
      "Epoch 43/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.7557 - accuracy: 0.3909 - val_loss: 3.9679 - val_accuracy: 0.3552\n",
      "Epoch 44/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.6962 - accuracy: 0.4003 - val_loss: 3.9675 - val_accuracy: 0.3567\n",
      "Epoch 45/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.6986 - accuracy: 0.4004 - val_loss: 3.8612 - val_accuracy: 0.3749\n",
      "Epoch 46/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.6835 - accuracy: 0.4069 - val_loss: 3.9838 - val_accuracy: 0.3546\n",
      "Epoch 47/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.6686 - accuracy: 0.4098 - val_loss: 3.9411 - val_accuracy: 0.3620\n",
      "Epoch 48/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.6409 - accuracy: 0.4153 - val_loss: 3.9369 - val_accuracy: 0.3558\n",
      "Epoch 49/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.5894 - accuracy: 0.4189 - val_loss: 3.8099 - val_accuracy: 0.3893\n",
      "Epoch 50/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.5869 - accuracy: 0.4218 - val_loss: 3.8734 - val_accuracy: 0.3710\n",
      "Epoch 51/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.5512 - accuracy: 0.4208 - val_loss: 3.8800 - val_accuracy: 0.3788\n",
      "Epoch 52/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.5470 - accuracy: 0.4282 - val_loss: 3.9088 - val_accuracy: 0.3714\n",
      "Epoch 53/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.5356 - accuracy: 0.4237 - val_loss: 3.8574 - val_accuracy: 0.3747\n",
      "Epoch 54/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.4886 - accuracy: 0.4290 - val_loss: 3.7082 - val_accuracy: 0.4002\n",
      "Epoch 55/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.4287 - accuracy: 0.4300 - val_loss: 3.7162 - val_accuracy: 0.3976\n",
      "Epoch 56/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.4059 - accuracy: 0.4388 - val_loss: 3.7676 - val_accuracy: 0.3887\n",
      "Epoch 57/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.4516 - accuracy: 0.4386 - val_loss: 3.6173 - val_accuracy: 0.4193\n",
      "Epoch 58/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.3716 - accuracy: 0.4482 - val_loss: 3.6146 - val_accuracy: 0.3983\n",
      "Epoch 59/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.2914 - accuracy: 0.4527 - val_loss: 3.7166 - val_accuracy: 0.3907\n",
      "Epoch 60/2500\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 3.3209 - accuracy: 0.4514 - val_loss: 3.4759 - val_accuracy: 0.4201\n",
      "Epoch 61/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.2751 - accuracy: 0.4485 - val_loss: 3.6002 - val_accuracy: 0.4063\n",
      "Epoch 62/2500\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.2733 - accuracy: 0.4531 - val_loss: 4.1359 - val_accuracy: 0.4001\n",
      "Epoch 63/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.5747 - accuracy: 0.4613 - val_loss: 3.5135 - val_accuracy: 0.4218\n",
      "Epoch 64/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.2575 - accuracy: 0.4557 - val_loss: 3.6769 - val_accuracy: 0.3918\n",
      "Epoch 65/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.2234 - accuracy: 0.4625 - val_loss: 3.5050 - val_accuracy: 0.4285\n",
      "Epoch 66/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.1988 - accuracy: 0.4651 - val_loss: 3.4351 - val_accuracy: 0.4285\n",
      "Epoch 67/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.1630 - accuracy: 0.4738 - val_loss: 3.5193 - val_accuracy: 0.4171\n",
      "Epoch 68/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.1661 - accuracy: 0.4731 - val_loss: 3.4680 - val_accuracy: 0.4252\n",
      "Epoch 69/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.1682 - accuracy: 0.4749 - val_loss: 3.3655 - val_accuracy: 0.4491\n",
      "Epoch 70/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.1556 - accuracy: 0.4758 - val_loss: 3.4223 - val_accuracy: 0.4350\n",
      "Epoch 71/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.9534 - accuracy: 0.5081 - val_loss: 3.2660 - val_accuracy: 0.4471\n",
      "Epoch 72/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.8444 - accuracy: 0.5170 - val_loss: 3.1671 - val_accuracy: 0.4570\n",
      "Epoch 73/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.7726 - accuracy: 0.5213 - val_loss: 3.1612 - val_accuracy: 0.4543\n",
      "Epoch 74/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.7212 - accuracy: 0.5300 - val_loss: 3.2073 - val_accuracy: 0.4608\n",
      "Epoch 75/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.7856 - accuracy: 0.5276 - val_loss: 3.1190 - val_accuracy: 0.4576\n",
      "Epoch 76/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6962 - accuracy: 0.5349 - val_loss: 3.1393 - val_accuracy: 0.4552\n",
      "Epoch 77/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.6716 - accuracy: 0.5346 - val_loss: 3.0996 - val_accuracy: 0.4674\n",
      "Epoch 78/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6784 - accuracy: 0.5354 - val_loss: 2.9845 - val_accuracy: 0.4734\n",
      "Epoch 79/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6097 - accuracy: 0.5383 - val_loss: 3.0096 - val_accuracy: 0.4713\n",
      "Epoch 80/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6078 - accuracy: 0.5430 - val_loss: 3.0477 - val_accuracy: 0.4705\n",
      "Epoch 81/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6126 - accuracy: 0.5434 - val_loss: 3.0171 - val_accuracy: 0.4683\n",
      "Epoch 82/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.5941 - accuracy: 0.5419 - val_loss: 3.0661 - val_accuracy: 0.4672\n",
      "Epoch 83/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.6023 - accuracy: 0.5427 - val_loss: 2.9888 - val_accuracy: 0.4757\n",
      "Epoch 84/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.5651 - accuracy: 0.5457 - val_loss: 3.0306 - val_accuracy: 0.4753\n",
      "Epoch 85/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.5478 - accuracy: 0.5532 - val_loss: 2.8674 - val_accuracy: 0.4899\n",
      "Epoch 86/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.5264 - accuracy: 0.5516 - val_loss: 2.9526 - val_accuracy: 0.4782\n",
      "Epoch 87/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.5182 - accuracy: 0.5544 - val_loss: 2.8830 - val_accuracy: 0.4908\n",
      "Epoch 88/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.5386 - accuracy: 0.5533 - val_loss: 2.9020 - val_accuracy: 0.4962\n",
      "Epoch 89/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 2.5043 - accuracy: 0.5602 - val_loss: 2.8374 - val_accuracy: 0.4924\n",
      "Epoch 90/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.5381 - accuracy: 0.5556 - val_loss: 2.9140 - val_accuracy: 0.4843\n",
      "Epoch 91/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.4719 - accuracy: 0.5562 - val_loss: 2.8126 - val_accuracy: 0.5008\n",
      "Epoch 92/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.4450 - accuracy: 0.5640 - val_loss: 2.7846 - val_accuracy: 0.5064\n",
      "Epoch 93/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.4472 - accuracy: 0.5612 - val_loss: 2.8717 - val_accuracy: 0.4832\n",
      "Epoch 94/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.4417 - accuracy: 0.5582 - val_loss: 2.8646 - val_accuracy: 0.4961\n",
      "Epoch 95/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.4425 - accuracy: 0.5674 - val_loss: 2.9273 - val_accuracy: 0.4844\n",
      "Epoch 96/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.4303 - accuracy: 0.5630 - val_loss: 2.8645 - val_accuracy: 0.4892\n",
      "Epoch 97/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.4101 - accuracy: 0.5678 - val_loss: 2.8259 - val_accuracy: 0.4995\n",
      "Epoch 98/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.4185 - accuracy: 0.5638 - val_loss: 2.7749 - val_accuracy: 0.5055\n",
      "Epoch 99/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.4234 - accuracy: 0.5690 - val_loss: 2.8898 - val_accuracy: 0.4831\n",
      "Epoch 100/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3891 - accuracy: 0.5720 - val_loss: 2.8180 - val_accuracy: 0.4938\n",
      "Epoch 101/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3727 - accuracy: 0.5684 - val_loss: 2.7792 - val_accuracy: 0.5032\n",
      "Epoch 102/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3863 - accuracy: 0.5717 - val_loss: 2.9108 - val_accuracy: 0.4927\n",
      "Epoch 103/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3978 - accuracy: 0.5727 - val_loss: 2.8388 - val_accuracy: 0.4918\n",
      "Epoch 104/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3843 - accuracy: 0.5721 - val_loss: 2.7966 - val_accuracy: 0.4983\n",
      "Epoch 105/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3885 - accuracy: 0.5720 - val_loss: 2.8865 - val_accuracy: 0.4878\n",
      "Epoch 106/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3655 - accuracy: 0.5748 - val_loss: 2.8216 - val_accuracy: 0.4949\n",
      "Epoch 107/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3433 - accuracy: 0.5800 - val_loss: 2.7946 - val_accuracy: 0.5021\n",
      "Epoch 108/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3502 - accuracy: 0.5789 - val_loss: 2.8217 - val_accuracy: 0.4971\n",
      "Epoch 109/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3383 - accuracy: 0.5799 - val_loss: 2.8341 - val_accuracy: 0.4999\n",
      "Epoch 110/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.3379 - accuracy: 0.5805 - val_loss: 2.6787 - val_accuracy: 0.5231\n",
      "Epoch 111/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.1853 - accuracy: 0.6109 - val_loss: 2.6094 - val_accuracy: 0.5322\n",
      "Epoch 112/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.1458 - accuracy: 0.6160 - val_loss: 2.6305 - val_accuracy: 0.5267\n",
      "Epoch 113/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.1095 - accuracy: 0.6202 - val_loss: 2.6088 - val_accuracy: 0.5280\n",
      "Epoch 114/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.0815 - accuracy: 0.6235 - val_loss: 2.6054 - val_accuracy: 0.5260\n",
      "Epoch 115/2500\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.0656 - accuracy: 0.6251 - val_loss: 2.5818 - val_accuracy: 0.5293\n",
      "Epoch 116/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.0789 - accuracy: 0.6284 - val_loss: 2.5695 - val_accuracy: 0.5298\n",
      "Epoch 117/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.0473 - accuracy: 0.6289 - val_loss: 2.5609 - val_accuracy: 0.5317\n",
      "Epoch 118/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.0337 - accuracy: 0.6303 - val_loss: 2.5567 - val_accuracy: 0.5329\n",
      "Epoch 119/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.0057 - accuracy: 0.6352 - val_loss: 2.5718 - val_accuracy: 0.5288\n",
      "Epoch 120/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.0008 - accuracy: 0.6362 - val_loss: 2.5573 - val_accuracy: 0.5305\n",
      "Epoch 121/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9990 - accuracy: 0.6335 - val_loss: 2.5128 - val_accuracy: 0.5346\n",
      "Epoch 122/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9805 - accuracy: 0.6387 - val_loss: 2.5355 - val_accuracy: 0.5318\n",
      "Epoch 123/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9811 - accuracy: 0.6358 - val_loss: 2.5558 - val_accuracy: 0.5323\n",
      "Epoch 124/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9714 - accuracy: 0.6399 - val_loss: 2.5041 - val_accuracy: 0.5352\n",
      "Epoch 125/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9421 - accuracy: 0.6422 - val_loss: 2.5112 - val_accuracy: 0.5355\n",
      "Epoch 126/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9388 - accuracy: 0.6430 - val_loss: 2.5106 - val_accuracy: 0.5337\n",
      "Epoch 127/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9294 - accuracy: 0.6451 - val_loss: 2.5058 - val_accuracy: 0.5355\n",
      "Epoch 128/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9322 - accuracy: 0.6428 - val_loss: 2.5419 - val_accuracy: 0.5274\n",
      "Epoch 129/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.9201 - accuracy: 0.6480 - val_loss: 2.5180 - val_accuracy: 0.5308\n",
      "Epoch 130/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9151 - accuracy: 0.6447 - val_loss: 2.5403 - val_accuracy: 0.5293\n",
      "Epoch 131/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9116 - accuracy: 0.6461 - val_loss: 2.5111 - val_accuracy: 0.5340\n",
      "Epoch 132/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.9012 - accuracy: 0.6487 - val_loss: 2.4798 - val_accuracy: 0.5405\n",
      "Epoch 133/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9066 - accuracy: 0.6455 - val_loss: 2.4438 - val_accuracy: 0.5454\n",
      "Epoch 134/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8953 - accuracy: 0.6467 - val_loss: 2.4650 - val_accuracy: 0.5401\n",
      "Epoch 135/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8852 - accuracy: 0.6506 - val_loss: 2.4570 - val_accuracy: 0.5468\n",
      "Epoch 136/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.9006 - accuracy: 0.6469 - val_loss: 2.4822 - val_accuracy: 0.5381\n",
      "Epoch 137/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8781 - accuracy: 0.6535 - val_loss: 2.4540 - val_accuracy: 0.5434\n",
      "Epoch 138/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8712 - accuracy: 0.6465 - val_loss: 2.4648 - val_accuracy: 0.5385\n",
      "Epoch 139/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8520 - accuracy: 0.6523 - val_loss: 2.4263 - val_accuracy: 0.5474\n",
      "Epoch 140/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8457 - accuracy: 0.6534 - val_loss: 2.4585 - val_accuracy: 0.5395\n",
      "Epoch 141/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8427 - accuracy: 0.6532 - val_loss: 2.4376 - val_accuracy: 0.5462\n",
      "Epoch 142/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8582 - accuracy: 0.6534 - val_loss: 2.4538 - val_accuracy: 0.5417\n",
      "Epoch 143/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8380 - accuracy: 0.6572 - val_loss: 2.4418 - val_accuracy: 0.5435\n",
      "Epoch 144/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8328 - accuracy: 0.6545 - val_loss: 2.4253 - val_accuracy: 0.5462\n",
      "Epoch 145/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8400 - accuracy: 0.6587 - val_loss: 2.3901 - val_accuracy: 0.5503\n",
      "Epoch 146/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8266 - accuracy: 0.6583 - val_loss: 2.4266 - val_accuracy: 0.5420\n",
      "Epoch 147/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8281 - accuracy: 0.6530 - val_loss: 2.4275 - val_accuracy: 0.5423\n",
      "Epoch 148/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8243 - accuracy: 0.6562 - val_loss: 2.4109 - val_accuracy: 0.5445\n",
      "Epoch 149/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8180 - accuracy: 0.6593 - val_loss: 2.4088 - val_accuracy: 0.5447\n",
      "Epoch 150/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8085 - accuracy: 0.6622 - val_loss: 2.4285 - val_accuracy: 0.5429\n",
      "Epoch 151/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8025 - accuracy: 0.6596 - val_loss: 2.4592 - val_accuracy: 0.5442\n",
      "Epoch 152/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8275 - accuracy: 0.6597 - val_loss: 2.3975 - val_accuracy: 0.5483\n",
      "Epoch 153/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7987 - accuracy: 0.6610 - val_loss: 2.4207 - val_accuracy: 0.5470\n",
      "Epoch 154/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8043 - accuracy: 0.6599 - val_loss: 2.4138 - val_accuracy: 0.5493\n",
      "Epoch 155/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7874 - accuracy: 0.6639 - val_loss: 2.4080 - val_accuracy: 0.5516\n",
      "Epoch 156/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.8005 - accuracy: 0.6610 - val_loss: 2.4019 - val_accuracy: 0.5482\n",
      "Epoch 157/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7839 - accuracy: 0.6640 - val_loss: 2.3838 - val_accuracy: 0.5496\n",
      "Epoch 158/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7894 - accuracy: 0.6623 - val_loss: 2.3982 - val_accuracy: 0.5476\n",
      "Epoch 159/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7774 - accuracy: 0.6666 - val_loss: 2.3922 - val_accuracy: 0.5466\n",
      "Epoch 160/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7828 - accuracy: 0.6655 - val_loss: 2.3644 - val_accuracy: 0.5511\n",
      "Epoch 161/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7653 - accuracy: 0.6661 - val_loss: 2.4114 - val_accuracy: 0.5490\n",
      "Epoch 162/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7771 - accuracy: 0.6675 - val_loss: 2.3980 - val_accuracy: 0.5496\n",
      "Epoch 163/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7787 - accuracy: 0.6655 - val_loss: 2.3948 - val_accuracy: 0.5521\n",
      "Epoch 164/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7722 - accuracy: 0.6664 - val_loss: 2.3691 - val_accuracy: 0.5558\n",
      "Epoch 165/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7552 - accuracy: 0.6707 - val_loss: 2.3813 - val_accuracy: 0.5525\n",
      "Epoch 166/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7587 - accuracy: 0.6677 - val_loss: 2.4129 - val_accuracy: 0.5463\n",
      "Epoch 167/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7357 - accuracy: 0.6707 - val_loss: 2.3913 - val_accuracy: 0.5505\n",
      "Epoch 168/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7810 - accuracy: 0.6679 - val_loss: 2.4142 - val_accuracy: 0.5499\n",
      "Epoch 169/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7397 - accuracy: 0.6710 - val_loss: 2.3893 - val_accuracy: 0.5499\n",
      "Epoch 170/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7436 - accuracy: 0.6679 - val_loss: 2.3531 - val_accuracy: 0.5541\n",
      "Epoch 171/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7311 - accuracy: 0.6705 - val_loss: 2.3740 - val_accuracy: 0.5504\n",
      "Epoch 172/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7418 - accuracy: 0.6721 - val_loss: 2.3565 - val_accuracy: 0.5577\n",
      "Epoch 173/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7328 - accuracy: 0.6708 - val_loss: 2.3687 - val_accuracy: 0.5531\n",
      "Epoch 174/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7378 - accuracy: 0.6698 - val_loss: 2.4056 - val_accuracy: 0.5461\n",
      "Epoch 175/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7263 - accuracy: 0.6720 - val_loss: 2.3713 - val_accuracy: 0.5541\n",
      "Epoch 176/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7267 - accuracy: 0.6746 - val_loss: 2.3496 - val_accuracy: 0.5569\n",
      "Epoch 177/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7228 - accuracy: 0.6748 - val_loss: 2.3719 - val_accuracy: 0.5553\n",
      "Epoch 178/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7305 - accuracy: 0.6713 - val_loss: 2.4035 - val_accuracy: 0.5497\n",
      "Epoch 179/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7263 - accuracy: 0.6719 - val_loss: 2.4025 - val_accuracy: 0.5516\n",
      "Epoch 180/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7176 - accuracy: 0.6748 - val_loss: 2.3905 - val_accuracy: 0.5532\n",
      "Epoch 181/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7199 - accuracy: 0.6770 - val_loss: 2.3631 - val_accuracy: 0.5558\n",
      "Epoch 182/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7110 - accuracy: 0.6734 - val_loss: 2.3684 - val_accuracy: 0.5538\n",
      "Epoch 183/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.7080 - accuracy: 0.6742 - val_loss: 2.3538 - val_accuracy: 0.5604\n",
      "Epoch 184/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.7029 - accuracy: 0.6752 - val_loss: 2.3866 - val_accuracy: 0.5548\n",
      "Epoch 185/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6994 - accuracy: 0.6785 - val_loss: 2.3439 - val_accuracy: 0.5620\n",
      "Epoch 186/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6980 - accuracy: 0.6788 - val_loss: 2.3468 - val_accuracy: 0.5615\n",
      "Epoch 187/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6926 - accuracy: 0.6813 - val_loss: 2.3847 - val_accuracy: 0.5537\n",
      "Epoch 188/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6993 - accuracy: 0.6838 - val_loss: 2.3279 - val_accuracy: 0.5608\n",
      "Epoch 189/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6800 - accuracy: 0.6831 - val_loss: 2.3343 - val_accuracy: 0.5611\n",
      "Epoch 190/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6880 - accuracy: 0.6787 - val_loss: 2.3405 - val_accuracy: 0.5577\n",
      "Epoch 191/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6869 - accuracy: 0.6810 - val_loss: 2.3569 - val_accuracy: 0.5569\n",
      "Epoch 192/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6787 - accuracy: 0.6823 - val_loss: 2.3376 - val_accuracy: 0.5628\n",
      "Epoch 193/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6753 - accuracy: 0.6853 - val_loss: 2.3575 - val_accuracy: 0.5570\n",
      "Epoch 194/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6810 - accuracy: 0.6831 - val_loss: 2.3747 - val_accuracy: 0.5589\n",
      "Epoch 195/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6841 - accuracy: 0.6836 - val_loss: 2.3647 - val_accuracy: 0.5579\n",
      "Epoch 196/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6865 - accuracy: 0.6796 - val_loss: 2.3918 - val_accuracy: 0.5513\n",
      "Epoch 197/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6803 - accuracy: 0.6779 - val_loss: 2.3717 - val_accuracy: 0.5572\n",
      "Epoch 198/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6653 - accuracy: 0.6845 - val_loss: 2.3576 - val_accuracy: 0.5582\n",
      "Epoch 199/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6701 - accuracy: 0.6835 - val_loss: 2.3174 - val_accuracy: 0.5635\n",
      "Epoch 200/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6594 - accuracy: 0.6835 - val_loss: 2.4148 - val_accuracy: 0.5495\n",
      "Epoch 201/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6700 - accuracy: 0.6871 - val_loss: 2.3250 - val_accuracy: 0.5625\n",
      "Epoch 202/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6706 - accuracy: 0.6842 - val_loss: 2.3828 - val_accuracy: 0.5552\n",
      "Epoch 203/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6560 - accuracy: 0.6857 - val_loss: 2.3464 - val_accuracy: 0.5599\n",
      "Epoch 204/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6560 - accuracy: 0.6873 - val_loss: 2.3484 - val_accuracy: 0.5614\n",
      "Epoch 205/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6576 - accuracy: 0.6849 - val_loss: 2.3442 - val_accuracy: 0.5605\n",
      "Epoch 206/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6666 - accuracy: 0.6852 - val_loss: 2.3382 - val_accuracy: 0.5642\n",
      "Epoch 207/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6388 - accuracy: 0.6921 - val_loss: 2.3112 - val_accuracy: 0.5690\n",
      "Epoch 208/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6450 - accuracy: 0.6890 - val_loss: 2.3221 - val_accuracy: 0.5661\n",
      "Epoch 209/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6337 - accuracy: 0.6904 - val_loss: 2.3388 - val_accuracy: 0.5592\n",
      "Epoch 210/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6444 - accuracy: 0.6875 - val_loss: 2.3149 - val_accuracy: 0.5628\n",
      "Epoch 211/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6363 - accuracy: 0.6893 - val_loss: 2.3644 - val_accuracy: 0.5550\n",
      "Epoch 212/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6348 - accuracy: 0.6897 - val_loss: 2.3496 - val_accuracy: 0.5591\n",
      "Epoch 213/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6328 - accuracy: 0.6957 - val_loss: 2.3371 - val_accuracy: 0.5618\n",
      "Epoch 214/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6435 - accuracy: 0.6905 - val_loss: 2.3250 - val_accuracy: 0.5623\n",
      "Epoch 215/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6378 - accuracy: 0.6889 - val_loss: 2.3612 - val_accuracy: 0.5572\n",
      "Epoch 216/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6371 - accuracy: 0.6879 - val_loss: 2.3578 - val_accuracy: 0.5599\n",
      "Epoch 217/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6311 - accuracy: 0.6933 - val_loss: 2.2843 - val_accuracy: 0.5695\n",
      "Epoch 218/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6246 - accuracy: 0.6910 - val_loss: 2.3631 - val_accuracy: 0.5575\n",
      "Epoch 219/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6253 - accuracy: 0.6912 - val_loss: 2.3232 - val_accuracy: 0.5660\n",
      "Epoch 220/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6163 - accuracy: 0.6941 - val_loss: 2.2985 - val_accuracy: 0.5698\n",
      "Epoch 221/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.6245 - accuracy: 0.6930 - val_loss: 2.3705 - val_accuracy: 0.5602\n",
      "Epoch 222/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6341 - accuracy: 0.6918 - val_loss: 2.3294 - val_accuracy: 0.5650\n",
      "Epoch 223/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6208 - accuracy: 0.6926 - val_loss: 2.2988 - val_accuracy: 0.5702\n",
      "Epoch 224/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6207 - accuracy: 0.6918 - val_loss: 2.3031 - val_accuracy: 0.5650\n",
      "Epoch 225/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6190 - accuracy: 0.6910 - val_loss: 2.3108 - val_accuracy: 0.5679\n",
      "Epoch 226/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6063 - accuracy: 0.6976 - val_loss: 2.3109 - val_accuracy: 0.5695\n",
      "Epoch 227/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6107 - accuracy: 0.6946 - val_loss: 2.3058 - val_accuracy: 0.5697\n",
      "Epoch 228/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6117 - accuracy: 0.6983 - val_loss: 2.3252 - val_accuracy: 0.5702\n",
      "Epoch 229/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6030 - accuracy: 0.6954 - val_loss: 2.3425 - val_accuracy: 0.5650\n",
      "Epoch 230/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.5941 - accuracy: 0.6999 - val_loss: 2.3234 - val_accuracy: 0.5685\n",
      "Epoch 231/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5952 - accuracy: 0.7011 - val_loss: 2.3159 - val_accuracy: 0.5708\n",
      "Epoch 232/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6050 - accuracy: 0.6974 - val_loss: 2.3390 - val_accuracy: 0.5678\n",
      "Epoch 233/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6025 - accuracy: 0.6973 - val_loss: 2.2985 - val_accuracy: 0.5727\n",
      "Epoch 234/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6030 - accuracy: 0.6944 - val_loss: 2.3294 - val_accuracy: 0.5679\n",
      "Epoch 235/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.6044 - accuracy: 0.6956 - val_loss: 2.3324 - val_accuracy: 0.5674\n",
      "Epoch 236/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.6073 - accuracy: 0.6971 - val_loss: 2.3465 - val_accuracy: 0.5668\n",
      "Epoch 237/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5884 - accuracy: 0.6994 - val_loss: 2.3091 - val_accuracy: 0.5713\n",
      "Epoch 238/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5880 - accuracy: 0.6977 - val_loss: 2.2919 - val_accuracy: 0.5756\n",
      "Epoch 239/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5948 - accuracy: 0.6994 - val_loss: 2.3269 - val_accuracy: 0.5686\n",
      "Epoch 240/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5930 - accuracy: 0.7034 - val_loss: 2.3367 - val_accuracy: 0.5657\n",
      "Epoch 241/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5838 - accuracy: 0.6991 - val_loss: 2.2995 - val_accuracy: 0.5756\n",
      "Epoch 242/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5744 - accuracy: 0.7015 - val_loss: 2.3154 - val_accuracy: 0.5725\n",
      "Epoch 243/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5839 - accuracy: 0.6977 - val_loss: 2.2913 - val_accuracy: 0.5763\n",
      "Epoch 244/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5894 - accuracy: 0.7017 - val_loss: 2.2837 - val_accuracy: 0.5761\n",
      "Epoch 245/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5777 - accuracy: 0.7041 - val_loss: 2.3189 - val_accuracy: 0.5693\n",
      "Epoch 246/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5630 - accuracy: 0.7035 - val_loss: 2.3088 - val_accuracy: 0.5765\n",
      "Epoch 247/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5862 - accuracy: 0.7008 - val_loss: 2.3016 - val_accuracy: 0.5711\n",
      "Epoch 248/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5733 - accuracy: 0.7025 - val_loss: 2.2836 - val_accuracy: 0.5784\n",
      "Epoch 249/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5672 - accuracy: 0.7038 - val_loss: 2.3090 - val_accuracy: 0.5736\n",
      "Epoch 250/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5785 - accuracy: 0.7024 - val_loss: 2.3530 - val_accuracy: 0.5653\n",
      "Epoch 251/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5762 - accuracy: 0.7007 - val_loss: 2.2933 - val_accuracy: 0.5764\n",
      "Epoch 252/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5671 - accuracy: 0.7026 - val_loss: 2.3253 - val_accuracy: 0.5722\n",
      "Epoch 253/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5586 - accuracy: 0.7039 - val_loss: 2.2872 - val_accuracy: 0.5789\n",
      "Epoch 254/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5687 - accuracy: 0.7019 - val_loss: 2.2886 - val_accuracy: 0.5807\n",
      "Epoch 255/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5642 - accuracy: 0.7028 - val_loss: 2.3062 - val_accuracy: 0.5725\n",
      "Epoch 256/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5596 - accuracy: 0.7046 - val_loss: 2.2885 - val_accuracy: 0.5759\n",
      "Epoch 257/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5545 - accuracy: 0.7072 - val_loss: 2.3132 - val_accuracy: 0.5752\n",
      "Epoch 258/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5634 - accuracy: 0.7080 - val_loss: 2.2771 - val_accuracy: 0.5796\n",
      "Epoch 259/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5683 - accuracy: 0.7012 - val_loss: 2.3350 - val_accuracy: 0.5717\n",
      "Epoch 260/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5653 - accuracy: 0.7052 - val_loss: 2.3156 - val_accuracy: 0.5754\n",
      "Epoch 261/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5569 - accuracy: 0.7064 - val_loss: 2.3075 - val_accuracy: 0.5754\n",
      "Epoch 262/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5449 - accuracy: 0.7100 - val_loss: 2.3246 - val_accuracy: 0.5738\n",
      "Epoch 263/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5454 - accuracy: 0.7113 - val_loss: 2.3040 - val_accuracy: 0.5753\n",
      "Epoch 264/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5442 - accuracy: 0.7084 - val_loss: 2.3330 - val_accuracy: 0.5715\n",
      "Epoch 265/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5455 - accuracy: 0.7102 - val_loss: 2.3201 - val_accuracy: 0.5713\n",
      "Epoch 266/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5400 - accuracy: 0.7108 - val_loss: 2.3204 - val_accuracy: 0.5737\n",
      "Epoch 267/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5421 - accuracy: 0.7098 - val_loss: 2.2759 - val_accuracy: 0.5811\n",
      "Epoch 268/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5532 - accuracy: 0.7066 - val_loss: 2.2685 - val_accuracy: 0.5833\n",
      "Epoch 269/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5351 - accuracy: 0.7135 - val_loss: 2.3161 - val_accuracy: 0.5760\n",
      "Epoch 270/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5377 - accuracy: 0.7131 - val_loss: 2.3432 - val_accuracy: 0.5741\n",
      "Epoch 271/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5460 - accuracy: 0.7108 - val_loss: 2.3182 - val_accuracy: 0.5743\n",
      "Epoch 272/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5252 - accuracy: 0.7124 - val_loss: 2.2859 - val_accuracy: 0.5789\n",
      "Epoch 273/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5372 - accuracy: 0.7149 - val_loss: 2.2886 - val_accuracy: 0.5804\n",
      "Epoch 274/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5501 - accuracy: 0.7118 - val_loss: 2.3111 - val_accuracy: 0.5752\n",
      "Epoch 275/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5140 - accuracy: 0.7145 - val_loss: 2.3065 - val_accuracy: 0.5780\n",
      "Epoch 276/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5271 - accuracy: 0.7143 - val_loss: 2.2917 - val_accuracy: 0.5777\n",
      "Epoch 277/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5332 - accuracy: 0.7129 - val_loss: 2.3321 - val_accuracy: 0.5745\n",
      "Epoch 278/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5195 - accuracy: 0.7133 - val_loss: 2.3199 - val_accuracy: 0.5728\n",
      "Epoch 279/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5310 - accuracy: 0.7134 - val_loss: 2.3023 - val_accuracy: 0.5751\n",
      "Epoch 280/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5245 - accuracy: 0.7130 - val_loss: 2.3354 - val_accuracy: 0.5727\n",
      "Epoch 281/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.5284 - accuracy: 0.7086 - val_loss: 2.2955 - val_accuracy: 0.5798\n",
      "Epoch 282/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5174 - accuracy: 0.7164 - val_loss: 2.2829 - val_accuracy: 0.5822\n",
      "Epoch 283/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5254 - accuracy: 0.7165 - val_loss: 2.2993 - val_accuracy: 0.5756\n",
      "Epoch 284/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5172 - accuracy: 0.7164 - val_loss: 2.3021 - val_accuracy: 0.5792\n",
      "Epoch 285/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.5350 - accuracy: 0.7134 - val_loss: 2.2917 - val_accuracy: 0.5806\n",
      "Epoch 286/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5185 - accuracy: 0.7145 - val_loss: 2.2671 - val_accuracy: 0.5857\n",
      "Epoch 287/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5151 - accuracy: 0.7151 - val_loss: 2.2681 - val_accuracy: 0.5842\n",
      "Epoch 288/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5234 - accuracy: 0.7182 - val_loss: 2.2953 - val_accuracy: 0.5783\n",
      "Epoch 289/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5123 - accuracy: 0.7179 - val_loss: 2.2841 - val_accuracy: 0.5818\n",
      "Epoch 290/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5175 - accuracy: 0.7169 - val_loss: 2.3121 - val_accuracy: 0.5761\n",
      "Epoch 291/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5101 - accuracy: 0.7184 - val_loss: 2.3131 - val_accuracy: 0.5766\n",
      "Epoch 292/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5158 - accuracy: 0.7136 - val_loss: 2.2739 - val_accuracy: 0.5835\n",
      "Epoch 293/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5014 - accuracy: 0.7178 - val_loss: 2.2996 - val_accuracy: 0.5824\n",
      "Epoch 294/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5138 - accuracy: 0.7223 - val_loss: 2.2943 - val_accuracy: 0.5754\n",
      "Epoch 295/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5130 - accuracy: 0.7216 - val_loss: 2.2833 - val_accuracy: 0.5819\n",
      "Epoch 296/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5101 - accuracy: 0.7144 - val_loss: 2.2868 - val_accuracy: 0.5809\n",
      "Epoch 297/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5055 - accuracy: 0.7217 - val_loss: 2.2919 - val_accuracy: 0.5817\n",
      "Epoch 298/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4959 - accuracy: 0.7163 - val_loss: 2.3059 - val_accuracy: 0.5796\n",
      "Epoch 299/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5095 - accuracy: 0.7167 - val_loss: 2.2888 - val_accuracy: 0.5822\n",
      "Epoch 300/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4967 - accuracy: 0.7223 - val_loss: 2.3026 - val_accuracy: 0.5812\n",
      "Epoch 301/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5002 - accuracy: 0.7219 - val_loss: 2.3206 - val_accuracy: 0.5821\n",
      "Epoch 302/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5120 - accuracy: 0.7224 - val_loss: 2.2961 - val_accuracy: 0.5850\n",
      "Epoch 303/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4938 - accuracy: 0.7252 - val_loss: 2.2967 - val_accuracy: 0.5805\n",
      "Epoch 304/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 1.4806 - accuracy: 0.7243 - val_loss: 2.2940 - val_accuracy: 0.5820\n",
      "Epoch 305/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4756 - accuracy: 0.7279 - val_loss: 2.3230 - val_accuracy: 0.5779\n",
      "Epoch 306/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4922 - accuracy: 0.7212 - val_loss: 2.3255 - val_accuracy: 0.5799\n",
      "Epoch 307/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.5075 - accuracy: 0.7181 - val_loss: 2.3051 - val_accuracy: 0.5805\n",
      "Epoch 308/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4820 - accuracy: 0.7213 - val_loss: 2.3550 - val_accuracy: 0.5778\n",
      "Epoch 309/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.5025 - accuracy: 0.7216 - val_loss: 2.3072 - val_accuracy: 0.5800\n",
      "Epoch 310/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4801 - accuracy: 0.7233 - val_loss: 2.2925 - val_accuracy: 0.5824\n",
      "Epoch 311/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4667 - accuracy: 0.7289 - val_loss: 2.3101 - val_accuracy: 0.5763\n",
      "Epoch 312/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4807 - accuracy: 0.7237 - val_loss: 2.3040 - val_accuracy: 0.5795\n",
      "Epoch 313/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4823 - accuracy: 0.7285 - val_loss: 2.3043 - val_accuracy: 0.5838\n",
      "Epoch 314/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4839 - accuracy: 0.7208 - val_loss: 2.2919 - val_accuracy: 0.5812\n",
      "Epoch 315/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4764 - accuracy: 0.7243 - val_loss: 2.3179 - val_accuracy: 0.5774\n",
      "Epoch 316/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4752 - accuracy: 0.7282 - val_loss: 2.2787 - val_accuracy: 0.5841\n",
      "Epoch 317/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4705 - accuracy: 0.7248 - val_loss: 2.3120 - val_accuracy: 0.5816\n",
      "Epoch 318/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4807 - accuracy: 0.7272 - val_loss: 2.3104 - val_accuracy: 0.5782\n",
      "Epoch 319/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4591 - accuracy: 0.7290 - val_loss: 2.2832 - val_accuracy: 0.5836\n",
      "Epoch 320/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4775 - accuracy: 0.7261 - val_loss: 2.3074 - val_accuracy: 0.5834\n",
      "Epoch 321/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4673 - accuracy: 0.7285 - val_loss: 2.2744 - val_accuracy: 0.5820\n",
      "Epoch 322/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4739 - accuracy: 0.7248 - val_loss: 2.2658 - val_accuracy: 0.5872\n",
      "Epoch 323/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4738 - accuracy: 0.7257 - val_loss: 2.3028 - val_accuracy: 0.5817\n",
      "Epoch 324/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4715 - accuracy: 0.7297 - val_loss: 2.3112 - val_accuracy: 0.5809\n",
      "Epoch 325/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4637 - accuracy: 0.7291 - val_loss: 2.3104 - val_accuracy: 0.5825\n",
      "Epoch 326/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4611 - accuracy: 0.7271 - val_loss: 2.3266 - val_accuracy: 0.5796\n",
      "Epoch 327/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4636 - accuracy: 0.7263 - val_loss: 2.3198 - val_accuracy: 0.5795\n",
      "Epoch 328/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4646 - accuracy: 0.7263 - val_loss: 2.3044 - val_accuracy: 0.5825\n",
      "Epoch 329/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4536 - accuracy: 0.7270 - val_loss: 2.2854 - val_accuracy: 0.5887\n",
      "Epoch 330/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4457 - accuracy: 0.7331 - val_loss: 2.3034 - val_accuracy: 0.5843\n",
      "Epoch 331/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4688 - accuracy: 0.7318 - val_loss: 2.2762 - val_accuracy: 0.5885\n",
      "Epoch 332/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4568 - accuracy: 0.7293 - val_loss: 2.3184 - val_accuracy: 0.5845\n",
      "Epoch 333/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4637 - accuracy: 0.7304 - val_loss: 2.2878 - val_accuracy: 0.5901\n",
      "Epoch 334/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4553 - accuracy: 0.7273 - val_loss: 2.2879 - val_accuracy: 0.5883\n",
      "Epoch 335/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4535 - accuracy: 0.7286 - val_loss: 2.2750 - val_accuracy: 0.5854\n",
      "Epoch 336/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4499 - accuracy: 0.7298 - val_loss: 2.2628 - val_accuracy: 0.5944\n",
      "Epoch 337/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4506 - accuracy: 0.7303 - val_loss: 2.3038 - val_accuracy: 0.5843\n",
      "Epoch 338/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4480 - accuracy: 0.7304 - val_loss: 2.2718 - val_accuracy: 0.5892\n",
      "Epoch 339/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4576 - accuracy: 0.7305 - val_loss: 2.3177 - val_accuracy: 0.5853\n",
      "Epoch 340/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4466 - accuracy: 0.7329 - val_loss: 2.3556 - val_accuracy: 0.5775\n",
      "Epoch 341/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4478 - accuracy: 0.7325 - val_loss: 2.3001 - val_accuracy: 0.5850\n",
      "Epoch 342/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4334 - accuracy: 0.7369 - val_loss: 2.2997 - val_accuracy: 0.5890\n",
      "Epoch 343/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4341 - accuracy: 0.7342 - val_loss: 2.3214 - val_accuracy: 0.5831\n",
      "Epoch 344/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4343 - accuracy: 0.7353 - val_loss: 2.3294 - val_accuracy: 0.5815\n",
      "Epoch 345/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4441 - accuracy: 0.7321 - val_loss: 2.3607 - val_accuracy: 0.5770\n",
      "Epoch 346/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4439 - accuracy: 0.7319 - val_loss: 2.2657 - val_accuracy: 0.5892\n",
      "Epoch 347/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4298 - accuracy: 0.7374 - val_loss: 2.3204 - val_accuracy: 0.5830\n",
      "Epoch 348/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4407 - accuracy: 0.7325 - val_loss: 2.2937 - val_accuracy: 0.5866\n",
      "Epoch 349/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4343 - accuracy: 0.7320 - val_loss: 2.3202 - val_accuracy: 0.5828\n",
      "Epoch 350/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4392 - accuracy: 0.7374 - val_loss: 2.2959 - val_accuracy: 0.5859\n",
      "Epoch 351/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4409 - accuracy: 0.7310 - val_loss: 2.3135 - val_accuracy: 0.5836\n",
      "Epoch 352/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4408 - accuracy: 0.7364 - val_loss: 2.3426 - val_accuracy: 0.5875\n",
      "Epoch 353/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4476 - accuracy: 0.7330 - val_loss: 2.2983 - val_accuracy: 0.5890\n",
      "Epoch 354/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4292 - accuracy: 0.7374 - val_loss: 2.2858 - val_accuracy: 0.5908\n",
      "Epoch 355/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4245 - accuracy: 0.7380 - val_loss: 2.2891 - val_accuracy: 0.5888\n",
      "Epoch 356/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4329 - accuracy: 0.7375 - val_loss: 2.3086 - val_accuracy: 0.5874\n",
      "Epoch 357/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4304 - accuracy: 0.7332 - val_loss: 2.3024 - val_accuracy: 0.5874\n",
      "Epoch 358/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4282 - accuracy: 0.7355 - val_loss: 2.2867 - val_accuracy: 0.5878\n",
      "Epoch 359/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4295 - accuracy: 0.7347 - val_loss: 2.3131 - val_accuracy: 0.5877\n",
      "Epoch 360/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4208 - accuracy: 0.7410 - val_loss: 2.3225 - val_accuracy: 0.5890\n",
      "Epoch 361/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4342 - accuracy: 0.7321 - val_loss: 2.2986 - val_accuracy: 0.5887\n",
      "Epoch 362/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4313 - accuracy: 0.7378 - val_loss: 2.2924 - val_accuracy: 0.5913\n",
      "Epoch 363/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4238 - accuracy: 0.7350 - val_loss: 2.2871 - val_accuracy: 0.5908\n",
      "Epoch 364/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4298 - accuracy: 0.7344 - val_loss: 2.2946 - val_accuracy: 0.5927\n",
      "Epoch 365/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4204 - accuracy: 0.7371 - val_loss: 2.2797 - val_accuracy: 0.5911\n",
      "Epoch 366/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4179 - accuracy: 0.7382 - val_loss: 2.2800 - val_accuracy: 0.5928\n",
      "Epoch 367/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4280 - accuracy: 0.7352 - val_loss: 2.2884 - val_accuracy: 0.5906\n",
      "Epoch 368/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4248 - accuracy: 0.7365 - val_loss: 2.2798 - val_accuracy: 0.5925\n",
      "Epoch 369/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4141 - accuracy: 0.7398 - val_loss: 2.2733 - val_accuracy: 0.5933\n",
      "Epoch 370/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4189 - accuracy: 0.7382 - val_loss: 2.2693 - val_accuracy: 0.5936\n",
      "Epoch 371/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4143 - accuracy: 0.7396 - val_loss: 2.3287 - val_accuracy: 0.5824\n",
      "Epoch 372/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4158 - accuracy: 0.7361 - val_loss: 2.2649 - val_accuracy: 0.5930\n",
      "Epoch 373/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4001 - accuracy: 0.7459 - val_loss: 2.2864 - val_accuracy: 0.5894\n",
      "Epoch 374/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4185 - accuracy: 0.7379 - val_loss: 2.3017 - val_accuracy: 0.5831\n",
      "Epoch 375/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4025 - accuracy: 0.7404 - val_loss: 2.2863 - val_accuracy: 0.5935\n",
      "Epoch 376/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4109 - accuracy: 0.7442 - val_loss: 2.2543 - val_accuracy: 0.5923\n",
      "Epoch 377/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4155 - accuracy: 0.7361 - val_loss: 2.3006 - val_accuracy: 0.5903\n",
      "Epoch 378/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4143 - accuracy: 0.7417 - val_loss: 2.3100 - val_accuracy: 0.5888\n",
      "Epoch 379/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4062 - accuracy: 0.7417 - val_loss: 2.3141 - val_accuracy: 0.5892\n",
      "Epoch 380/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4038 - accuracy: 0.7439 - val_loss: 2.3059 - val_accuracy: 0.5889\n",
      "Epoch 381/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4079 - accuracy: 0.7410 - val_loss: 2.3005 - val_accuracy: 0.5913\n",
      "Epoch 382/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4161 - accuracy: 0.7419 - val_loss: 2.2830 - val_accuracy: 0.5919\n",
      "Epoch 383/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4105 - accuracy: 0.7442 - val_loss: 2.2999 - val_accuracy: 0.5877\n",
      "Epoch 384/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4103 - accuracy: 0.7407 - val_loss: 2.2485 - val_accuracy: 0.5957\n",
      "Epoch 385/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3926 - accuracy: 0.7475 - val_loss: 2.2883 - val_accuracy: 0.5907\n",
      "Epoch 386/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4056 - accuracy: 0.7422 - val_loss: 2.2791 - val_accuracy: 0.5950\n",
      "Epoch 387/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3935 - accuracy: 0.7444 - val_loss: 2.2579 - val_accuracy: 0.5969\n",
      "Epoch 388/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3977 - accuracy: 0.7460 - val_loss: 2.2614 - val_accuracy: 0.5929\n",
      "Epoch 389/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4017 - accuracy: 0.7458 - val_loss: 2.3013 - val_accuracy: 0.5910\n",
      "Epoch 390/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3977 - accuracy: 0.7435 - val_loss: 2.2684 - val_accuracy: 0.5929\n",
      "Epoch 391/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3873 - accuracy: 0.7463 - val_loss: 2.2626 - val_accuracy: 0.5947\n",
      "Epoch 392/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4063 - accuracy: 0.7436 - val_loss: 2.2756 - val_accuracy: 0.5976\n",
      "Epoch 393/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4109 - accuracy: 0.7461 - val_loss: 2.2994 - val_accuracy: 0.5933\n",
      "Epoch 394/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.3956 - accuracy: 0.7434 - val_loss: 2.2727 - val_accuracy: 0.5957\n",
      "Epoch 395/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3746 - accuracy: 0.7479 - val_loss: 2.2563 - val_accuracy: 0.5965\n",
      "Epoch 396/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3797 - accuracy: 0.7493 - val_loss: 2.2503 - val_accuracy: 0.5972\n",
      "Epoch 397/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3899 - accuracy: 0.7445 - val_loss: 2.2595 - val_accuracy: 0.5955\n",
      "Epoch 398/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3811 - accuracy: 0.7471 - val_loss: 2.3075 - val_accuracy: 0.5876\n",
      "Epoch 399/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3887 - accuracy: 0.7451 - val_loss: 2.2696 - val_accuracy: 0.5932\n",
      "Epoch 400/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3875 - accuracy: 0.7482 - val_loss: 2.2870 - val_accuracy: 0.5975\n",
      "Epoch 401/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3977 - accuracy: 0.7506 - val_loss: 2.2767 - val_accuracy: 0.5970\n",
      "Epoch 402/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3966 - accuracy: 0.7447 - val_loss: 2.2822 - val_accuracy: 0.5912\n",
      "Epoch 403/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3710 - accuracy: 0.7490 - val_loss: 2.2585 - val_accuracy: 0.5956\n",
      "Epoch 404/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3896 - accuracy: 0.7481 - val_loss: 2.2780 - val_accuracy: 0.5943\n",
      "Epoch 405/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3886 - accuracy: 0.7480 - val_loss: 2.2791 - val_accuracy: 0.5899\n",
      "Epoch 406/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3800 - accuracy: 0.7495 - val_loss: 2.2629 - val_accuracy: 0.5981\n",
      "Epoch 407/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3792 - accuracy: 0.7519 - val_loss: 2.2773 - val_accuracy: 0.5949\n",
      "Epoch 408/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3815 - accuracy: 0.7464 - val_loss: 2.3171 - val_accuracy: 0.5950\n",
      "Epoch 409/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4115 - accuracy: 0.7470 - val_loss: 2.2713 - val_accuracy: 0.5950\n",
      "Epoch 410/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3830 - accuracy: 0.7488 - val_loss: 2.2656 - val_accuracy: 0.5958\n",
      "Epoch 411/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3769 - accuracy: 0.7508 - val_loss: 2.2443 - val_accuracy: 0.5981\n",
      "Epoch 412/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3725 - accuracy: 0.7500 - val_loss: 2.3259 - val_accuracy: 0.5926\n",
      "Epoch 413/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.4036 - accuracy: 0.7494 - val_loss: 2.2814 - val_accuracy: 0.5919\n",
      "Epoch 414/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.3699 - accuracy: 0.7483 - val_loss: 2.2831 - val_accuracy: 0.5924\n",
      "Epoch 415/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3635 - accuracy: 0.7526 - val_loss: 2.2571 - val_accuracy: 0.5965\n",
      "Epoch 416/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3682 - accuracy: 0.7474 - val_loss: 2.2507 - val_accuracy: 0.5967\n",
      "Epoch 417/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3692 - accuracy: 0.7530 - val_loss: 2.2821 - val_accuracy: 0.5914\n",
      "Epoch 418/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3718 - accuracy: 0.7522 - val_loss: 2.2956 - val_accuracy: 0.5888\n",
      "Epoch 419/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3649 - accuracy: 0.7517 - val_loss: 2.3045 - val_accuracy: 0.5884\n",
      "Epoch 420/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3672 - accuracy: 0.7505 - val_loss: 2.2400 - val_accuracy: 0.6017\n",
      "Epoch 421/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3673 - accuracy: 0.7512 - val_loss: 2.2358 - val_accuracy: 0.6028\n",
      "Epoch 422/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3830 - accuracy: 0.7509 - val_loss: 2.2853 - val_accuracy: 0.5972\n",
      "Epoch 423/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3639 - accuracy: 0.7539 - val_loss: 2.2697 - val_accuracy: 0.6011\n",
      "Epoch 424/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3765 - accuracy: 0.7497 - val_loss: 2.3045 - val_accuracy: 0.5912\n",
      "Epoch 425/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.4018 - accuracy: 0.7485 - val_loss: 2.2849 - val_accuracy: 0.5973\n",
      "Epoch 426/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3685 - accuracy: 0.7569 - val_loss: 2.2763 - val_accuracy: 0.5963\n",
      "Epoch 427/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.3538 - accuracy: 0.7535 - val_loss: 2.2684 - val_accuracy: 0.5920\n",
      "Epoch 428/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.3749 - accuracy: 0.7492 - val_loss: 2.2962 - val_accuracy: 0.5911\n",
      "Epoch 429/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3632 - accuracy: 0.7532 - val_loss: 2.3120 - val_accuracy: 0.5886\n",
      "Epoch 430/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3584 - accuracy: 0.7529 - val_loss: 2.2628 - val_accuracy: 0.5997\n",
      "Epoch 431/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3516 - accuracy: 0.7551 - val_loss: 2.2847 - val_accuracy: 0.5920\n",
      "Epoch 432/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3515 - accuracy: 0.7541 - val_loss: 2.2872 - val_accuracy: 0.5937\n",
      "Epoch 433/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3525 - accuracy: 0.7552 - val_loss: 2.3091 - val_accuracy: 0.5921\n",
      "Epoch 434/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3576 - accuracy: 0.7555 - val_loss: 2.2821 - val_accuracy: 0.5954\n",
      "Epoch 435/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3532 - accuracy: 0.7575 - val_loss: 2.2692 - val_accuracy: 0.5981\n",
      "Epoch 436/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3647 - accuracy: 0.7507 - val_loss: 2.2726 - val_accuracy: 0.5971\n",
      "Epoch 437/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3473 - accuracy: 0.7545 - val_loss: 2.2310 - val_accuracy: 0.6042\n",
      "Epoch 438/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3481 - accuracy: 0.7589 - val_loss: 2.3005 - val_accuracy: 0.5942\n",
      "Epoch 439/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3431 - accuracy: 0.7578 - val_loss: 2.3083 - val_accuracy: 0.5945\n",
      "Epoch 440/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3458 - accuracy: 0.7549 - val_loss: 2.2895 - val_accuracy: 0.5958\n",
      "Epoch 441/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3511 - accuracy: 0.7543 - val_loss: 2.2790 - val_accuracy: 0.5996\n",
      "Epoch 442/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3479 - accuracy: 0.7544 - val_loss: 2.2477 - val_accuracy: 0.6016\n",
      "Epoch 443/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3471 - accuracy: 0.7550 - val_loss: 2.3218 - val_accuracy: 0.5924\n",
      "Epoch 444/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3526 - accuracy: 0.7551 - val_loss: 2.3071 - val_accuracy: 0.5947\n",
      "Epoch 445/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3462 - accuracy: 0.7545 - val_loss: 2.2855 - val_accuracy: 0.5940\n",
      "Epoch 446/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3288 - accuracy: 0.7582 - val_loss: 2.3016 - val_accuracy: 0.5960\n",
      "Epoch 447/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3407 - accuracy: 0.7597 - val_loss: 2.3321 - val_accuracy: 0.5902\n",
      "Epoch 448/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3481 - accuracy: 0.7608 - val_loss: 2.2803 - val_accuracy: 0.5970\n",
      "Epoch 449/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3378 - accuracy: 0.7603 - val_loss: 2.3110 - val_accuracy: 0.5906\n",
      "Epoch 450/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3439 - accuracy: 0.7558 - val_loss: 2.2917 - val_accuracy: 0.5955\n",
      "Epoch 451/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3479 - accuracy: 0.7565 - val_loss: 2.2857 - val_accuracy: 0.5955\n",
      "Epoch 452/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3502 - accuracy: 0.7529 - val_loss: 2.3153 - val_accuracy: 0.5938\n",
      "Epoch 453/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3488 - accuracy: 0.7571 - val_loss: 2.3021 - val_accuracy: 0.5988\n",
      "Epoch 454/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3670 - accuracy: 0.7559 - val_loss: 2.2822 - val_accuracy: 0.6014\n",
      "Epoch 455/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3345 - accuracy: 0.7598 - val_loss: 2.2580 - val_accuracy: 0.6030\n",
      "Epoch 456/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3471 - accuracy: 0.7573 - val_loss: 2.3002 - val_accuracy: 0.5959\n",
      "Epoch 457/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3430 - accuracy: 0.7596 - val_loss: 2.2833 - val_accuracy: 0.6006\n",
      "Epoch 458/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3300 - accuracy: 0.7605 - val_loss: 2.2898 - val_accuracy: 0.5951\n",
      "Epoch 459/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3403 - accuracy: 0.7582 - val_loss: 2.2662 - val_accuracy: 0.5960\n",
      "Epoch 460/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3342 - accuracy: 0.7627 - val_loss: 2.2885 - val_accuracy: 0.5969\n",
      "Epoch 461/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3337 - accuracy: 0.7630 - val_loss: 2.3387 - val_accuracy: 0.5924\n",
      "Epoch 462/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3480 - accuracy: 0.7605 - val_loss: 2.3193 - val_accuracy: 0.5921\n",
      "Epoch 463/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3309 - accuracy: 0.7643 - val_loss: 2.2841 - val_accuracy: 0.5937\n",
      "Epoch 464/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3305 - accuracy: 0.7584 - val_loss: 2.2829 - val_accuracy: 0.5930\n",
      "Epoch 465/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3159 - accuracy: 0.7632 - val_loss: 2.2897 - val_accuracy: 0.5959\n",
      "Epoch 466/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3195 - accuracy: 0.7642 - val_loss: 2.2998 - val_accuracy: 0.5903\n",
      "Epoch 467/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3257 - accuracy: 0.7614 - val_loss: 2.3295 - val_accuracy: 0.5895\n",
      "Epoch 468/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3251 - accuracy: 0.7641 - val_loss: 2.2950 - val_accuracy: 0.5935\n",
      "Epoch 469/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3226 - accuracy: 0.7613 - val_loss: 2.2700 - val_accuracy: 0.5955\n",
      "Epoch 470/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3306 - accuracy: 0.7594 - val_loss: 2.2340 - val_accuracy: 0.6042\n",
      "Epoch 471/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3325 - accuracy: 0.7599 - val_loss: 2.2421 - val_accuracy: 0.6023\n",
      "Epoch 472/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3196 - accuracy: 0.7644 - val_loss: 2.2671 - val_accuracy: 0.5984\n",
      "Epoch 473/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3198 - accuracy: 0.7652 - val_loss: 2.3219 - val_accuracy: 0.5916\n",
      "Epoch 474/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3209 - accuracy: 0.7657 - val_loss: 2.3227 - val_accuracy: 0.5952\n",
      "Epoch 475/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3465 - accuracy: 0.7636 - val_loss: 2.3022 - val_accuracy: 0.5932\n",
      "Epoch 476/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.3378 - accuracy: 0.7594 - val_loss: 2.3077 - val_accuracy: 0.5970\n",
      "Epoch 477/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3315 - accuracy: 0.7634 - val_loss: 2.3015 - val_accuracy: 0.5988\n",
      "Epoch 478/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3325 - accuracy: 0.7586 - val_loss: 2.2851 - val_accuracy: 0.5975\n",
      "Epoch 479/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3214 - accuracy: 0.7644 - val_loss: 2.2716 - val_accuracy: 0.6011\n",
      "Epoch 480/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3209 - accuracy: 0.7614 - val_loss: 2.2797 - val_accuracy: 0.6022\n",
      "Epoch 481/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3171 - accuracy: 0.7646 - val_loss: 2.3438 - val_accuracy: 0.5883\n",
      "Epoch 482/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3121 - accuracy: 0.7682 - val_loss: 2.2540 - val_accuracy: 0.6034\n",
      "Epoch 483/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3119 - accuracy: 0.7672 - val_loss: 2.2489 - val_accuracy: 0.6048\n",
      "Epoch 484/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3095 - accuracy: 0.7684 - val_loss: 2.2601 - val_accuracy: 0.6071\n",
      "Epoch 485/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3056 - accuracy: 0.7661 - val_loss: 2.3018 - val_accuracy: 0.5975\n",
      "Epoch 486/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3091 - accuracy: 0.7619 - val_loss: 2.2754 - val_accuracy: 0.6019\n",
      "Epoch 487/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3218 - accuracy: 0.7641 - val_loss: 2.2447 - val_accuracy: 0.6042\n",
      "Epoch 488/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3141 - accuracy: 0.7653 - val_loss: 2.2547 - val_accuracy: 0.6064\n",
      "Epoch 489/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3084 - accuracy: 0.7647 - val_loss: 2.2853 - val_accuracy: 0.6088\n",
      "Epoch 490/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3445 - accuracy: 0.7668 - val_loss: 2.2736 - val_accuracy: 0.6044\n",
      "Epoch 491/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.3261 - accuracy: 0.7642 - val_loss: 2.2854 - val_accuracy: 0.5999\n",
      "Epoch 492/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2965 - accuracy: 0.7713 - val_loss: 2.2674 - val_accuracy: 0.6027\n",
      "Epoch 493/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3047 - accuracy: 0.7685 - val_loss: 2.2450 - val_accuracy: 0.6045\n",
      "Epoch 494/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3072 - accuracy: 0.7661 - val_loss: 2.2983 - val_accuracy: 0.5979\n",
      "Epoch 495/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3141 - accuracy: 0.7660 - val_loss: 2.2527 - val_accuracy: 0.6032\n",
      "Epoch 496/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3133 - accuracy: 0.7631 - val_loss: 2.2540 - val_accuracy: 0.6057\n",
      "Epoch 497/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3203 - accuracy: 0.7654 - val_loss: 2.2995 - val_accuracy: 0.5994\n",
      "Epoch 498/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2974 - accuracy: 0.7723 - val_loss: 2.3103 - val_accuracy: 0.5957\n",
      "Epoch 499/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3125 - accuracy: 0.7652 - val_loss: 2.2826 - val_accuracy: 0.6009\n",
      "Epoch 500/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3183 - accuracy: 0.7656 - val_loss: 2.2916 - val_accuracy: 0.6000\n",
      "Epoch 501/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3106 - accuracy: 0.7686 - val_loss: 2.2781 - val_accuracy: 0.5993\n",
      "Epoch 502/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3183 - accuracy: 0.7719 - val_loss: 2.3014 - val_accuracy: 0.5999\n",
      "Epoch 503/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2995 - accuracy: 0.7674 - val_loss: 2.2925 - val_accuracy: 0.6002\n",
      "Epoch 504/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3112 - accuracy: 0.7654 - val_loss: 2.2841 - val_accuracy: 0.5996\n",
      "Epoch 505/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3153 - accuracy: 0.7653 - val_loss: 2.2706 - val_accuracy: 0.6062\n",
      "Epoch 506/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3029 - accuracy: 0.7684 - val_loss: 2.2943 - val_accuracy: 0.6011\n",
      "Epoch 507/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2933 - accuracy: 0.7707 - val_loss: 2.3036 - val_accuracy: 0.6015\n",
      "Epoch 508/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3019 - accuracy: 0.7680 - val_loss: 2.3281 - val_accuracy: 0.5969\n",
      "Epoch 509/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2934 - accuracy: 0.7702 - val_loss: 2.3532 - val_accuracy: 0.5924\n",
      "Epoch 510/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2894 - accuracy: 0.7712 - val_loss: 2.2846 - val_accuracy: 0.6031\n",
      "Epoch 511/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2979 - accuracy: 0.7665 - val_loss: 2.3242 - val_accuracy: 0.5974\n",
      "Epoch 512/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2902 - accuracy: 0.7709 - val_loss: 2.3080 - val_accuracy: 0.6006\n",
      "Epoch 513/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2911 - accuracy: 0.7709 - val_loss: 2.2964 - val_accuracy: 0.6027\n",
      "Epoch 514/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2944 - accuracy: 0.7715 - val_loss: 2.2846 - val_accuracy: 0.6049\n",
      "Epoch 515/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.3042 - accuracy: 0.7656 - val_loss: 2.2702 - val_accuracy: 0.6065\n",
      "Epoch 516/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3101 - accuracy: 0.7667 - val_loss: 2.2907 - val_accuracy: 0.6020\n",
      "Epoch 517/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2969 - accuracy: 0.7721 - val_loss: 2.3266 - val_accuracy: 0.5995\n",
      "Epoch 518/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2846 - accuracy: 0.7751 - val_loss: 2.2909 - val_accuracy: 0.5982\n",
      "Epoch 519/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2820 - accuracy: 0.7762 - val_loss: 2.2899 - val_accuracy: 0.5997\n",
      "Epoch 520/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2918 - accuracy: 0.7693 - val_loss: 2.3237 - val_accuracy: 0.5971\n",
      "Epoch 521/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2931 - accuracy: 0.7677 - val_loss: 2.2946 - val_accuracy: 0.6059\n",
      "Epoch 522/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2866 - accuracy: 0.7714 - val_loss: 2.2760 - val_accuracy: 0.6020\n",
      "Epoch 523/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2963 - accuracy: 0.7645 - val_loss: 2.2848 - val_accuracy: 0.6016\n",
      "Epoch 524/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2924 - accuracy: 0.7706 - val_loss: 2.2551 - val_accuracy: 0.6040\n",
      "Epoch 525/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2858 - accuracy: 0.7716 - val_loss: 2.2718 - val_accuracy: 0.6062\n",
      "Epoch 526/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2881 - accuracy: 0.7726 - val_loss: 2.2621 - val_accuracy: 0.6115\n",
      "Epoch 527/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2957 - accuracy: 0.7718 - val_loss: 2.2705 - val_accuracy: 0.6051\n",
      "Epoch 528/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2815 - accuracy: 0.7748 - val_loss: 2.3044 - val_accuracy: 0.5990\n",
      "Epoch 529/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2869 - accuracy: 0.7707 - val_loss: 2.3410 - val_accuracy: 0.5966\n",
      "Epoch 530/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.3262 - accuracy: 0.7718 - val_loss: 2.3101 - val_accuracy: 0.6031\n",
      "Epoch 531/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2996 - accuracy: 0.7750 - val_loss: 2.2875 - val_accuracy: 0.6022\n",
      "Epoch 532/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2909 - accuracy: 0.7693 - val_loss: 2.2769 - val_accuracy: 0.6032\n",
      "Epoch 533/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2871 - accuracy: 0.7711 - val_loss: 2.2669 - val_accuracy: 0.6059\n",
      "Epoch 534/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2806 - accuracy: 0.7760 - val_loss: 2.3108 - val_accuracy: 0.6034\n",
      "Epoch 535/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2791 - accuracy: 0.7753 - val_loss: 2.3015 - val_accuracy: 0.6034\n",
      "Epoch 536/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2759 - accuracy: 0.7760 - val_loss: 2.3311 - val_accuracy: 0.5953\n",
      "Epoch 537/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2907 - accuracy: 0.7697 - val_loss: 2.3381 - val_accuracy: 0.6018\n",
      "Epoch 538/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.3048 - accuracy: 0.7722 - val_loss: 2.3160 - val_accuracy: 0.6039\n",
      "Epoch 539/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2808 - accuracy: 0.7751 - val_loss: 2.2911 - val_accuracy: 0.6030\n",
      "Epoch 540/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.2776 - accuracy: 0.7786 - val_loss: 2.2863 - val_accuracy: 0.6035\n",
      "Epoch 541/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2723 - accuracy: 0.7726 - val_loss: 2.2794 - val_accuracy: 0.6054\n",
      "Epoch 542/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2777 - accuracy: 0.7742 - val_loss: 2.3083 - val_accuracy: 0.5997\n",
      "Epoch 543/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2642 - accuracy: 0.7749 - val_loss: 2.2495 - val_accuracy: 0.6088\n",
      "Epoch 544/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2796 - accuracy: 0.7720 - val_loss: 2.2643 - val_accuracy: 0.6049\n",
      "Epoch 545/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2749 - accuracy: 0.7742 - val_loss: 2.2838 - val_accuracy: 0.6057\n",
      "Epoch 546/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2814 - accuracy: 0.7770 - val_loss: 2.2770 - val_accuracy: 0.6044\n",
      "Epoch 547/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2765 - accuracy: 0.7783 - val_loss: 2.2814 - val_accuracy: 0.6062\n",
      "Epoch 548/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2744 - accuracy: 0.7748 - val_loss: 2.2894 - val_accuracy: 0.6044\n",
      "Epoch 549/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2676 - accuracy: 0.7781 - val_loss: 2.2746 - val_accuracy: 0.6061\n",
      "Epoch 550/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2816 - accuracy: 0.7727 - val_loss: 2.2651 - val_accuracy: 0.6087\n",
      "Epoch 551/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2960 - accuracy: 0.7776 - val_loss: 2.2961 - val_accuracy: 0.6040\n",
      "Epoch 552/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2673 - accuracy: 0.7776 - val_loss: 2.2752 - val_accuracy: 0.6043\n",
      "Epoch 553/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2641 - accuracy: 0.7797 - val_loss: 2.2496 - val_accuracy: 0.6111\n",
      "Epoch 554/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2631 - accuracy: 0.7782 - val_loss: 2.2584 - val_accuracy: 0.6092\n",
      "Epoch 555/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2694 - accuracy: 0.7748 - val_loss: 2.3195 - val_accuracy: 0.6003\n",
      "Epoch 556/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2672 - accuracy: 0.7804 - val_loss: 2.3141 - val_accuracy: 0.6029\n",
      "Epoch 557/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2720 - accuracy: 0.7758 - val_loss: 2.3077 - val_accuracy: 0.6045\n",
      "Epoch 558/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2741 - accuracy: 0.7799 - val_loss: 2.3221 - val_accuracy: 0.5986\n",
      "Epoch 559/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2854 - accuracy: 0.7719 - val_loss: 2.2944 - val_accuracy: 0.6039\n",
      "Epoch 560/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2612 - accuracy: 0.7764 - val_loss: 2.3092 - val_accuracy: 0.5992\n",
      "Epoch 561/2500\n",
      "196/196 [==============================] - 17s 83ms/step - loss: 1.2709 - accuracy: 0.7789 - val_loss: 2.3380 - val_accuracy: 0.5971\n",
      "Epoch 562/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2508 - accuracy: 0.7816 - val_loss: 2.2863 - val_accuracy: 0.6053\n",
      "Epoch 563/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2633 - accuracy: 0.7777 - val_loss: 2.3294 - val_accuracy: 0.5973\n",
      "Epoch 564/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2715 - accuracy: 0.7781 - val_loss: 2.3034 - val_accuracy: 0.6013\n",
      "Epoch 565/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2656 - accuracy: 0.7766 - val_loss: 2.3149 - val_accuracy: 0.6012\n",
      "Epoch 566/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2835 - accuracy: 0.7768 - val_loss: 2.2765 - val_accuracy: 0.6079\n",
      "Epoch 567/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2739 - accuracy: 0.7748 - val_loss: 2.2705 - val_accuracy: 0.6078\n",
      "Epoch 568/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2598 - accuracy: 0.7777 - val_loss: 2.3093 - val_accuracy: 0.6066\n",
      "Epoch 569/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2901 - accuracy: 0.7761 - val_loss: 2.3305 - val_accuracy: 0.5974\n",
      "Epoch 570/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2594 - accuracy: 0.7784 - val_loss: 2.2939 - val_accuracy: 0.6049\n",
      "Epoch 571/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2649 - accuracy: 0.7755 - val_loss: 2.3053 - val_accuracy: 0.6022\n",
      "Epoch 572/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2780 - accuracy: 0.7734 - val_loss: 2.3304 - val_accuracy: 0.6047\n",
      "Epoch 573/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2846 - accuracy: 0.7768 - val_loss: 2.2736 - val_accuracy: 0.6084\n",
      "Epoch 574/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2755 - accuracy: 0.7761 - val_loss: 2.2739 - val_accuracy: 0.6043\n",
      "Epoch 575/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.2606 - accuracy: 0.7790 - val_loss: 2.3093 - val_accuracy: 0.5997\n",
      "Epoch 576/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2619 - accuracy: 0.7798 - val_loss: 2.2977 - val_accuracy: 0.6046\n",
      "Epoch 577/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2695 - accuracy: 0.7777 - val_loss: 2.2898 - val_accuracy: 0.6046\n",
      "Epoch 578/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2539 - accuracy: 0.7790 - val_loss: 2.3259 - val_accuracy: 0.5971\n",
      "Epoch 579/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2523 - accuracy: 0.7808 - val_loss: 2.3102 - val_accuracy: 0.6025\n",
      "Epoch 580/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.2559 - accuracy: 0.7821 - val_loss: 2.3075 - val_accuracy: 0.6012\n",
      "Epoch 581/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2661 - accuracy: 0.7788 - val_loss: 2.2564 - val_accuracy: 0.6093\n",
      "Epoch 582/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2503 - accuracy: 0.7805 - val_loss: 2.2644 - val_accuracy: 0.6089\n",
      "Epoch 583/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2603 - accuracy: 0.7794 - val_loss: 2.2743 - val_accuracy: 0.6059\n",
      "Epoch 584/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2466 - accuracy: 0.7802 - val_loss: 2.2849 - val_accuracy: 0.6112\n",
      "Epoch 585/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2547 - accuracy: 0.7796 - val_loss: 2.3125 - val_accuracy: 0.6048\n",
      "Epoch 586/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2600 - accuracy: 0.7771 - val_loss: 2.2841 - val_accuracy: 0.6074\n",
      "Epoch 587/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2666 - accuracy: 0.7816 - val_loss: 2.3063 - val_accuracy: 0.6031\n",
      "Epoch 588/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2560 - accuracy: 0.7792 - val_loss: 2.2887 - val_accuracy: 0.6040\n",
      "Epoch 589/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2598 - accuracy: 0.7768 - val_loss: 2.2992 - val_accuracy: 0.6041\n",
      "Epoch 590/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2538 - accuracy: 0.7791 - val_loss: 2.3180 - val_accuracy: 0.6016\n",
      "Epoch 591/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2693 - accuracy: 0.7777 - val_loss: 2.2610 - val_accuracy: 0.6080\n",
      "Epoch 592/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2496 - accuracy: 0.7833 - val_loss: 2.2719 - val_accuracy: 0.6073\n",
      "Epoch 593/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2548 - accuracy: 0.7794 - val_loss: 2.2595 - val_accuracy: 0.6076\n",
      "Epoch 594/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2532 - accuracy: 0.7817 - val_loss: 2.2493 - val_accuracy: 0.6112\n",
      "Epoch 595/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2437 - accuracy: 0.7808 - val_loss: 2.2680 - val_accuracy: 0.6100\n",
      "Epoch 596/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2531 - accuracy: 0.7789 - val_loss: 2.2934 - val_accuracy: 0.6075\n",
      "Epoch 597/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2511 - accuracy: 0.7827 - val_loss: 2.3029 - val_accuracy: 0.6068\n",
      "Epoch 598/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2600 - accuracy: 0.7791 - val_loss: 2.2623 - val_accuracy: 0.6129\n",
      "Epoch 599/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.2437 - accuracy: 0.7848 - val_loss: 2.3035 - val_accuracy: 0.6062\n",
      "Epoch 600/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2410 - accuracy: 0.7855 - val_loss: 2.2970 - val_accuracy: 0.6106\n",
      "Epoch 601/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2485 - accuracy: 0.7821 - val_loss: 2.3089 - val_accuracy: 0.6067\n",
      "Epoch 602/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2370 - accuracy: 0.7866 - val_loss: 2.2913 - val_accuracy: 0.6114\n",
      "Epoch 603/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2451 - accuracy: 0.7875 - val_loss: 2.2845 - val_accuracy: 0.6085\n",
      "Epoch 604/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2442 - accuracy: 0.7830 - val_loss: 2.2759 - val_accuracy: 0.6110\n",
      "Epoch 605/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2377 - accuracy: 0.7850 - val_loss: 2.3416 - val_accuracy: 0.6002\n",
      "Epoch 606/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2583 - accuracy: 0.7843 - val_loss: 2.3313 - val_accuracy: 0.6075\n",
      "Epoch 607/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2535 - accuracy: 0.7817 - val_loss: 2.3370 - val_accuracy: 0.6060\n",
      "Epoch 608/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2565 - accuracy: 0.7798 - val_loss: 2.2995 - val_accuracy: 0.6053\n",
      "Epoch 609/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2420 - accuracy: 0.7841 - val_loss: 2.2759 - val_accuracy: 0.6086\n",
      "Epoch 610/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2391 - accuracy: 0.7836 - val_loss: 2.3310 - val_accuracy: 0.6084\n",
      "Epoch 611/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2358 - accuracy: 0.7836 - val_loss: 2.3198 - val_accuracy: 0.6034\n",
      "Epoch 612/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2436 - accuracy: 0.7811 - val_loss: 2.2929 - val_accuracy: 0.6043\n",
      "Epoch 613/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2624 - accuracy: 0.7800 - val_loss: 2.2685 - val_accuracy: 0.6108\n",
      "Epoch 614/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2484 - accuracy: 0.7833 - val_loss: 2.3434 - val_accuracy: 0.6034\n",
      "Epoch 615/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2444 - accuracy: 0.7839 - val_loss: 2.2694 - val_accuracy: 0.6104\n",
      "Epoch 616/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2355 - accuracy: 0.7878 - val_loss: 2.3137 - val_accuracy: 0.6046\n",
      "Epoch 617/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2291 - accuracy: 0.7876 - val_loss: 2.2808 - val_accuracy: 0.6063\n",
      "Epoch 618/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2280 - accuracy: 0.7871 - val_loss: 2.2920 - val_accuracy: 0.6064\n",
      "Epoch 619/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2345 - accuracy: 0.7868 - val_loss: 2.2666 - val_accuracy: 0.6109\n",
      "Epoch 620/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2351 - accuracy: 0.7853 - val_loss: 2.3064 - val_accuracy: 0.6050\n",
      "Epoch 621/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2291 - accuracy: 0.7879 - val_loss: 2.2966 - val_accuracy: 0.6087\n",
      "Epoch 622/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2382 - accuracy: 0.7847 - val_loss: 2.3141 - val_accuracy: 0.6057\n",
      "Epoch 623/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2470 - accuracy: 0.7823 - val_loss: 2.3782 - val_accuracy: 0.6041\n",
      "Epoch 624/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2511 - accuracy: 0.7860 - val_loss: 2.3141 - val_accuracy: 0.6077\n",
      "Epoch 625/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2316 - accuracy: 0.7868 - val_loss: 2.3341 - val_accuracy: 0.6051\n",
      "Epoch 626/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2214 - accuracy: 0.7878 - val_loss: 2.3319 - val_accuracy: 0.6026\n",
      "Epoch 627/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2255 - accuracy: 0.7873 - val_loss: 2.3108 - val_accuracy: 0.6096\n",
      "Epoch 628/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2359 - accuracy: 0.7878 - val_loss: 2.3262 - val_accuracy: 0.6053\n",
      "Epoch 629/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2265 - accuracy: 0.7854 - val_loss: 2.2931 - val_accuracy: 0.6096\n",
      "Epoch 630/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2355 - accuracy: 0.7827 - val_loss: 2.2800 - val_accuracy: 0.6100\n",
      "Epoch 631/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2500 - accuracy: 0.7799 - val_loss: 2.2686 - val_accuracy: 0.6114\n",
      "Epoch 632/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2354 - accuracy: 0.7885 - val_loss: 2.2936 - val_accuracy: 0.6104\n",
      "Epoch 633/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2431 - accuracy: 0.7848 - val_loss: 2.2919 - val_accuracy: 0.6085\n",
      "Epoch 634/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2505 - accuracy: 0.7809 - val_loss: 2.3109 - val_accuracy: 0.6077\n",
      "Epoch 635/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2477 - accuracy: 0.7847 - val_loss: 2.2522 - val_accuracy: 0.6165\n",
      "Epoch 636/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2221 - accuracy: 0.7908 - val_loss: 2.2681 - val_accuracy: 0.6137\n",
      "Epoch 637/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2369 - accuracy: 0.7846 - val_loss: 2.2560 - val_accuracy: 0.6142\n",
      "Epoch 638/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2278 - accuracy: 0.7857 - val_loss: 2.2761 - val_accuracy: 0.6160\n",
      "Epoch 639/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2302 - accuracy: 0.7877 - val_loss: 2.2752 - val_accuracy: 0.6111\n",
      "Epoch 640/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2219 - accuracy: 0.7892 - val_loss: 2.2747 - val_accuracy: 0.6128\n",
      "Epoch 641/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2233 - accuracy: 0.7898 - val_loss: 2.3092 - val_accuracy: 0.6090\n",
      "Epoch 642/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2223 - accuracy: 0.7876 - val_loss: 2.3145 - val_accuracy: 0.6050\n",
      "Epoch 643/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2246 - accuracy: 0.7874 - val_loss: 2.3186 - val_accuracy: 0.6023\n",
      "Epoch 644/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2135 - accuracy: 0.7907 - val_loss: 2.2574 - val_accuracy: 0.6139\n",
      "Epoch 645/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2310 - accuracy: 0.7890 - val_loss: 2.3022 - val_accuracy: 0.6090\n",
      "Epoch 646/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2134 - accuracy: 0.7917 - val_loss: 2.2375 - val_accuracy: 0.6171\n",
      "Epoch 647/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2137 - accuracy: 0.7882 - val_loss: 2.2699 - val_accuracy: 0.6134\n",
      "Epoch 648/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2349 - accuracy: 0.7884 - val_loss: 2.3200 - val_accuracy: 0.6065\n",
      "Epoch 649/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2302 - accuracy: 0.7873 - val_loss: 2.2695 - val_accuracy: 0.6098\n",
      "Epoch 650/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2368 - accuracy: 0.7868 - val_loss: 2.3097 - val_accuracy: 0.6052\n",
      "Epoch 651/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2208 - accuracy: 0.7877 - val_loss: 2.2978 - val_accuracy: 0.6079\n",
      "Epoch 652/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2168 - accuracy: 0.7894 - val_loss: 2.2988 - val_accuracy: 0.6057\n",
      "Epoch 653/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2213 - accuracy: 0.7898 - val_loss: 2.2825 - val_accuracy: 0.6138\n",
      "Epoch 654/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2303 - accuracy: 0.7888 - val_loss: 2.3268 - val_accuracy: 0.6076\n",
      "Epoch 655/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.2253 - accuracy: 0.7863 - val_loss: 2.3465 - val_accuracy: 0.6085\n",
      "Epoch 656/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2472 - accuracy: 0.7882 - val_loss: 2.2781 - val_accuracy: 0.6128\n",
      "Epoch 657/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2324 - accuracy: 0.7874 - val_loss: 2.2864 - val_accuracy: 0.6147\n",
      "Epoch 658/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2102 - accuracy: 0.7925 - val_loss: 2.3299 - val_accuracy: 0.6058\n",
      "Epoch 659/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2261 - accuracy: 0.7867 - val_loss: 2.3552 - val_accuracy: 0.6055\n",
      "Epoch 660/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2263 - accuracy: 0.7905 - val_loss: 2.2591 - val_accuracy: 0.6117\n",
      "Epoch 661/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2204 - accuracy: 0.7890 - val_loss: 2.3167 - val_accuracy: 0.6090\n",
      "Epoch 662/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2175 - accuracy: 0.7935 - val_loss: 2.3019 - val_accuracy: 0.6100\n",
      "Epoch 663/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2182 - accuracy: 0.7913 - val_loss: 2.3185 - val_accuracy: 0.6071\n",
      "Epoch 664/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2260 - accuracy: 0.7871 - val_loss: 2.2703 - val_accuracy: 0.6143\n",
      "Epoch 665/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2090 - accuracy: 0.7921 - val_loss: 2.2891 - val_accuracy: 0.6105\n",
      "Epoch 666/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2166 - accuracy: 0.7890 - val_loss: 2.3254 - val_accuracy: 0.6065\n",
      "Epoch 667/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2255 - accuracy: 0.7856 - val_loss: 2.3021 - val_accuracy: 0.6075\n",
      "Epoch 668/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2306 - accuracy: 0.7883 - val_loss: 2.3206 - val_accuracy: 0.6058\n",
      "Epoch 669/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2063 - accuracy: 0.7919 - val_loss: 2.2963 - val_accuracy: 0.6113\n",
      "Epoch 670/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2101 - accuracy: 0.7910 - val_loss: 2.2735 - val_accuracy: 0.6130\n",
      "Epoch 671/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2087 - accuracy: 0.7909 - val_loss: 2.3284 - val_accuracy: 0.6069\n",
      "Epoch 672/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2189 - accuracy: 0.7889 - val_loss: 2.3012 - val_accuracy: 0.6084\n",
      "Epoch 673/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2042 - accuracy: 0.7949 - val_loss: 2.3322 - val_accuracy: 0.6065\n",
      "Epoch 674/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2352 - accuracy: 0.7904 - val_loss: 2.3006 - val_accuracy: 0.6089\n",
      "Epoch 675/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2077 - accuracy: 0.7938 - val_loss: 2.3385 - val_accuracy: 0.6053\n",
      "Epoch 676/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2137 - accuracy: 0.7910 - val_loss: 2.2851 - val_accuracy: 0.6136\n",
      "Epoch 677/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2001 - accuracy: 0.7947 - val_loss: 2.2947 - val_accuracy: 0.6138\n",
      "Epoch 678/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2139 - accuracy: 0.7923 - val_loss: 2.3067 - val_accuracy: 0.6157\n",
      "Epoch 679/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2205 - accuracy: 0.7908 - val_loss: 2.2769 - val_accuracy: 0.6171\n",
      "Epoch 680/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2199 - accuracy: 0.7933 - val_loss: 2.3400 - val_accuracy: 0.6096\n",
      "Epoch 681/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2012 - accuracy: 0.7931 - val_loss: 2.3144 - val_accuracy: 0.6132\n",
      "Epoch 682/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2033 - accuracy: 0.7928 - val_loss: 2.3029 - val_accuracy: 0.6124\n",
      "Epoch 683/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2062 - accuracy: 0.7956 - val_loss: 2.2910 - val_accuracy: 0.6145\n",
      "Epoch 684/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2081 - accuracy: 0.7888 - val_loss: 2.3199 - val_accuracy: 0.6095\n",
      "Epoch 685/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2020 - accuracy: 0.7923 - val_loss: 2.2952 - val_accuracy: 0.6145\n",
      "Epoch 686/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2136 - accuracy: 0.7918 - val_loss: 2.3405 - val_accuracy: 0.6049\n",
      "Epoch 687/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1998 - accuracy: 0.7943 - val_loss: 2.3532 - val_accuracy: 0.6054\n",
      "Epoch 688/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2227 - accuracy: 0.7916 - val_loss: 2.3031 - val_accuracy: 0.6085\n",
      "Epoch 689/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2081 - accuracy: 0.7917 - val_loss: 2.3045 - val_accuracy: 0.6084\n",
      "Epoch 690/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1973 - accuracy: 0.7912 - val_loss: 2.3365 - val_accuracy: 0.6061\n",
      "Epoch 691/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2195 - accuracy: 0.7935 - val_loss: 2.2948 - val_accuracy: 0.6140\n",
      "Epoch 692/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1970 - accuracy: 0.7961 - val_loss: 2.3130 - val_accuracy: 0.6089\n",
      "Epoch 693/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2149 - accuracy: 0.7943 - val_loss: 2.2711 - val_accuracy: 0.6144\n",
      "Epoch 694/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2118 - accuracy: 0.7903 - val_loss: 2.3115 - val_accuracy: 0.6082\n",
      "Epoch 695/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2071 - accuracy: 0.7918 - val_loss: 2.2878 - val_accuracy: 0.6121\n",
      "Epoch 696/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2040 - accuracy: 0.7944 - val_loss: 2.2925 - val_accuracy: 0.6116\n",
      "Epoch 697/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2035 - accuracy: 0.7947 - val_loss: 2.2894 - val_accuracy: 0.6101\n",
      "Epoch 698/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2001 - accuracy: 0.7911 - val_loss: 2.2977 - val_accuracy: 0.6120\n",
      "Epoch 699/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2066 - accuracy: 0.7952 - val_loss: 2.3292 - val_accuracy: 0.6112\n",
      "Epoch 700/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2122 - accuracy: 0.7946 - val_loss: 2.2826 - val_accuracy: 0.6151\n",
      "Epoch 701/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1981 - accuracy: 0.7951 - val_loss: 2.3095 - val_accuracy: 0.6096\n",
      "Epoch 702/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1920 - accuracy: 0.7966 - val_loss: 2.3550 - val_accuracy: 0.6050\n",
      "Epoch 703/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1891 - accuracy: 0.7960 - val_loss: 2.2998 - val_accuracy: 0.6154\n",
      "Epoch 704/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1983 - accuracy: 0.7986 - val_loss: 2.3237 - val_accuracy: 0.6064\n",
      "Epoch 705/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1892 - accuracy: 0.7950 - val_loss: 2.2963 - val_accuracy: 0.6118\n",
      "Epoch 706/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2031 - accuracy: 0.7930 - val_loss: 2.3475 - val_accuracy: 0.6068\n",
      "Epoch 707/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2136 - accuracy: 0.7942 - val_loss: 2.3406 - val_accuracy: 0.6075\n",
      "Epoch 708/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1929 - accuracy: 0.7975 - val_loss: 2.2903 - val_accuracy: 0.6146\n",
      "Epoch 709/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2044 - accuracy: 0.7935 - val_loss: 2.3059 - val_accuracy: 0.6165\n",
      "Epoch 710/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2028 - accuracy: 0.7968 - val_loss: 2.3128 - val_accuracy: 0.6169\n",
      "Epoch 711/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1980 - accuracy: 0.7958 - val_loss: 2.2970 - val_accuracy: 0.6152\n",
      "Epoch 712/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2010 - accuracy: 0.7943 - val_loss: 2.3236 - val_accuracy: 0.6138\n",
      "Epoch 713/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1990 - accuracy: 0.7942 - val_loss: 2.3511 - val_accuracy: 0.6080\n",
      "Epoch 714/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2010 - accuracy: 0.7963 - val_loss: 2.3128 - val_accuracy: 0.6101\n",
      "Epoch 715/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1982 - accuracy: 0.7927 - val_loss: 2.3344 - val_accuracy: 0.6096\n",
      "Epoch 716/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2007 - accuracy: 0.7940 - val_loss: 2.3014 - val_accuracy: 0.6161\n",
      "Epoch 717/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.2079 - accuracy: 0.7923 - val_loss: 2.3014 - val_accuracy: 0.6116\n",
      "Epoch 718/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1873 - accuracy: 0.7989 - val_loss: 2.2929 - val_accuracy: 0.6148\n",
      "Epoch 719/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1970 - accuracy: 0.7969 - val_loss: 2.3094 - val_accuracy: 0.6146\n",
      "Epoch 720/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2031 - accuracy: 0.7998 - val_loss: 2.3193 - val_accuracy: 0.6101\n",
      "Epoch 721/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1960 - accuracy: 0.7934 - val_loss: 2.3396 - val_accuracy: 0.6116\n",
      "Epoch 722/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1912 - accuracy: 0.7974 - val_loss: 2.3006 - val_accuracy: 0.6160\n",
      "Epoch 723/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1931 - accuracy: 0.7956 - val_loss: 2.2672 - val_accuracy: 0.6175\n",
      "Epoch 724/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1956 - accuracy: 0.7971 - val_loss: 2.3113 - val_accuracy: 0.6150\n",
      "Epoch 725/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1823 - accuracy: 0.7993 - val_loss: 2.3061 - val_accuracy: 0.6161\n",
      "Epoch 726/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1893 - accuracy: 0.7987 - val_loss: 2.3325 - val_accuracy: 0.6178\n",
      "Epoch 727/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2080 - accuracy: 0.7980 - val_loss: 2.3079 - val_accuracy: 0.6116\n",
      "Epoch 728/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1844 - accuracy: 0.7967 - val_loss: 2.2858 - val_accuracy: 0.6195\n",
      "Epoch 729/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1830 - accuracy: 0.7989 - val_loss: 2.3593 - val_accuracy: 0.6078\n",
      "Epoch 730/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1974 - accuracy: 0.7956 - val_loss: 2.3230 - val_accuracy: 0.6096\n",
      "Epoch 731/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1803 - accuracy: 0.7995 - val_loss: 2.2981 - val_accuracy: 0.6134\n",
      "Epoch 732/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1930 - accuracy: 0.7957 - val_loss: 2.2927 - val_accuracy: 0.6139\n",
      "Epoch 733/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1881 - accuracy: 0.7976 - val_loss: 2.2872 - val_accuracy: 0.6171\n",
      "Epoch 734/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1882 - accuracy: 0.7984 - val_loss: 2.3186 - val_accuracy: 0.6154\n",
      "Epoch 735/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.2051 - accuracy: 0.7965 - val_loss: 2.3161 - val_accuracy: 0.6131\n",
      "Epoch 736/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1794 - accuracy: 0.8025 - val_loss: 2.2901 - val_accuracy: 0.6141\n",
      "Epoch 737/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1734 - accuracy: 0.7983 - val_loss: 2.3170 - val_accuracy: 0.6151\n",
      "Epoch 738/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1983 - accuracy: 0.7970 - val_loss: 2.3006 - val_accuracy: 0.6119\n",
      "Epoch 739/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1829 - accuracy: 0.7998 - val_loss: 2.3382 - val_accuracy: 0.6123\n",
      "Epoch 740/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2028 - accuracy: 0.7961 - val_loss: 2.2720 - val_accuracy: 0.6184\n",
      "Epoch 741/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.2055 - accuracy: 0.7955 - val_loss: 2.2726 - val_accuracy: 0.6205\n",
      "Epoch 742/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1883 - accuracy: 0.7970 - val_loss: 2.3043 - val_accuracy: 0.6156\n",
      "Epoch 743/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1807 - accuracy: 0.7988 - val_loss: 2.3255 - val_accuracy: 0.6090\n",
      "Epoch 744/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1830 - accuracy: 0.7946 - val_loss: 2.2754 - val_accuracy: 0.6206\n",
      "Epoch 745/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1931 - accuracy: 0.7950 - val_loss: 2.3570 - val_accuracy: 0.6071\n",
      "Epoch 746/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1894 - accuracy: 0.7953 - val_loss: 2.2803 - val_accuracy: 0.6204\n",
      "Epoch 747/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1658 - accuracy: 0.8044 - val_loss: 2.3383 - val_accuracy: 0.6106\n",
      "Epoch 748/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1878 - accuracy: 0.7998 - val_loss: 2.3073 - val_accuracy: 0.6140\n",
      "Epoch 749/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1855 - accuracy: 0.7960 - val_loss: 2.3067 - val_accuracy: 0.6160\n",
      "Epoch 750/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1839 - accuracy: 0.7979 - val_loss: 2.3049 - val_accuracy: 0.6157\n",
      "Epoch 751/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1773 - accuracy: 0.8017 - val_loss: 2.2971 - val_accuracy: 0.6208\n",
      "Epoch 752/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1877 - accuracy: 0.8003 - val_loss: 2.3415 - val_accuracy: 0.6099\n",
      "Epoch 753/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1661 - accuracy: 0.8054 - val_loss: 2.3305 - val_accuracy: 0.6129\n",
      "Epoch 754/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1809 - accuracy: 0.7999 - val_loss: 2.3109 - val_accuracy: 0.6162\n",
      "Epoch 755/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1854 - accuracy: 0.8024 - val_loss: 2.2861 - val_accuracy: 0.6177\n",
      "Epoch 756/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1692 - accuracy: 0.7989 - val_loss: 2.3705 - val_accuracy: 0.6105\n",
      "Epoch 757/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.2104 - accuracy: 0.7996 - val_loss: 2.3137 - val_accuracy: 0.6192\n",
      "Epoch 758/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1871 - accuracy: 0.7960 - val_loss: 2.3668 - val_accuracy: 0.6087\n",
      "Epoch 759/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1692 - accuracy: 0.8045 - val_loss: 2.3339 - val_accuracy: 0.6125\n",
      "Epoch 760/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1862 - accuracy: 0.7982 - val_loss: 2.3139 - val_accuracy: 0.6173\n",
      "Epoch 761/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1654 - accuracy: 0.8021 - val_loss: 2.3599 - val_accuracy: 0.6115\n",
      "Epoch 762/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1692 - accuracy: 0.8031 - val_loss: 2.2847 - val_accuracy: 0.6173\n",
      "Epoch 763/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1725 - accuracy: 0.8032 - val_loss: 2.3433 - val_accuracy: 0.6103\n",
      "Epoch 764/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1750 - accuracy: 0.8010 - val_loss: 2.3043 - val_accuracy: 0.6163\n",
      "Epoch 765/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1616 - accuracy: 0.8041 - val_loss: 2.3392 - val_accuracy: 0.6139\n",
      "Epoch 766/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1711 - accuracy: 0.8049 - val_loss: 2.3490 - val_accuracy: 0.6122\n",
      "Epoch 767/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1706 - accuracy: 0.8036 - val_loss: 2.3206 - val_accuracy: 0.6119\n",
      "Epoch 768/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1832 - accuracy: 0.8015 - val_loss: 2.3107 - val_accuracy: 0.6160\n",
      "Epoch 769/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1817 - accuracy: 0.7998 - val_loss: 2.3381 - val_accuracy: 0.6152\n",
      "Epoch 770/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1812 - accuracy: 0.8024 - val_loss: 2.3180 - val_accuracy: 0.6119\n",
      "Epoch 771/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1786 - accuracy: 0.8019 - val_loss: 2.3415 - val_accuracy: 0.6134\n",
      "Epoch 772/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1991 - accuracy: 0.8027 - val_loss: 2.2932 - val_accuracy: 0.6175\n",
      "Epoch 773/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1695 - accuracy: 0.8029 - val_loss: 2.2852 - val_accuracy: 0.6174\n",
      "Epoch 774/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1617 - accuracy: 0.8034 - val_loss: 2.2945 - val_accuracy: 0.6185\n",
      "Epoch 775/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1719 - accuracy: 0.8009 - val_loss: 2.3124 - val_accuracy: 0.6158\n",
      "Epoch 776/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1641 - accuracy: 0.8041 - val_loss: 2.3048 - val_accuracy: 0.6167\n",
      "Epoch 777/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1722 - accuracy: 0.8012 - val_loss: 2.3108 - val_accuracy: 0.6216\n",
      "Epoch 778/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1654 - accuracy: 0.8043 - val_loss: 2.3174 - val_accuracy: 0.6160\n",
      "Epoch 779/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1684 - accuracy: 0.8017 - val_loss: 2.3159 - val_accuracy: 0.6167\n",
      "Epoch 780/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1614 - accuracy: 0.8059 - val_loss: 2.2993 - val_accuracy: 0.6186\n",
      "Epoch 781/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1649 - accuracy: 0.8041 - val_loss: 2.3185 - val_accuracy: 0.6212\n",
      "Epoch 782/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1677 - accuracy: 0.8075 - val_loss: 2.2888 - val_accuracy: 0.6191\n",
      "Epoch 783/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1766 - accuracy: 0.8030 - val_loss: 2.3220 - val_accuracy: 0.6149\n",
      "Epoch 784/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1613 - accuracy: 0.8029 - val_loss: 2.3239 - val_accuracy: 0.6136\n",
      "Epoch 785/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1661 - accuracy: 0.8009 - val_loss: 2.3055 - val_accuracy: 0.6171\n",
      "Epoch 786/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1662 - accuracy: 0.8043 - val_loss: 2.3465 - val_accuracy: 0.6139\n",
      "Epoch 787/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1825 - accuracy: 0.8033 - val_loss: 2.2789 - val_accuracy: 0.6228\n",
      "Epoch 788/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1708 - accuracy: 0.8018 - val_loss: 2.2956 - val_accuracy: 0.6175\n",
      "Epoch 789/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1603 - accuracy: 0.8036 - val_loss: 2.3503 - val_accuracy: 0.6131\n",
      "Epoch 790/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1641 - accuracy: 0.8048 - val_loss: 2.3159 - val_accuracy: 0.6143\n",
      "Epoch 791/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1628 - accuracy: 0.8030 - val_loss: 2.2927 - val_accuracy: 0.6194\n",
      "Epoch 792/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1615 - accuracy: 0.8026 - val_loss: 2.3025 - val_accuracy: 0.6168\n",
      "Epoch 793/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1581 - accuracy: 0.8067 - val_loss: 2.3342 - val_accuracy: 0.6115\n",
      "Epoch 794/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1596 - accuracy: 0.8053 - val_loss: 2.3147 - val_accuracy: 0.6149\n",
      "Epoch 795/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1718 - accuracy: 0.8015 - val_loss: 2.3342 - val_accuracy: 0.6149\n",
      "Epoch 796/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1722 - accuracy: 0.8035 - val_loss: 2.3093 - val_accuracy: 0.6198\n",
      "Epoch 797/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1577 - accuracy: 0.8074 - val_loss: 2.3243 - val_accuracy: 0.6152\n",
      "Epoch 798/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1715 - accuracy: 0.8087 - val_loss: 2.3098 - val_accuracy: 0.6165\n",
      "Epoch 799/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1684 - accuracy: 0.8020 - val_loss: 2.3200 - val_accuracy: 0.6206\n",
      "Epoch 800/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1799 - accuracy: 0.8049 - val_loss: 2.3053 - val_accuracy: 0.6197\n",
      "Epoch 801/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1684 - accuracy: 0.8015 - val_loss: 2.2961 - val_accuracy: 0.6249\n",
      "Epoch 802/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1494 - accuracy: 0.8078 - val_loss: 2.3087 - val_accuracy: 0.6168\n",
      "Epoch 803/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1627 - accuracy: 0.8050 - val_loss: 2.3016 - val_accuracy: 0.6184\n",
      "Epoch 804/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1628 - accuracy: 0.8009 - val_loss: 2.2987 - val_accuracy: 0.6188\n",
      "Epoch 805/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1531 - accuracy: 0.8081 - val_loss: 2.3173 - val_accuracy: 0.6167\n",
      "Epoch 806/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1642 - accuracy: 0.8054 - val_loss: 2.3073 - val_accuracy: 0.6142\n",
      "Epoch 807/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1621 - accuracy: 0.8055 - val_loss: 2.3180 - val_accuracy: 0.6169\n",
      "Epoch 808/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1757 - accuracy: 0.8024 - val_loss: 2.3356 - val_accuracy: 0.6186\n",
      "Epoch 809/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.1838 - accuracy: 0.8062 - val_loss: 2.3210 - val_accuracy: 0.6211\n",
      "Epoch 810/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1618 - accuracy: 0.8081 - val_loss: 2.3570 - val_accuracy: 0.6103\n",
      "Epoch 811/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1742 - accuracy: 0.8064 - val_loss: 2.3157 - val_accuracy: 0.6166\n",
      "Epoch 812/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1627 - accuracy: 0.8013 - val_loss: 2.2794 - val_accuracy: 0.6186\n",
      "Epoch 813/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1463 - accuracy: 0.8099 - val_loss: 2.3026 - val_accuracy: 0.6176\n",
      "Epoch 814/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1605 - accuracy: 0.8047 - val_loss: 2.3152 - val_accuracy: 0.6105\n",
      "Epoch 815/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1482 - accuracy: 0.8079 - val_loss: 2.3147 - val_accuracy: 0.6196\n",
      "Epoch 816/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1556 - accuracy: 0.8063 - val_loss: 2.2990 - val_accuracy: 0.6197\n",
      "Epoch 817/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1474 - accuracy: 0.8086 - val_loss: 2.2928 - val_accuracy: 0.6177\n",
      "Epoch 818/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1554 - accuracy: 0.8056 - val_loss: 2.3303 - val_accuracy: 0.6132\n",
      "Epoch 819/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1579 - accuracy: 0.8080 - val_loss: 2.3088 - val_accuracy: 0.6180\n",
      "Epoch 820/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1592 - accuracy: 0.8066 - val_loss: 2.3464 - val_accuracy: 0.6128\n",
      "Epoch 821/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1563 - accuracy: 0.8076 - val_loss: 2.3120 - val_accuracy: 0.6183\n",
      "Epoch 822/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1529 - accuracy: 0.8082 - val_loss: 2.3494 - val_accuracy: 0.6132\n",
      "Epoch 823/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1687 - accuracy: 0.8073 - val_loss: 2.3051 - val_accuracy: 0.6191\n",
      "Epoch 824/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1423 - accuracy: 0.8105 - val_loss: 2.2990 - val_accuracy: 0.6197\n",
      "Epoch 825/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1520 - accuracy: 0.8063 - val_loss: 2.3042 - val_accuracy: 0.6164\n",
      "Epoch 826/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1488 - accuracy: 0.8080 - val_loss: 2.3045 - val_accuracy: 0.6210\n",
      "Epoch 827/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1565 - accuracy: 0.8084 - val_loss: 2.3237 - val_accuracy: 0.6155\n",
      "Epoch 828/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1667 - accuracy: 0.8050 - val_loss: 2.3300 - val_accuracy: 0.6188\n",
      "Epoch 829/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1559 - accuracy: 0.8093 - val_loss: 2.3107 - val_accuracy: 0.6210\n",
      "Epoch 830/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1621 - accuracy: 0.8095 - val_loss: 2.3019 - val_accuracy: 0.6183\n",
      "Epoch 831/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1382 - accuracy: 0.8110 - val_loss: 2.2898 - val_accuracy: 0.6222\n",
      "Epoch 832/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1475 - accuracy: 0.8088 - val_loss: 2.3461 - val_accuracy: 0.6165\n",
      "Epoch 833/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1795 - accuracy: 0.8070 - val_loss: 2.2943 - val_accuracy: 0.6195\n",
      "Epoch 834/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1598 - accuracy: 0.8085 - val_loss: 2.3093 - val_accuracy: 0.6159\n",
      "Epoch 835/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1404 - accuracy: 0.8095 - val_loss: 2.3093 - val_accuracy: 0.6176\n",
      "Epoch 836/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1468 - accuracy: 0.8096 - val_loss: 2.2931 - val_accuracy: 0.6189\n",
      "Epoch 837/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1384 - accuracy: 0.8095 - val_loss: 2.3183 - val_accuracy: 0.6148\n",
      "Epoch 838/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1493 - accuracy: 0.8081 - val_loss: 2.3025 - val_accuracy: 0.6171\n",
      "Epoch 839/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1439 - accuracy: 0.8094 - val_loss: 2.3072 - val_accuracy: 0.6187\n",
      "Epoch 840/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1564 - accuracy: 0.8062 - val_loss: 2.2823 - val_accuracy: 0.6238\n",
      "Epoch 841/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1498 - accuracy: 0.8089 - val_loss: 2.3018 - val_accuracy: 0.6202\n",
      "Epoch 842/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1504 - accuracy: 0.8065 - val_loss: 2.3310 - val_accuracy: 0.6221\n",
      "Epoch 843/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1648 - accuracy: 0.8045 - val_loss: 2.3160 - val_accuracy: 0.6152\n",
      "Epoch 844/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1606 - accuracy: 0.8045 - val_loss: 2.3387 - val_accuracy: 0.6142\n",
      "Epoch 845/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1476 - accuracy: 0.8112 - val_loss: 2.3343 - val_accuracy: 0.6155\n",
      "Epoch 846/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1455 - accuracy: 0.8071 - val_loss: 2.3145 - val_accuracy: 0.6167\n",
      "Epoch 847/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1357 - accuracy: 0.8117 - val_loss: 2.3076 - val_accuracy: 0.6197\n",
      "Epoch 848/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1411 - accuracy: 0.8094 - val_loss: 2.3347 - val_accuracy: 0.6139\n",
      "Epoch 849/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1637 - accuracy: 0.8086 - val_loss: 2.3007 - val_accuracy: 0.6203\n",
      "Epoch 850/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1354 - accuracy: 0.8116 - val_loss: 2.2636 - val_accuracy: 0.6276\n",
      "Epoch 851/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1548 - accuracy: 0.8072 - val_loss: 2.3153 - val_accuracy: 0.6199\n",
      "Epoch 852/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1346 - accuracy: 0.8089 - val_loss: 2.2855 - val_accuracy: 0.6196\n",
      "Epoch 853/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1575 - accuracy: 0.8084 - val_loss: 2.3341 - val_accuracy: 0.6157\n",
      "Epoch 854/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1513 - accuracy: 0.8099 - val_loss: 2.3149 - val_accuracy: 0.6190\n",
      "Epoch 855/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1568 - accuracy: 0.8043 - val_loss: 2.3038 - val_accuracy: 0.6188\n",
      "Epoch 856/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1579 - accuracy: 0.8076 - val_loss: 2.2969 - val_accuracy: 0.6192\n",
      "Epoch 857/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1484 - accuracy: 0.8121 - val_loss: 2.3333 - val_accuracy: 0.6140\n",
      "Epoch 858/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1500 - accuracy: 0.8105 - val_loss: 2.3168 - val_accuracy: 0.6219\n",
      "Epoch 859/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1353 - accuracy: 0.8111 - val_loss: 2.3217 - val_accuracy: 0.6190\n",
      "Epoch 860/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1477 - accuracy: 0.8106 - val_loss: 2.3162 - val_accuracy: 0.6190\n",
      "Epoch 861/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1469 - accuracy: 0.8117 - val_loss: 2.2818 - val_accuracy: 0.6240\n",
      "Epoch 862/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1314 - accuracy: 0.8146 - val_loss: 2.3042 - val_accuracy: 0.6245\n",
      "Epoch 863/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1490 - accuracy: 0.8086 - val_loss: 2.3260 - val_accuracy: 0.6164\n",
      "Epoch 864/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1563 - accuracy: 0.8108 - val_loss: 2.2922 - val_accuracy: 0.6194\n",
      "Epoch 865/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1355 - accuracy: 0.8133 - val_loss: 2.3473 - val_accuracy: 0.6134\n",
      "Epoch 866/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1452 - accuracy: 0.8076 - val_loss: 2.3635 - val_accuracy: 0.6156\n",
      "Epoch 867/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1705 - accuracy: 0.8044 - val_loss: 2.3624 - val_accuracy: 0.6164\n",
      "Epoch 868/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1549 - accuracy: 0.8149 - val_loss: 2.2737 - val_accuracy: 0.6236\n",
      "Epoch 869/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1583 - accuracy: 0.8061 - val_loss: 2.3039 - val_accuracy: 0.6185\n",
      "Epoch 870/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1282 - accuracy: 0.8170 - val_loss: 2.3292 - val_accuracy: 0.6194\n",
      "Epoch 871/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1582 - accuracy: 0.8066 - val_loss: 2.3157 - val_accuracy: 0.6228\n",
      "Epoch 872/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1519 - accuracy: 0.8109 - val_loss: 2.3123 - val_accuracy: 0.6191\n",
      "Epoch 873/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1446 - accuracy: 0.8087 - val_loss: 2.3295 - val_accuracy: 0.6186\n",
      "Epoch 874/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1358 - accuracy: 0.8142 - val_loss: 2.3158 - val_accuracy: 0.6237\n",
      "Epoch 875/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1382 - accuracy: 0.8110 - val_loss: 2.2723 - val_accuracy: 0.6261\n",
      "Epoch 876/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1404 - accuracy: 0.8113 - val_loss: 2.2862 - val_accuracy: 0.6255\n",
      "Epoch 877/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1294 - accuracy: 0.8111 - val_loss: 2.2822 - val_accuracy: 0.6209\n",
      "Epoch 878/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1385 - accuracy: 0.8132 - val_loss: 2.3172 - val_accuracy: 0.6237\n",
      "Epoch 879/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1524 - accuracy: 0.8128 - val_loss: 2.3020 - val_accuracy: 0.6190\n",
      "Epoch 880/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1404 - accuracy: 0.8130 - val_loss: 2.3396 - val_accuracy: 0.6172\n",
      "Epoch 881/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1564 - accuracy: 0.8119 - val_loss: 2.3171 - val_accuracy: 0.6184\n",
      "Epoch 882/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1453 - accuracy: 0.8113 - val_loss: 2.3287 - val_accuracy: 0.6165\n",
      "Epoch 883/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1322 - accuracy: 0.8145 - val_loss: 2.3043 - val_accuracy: 0.6205\n",
      "Epoch 884/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1299 - accuracy: 0.8128 - val_loss: 2.2980 - val_accuracy: 0.6208\n",
      "Epoch 885/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1312 - accuracy: 0.8117 - val_loss: 2.3527 - val_accuracy: 0.6160\n",
      "Epoch 886/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1355 - accuracy: 0.8118 - val_loss: 2.3175 - val_accuracy: 0.6188\n",
      "Epoch 887/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1281 - accuracy: 0.8123 - val_loss: 2.3067 - val_accuracy: 0.6222\n",
      "Epoch 888/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1378 - accuracy: 0.8106 - val_loss: 2.3085 - val_accuracy: 0.6274\n",
      "Epoch 889/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1552 - accuracy: 0.8101 - val_loss: 2.3387 - val_accuracy: 0.6138\n",
      "Epoch 890/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1515 - accuracy: 0.8122 - val_loss: 2.3125 - val_accuracy: 0.6231\n",
      "Epoch 891/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1224 - accuracy: 0.8164 - val_loss: 2.3584 - val_accuracy: 0.6124\n",
      "Epoch 892/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1313 - accuracy: 0.8123 - val_loss: 2.3450 - val_accuracy: 0.6174\n",
      "Epoch 893/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1243 - accuracy: 0.8159 - val_loss: 2.3437 - val_accuracy: 0.6145\n",
      "Epoch 894/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1257 - accuracy: 0.8159 - val_loss: 2.3378 - val_accuracy: 0.6153\n",
      "Epoch 895/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1420 - accuracy: 0.8132 - val_loss: 2.2926 - val_accuracy: 0.6206\n",
      "Epoch 896/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1275 - accuracy: 0.8128 - val_loss: 2.3156 - val_accuracy: 0.6209\n",
      "Epoch 897/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1437 - accuracy: 0.8111 - val_loss: 2.3151 - val_accuracy: 0.6218\n",
      "Epoch 898/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1395 - accuracy: 0.8104 - val_loss: 2.3005 - val_accuracy: 0.6210\n",
      "Epoch 899/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1335 - accuracy: 0.8139 - val_loss: 2.2759 - val_accuracy: 0.6224\n",
      "Epoch 900/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1331 - accuracy: 0.8109 - val_loss: 2.2772 - val_accuracy: 0.6246\n",
      "Epoch 901/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1565 - accuracy: 0.8112 - val_loss: 2.2971 - val_accuracy: 0.6248\n",
      "Epoch 902/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1440 - accuracy: 0.8100 - val_loss: 2.3376 - val_accuracy: 0.6191\n",
      "Epoch 903/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1297 - accuracy: 0.8147 - val_loss: 2.3385 - val_accuracy: 0.6191\n",
      "Epoch 904/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1290 - accuracy: 0.8119 - val_loss: 2.2907 - val_accuracy: 0.6206\n",
      "Epoch 905/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1209 - accuracy: 0.8170 - val_loss: 2.3186 - val_accuracy: 0.6216\n",
      "Epoch 906/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1332 - accuracy: 0.8132 - val_loss: 2.2972 - val_accuracy: 0.6250\n",
      "Epoch 907/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1293 - accuracy: 0.8127 - val_loss: 2.3094 - val_accuracy: 0.6174\n",
      "Epoch 908/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1327 - accuracy: 0.8135 - val_loss: 2.3328 - val_accuracy: 0.6181\n",
      "Epoch 909/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1320 - accuracy: 0.8128 - val_loss: 2.3162 - val_accuracy: 0.6176\n",
      "Epoch 910/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1324 - accuracy: 0.8124 - val_loss: 2.3150 - val_accuracy: 0.6223\n",
      "Epoch 911/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1324 - accuracy: 0.8119 - val_loss: 2.3013 - val_accuracy: 0.6204\n",
      "Epoch 912/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1343 - accuracy: 0.8107 - val_loss: 2.2965 - val_accuracy: 0.6226\n",
      "Epoch 913/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1342 - accuracy: 0.8122 - val_loss: 2.2914 - val_accuracy: 0.6197\n",
      "Epoch 914/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1237 - accuracy: 0.8129 - val_loss: 2.3026 - val_accuracy: 0.6229\n",
      "Epoch 915/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1226 - accuracy: 0.8150 - val_loss: 2.2944 - val_accuracy: 0.6223\n",
      "Epoch 916/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1292 - accuracy: 0.8144 - val_loss: 2.2965 - val_accuracy: 0.6205\n",
      "Epoch 917/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1309 - accuracy: 0.8149 - val_loss: 2.3130 - val_accuracy: 0.6181\n",
      "Epoch 918/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1152 - accuracy: 0.8152 - val_loss: 2.2739 - val_accuracy: 0.6278\n",
      "Epoch 919/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1285 - accuracy: 0.8134 - val_loss: 2.3400 - val_accuracy: 0.6137\n",
      "Epoch 920/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1218 - accuracy: 0.8190 - val_loss: 2.3158 - val_accuracy: 0.6223\n",
      "Epoch 921/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1254 - accuracy: 0.8143 - val_loss: 2.3142 - val_accuracy: 0.6222\n",
      "Epoch 922/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1340 - accuracy: 0.8119 - val_loss: 2.3615 - val_accuracy: 0.6129\n",
      "Epoch 923/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1143 - accuracy: 0.8177 - val_loss: 2.2778 - val_accuracy: 0.6258\n",
      "Epoch 924/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1440 - accuracy: 0.8121 - val_loss: 2.3338 - val_accuracy: 0.6167\n",
      "Epoch 925/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1218 - accuracy: 0.8181 - val_loss: 2.3248 - val_accuracy: 0.6205\n",
      "Epoch 926/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1128 - accuracy: 0.8178 - val_loss: 2.3094 - val_accuracy: 0.6193\n",
      "Epoch 927/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1197 - accuracy: 0.8158 - val_loss: 2.3520 - val_accuracy: 0.6141\n",
      "Epoch 928/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1179 - accuracy: 0.8160 - val_loss: 2.3009 - val_accuracy: 0.6248\n",
      "Epoch 929/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1149 - accuracy: 0.8179 - val_loss: 2.3605 - val_accuracy: 0.6115\n",
      "Epoch 930/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1322 - accuracy: 0.8126 - val_loss: 2.3161 - val_accuracy: 0.6232\n",
      "Epoch 931/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1247 - accuracy: 0.8157 - val_loss: 2.2963 - val_accuracy: 0.6222\n",
      "Epoch 932/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1153 - accuracy: 0.8187 - val_loss: 2.2773 - val_accuracy: 0.6263\n",
      "Epoch 933/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1270 - accuracy: 0.8141 - val_loss: 2.3112 - val_accuracy: 0.6222\n",
      "Epoch 934/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1274 - accuracy: 0.8187 - val_loss: 2.3238 - val_accuracy: 0.6228\n",
      "Epoch 935/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1316 - accuracy: 0.8157 - val_loss: 2.3378 - val_accuracy: 0.6222\n",
      "Epoch 936/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1391 - accuracy: 0.8132 - val_loss: 2.3259 - val_accuracy: 0.6212\n",
      "Epoch 937/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1221 - accuracy: 0.8121 - val_loss: 2.3122 - val_accuracy: 0.6178\n",
      "Epoch 938/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1274 - accuracy: 0.8140 - val_loss: 2.3089 - val_accuracy: 0.6217\n",
      "Epoch 939/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1389 - accuracy: 0.8135 - val_loss: 2.3066 - val_accuracy: 0.6200\n",
      "Epoch 940/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1161 - accuracy: 0.8159 - val_loss: 2.3223 - val_accuracy: 0.6213\n",
      "Epoch 941/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1347 - accuracy: 0.8122 - val_loss: 2.3125 - val_accuracy: 0.6201\n",
      "Epoch 942/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1306 - accuracy: 0.8172 - val_loss: 2.3278 - val_accuracy: 0.6177\n",
      "Epoch 943/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1318 - accuracy: 0.8128 - val_loss: 2.2856 - val_accuracy: 0.6232\n",
      "Epoch 944/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1175 - accuracy: 0.8187 - val_loss: 2.2838 - val_accuracy: 0.6277\n",
      "Epoch 945/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1169 - accuracy: 0.8167 - val_loss: 2.2911 - val_accuracy: 0.6247\n",
      "Epoch 946/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1219 - accuracy: 0.8188 - val_loss: 2.3795 - val_accuracy: 0.6139\n",
      "Epoch 947/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1265 - accuracy: 0.8203 - val_loss: 2.3420 - val_accuracy: 0.6176\n",
      "Epoch 948/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1191 - accuracy: 0.8158 - val_loss: 2.3109 - val_accuracy: 0.6197\n",
      "Epoch 949/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1060 - accuracy: 0.8198 - val_loss: 2.3493 - val_accuracy: 0.6176\n",
      "Epoch 950/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1516 - accuracy: 0.8156 - val_loss: 2.2887 - val_accuracy: 0.6210\n",
      "Epoch 951/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1200 - accuracy: 0.8163 - val_loss: 2.3126 - val_accuracy: 0.6209\n",
      "Epoch 952/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1154 - accuracy: 0.8198 - val_loss: 2.3023 - val_accuracy: 0.6185\n",
      "Epoch 953/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1187 - accuracy: 0.8153 - val_loss: 2.2871 - val_accuracy: 0.6252\n",
      "Epoch 954/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1200 - accuracy: 0.8182 - val_loss: 2.3376 - val_accuracy: 0.6162\n",
      "Epoch 955/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1176 - accuracy: 0.8156 - val_loss: 2.3180 - val_accuracy: 0.6187\n",
      "Epoch 956/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1239 - accuracy: 0.8136 - val_loss: 2.3027 - val_accuracy: 0.6211\n",
      "Epoch 957/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1194 - accuracy: 0.8202 - val_loss: 2.3587 - val_accuracy: 0.6161\n",
      "Epoch 958/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1198 - accuracy: 0.8166 - val_loss: 2.2770 - val_accuracy: 0.6286\n",
      "Epoch 959/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1131 - accuracy: 0.8158 - val_loss: 2.3231 - val_accuracy: 0.6231\n",
      "Epoch 960/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1177 - accuracy: 0.8165 - val_loss: 2.3168 - val_accuracy: 0.6181\n",
      "Epoch 961/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1103 - accuracy: 0.8183 - val_loss: 2.3277 - val_accuracy: 0.6181\n",
      "Epoch 962/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1264 - accuracy: 0.8172 - val_loss: 2.3319 - val_accuracy: 0.6183\n",
      "Epoch 963/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1059 - accuracy: 0.8214 - val_loss: 2.3471 - val_accuracy: 0.6175\n",
      "Epoch 964/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1041 - accuracy: 0.8187 - val_loss: 2.3195 - val_accuracy: 0.6224\n",
      "Epoch 965/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1094 - accuracy: 0.8181 - val_loss: 2.3531 - val_accuracy: 0.6193\n",
      "Epoch 966/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1151 - accuracy: 0.8225 - val_loss: 2.3073 - val_accuracy: 0.6218\n",
      "Epoch 967/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1089 - accuracy: 0.8188 - val_loss: 2.3093 - val_accuracy: 0.6308\n",
      "Epoch 968/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1425 - accuracy: 0.8195 - val_loss: 2.3452 - val_accuracy: 0.6208\n",
      "Epoch 969/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1184 - accuracy: 0.8196 - val_loss: 2.3376 - val_accuracy: 0.6190\n",
      "Epoch 970/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1087 - accuracy: 0.8194 - val_loss: 2.2958 - val_accuracy: 0.6235\n",
      "Epoch 971/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1159 - accuracy: 0.8166 - val_loss: 2.3019 - val_accuracy: 0.6227\n",
      "Epoch 972/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1201 - accuracy: 0.8142 - val_loss: 2.3052 - val_accuracy: 0.6252\n",
      "Epoch 973/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1217 - accuracy: 0.8147 - val_loss: 2.3308 - val_accuracy: 0.6199\n",
      "Epoch 974/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1141 - accuracy: 0.8168 - val_loss: 2.3397 - val_accuracy: 0.6208\n",
      "Epoch 975/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.1103 - accuracy: 0.8205 - val_loss: 2.3377 - val_accuracy: 0.6214\n",
      "Epoch 976/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1360 - accuracy: 0.8173 - val_loss: 2.3578 - val_accuracy: 0.6151\n",
      "Epoch 977/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1133 - accuracy: 0.8192 - val_loss: 2.3487 - val_accuracy: 0.6147\n",
      "Epoch 978/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1155 - accuracy: 0.8219 - val_loss: 2.3180 - val_accuracy: 0.6213\n",
      "Epoch 979/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0988 - accuracy: 0.8235 - val_loss: 2.3246 - val_accuracy: 0.6169\n",
      "Epoch 980/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1165 - accuracy: 0.8170 - val_loss: 2.3370 - val_accuracy: 0.6183\n",
      "Epoch 981/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1112 - accuracy: 0.8206 - val_loss: 2.3606 - val_accuracy: 0.6198\n",
      "Epoch 982/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1098 - accuracy: 0.8203 - val_loss: 2.2635 - val_accuracy: 0.6281\n",
      "Epoch 983/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1052 - accuracy: 0.8211 - val_loss: 2.3176 - val_accuracy: 0.6249\n",
      "Epoch 984/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1333 - accuracy: 0.8170 - val_loss: 2.3262 - val_accuracy: 0.6203\n",
      "Epoch 985/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1110 - accuracy: 0.8160 - val_loss: 2.3558 - val_accuracy: 0.6205\n",
      "Epoch 986/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1253 - accuracy: 0.8219 - val_loss: 2.2998 - val_accuracy: 0.6260\n",
      "Epoch 987/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1184 - accuracy: 0.8205 - val_loss: 2.3226 - val_accuracy: 0.6252\n",
      "Epoch 988/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1089 - accuracy: 0.8206 - val_loss: 2.3164 - val_accuracy: 0.6238\n",
      "Epoch 989/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1062 - accuracy: 0.8197 - val_loss: 2.2859 - val_accuracy: 0.6235\n",
      "Epoch 990/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1106 - accuracy: 0.8192 - val_loss: 2.2750 - val_accuracy: 0.6311\n",
      "Epoch 991/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1124 - accuracy: 0.8203 - val_loss: 2.3151 - val_accuracy: 0.6208\n",
      "Epoch 992/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0905 - accuracy: 0.8234 - val_loss: 2.2885 - val_accuracy: 0.6269\n",
      "Epoch 993/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1046 - accuracy: 0.8202 - val_loss: 2.2897 - val_accuracy: 0.6267\n",
      "Epoch 994/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1035 - accuracy: 0.8207 - val_loss: 2.2927 - val_accuracy: 0.6288\n",
      "Epoch 995/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1066 - accuracy: 0.8233 - val_loss: 2.3418 - val_accuracy: 0.6209\n",
      "Epoch 996/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0973 - accuracy: 0.8218 - val_loss: 2.2773 - val_accuracy: 0.6287\n",
      "Epoch 997/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0982 - accuracy: 0.8218 - val_loss: 2.3484 - val_accuracy: 0.6206\n",
      "Epoch 998/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1028 - accuracy: 0.8227 - val_loss: 2.3400 - val_accuracy: 0.6229\n",
      "Epoch 999/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1127 - accuracy: 0.8202 - val_loss: 2.3269 - val_accuracy: 0.6217\n",
      "Epoch 1000/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1077 - accuracy: 0.8223 - val_loss: 2.2936 - val_accuracy: 0.6269\n",
      "Epoch 1001/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1062 - accuracy: 0.8206 - val_loss: 2.3440 - val_accuracy: 0.6195\n",
      "Epoch 1002/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1122 - accuracy: 0.8180 - val_loss: 2.3368 - val_accuracy: 0.6190\n",
      "Epoch 1003/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1061 - accuracy: 0.8177 - val_loss: 2.3261 - val_accuracy: 0.6237\n",
      "Epoch 1004/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1166 - accuracy: 0.8181 - val_loss: 2.3488 - val_accuracy: 0.6197\n",
      "Epoch 1005/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1133 - accuracy: 0.8175 - val_loss: 2.3011 - val_accuracy: 0.6282\n",
      "Epoch 1006/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0972 - accuracy: 0.8210 - val_loss: 2.3380 - val_accuracy: 0.6219\n",
      "Epoch 1007/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1085 - accuracy: 0.8195 - val_loss: 2.2987 - val_accuracy: 0.6264\n",
      "Epoch 1008/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1021 - accuracy: 0.8214 - val_loss: 2.2945 - val_accuracy: 0.6234\n",
      "Epoch 1009/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0952 - accuracy: 0.8246 - val_loss: 2.3047 - val_accuracy: 0.6223\n",
      "Epoch 1010/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0911 - accuracy: 0.8257 - val_loss: 2.3271 - val_accuracy: 0.6160\n",
      "Epoch 1011/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1040 - accuracy: 0.8190 - val_loss: 2.3090 - val_accuracy: 0.6250\n",
      "Epoch 1012/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0973 - accuracy: 0.8231 - val_loss: 2.3426 - val_accuracy: 0.6220\n",
      "Epoch 1013/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1142 - accuracy: 0.8215 - val_loss: 2.3312 - val_accuracy: 0.6195\n",
      "Epoch 1014/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1088 - accuracy: 0.8212 - val_loss: 2.2633 - val_accuracy: 0.6326\n",
      "Epoch 1015/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1036 - accuracy: 0.8201 - val_loss: 2.3101 - val_accuracy: 0.6221\n",
      "Epoch 1016/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0976 - accuracy: 0.8261 - val_loss: 2.3358 - val_accuracy: 0.6218\n",
      "Epoch 1017/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0992 - accuracy: 0.8202 - val_loss: 2.3182 - val_accuracy: 0.6222\n",
      "Epoch 1018/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0996 - accuracy: 0.8235 - val_loss: 2.3375 - val_accuracy: 0.6229\n",
      "Epoch 1019/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0961 - accuracy: 0.8210 - val_loss: 2.3145 - val_accuracy: 0.6246\n",
      "Epoch 1020/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1066 - accuracy: 0.8198 - val_loss: 2.3518 - val_accuracy: 0.6255\n",
      "Epoch 1021/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1115 - accuracy: 0.8242 - val_loss: 2.3403 - val_accuracy: 0.6196\n",
      "Epoch 1022/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1019 - accuracy: 0.8206 - val_loss: 2.3092 - val_accuracy: 0.6267\n",
      "Epoch 1023/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0905 - accuracy: 0.8253 - val_loss: 2.3181 - val_accuracy: 0.6257\n",
      "Epoch 1024/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0961 - accuracy: 0.8257 - val_loss: 2.3261 - val_accuracy: 0.6266\n",
      "Epoch 1025/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1060 - accuracy: 0.8213 - val_loss: 2.3204 - val_accuracy: 0.6229\n",
      "Epoch 1026/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0999 - accuracy: 0.8216 - val_loss: 2.3111 - val_accuracy: 0.6271\n",
      "Epoch 1027/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1034 - accuracy: 0.8217 - val_loss: 2.3646 - val_accuracy: 0.6191\n",
      "Epoch 1028/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0863 - accuracy: 0.8248 - val_loss: 2.3280 - val_accuracy: 0.6232\n",
      "Epoch 1029/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1025 - accuracy: 0.8193 - val_loss: 2.3649 - val_accuracy: 0.6180\n",
      "Epoch 1030/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0916 - accuracy: 0.8243 - val_loss: 2.3518 - val_accuracy: 0.6229\n",
      "Epoch 1031/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1005 - accuracy: 0.8222 - val_loss: 2.3990 - val_accuracy: 0.6175\n",
      "Epoch 1032/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1042 - accuracy: 0.8239 - val_loss: 2.3276 - val_accuracy: 0.6271\n",
      "Epoch 1033/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0965 - accuracy: 0.8217 - val_loss: 2.3199 - val_accuracy: 0.6283\n",
      "Epoch 1034/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1009 - accuracy: 0.8237 - val_loss: 2.3820 - val_accuracy: 0.6167\n",
      "Epoch 1035/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0926 - accuracy: 0.8252 - val_loss: 2.3393 - val_accuracy: 0.6248\n",
      "Epoch 1036/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0981 - accuracy: 0.8265 - val_loss: 2.3423 - val_accuracy: 0.6221\n",
      "Epoch 1037/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0978 - accuracy: 0.8239 - val_loss: 2.3493 - val_accuracy: 0.6236\n",
      "Epoch 1038/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1059 - accuracy: 0.8230 - val_loss: 2.3255 - val_accuracy: 0.6241\n",
      "Epoch 1039/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1084 - accuracy: 0.8201 - val_loss: 2.3647 - val_accuracy: 0.6209\n",
      "Epoch 1040/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0975 - accuracy: 0.8207 - val_loss: 2.3249 - val_accuracy: 0.6238\n",
      "Epoch 1041/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0937 - accuracy: 0.8256 - val_loss: 2.3415 - val_accuracy: 0.6243\n",
      "Epoch 1042/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1077 - accuracy: 0.8238 - val_loss: 2.3261 - val_accuracy: 0.6225\n",
      "Epoch 1043/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0971 - accuracy: 0.8205 - val_loss: 2.3140 - val_accuracy: 0.6273\n",
      "Epoch 1044/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0877 - accuracy: 0.8225 - val_loss: 2.3366 - val_accuracy: 0.6242\n",
      "Epoch 1045/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0965 - accuracy: 0.8217 - val_loss: 2.3475 - val_accuracy: 0.6250\n",
      "Epoch 1046/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0926 - accuracy: 0.8232 - val_loss: 2.3305 - val_accuracy: 0.6254\n",
      "Epoch 1047/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1019 - accuracy: 0.8239 - val_loss: 2.3579 - val_accuracy: 0.6222\n",
      "Epoch 1048/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1083 - accuracy: 0.8228 - val_loss: 2.3278 - val_accuracy: 0.6240\n",
      "Epoch 1049/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0881 - accuracy: 0.8243 - val_loss: 2.3163 - val_accuracy: 0.6282\n",
      "Epoch 1050/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0872 - accuracy: 0.8249 - val_loss: 2.3428 - val_accuracy: 0.6238\n",
      "Epoch 1051/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0882 - accuracy: 0.8237 - val_loss: 2.3547 - val_accuracy: 0.6249\n",
      "Epoch 1052/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0951 - accuracy: 0.8236 - val_loss: 2.3448 - val_accuracy: 0.6220\n",
      "Epoch 1053/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0917 - accuracy: 0.8281 - val_loss: 2.3250 - val_accuracy: 0.6254\n",
      "Epoch 1054/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0962 - accuracy: 0.8264 - val_loss: 2.3300 - val_accuracy: 0.6258\n",
      "Epoch 1055/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0889 - accuracy: 0.8246 - val_loss: 2.3100 - val_accuracy: 0.6288\n",
      "Epoch 1056/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1173 - accuracy: 0.8238 - val_loss: 2.3231 - val_accuracy: 0.6270\n",
      "Epoch 1057/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.1015 - accuracy: 0.8224 - val_loss: 2.3758 - val_accuracy: 0.6208\n",
      "Epoch 1058/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0932 - accuracy: 0.8214 - val_loss: 2.3579 - val_accuracy: 0.6195\n",
      "Epoch 1059/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0832 - accuracy: 0.8263 - val_loss: 2.3330 - val_accuracy: 0.6244\n",
      "Epoch 1060/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0924 - accuracy: 0.8233 - val_loss: 2.3371 - val_accuracy: 0.6275\n",
      "Epoch 1061/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0886 - accuracy: 0.8254 - val_loss: 2.4055 - val_accuracy: 0.6202\n",
      "Epoch 1062/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0965 - accuracy: 0.8228 - val_loss: 2.3691 - val_accuracy: 0.6209\n",
      "Epoch 1063/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1109 - accuracy: 0.8234 - val_loss: 2.3638 - val_accuracy: 0.6204\n",
      "Epoch 1064/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0850 - accuracy: 0.8272 - val_loss: 2.3851 - val_accuracy: 0.6197\n",
      "Epoch 1065/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0931 - accuracy: 0.8263 - val_loss: 2.3380 - val_accuracy: 0.6225\n",
      "Epoch 1066/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0801 - accuracy: 0.8292 - val_loss: 2.3884 - val_accuracy: 0.6152\n",
      "Epoch 1067/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0949 - accuracy: 0.8241 - val_loss: 2.3642 - val_accuracy: 0.6241\n",
      "Epoch 1068/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0884 - accuracy: 0.8256 - val_loss: 2.3543 - val_accuracy: 0.6254\n",
      "Epoch 1069/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0913 - accuracy: 0.8241 - val_loss: 2.3466 - val_accuracy: 0.6266\n",
      "Epoch 1070/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0781 - accuracy: 0.8299 - val_loss: 2.3715 - val_accuracy: 0.6265\n",
      "Epoch 1071/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0865 - accuracy: 0.8252 - val_loss: 2.3786 - val_accuracy: 0.6197\n",
      "Epoch 1072/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0753 - accuracy: 0.8258 - val_loss: 2.3593 - val_accuracy: 0.6234\n",
      "Epoch 1073/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0914 - accuracy: 0.8268 - val_loss: 2.3368 - val_accuracy: 0.6281\n",
      "Epoch 1074/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.1015 - accuracy: 0.8216 - val_loss: 2.3934 - val_accuracy: 0.6209\n",
      "Epoch 1075/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0854 - accuracy: 0.8296 - val_loss: 2.3801 - val_accuracy: 0.6167\n",
      "Epoch 1076/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0897 - accuracy: 0.8255 - val_loss: 2.3707 - val_accuracy: 0.6169\n",
      "Epoch 1077/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0890 - accuracy: 0.8244 - val_loss: 2.3615 - val_accuracy: 0.6234\n",
      "Epoch 1078/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0867 - accuracy: 0.8240 - val_loss: 2.3386 - val_accuracy: 0.6222\n",
      "Epoch 1079/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1005 - accuracy: 0.8232 - val_loss: 2.3372 - val_accuracy: 0.6282\n",
      "Epoch 1080/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0840 - accuracy: 0.8243 - val_loss: 2.3198 - val_accuracy: 0.6282\n",
      "Epoch 1081/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0856 - accuracy: 0.8243 - val_loss: 2.3318 - val_accuracy: 0.6264\n",
      "Epoch 1082/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0833 - accuracy: 0.8225 - val_loss: 2.2913 - val_accuracy: 0.6317\n",
      "Epoch 1083/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0874 - accuracy: 0.8218 - val_loss: 2.3258 - val_accuracy: 0.6262\n",
      "Epoch 1084/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0780 - accuracy: 0.8265 - val_loss: 2.3243 - val_accuracy: 0.6251\n",
      "Epoch 1085/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0838 - accuracy: 0.8289 - val_loss: 2.3280 - val_accuracy: 0.6269\n",
      "Epoch 1086/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0844 - accuracy: 0.8255 - val_loss: 2.3131 - val_accuracy: 0.6242\n",
      "Epoch 1087/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0866 - accuracy: 0.8266 - val_loss: 2.2793 - val_accuracy: 0.6315\n",
      "Epoch 1088/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0996 - accuracy: 0.8237 - val_loss: 2.3838 - val_accuracy: 0.6242\n",
      "Epoch 1089/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0980 - accuracy: 0.8307 - val_loss: 2.3267 - val_accuracy: 0.6276\n",
      "Epoch 1090/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0864 - accuracy: 0.8268 - val_loss: 2.3107 - val_accuracy: 0.6278\n",
      "Epoch 1091/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0842 - accuracy: 0.8267 - val_loss: 2.3204 - val_accuracy: 0.6290\n",
      "Epoch 1092/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0918 - accuracy: 0.8247 - val_loss: 2.3254 - val_accuracy: 0.6251\n",
      "Epoch 1093/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0863 - accuracy: 0.8262 - val_loss: 2.3704 - val_accuracy: 0.6177\n",
      "Epoch 1094/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0934 - accuracy: 0.8253 - val_loss: 2.2922 - val_accuracy: 0.6304\n",
      "Epoch 1095/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0862 - accuracy: 0.8240 - val_loss: 2.3196 - val_accuracy: 0.6305\n",
      "Epoch 1096/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.1025 - accuracy: 0.8249 - val_loss: 2.3258 - val_accuracy: 0.6309\n",
      "Epoch 1097/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0868 - accuracy: 0.8264 - val_loss: 2.3573 - val_accuracy: 0.6227\n",
      "Epoch 1098/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0863 - accuracy: 0.8260 - val_loss: 2.3834 - val_accuracy: 0.6202\n",
      "Epoch 1099/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0825 - accuracy: 0.8252 - val_loss: 2.3173 - val_accuracy: 0.6257\n",
      "Epoch 1100/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0823 - accuracy: 0.8276 - val_loss: 2.3506 - val_accuracy: 0.6262\n",
      "Epoch 1101/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0813 - accuracy: 0.8297 - val_loss: 2.3220 - val_accuracy: 0.6264\n",
      "Epoch 1102/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0755 - accuracy: 0.8293 - val_loss: 2.3259 - val_accuracy: 0.6287\n",
      "Epoch 1103/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0830 - accuracy: 0.8271 - val_loss: 2.3357 - val_accuracy: 0.6289\n",
      "Epoch 1104/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0845 - accuracy: 0.8280 - val_loss: 2.3144 - val_accuracy: 0.6308\n",
      "Epoch 1105/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0914 - accuracy: 0.8257 - val_loss: 2.3314 - val_accuracy: 0.6252\n",
      "Epoch 1106/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0851 - accuracy: 0.8264 - val_loss: 2.3743 - val_accuracy: 0.6209\n",
      "Epoch 1107/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0941 - accuracy: 0.8272 - val_loss: 2.3411 - val_accuracy: 0.6292\n",
      "Epoch 1108/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0719 - accuracy: 0.8293 - val_loss: 2.3515 - val_accuracy: 0.6242\n",
      "Epoch 1109/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0879 - accuracy: 0.8251 - val_loss: 2.3232 - val_accuracy: 0.6273\n",
      "Epoch 1110/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0789 - accuracy: 0.8257 - val_loss: 2.3567 - val_accuracy: 0.6246\n",
      "Epoch 1111/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0785 - accuracy: 0.8280 - val_loss: 2.3339 - val_accuracy: 0.6282\n",
      "Epoch 1112/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0898 - accuracy: 0.8279 - val_loss: 2.3274 - val_accuracy: 0.6302\n",
      "Epoch 1113/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0771 - accuracy: 0.8278 - val_loss: 2.2730 - val_accuracy: 0.6353\n",
      "Epoch 1114/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0760 - accuracy: 0.8288 - val_loss: 2.3133 - val_accuracy: 0.6274\n",
      "Epoch 1115/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0715 - accuracy: 0.8281 - val_loss: 2.2830 - val_accuracy: 0.6364\n",
      "Epoch 1116/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0822 - accuracy: 0.8259 - val_loss: 2.3167 - val_accuracy: 0.6294\n",
      "Epoch 1117/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0926 - accuracy: 0.8251 - val_loss: 2.3465 - val_accuracy: 0.6280\n",
      "Epoch 1118/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0627 - accuracy: 0.8328 - val_loss: 2.3521 - val_accuracy: 0.6263\n",
      "Epoch 1119/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0819 - accuracy: 0.8295 - val_loss: 2.3360 - val_accuracy: 0.6289\n",
      "Epoch 1120/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0684 - accuracy: 0.8306 - val_loss: 2.3550 - val_accuracy: 0.6287\n",
      "Epoch 1121/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0840 - accuracy: 0.8286 - val_loss: 2.3410 - val_accuracy: 0.6295\n",
      "Epoch 1122/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0761 - accuracy: 0.8289 - val_loss: 2.3917 - val_accuracy: 0.6240\n",
      "Epoch 1123/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0878 - accuracy: 0.8258 - val_loss: 2.3525 - val_accuracy: 0.6297\n",
      "Epoch 1124/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0936 - accuracy: 0.8248 - val_loss: 2.3402 - val_accuracy: 0.6268\n",
      "Epoch 1125/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0806 - accuracy: 0.8281 - val_loss: 2.3187 - val_accuracy: 0.6285\n",
      "Epoch 1126/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0610 - accuracy: 0.8296 - val_loss: 2.3515 - val_accuracy: 0.6206\n",
      "Epoch 1127/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0751 - accuracy: 0.8300 - val_loss: 2.3585 - val_accuracy: 0.6272\n",
      "Epoch 1128/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0841 - accuracy: 0.8284 - val_loss: 2.3342 - val_accuracy: 0.6282\n",
      "Epoch 1129/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0672 - accuracy: 0.8323 - val_loss: 2.3581 - val_accuracy: 0.6247\n",
      "Epoch 1130/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0746 - accuracy: 0.8292 - val_loss: 2.3685 - val_accuracy: 0.6266\n",
      "Epoch 1131/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0940 - accuracy: 0.8289 - val_loss: 2.3457 - val_accuracy: 0.6256\n",
      "Epoch 1132/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0728 - accuracy: 0.8317 - val_loss: 2.3226 - val_accuracy: 0.6280\n",
      "Epoch 1133/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0754 - accuracy: 0.8266 - val_loss: 2.3900 - val_accuracy: 0.6199\n",
      "Epoch 1134/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0745 - accuracy: 0.8307 - val_loss: 2.3435 - val_accuracy: 0.6234\n",
      "Epoch 1135/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0946 - accuracy: 0.8262 - val_loss: 2.3751 - val_accuracy: 0.6248\n",
      "Epoch 1136/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0900 - accuracy: 0.8270 - val_loss: 2.3272 - val_accuracy: 0.6282\n",
      "Epoch 1137/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0790 - accuracy: 0.8300 - val_loss: 2.3409 - val_accuracy: 0.6223\n",
      "Epoch 1138/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0795 - accuracy: 0.8273 - val_loss: 2.3443 - val_accuracy: 0.6252\n",
      "Epoch 1139/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0890 - accuracy: 0.8263 - val_loss: 2.2981 - val_accuracy: 0.6317\n",
      "Epoch 1140/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0766 - accuracy: 0.8281 - val_loss: 2.3205 - val_accuracy: 0.6269\n",
      "Epoch 1141/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0730 - accuracy: 0.8253 - val_loss: 2.3632 - val_accuracy: 0.6220\n",
      "Epoch 1142/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0644 - accuracy: 0.8308 - val_loss: 2.3809 - val_accuracy: 0.6209\n",
      "Epoch 1143/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0856 - accuracy: 0.8278 - val_loss: 2.3577 - val_accuracy: 0.6250\n",
      "Epoch 1144/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0743 - accuracy: 0.8281 - val_loss: 2.2900 - val_accuracy: 0.6353\n",
      "Epoch 1145/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0635 - accuracy: 0.8325 - val_loss: 2.3192 - val_accuracy: 0.6278\n",
      "Epoch 1146/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0579 - accuracy: 0.8331 - val_loss: 2.3437 - val_accuracy: 0.6303\n",
      "Epoch 1147/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0652 - accuracy: 0.8318 - val_loss: 2.3455 - val_accuracy: 0.6313\n",
      "Epoch 1148/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0997 - accuracy: 0.8260 - val_loss: 2.3323 - val_accuracy: 0.6336\n",
      "Epoch 1149/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0814 - accuracy: 0.8281 - val_loss: 2.3328 - val_accuracy: 0.6292\n",
      "Epoch 1150/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0757 - accuracy: 0.8308 - val_loss: 2.3675 - val_accuracy: 0.6206\n",
      "Epoch 1151/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0802 - accuracy: 0.8303 - val_loss: 2.3121 - val_accuracy: 0.6327\n",
      "Epoch 1152/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0708 - accuracy: 0.8306 - val_loss: 2.3361 - val_accuracy: 0.6267\n",
      "Epoch 1153/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0819 - accuracy: 0.8306 - val_loss: 2.3090 - val_accuracy: 0.6353\n",
      "Epoch 1154/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0766 - accuracy: 0.8310 - val_loss: 2.3526 - val_accuracy: 0.6242\n",
      "Epoch 1155/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0731 - accuracy: 0.8287 - val_loss: 2.3623 - val_accuracy: 0.6225\n",
      "Epoch 1156/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0741 - accuracy: 0.8288 - val_loss: 2.3198 - val_accuracy: 0.6323\n",
      "Epoch 1157/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0666 - accuracy: 0.8314 - val_loss: 2.3464 - val_accuracy: 0.6248\n",
      "Epoch 1158/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0731 - accuracy: 0.8297 - val_loss: 2.3383 - val_accuracy: 0.6299\n",
      "Epoch 1159/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0745 - accuracy: 0.8314 - val_loss: 2.3174 - val_accuracy: 0.6283\n",
      "Epoch 1160/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0705 - accuracy: 0.8311 - val_loss: 2.3552 - val_accuracy: 0.6228\n",
      "Epoch 1161/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0640 - accuracy: 0.8303 - val_loss: 2.3301 - val_accuracy: 0.6314\n",
      "Epoch 1162/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0596 - accuracy: 0.8342 - val_loss: 2.3512 - val_accuracy: 0.6294\n",
      "Epoch 1163/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0633 - accuracy: 0.8356 - val_loss: 2.3199 - val_accuracy: 0.6271\n",
      "Epoch 1164/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0593 - accuracy: 0.8338 - val_loss: 2.3117 - val_accuracy: 0.6307\n",
      "Epoch 1165/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0638 - accuracy: 0.8302 - val_loss: 2.3194 - val_accuracy: 0.6287\n",
      "Epoch 1166/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0906 - accuracy: 0.8265 - val_loss: 2.3250 - val_accuracy: 0.6303\n",
      "Epoch 1167/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0681 - accuracy: 0.8295 - val_loss: 2.3748 - val_accuracy: 0.6240\n",
      "Epoch 1168/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0774 - accuracy: 0.8287 - val_loss: 2.3424 - val_accuracy: 0.6283\n",
      "Epoch 1169/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0735 - accuracy: 0.8301 - val_loss: 2.3459 - val_accuracy: 0.6249\n",
      "Epoch 1170/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0703 - accuracy: 0.8331 - val_loss: 2.3548 - val_accuracy: 0.6245\n",
      "Epoch 1171/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0794 - accuracy: 0.8306 - val_loss: 2.3129 - val_accuracy: 0.6301\n",
      "Epoch 1172/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0652 - accuracy: 0.8325 - val_loss: 2.3325 - val_accuracy: 0.6306\n",
      "Epoch 1173/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0679 - accuracy: 0.8290 - val_loss: 2.3390 - val_accuracy: 0.6285\n",
      "Epoch 1174/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0645 - accuracy: 0.8317 - val_loss: 2.3286 - val_accuracy: 0.6289\n",
      "Epoch 1175/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0791 - accuracy: 0.8285 - val_loss: 2.3237 - val_accuracy: 0.6294\n",
      "Epoch 1176/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0588 - accuracy: 0.8337 - val_loss: 2.3560 - val_accuracy: 0.6253\n",
      "Epoch 1177/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0582 - accuracy: 0.8351 - val_loss: 2.3467 - val_accuracy: 0.6256\n",
      "Epoch 1178/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0545 - accuracy: 0.8331 - val_loss: 2.3326 - val_accuracy: 0.6270\n",
      "Epoch 1179/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0578 - accuracy: 0.8346 - val_loss: 2.3835 - val_accuracy: 0.6232\n",
      "Epoch 1180/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0759 - accuracy: 0.8315 - val_loss: 2.3583 - val_accuracy: 0.6304\n",
      "Epoch 1181/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0599 - accuracy: 0.8347 - val_loss: 2.3249 - val_accuracy: 0.6300\n",
      "Epoch 1182/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0531 - accuracy: 0.8359 - val_loss: 2.4176 - val_accuracy: 0.6171\n",
      "Epoch 1183/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0836 - accuracy: 0.8304 - val_loss: 2.3477 - val_accuracy: 0.6287\n",
      "Epoch 1184/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0680 - accuracy: 0.8304 - val_loss: 2.3202 - val_accuracy: 0.6305\n",
      "Epoch 1185/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0815 - accuracy: 0.8279 - val_loss: 2.3303 - val_accuracy: 0.6238\n",
      "Epoch 1186/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0608 - accuracy: 0.8346 - val_loss: 2.3375 - val_accuracy: 0.6296\n",
      "Epoch 1187/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0664 - accuracy: 0.8296 - val_loss: 2.3559 - val_accuracy: 0.6260\n",
      "Epoch 1188/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0614 - accuracy: 0.8319 - val_loss: 2.3353 - val_accuracy: 0.6270\n",
      "Epoch 1189/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0827 - accuracy: 0.8277 - val_loss: 2.3734 - val_accuracy: 0.6244\n",
      "Epoch 1190/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0731 - accuracy: 0.8344 - val_loss: 2.3636 - val_accuracy: 0.6233\n",
      "Epoch 1191/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0626 - accuracy: 0.8325 - val_loss: 2.3163 - val_accuracy: 0.6308\n",
      "Epoch 1192/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0660 - accuracy: 0.8342 - val_loss: 2.2913 - val_accuracy: 0.6340\n",
      "Epoch 1193/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0661 - accuracy: 0.8341 - val_loss: 2.3431 - val_accuracy: 0.6262\n",
      "Epoch 1194/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0559 - accuracy: 0.8354 - val_loss: 2.3437 - val_accuracy: 0.6287\n",
      "Epoch 1195/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0781 - accuracy: 0.8276 - val_loss: 2.4009 - val_accuracy: 0.6198\n",
      "Epoch 1196/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0610 - accuracy: 0.8314 - val_loss: 2.3666 - val_accuracy: 0.6240\n",
      "Epoch 1197/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0874 - accuracy: 0.8288 - val_loss: 2.3473 - val_accuracy: 0.6264\n",
      "Epoch 1198/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0690 - accuracy: 0.8325 - val_loss: 2.3699 - val_accuracy: 0.6219\n",
      "Epoch 1199/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0805 - accuracy: 0.8281 - val_loss: 2.3529 - val_accuracy: 0.6247\n",
      "Epoch 1200/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0609 - accuracy: 0.8329 - val_loss: 2.3275 - val_accuracy: 0.6316\n",
      "Epoch 1201/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0754 - accuracy: 0.8324 - val_loss: 2.3201 - val_accuracy: 0.6280\n",
      "Epoch 1202/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0601 - accuracy: 0.8353 - val_loss: 2.3825 - val_accuracy: 0.6207\n",
      "Epoch 1203/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0742 - accuracy: 0.8289 - val_loss: 2.3538 - val_accuracy: 0.6245\n",
      "Epoch 1204/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0587 - accuracy: 0.8329 - val_loss: 2.4117 - val_accuracy: 0.6194\n",
      "Epoch 1205/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0596 - accuracy: 0.8315 - val_loss: 2.3757 - val_accuracy: 0.6210\n",
      "Epoch 1206/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0619 - accuracy: 0.8315 - val_loss: 2.3858 - val_accuracy: 0.6168\n",
      "Epoch 1207/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0584 - accuracy: 0.8307 - val_loss: 2.3729 - val_accuracy: 0.6262\n",
      "Epoch 1208/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0630 - accuracy: 0.8338 - val_loss: 2.3625 - val_accuracy: 0.6273\n",
      "Epoch 1209/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0588 - accuracy: 0.8334 - val_loss: 2.3467 - val_accuracy: 0.6296\n",
      "Epoch 1210/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0634 - accuracy: 0.8286 - val_loss: 2.3896 - val_accuracy: 0.6215\n",
      "Epoch 1211/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0609 - accuracy: 0.8355 - val_loss: 2.4072 - val_accuracy: 0.6174\n",
      "Epoch 1212/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0528 - accuracy: 0.8346 - val_loss: 2.3578 - val_accuracy: 0.6253\n",
      "Epoch 1213/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0636 - accuracy: 0.8297 - val_loss: 2.4011 - val_accuracy: 0.6194\n",
      "Epoch 1214/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0556 - accuracy: 0.8338 - val_loss: 2.3736 - val_accuracy: 0.6245\n",
      "Epoch 1215/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0563 - accuracy: 0.8332 - val_loss: 2.3778 - val_accuracy: 0.6253\n",
      "Epoch 1216/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0671 - accuracy: 0.8341 - val_loss: 2.3983 - val_accuracy: 0.6196\n",
      "Epoch 1217/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0667 - accuracy: 0.8324 - val_loss: 2.3671 - val_accuracy: 0.6235\n",
      "Epoch 1218/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0697 - accuracy: 0.8319 - val_loss: 2.3156 - val_accuracy: 0.6290\n",
      "Epoch 1219/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0625 - accuracy: 0.8331 - val_loss: 2.3284 - val_accuracy: 0.6276\n",
      "Epoch 1220/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0688 - accuracy: 0.8317 - val_loss: 2.3942 - val_accuracy: 0.6223\n",
      "Epoch 1221/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0576 - accuracy: 0.8371 - val_loss: 2.3300 - val_accuracy: 0.6291\n",
      "Epoch 1222/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0580 - accuracy: 0.8339 - val_loss: 2.3717 - val_accuracy: 0.6238\n",
      "Epoch 1223/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0597 - accuracy: 0.8322 - val_loss: 2.3221 - val_accuracy: 0.6296\n",
      "Epoch 1224/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0566 - accuracy: 0.8367 - val_loss: 2.3466 - val_accuracy: 0.6287\n",
      "Epoch 1225/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0594 - accuracy: 0.8361 - val_loss: 2.3949 - val_accuracy: 0.6281\n",
      "Epoch 1226/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0733 - accuracy: 0.8328 - val_loss: 2.3817 - val_accuracy: 0.6283\n",
      "Epoch 1227/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0620 - accuracy: 0.8319 - val_loss: 2.3370 - val_accuracy: 0.6366\n",
      "Epoch 1228/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0644 - accuracy: 0.8335 - val_loss: 2.3675 - val_accuracy: 0.6303\n",
      "Epoch 1229/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0500 - accuracy: 0.8347 - val_loss: 2.3360 - val_accuracy: 0.6309\n",
      "Epoch 1230/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0607 - accuracy: 0.8322 - val_loss: 2.3883 - val_accuracy: 0.6221\n",
      "Epoch 1231/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0593 - accuracy: 0.8328 - val_loss: 2.3473 - val_accuracy: 0.6282\n",
      "Epoch 1232/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0514 - accuracy: 0.8358 - val_loss: 2.3208 - val_accuracy: 0.6286\n",
      "Epoch 1233/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0537 - accuracy: 0.8323 - val_loss: 2.3301 - val_accuracy: 0.6333\n",
      "Epoch 1234/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0520 - accuracy: 0.8355 - val_loss: 2.3422 - val_accuracy: 0.6290\n",
      "Epoch 1235/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0620 - accuracy: 0.8305 - val_loss: 2.3137 - val_accuracy: 0.6288\n",
      "Epoch 1236/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0641 - accuracy: 0.8320 - val_loss: 2.3147 - val_accuracy: 0.6332\n",
      "Epoch 1237/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0607 - accuracy: 0.8319 - val_loss: 2.3541 - val_accuracy: 0.6286\n",
      "Epoch 1238/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0587 - accuracy: 0.8360 - val_loss: 2.3384 - val_accuracy: 0.6329\n",
      "Epoch 1239/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0541 - accuracy: 0.8356 - val_loss: 2.3408 - val_accuracy: 0.6301\n",
      "Epoch 1240/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0533 - accuracy: 0.8350 - val_loss: 2.3435 - val_accuracy: 0.6287\n",
      "Epoch 1241/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0585 - accuracy: 0.8352 - val_loss: 2.3407 - val_accuracy: 0.6295\n",
      "Epoch 1242/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0562 - accuracy: 0.8339 - val_loss: 2.3409 - val_accuracy: 0.6283\n",
      "Epoch 1243/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0588 - accuracy: 0.8310 - val_loss: 2.3863 - val_accuracy: 0.6217\n",
      "Epoch 1244/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0591 - accuracy: 0.8321 - val_loss: 2.2839 - val_accuracy: 0.6325\n",
      "Epoch 1245/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0453 - accuracy: 0.8384 - val_loss: 2.3074 - val_accuracy: 0.6340\n",
      "Epoch 1246/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0759 - accuracy: 0.8291 - val_loss: 2.3477 - val_accuracy: 0.6282\n",
      "Epoch 1247/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0602 - accuracy: 0.8346 - val_loss: 2.3573 - val_accuracy: 0.6264\n",
      "Epoch 1248/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0501 - accuracy: 0.8342 - val_loss: 2.3483 - val_accuracy: 0.6315\n",
      "Epoch 1249/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0538 - accuracy: 0.8349 - val_loss: 2.3462 - val_accuracy: 0.6267\n",
      "Epoch 1250/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0532 - accuracy: 0.8339 - val_loss: 2.3227 - val_accuracy: 0.6312\n",
      "Epoch 1251/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0485 - accuracy: 0.8341 - val_loss: 2.3269 - val_accuracy: 0.6311\n",
      "Epoch 1252/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0657 - accuracy: 0.8333 - val_loss: 2.3446 - val_accuracy: 0.6230\n",
      "Epoch 1253/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0642 - accuracy: 0.8310 - val_loss: 2.3617 - val_accuracy: 0.6291\n",
      "Epoch 1254/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0640 - accuracy: 0.8343 - val_loss: 2.3401 - val_accuracy: 0.6318\n",
      "Epoch 1255/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0459 - accuracy: 0.8376 - val_loss: 2.3531 - val_accuracy: 0.6259\n",
      "Epoch 1256/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0510 - accuracy: 0.8362 - val_loss: 2.3605 - val_accuracy: 0.6261\n",
      "Epoch 1257/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0670 - accuracy: 0.8366 - val_loss: 2.3528 - val_accuracy: 0.6262\n",
      "Epoch 1258/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0530 - accuracy: 0.8367 - val_loss: 2.3021 - val_accuracy: 0.6344\n",
      "Epoch 1259/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0602 - accuracy: 0.8336 - val_loss: 2.3400 - val_accuracy: 0.6333\n",
      "Epoch 1260/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0535 - accuracy: 0.8331 - val_loss: 2.3787 - val_accuracy: 0.6250\n",
      "Epoch 1261/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0535 - accuracy: 0.8378 - val_loss: 2.3739 - val_accuracy: 0.6258\n",
      "Epoch 1262/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0572 - accuracy: 0.8364 - val_loss: 2.3673 - val_accuracy: 0.6302\n",
      "Epoch 1263/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0613 - accuracy: 0.8340 - val_loss: 2.3759 - val_accuracy: 0.6257\n",
      "Epoch 1264/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0652 - accuracy: 0.8382 - val_loss: 2.3299 - val_accuracy: 0.6322\n",
      "Epoch 1265/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0527 - accuracy: 0.8355 - val_loss: 2.3319 - val_accuracy: 0.6308\n",
      "Epoch 1266/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0441 - accuracy: 0.8377 - val_loss: 2.3638 - val_accuracy: 0.6265\n",
      "Epoch 1267/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0569 - accuracy: 0.8342 - val_loss: 2.3221 - val_accuracy: 0.6331\n",
      "Epoch 1268/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0444 - accuracy: 0.8389 - val_loss: 2.3591 - val_accuracy: 0.6249\n",
      "Epoch 1269/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0502 - accuracy: 0.8339 - val_loss: 2.3817 - val_accuracy: 0.6213\n",
      "Epoch 1270/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0559 - accuracy: 0.8367 - val_loss: 2.3849 - val_accuracy: 0.6294\n",
      "Epoch 1271/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0514 - accuracy: 0.8332 - val_loss: 2.3987 - val_accuracy: 0.6266\n",
      "Epoch 1272/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0660 - accuracy: 0.8351 - val_loss: 2.3581 - val_accuracy: 0.6254\n",
      "Epoch 1273/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0533 - accuracy: 0.8338 - val_loss: 2.3434 - val_accuracy: 0.6319\n",
      "Epoch 1274/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0500 - accuracy: 0.8377 - val_loss: 2.3805 - val_accuracy: 0.6280\n",
      "Epoch 1275/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0398 - accuracy: 0.8391 - val_loss: 2.3413 - val_accuracy: 0.6309\n",
      "Epoch 1276/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0479 - accuracy: 0.8367 - val_loss: 2.3735 - val_accuracy: 0.6249\n",
      "Epoch 1277/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0525 - accuracy: 0.8348 - val_loss: 2.3834 - val_accuracy: 0.6240\n",
      "Epoch 1278/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0473 - accuracy: 0.8366 - val_loss: 2.3369 - val_accuracy: 0.6281\n",
      "Epoch 1279/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0552 - accuracy: 0.8340 - val_loss: 2.4226 - val_accuracy: 0.6231\n",
      "Epoch 1280/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0706 - accuracy: 0.8333 - val_loss: 2.3819 - val_accuracy: 0.6264\n",
      "Epoch 1281/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0577 - accuracy: 0.8353 - val_loss: 2.3384 - val_accuracy: 0.6287\n",
      "Epoch 1282/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0414 - accuracy: 0.8372 - val_loss: 2.3918 - val_accuracy: 0.6230\n",
      "Epoch 1283/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0533 - accuracy: 0.8345 - val_loss: 2.3893 - val_accuracy: 0.6238\n",
      "Epoch 1284/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0556 - accuracy: 0.8359 - val_loss: 2.3816 - val_accuracy: 0.6295\n",
      "Epoch 1285/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0673 - accuracy: 0.8370 - val_loss: 2.4026 - val_accuracy: 0.6223\n",
      "Epoch 1286/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0523 - accuracy: 0.8375 - val_loss: 2.3764 - val_accuracy: 0.6258\n",
      "Epoch 1287/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0468 - accuracy: 0.8344 - val_loss: 2.3750 - val_accuracy: 0.6260\n",
      "Epoch 1288/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0509 - accuracy: 0.8355 - val_loss: 2.3532 - val_accuracy: 0.6278\n",
      "Epoch 1289/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0467 - accuracy: 0.8353 - val_loss: 2.3375 - val_accuracy: 0.6315\n",
      "Epoch 1290/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0663 - accuracy: 0.8352 - val_loss: 2.4097 - val_accuracy: 0.6200\n",
      "Epoch 1291/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0411 - accuracy: 0.8401 - val_loss: 2.3746 - val_accuracy: 0.6291\n",
      "Epoch 1292/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0563 - accuracy: 0.8367 - val_loss: 2.3811 - val_accuracy: 0.6257\n",
      "Epoch 1293/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0482 - accuracy: 0.8409 - val_loss: 2.3991 - val_accuracy: 0.6233\n",
      "Epoch 1294/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0545 - accuracy: 0.8370 - val_loss: 2.3320 - val_accuracy: 0.6331\n",
      "Epoch 1295/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0475 - accuracy: 0.8386 - val_loss: 2.4033 - val_accuracy: 0.6236\n",
      "Epoch 1296/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0476 - accuracy: 0.8368 - val_loss: 2.3348 - val_accuracy: 0.6276\n",
      "Epoch 1297/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0437 - accuracy: 0.8373 - val_loss: 2.3881 - val_accuracy: 0.6209\n",
      "Epoch 1298/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0452 - accuracy: 0.8369 - val_loss: 2.3849 - val_accuracy: 0.6241\n",
      "Epoch 1299/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0496 - accuracy: 0.8386 - val_loss: 2.3732 - val_accuracy: 0.6253\n",
      "Epoch 1300/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0457 - accuracy: 0.8363 - val_loss: 2.3534 - val_accuracy: 0.6261\n",
      "Epoch 1301/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0557 - accuracy: 0.8350 - val_loss: 2.4058 - val_accuracy: 0.6224\n",
      "Epoch 1302/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0581 - accuracy: 0.8364 - val_loss: 2.3234 - val_accuracy: 0.6341\n",
      "Epoch 1303/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0498 - accuracy: 0.8369 - val_loss: 2.3457 - val_accuracy: 0.6276\n",
      "Epoch 1304/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0516 - accuracy: 0.8374 - val_loss: 2.3624 - val_accuracy: 0.6271\n",
      "Epoch 1305/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0404 - accuracy: 0.8392 - val_loss: 2.3268 - val_accuracy: 0.6327\n",
      "Epoch 1306/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0475 - accuracy: 0.8369 - val_loss: 2.3435 - val_accuracy: 0.6353\n",
      "Epoch 1307/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0619 - accuracy: 0.8375 - val_loss: 2.3416 - val_accuracy: 0.6341\n",
      "Epoch 1308/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0395 - accuracy: 0.8407 - val_loss: 2.3517 - val_accuracy: 0.6297\n",
      "Epoch 1309/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0459 - accuracy: 0.8382 - val_loss: 2.3945 - val_accuracy: 0.6261\n",
      "Epoch 1310/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0524 - accuracy: 0.8364 - val_loss: 2.3144 - val_accuracy: 0.6338\n",
      "Epoch 1311/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0386 - accuracy: 0.8361 - val_loss: 2.3600 - val_accuracy: 0.6270\n",
      "Epoch 1312/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0412 - accuracy: 0.8380 - val_loss: 2.3744 - val_accuracy: 0.6290\n",
      "Epoch 1313/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0365 - accuracy: 0.8411 - val_loss: 2.3353 - val_accuracy: 0.6286\n",
      "Epoch 1314/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0470 - accuracy: 0.8364 - val_loss: 2.3276 - val_accuracy: 0.6323\n",
      "Epoch 1315/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0404 - accuracy: 0.8397 - val_loss: 2.3532 - val_accuracy: 0.6271\n",
      "Epoch 1316/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0427 - accuracy: 0.8375 - val_loss: 2.3666 - val_accuracy: 0.6282\n",
      "Epoch 1317/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0319 - accuracy: 0.8394 - val_loss: 2.3619 - val_accuracy: 0.6332\n",
      "Epoch 1318/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0480 - accuracy: 0.8389 - val_loss: 2.3528 - val_accuracy: 0.6291\n",
      "Epoch 1319/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0346 - accuracy: 0.8402 - val_loss: 2.3203 - val_accuracy: 0.6356\n",
      "Epoch 1320/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0486 - accuracy: 0.8360 - val_loss: 2.3860 - val_accuracy: 0.6264\n",
      "Epoch 1321/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0462 - accuracy: 0.8382 - val_loss: 2.3471 - val_accuracy: 0.6327\n",
      "Epoch 1322/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0481 - accuracy: 0.8354 - val_loss: 2.3597 - val_accuracy: 0.6322\n",
      "Epoch 1323/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0411 - accuracy: 0.8371 - val_loss: 2.3425 - val_accuracy: 0.6351\n",
      "Epoch 1324/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0451 - accuracy: 0.8364 - val_loss: 2.3368 - val_accuracy: 0.6332\n",
      "Epoch 1325/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0294 - accuracy: 0.8422 - val_loss: 2.3586 - val_accuracy: 0.6323\n",
      "Epoch 1326/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0474 - accuracy: 0.8377 - val_loss: 2.3666 - val_accuracy: 0.6309\n",
      "Epoch 1327/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0411 - accuracy: 0.8386 - val_loss: 2.3396 - val_accuracy: 0.6339\n",
      "Epoch 1328/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0345 - accuracy: 0.8400 - val_loss: 2.3498 - val_accuracy: 0.6286\n",
      "Epoch 1329/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0557 - accuracy: 0.8363 - val_loss: 2.3723 - val_accuracy: 0.6298\n",
      "Epoch 1330/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0299 - accuracy: 0.8430 - val_loss: 2.3639 - val_accuracy: 0.6306\n",
      "Epoch 1331/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0551 - accuracy: 0.8387 - val_loss: 2.3500 - val_accuracy: 0.6310\n",
      "Epoch 1332/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0483 - accuracy: 0.8361 - val_loss: 2.3652 - val_accuracy: 0.6246\n",
      "Epoch 1333/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0502 - accuracy: 0.8363 - val_loss: 2.3499 - val_accuracy: 0.6321\n",
      "Epoch 1334/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0307 - accuracy: 0.8444 - val_loss: 2.3774 - val_accuracy: 0.6277\n",
      "Epoch 1335/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0433 - accuracy: 0.8403 - val_loss: 2.3956 - val_accuracy: 0.6264\n",
      "Epoch 1336/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0326 - accuracy: 0.8388 - val_loss: 2.3815 - val_accuracy: 0.6291\n",
      "Epoch 1337/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0492 - accuracy: 0.8362 - val_loss: 2.3562 - val_accuracy: 0.6309\n",
      "Epoch 1338/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0324 - accuracy: 0.8398 - val_loss: 2.3324 - val_accuracy: 0.6268\n",
      "Epoch 1339/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0363 - accuracy: 0.8407 - val_loss: 2.3365 - val_accuracy: 0.6328\n",
      "Epoch 1340/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0369 - accuracy: 0.8383 - val_loss: 2.3217 - val_accuracy: 0.6370\n",
      "Epoch 1341/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0478 - accuracy: 0.8369 - val_loss: 2.3638 - val_accuracy: 0.6338\n",
      "Epoch 1342/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0562 - accuracy: 0.8353 - val_loss: 2.3371 - val_accuracy: 0.6343\n",
      "Epoch 1343/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0502 - accuracy: 0.8383 - val_loss: 2.3373 - val_accuracy: 0.6362\n",
      "Epoch 1344/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0394 - accuracy: 0.8405 - val_loss: 2.3954 - val_accuracy: 0.6256\n",
      "Epoch 1345/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0392 - accuracy: 0.8375 - val_loss: 2.3606 - val_accuracy: 0.6308\n",
      "Epoch 1346/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0325 - accuracy: 0.8403 - val_loss: 2.3423 - val_accuracy: 0.6303\n",
      "Epoch 1347/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0401 - accuracy: 0.8426 - val_loss: 2.3616 - val_accuracy: 0.6251\n",
      "Epoch 1348/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0338 - accuracy: 0.8412 - val_loss: 2.3708 - val_accuracy: 0.6342\n",
      "Epoch 1349/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0416 - accuracy: 0.8419 - val_loss: 2.3511 - val_accuracy: 0.6301\n",
      "Epoch 1350/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0465 - accuracy: 0.8404 - val_loss: 2.3582 - val_accuracy: 0.6298\n",
      "Epoch 1351/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0394 - accuracy: 0.8379 - val_loss: 2.3105 - val_accuracy: 0.6336\n",
      "Epoch 1352/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0390 - accuracy: 0.8381 - val_loss: 2.4099 - val_accuracy: 0.6259\n",
      "Epoch 1353/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0649 - accuracy: 0.8379 - val_loss: 2.3749 - val_accuracy: 0.6314\n",
      "Epoch 1354/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0461 - accuracy: 0.8390 - val_loss: 2.3467 - val_accuracy: 0.6322\n",
      "Epoch 1355/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0333 - accuracy: 0.8399 - val_loss: 2.3712 - val_accuracy: 0.6310\n",
      "Epoch 1356/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0387 - accuracy: 0.8388 - val_loss: 2.3326 - val_accuracy: 0.6312\n",
      "Epoch 1357/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0371 - accuracy: 0.8416 - val_loss: 2.3523 - val_accuracy: 0.6318\n",
      "Epoch 1358/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0415 - accuracy: 0.8383 - val_loss: 2.3540 - val_accuracy: 0.6290\n",
      "Epoch 1359/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0308 - accuracy: 0.8456 - val_loss: 2.3413 - val_accuracy: 0.6347\n",
      "Epoch 1360/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0508 - accuracy: 0.8361 - val_loss: 2.3361 - val_accuracy: 0.6333\n",
      "Epoch 1361/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0402 - accuracy: 0.8400 - val_loss: 2.3397 - val_accuracy: 0.6327\n",
      "Epoch 1362/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0477 - accuracy: 0.8361 - val_loss: 2.3912 - val_accuracy: 0.6293\n",
      "Epoch 1363/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0333 - accuracy: 0.8398 - val_loss: 2.3204 - val_accuracy: 0.6347\n",
      "Epoch 1364/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0303 - accuracy: 0.8389 - val_loss: 2.3475 - val_accuracy: 0.6301\n",
      "Epoch 1365/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0467 - accuracy: 0.8390 - val_loss: 2.3330 - val_accuracy: 0.6331\n",
      "Epoch 1366/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0457 - accuracy: 0.8381 - val_loss: 2.3527 - val_accuracy: 0.6336\n",
      "Epoch 1367/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0366 - accuracy: 0.8439 - val_loss: 2.3426 - val_accuracy: 0.6349\n",
      "Epoch 1368/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0462 - accuracy: 0.8405 - val_loss: 2.3517 - val_accuracy: 0.6341\n",
      "Epoch 1369/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0333 - accuracy: 0.8419 - val_loss: 2.4117 - val_accuracy: 0.6295\n",
      "Epoch 1370/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0790 - accuracy: 0.8395 - val_loss: 2.3475 - val_accuracy: 0.6322\n",
      "Epoch 1371/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0365 - accuracy: 0.8439 - val_loss: 2.3562 - val_accuracy: 0.6302\n",
      "Epoch 1372/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0217 - accuracy: 0.8438 - val_loss: 2.3299 - val_accuracy: 0.6364\n",
      "Epoch 1373/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0345 - accuracy: 0.8397 - val_loss: 2.3327 - val_accuracy: 0.6356\n",
      "Epoch 1374/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0256 - accuracy: 0.8411 - val_loss: 2.3301 - val_accuracy: 0.6373\n",
      "Epoch 1375/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0358 - accuracy: 0.8396 - val_loss: 2.3291 - val_accuracy: 0.6341\n",
      "Epoch 1376/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0408 - accuracy: 0.8420 - val_loss: 2.3042 - val_accuracy: 0.6365\n",
      "Epoch 1377/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0293 - accuracy: 0.8408 - val_loss: 2.3752 - val_accuracy: 0.6322\n",
      "Epoch 1378/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0275 - accuracy: 0.8415 - val_loss: 2.3416 - val_accuracy: 0.6351\n",
      "Epoch 1379/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0386 - accuracy: 0.8408 - val_loss: 2.3158 - val_accuracy: 0.6365\n",
      "Epoch 1380/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0385 - accuracy: 0.8405 - val_loss: 2.3479 - val_accuracy: 0.6340\n",
      "Epoch 1381/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0422 - accuracy: 0.8376 - val_loss: 2.3344 - val_accuracy: 0.6328\n",
      "Epoch 1382/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0353 - accuracy: 0.8412 - val_loss: 2.3395 - val_accuracy: 0.6367\n",
      "Epoch 1383/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0329 - accuracy: 0.8387 - val_loss: 2.3337 - val_accuracy: 0.6340\n",
      "Epoch 1384/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0263 - accuracy: 0.8431 - val_loss: 2.3540 - val_accuracy: 0.6310\n",
      "Epoch 1385/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0514 - accuracy: 0.8375 - val_loss: 2.3507 - val_accuracy: 0.6316\n",
      "Epoch 1386/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0342 - accuracy: 0.8419 - val_loss: 2.3506 - val_accuracy: 0.6286\n",
      "Epoch 1387/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0392 - accuracy: 0.8387 - val_loss: 2.3202 - val_accuracy: 0.6389\n",
      "Epoch 1388/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0262 - accuracy: 0.8415 - val_loss: 2.3038 - val_accuracy: 0.6390\n",
      "Epoch 1389/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0277 - accuracy: 0.8409 - val_loss: 2.3102 - val_accuracy: 0.6375\n",
      "Epoch 1390/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0446 - accuracy: 0.8384 - val_loss: 2.3245 - val_accuracy: 0.6407\n",
      "Epoch 1391/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0416 - accuracy: 0.8420 - val_loss: 2.3314 - val_accuracy: 0.6330\n",
      "Epoch 1392/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0290 - accuracy: 0.8424 - val_loss: 2.3434 - val_accuracy: 0.6294\n",
      "Epoch 1393/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0290 - accuracy: 0.8433 - val_loss: 2.3936 - val_accuracy: 0.6257\n",
      "Epoch 1394/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0376 - accuracy: 0.8411 - val_loss: 2.3402 - val_accuracy: 0.6320\n",
      "Epoch 1395/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0341 - accuracy: 0.8402 - val_loss: 2.3820 - val_accuracy: 0.6252\n",
      "Epoch 1396/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0254 - accuracy: 0.8434 - val_loss: 2.3439 - val_accuracy: 0.6301\n",
      "Epoch 1397/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0351 - accuracy: 0.8414 - val_loss: 2.3681 - val_accuracy: 0.6306\n",
      "Epoch 1398/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0391 - accuracy: 0.8373 - val_loss: 2.3417 - val_accuracy: 0.6321\n",
      "Epoch 1399/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0326 - accuracy: 0.8404 - val_loss: 2.3430 - val_accuracy: 0.6314\n",
      "Epoch 1400/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0228 - accuracy: 0.8428 - val_loss: 2.3521 - val_accuracy: 0.6320\n",
      "Epoch 1401/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0358 - accuracy: 0.8437 - val_loss: 2.3473 - val_accuracy: 0.6318\n",
      "Epoch 1402/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0341 - accuracy: 0.8409 - val_loss: 2.4000 - val_accuracy: 0.6223\n",
      "Epoch 1403/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0315 - accuracy: 0.8429 - val_loss: 2.3786 - val_accuracy: 0.6269\n",
      "Epoch 1404/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0390 - accuracy: 0.8401 - val_loss: 2.3496 - val_accuracy: 0.6288\n",
      "Epoch 1405/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0474 - accuracy: 0.8409 - val_loss: 2.3430 - val_accuracy: 0.6300\n",
      "Epoch 1406/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0359 - accuracy: 0.8410 - val_loss: 2.3728 - val_accuracy: 0.6294\n",
      "Epoch 1407/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0295 - accuracy: 0.8401 - val_loss: 2.3170 - val_accuracy: 0.6393\n",
      "Epoch 1408/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0323 - accuracy: 0.8434 - val_loss: 2.3744 - val_accuracy: 0.6292\n",
      "Epoch 1409/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0396 - accuracy: 0.8384 - val_loss: 2.3460 - val_accuracy: 0.6316\n",
      "Epoch 1410/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0185 - accuracy: 0.8419 - val_loss: 2.3485 - val_accuracy: 0.6348\n",
      "Epoch 1411/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0216 - accuracy: 0.8447 - val_loss: 2.3209 - val_accuracy: 0.6378\n",
      "Epoch 1412/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0451 - accuracy: 0.8382 - val_loss: 2.3552 - val_accuracy: 0.6289\n",
      "Epoch 1413/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0337 - accuracy: 0.8432 - val_loss: 2.3509 - val_accuracy: 0.6327\n",
      "Epoch 1414/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0144 - accuracy: 0.8464 - val_loss: 2.3558 - val_accuracy: 0.6316\n",
      "Epoch 1415/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0256 - accuracy: 0.8438 - val_loss: 2.3383 - val_accuracy: 0.6282\n",
      "Epoch 1416/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0240 - accuracy: 0.8408 - val_loss: 2.3330 - val_accuracy: 0.6308\n",
      "Epoch 1417/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0284 - accuracy: 0.8426 - val_loss: 2.3268 - val_accuracy: 0.6343\n",
      "Epoch 1418/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0260 - accuracy: 0.8431 - val_loss: 2.3460 - val_accuracy: 0.6360\n",
      "Epoch 1419/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0199 - accuracy: 0.8431 - val_loss: 2.3551 - val_accuracy: 0.6337\n",
      "Epoch 1420/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0391 - accuracy: 0.8407 - val_loss: 2.4244 - val_accuracy: 0.6271\n",
      "Epoch 1421/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0308 - accuracy: 0.8441 - val_loss: 2.3570 - val_accuracy: 0.6301\n",
      "Epoch 1422/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0207 - accuracy: 0.8447 - val_loss: 2.3325 - val_accuracy: 0.6351\n",
      "Epoch 1423/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0176 - accuracy: 0.8442 - val_loss: 2.3528 - val_accuracy: 0.6346\n",
      "Epoch 1424/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0238 - accuracy: 0.8433 - val_loss: 2.3250 - val_accuracy: 0.6323\n",
      "Epoch 1425/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0238 - accuracy: 0.8442 - val_loss: 2.3368 - val_accuracy: 0.6381\n",
      "Epoch 1426/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0280 - accuracy: 0.8418 - val_loss: 2.3345 - val_accuracy: 0.6333\n",
      "Epoch 1427/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0256 - accuracy: 0.8438 - val_loss: 2.3479 - val_accuracy: 0.6330\n",
      "Epoch 1428/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0310 - accuracy: 0.8417 - val_loss: 2.3430 - val_accuracy: 0.6372\n",
      "Epoch 1429/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0456 - accuracy: 0.8379 - val_loss: 2.3060 - val_accuracy: 0.6363\n",
      "Epoch 1430/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0294 - accuracy: 0.8415 - val_loss: 2.3333 - val_accuracy: 0.6352\n",
      "Epoch 1431/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0241 - accuracy: 0.8435 - val_loss: 2.3428 - val_accuracy: 0.6317\n",
      "Epoch 1432/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0341 - accuracy: 0.8409 - val_loss: 2.3590 - val_accuracy: 0.6360\n",
      "Epoch 1433/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0483 - accuracy: 0.8393 - val_loss: 2.3150 - val_accuracy: 0.6363\n",
      "Epoch 1434/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0341 - accuracy: 0.8416 - val_loss: 2.3453 - val_accuracy: 0.6305\n",
      "Epoch 1435/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0172 - accuracy: 0.8465 - val_loss: 2.3940 - val_accuracy: 0.6278\n",
      "Epoch 1436/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0455 - accuracy: 0.8423 - val_loss: 2.3315 - val_accuracy: 0.6351\n",
      "Epoch 1437/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0286 - accuracy: 0.8404 - val_loss: 2.3611 - val_accuracy: 0.6304\n",
      "Epoch 1438/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0163 - accuracy: 0.8447 - val_loss: 2.3312 - val_accuracy: 0.6324\n",
      "Epoch 1439/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0250 - accuracy: 0.8439 - val_loss: 2.3266 - val_accuracy: 0.6340\n",
      "Epoch 1440/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0302 - accuracy: 0.8443 - val_loss: 2.2839 - val_accuracy: 0.6395\n",
      "Epoch 1441/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0161 - accuracy: 0.8459 - val_loss: 2.3486 - val_accuracy: 0.6303\n",
      "Epoch 1442/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0306 - accuracy: 0.8422 - val_loss: 2.2995 - val_accuracy: 0.6396\n",
      "Epoch 1443/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0312 - accuracy: 0.8442 - val_loss: 2.3339 - val_accuracy: 0.6317\n",
      "Epoch 1444/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0249 - accuracy: 0.8433 - val_loss: 2.3703 - val_accuracy: 0.6294\n",
      "Epoch 1445/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0115 - accuracy: 0.8489 - val_loss: 2.3307 - val_accuracy: 0.6346\n",
      "Epoch 1446/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0161 - accuracy: 0.8453 - val_loss: 2.3260 - val_accuracy: 0.6353\n",
      "Epoch 1447/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0244 - accuracy: 0.8446 - val_loss: 2.3440 - val_accuracy: 0.6328\n",
      "Epoch 1448/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0196 - accuracy: 0.8438 - val_loss: 2.3208 - val_accuracy: 0.6369\n",
      "Epoch 1449/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0204 - accuracy: 0.8447 - val_loss: 2.3865 - val_accuracy: 0.6286\n",
      "Epoch 1450/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0247 - accuracy: 0.8427 - val_loss: 2.3309 - val_accuracy: 0.6341\n",
      "Epoch 1451/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0187 - accuracy: 0.8471 - val_loss: 2.3900 - val_accuracy: 0.6320\n",
      "Epoch 1452/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0359 - accuracy: 0.8459 - val_loss: 2.3423 - val_accuracy: 0.6336\n",
      "Epoch 1453/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0249 - accuracy: 0.8418 - val_loss: 2.3608 - val_accuracy: 0.6308\n",
      "Epoch 1454/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0237 - accuracy: 0.8439 - val_loss: 2.3449 - val_accuracy: 0.6314\n",
      "Epoch 1455/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0248 - accuracy: 0.8418 - val_loss: 2.3462 - val_accuracy: 0.6333\n",
      "Epoch 1456/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0371 - accuracy: 0.8390 - val_loss: 2.3149 - val_accuracy: 0.6334\n",
      "Epoch 1457/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0293 - accuracy: 0.8421 - val_loss: 2.3437 - val_accuracy: 0.6336\n",
      "Epoch 1458/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0297 - accuracy: 0.8432 - val_loss: 2.3472 - val_accuracy: 0.6318\n",
      "Epoch 1459/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0206 - accuracy: 0.8437 - val_loss: 2.3615 - val_accuracy: 0.6287\n",
      "Epoch 1460/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0288 - accuracy: 0.8438 - val_loss: 2.3445 - val_accuracy: 0.6288\n",
      "Epoch 1461/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0200 - accuracy: 0.8455 - val_loss: 2.3617 - val_accuracy: 0.6310\n",
      "Epoch 1462/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0162 - accuracy: 0.8444 - val_loss: 2.3296 - val_accuracy: 0.6335\n",
      "Epoch 1463/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0124 - accuracy: 0.8470 - val_loss: 2.3319 - val_accuracy: 0.6359\n",
      "Epoch 1464/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0185 - accuracy: 0.8452 - val_loss: 2.3397 - val_accuracy: 0.6348\n",
      "Epoch 1465/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0202 - accuracy: 0.8457 - val_loss: 2.3359 - val_accuracy: 0.6342\n",
      "Epoch 1466/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0304 - accuracy: 0.8419 - val_loss: 2.3517 - val_accuracy: 0.6323\n",
      "Epoch 1467/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0256 - accuracy: 0.8404 - val_loss: 2.3964 - val_accuracy: 0.6299\n",
      "Epoch 1468/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0380 - accuracy: 0.8457 - val_loss: 2.3666 - val_accuracy: 0.6343\n",
      "Epoch 1469/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0192 - accuracy: 0.8448 - val_loss: 2.3393 - val_accuracy: 0.6343\n",
      "Epoch 1470/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0131 - accuracy: 0.8494 - val_loss: 2.3409 - val_accuracy: 0.6364\n",
      "Epoch 1471/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0195 - accuracy: 0.8417 - val_loss: 2.3573 - val_accuracy: 0.6293\n",
      "Epoch 1472/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0192 - accuracy: 0.8461 - val_loss: 2.3272 - val_accuracy: 0.6340\n",
      "Epoch 1473/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0243 - accuracy: 0.8471 - val_loss: 2.3376 - val_accuracy: 0.6356\n",
      "Epoch 1474/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0334 - accuracy: 0.8411 - val_loss: 2.3338 - val_accuracy: 0.6389\n",
      "Epoch 1475/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0273 - accuracy: 0.8422 - val_loss: 2.3370 - val_accuracy: 0.6360\n",
      "Epoch 1476/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0192 - accuracy: 0.8438 - val_loss: 2.3428 - val_accuracy: 0.6340\n",
      "Epoch 1477/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0380 - accuracy: 0.8418 - val_loss: 2.3931 - val_accuracy: 0.6280\n",
      "Epoch 1478/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0321 - accuracy: 0.8429 - val_loss: 2.3811 - val_accuracy: 0.6255\n",
      "Epoch 1479/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0346 - accuracy: 0.8425 - val_loss: 2.3790 - val_accuracy: 0.6306\n",
      "Epoch 1480/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0365 - accuracy: 0.8454 - val_loss: 2.3801 - val_accuracy: 0.6282\n",
      "Epoch 1481/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0266 - accuracy: 0.8436 - val_loss: 2.3327 - val_accuracy: 0.6343\n",
      "Epoch 1482/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0267 - accuracy: 0.8440 - val_loss: 2.3274 - val_accuracy: 0.6378\n",
      "Epoch 1483/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0236 - accuracy: 0.8477 - val_loss: 2.3817 - val_accuracy: 0.6321\n",
      "Epoch 1484/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0288 - accuracy: 0.8451 - val_loss: 2.3220 - val_accuracy: 0.6334\n",
      "Epoch 1485/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0215 - accuracy: 0.8480 - val_loss: 2.3447 - val_accuracy: 0.6315\n",
      "Epoch 1486/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0083 - accuracy: 0.8464 - val_loss: 2.3528 - val_accuracy: 0.6352\n",
      "Epoch 1487/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0282 - accuracy: 0.8416 - val_loss: 2.3623 - val_accuracy: 0.6340\n",
      "Epoch 1488/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0248 - accuracy: 0.8442 - val_loss: 2.3757 - val_accuracy: 0.6300\n",
      "Epoch 1489/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0236 - accuracy: 0.8440 - val_loss: 2.3928 - val_accuracy: 0.6261\n",
      "Epoch 1490/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0217 - accuracy: 0.8436 - val_loss: 2.3194 - val_accuracy: 0.6364\n",
      "Epoch 1491/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0068 - accuracy: 0.8486 - val_loss: 2.3457 - val_accuracy: 0.6322\n",
      "Epoch 1492/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0212 - accuracy: 0.8446 - val_loss: 2.3246 - val_accuracy: 0.6368\n",
      "Epoch 1493/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0185 - accuracy: 0.8455 - val_loss: 2.3478 - val_accuracy: 0.6348\n",
      "Epoch 1494/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0144 - accuracy: 0.8461 - val_loss: 2.3696 - val_accuracy: 0.6317\n",
      "Epoch 1495/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 1.0363 - accuracy: 0.8432 - val_loss: 2.3460 - val_accuracy: 0.6362\n",
      "Epoch 1496/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0285 - accuracy: 0.8443 - val_loss: 2.3657 - val_accuracy: 0.6300\n",
      "Epoch 1497/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0321 - accuracy: 0.8439 - val_loss: 2.3462 - val_accuracy: 0.6340\n",
      "Epoch 1498/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0135 - accuracy: 0.8458 - val_loss: 2.3282 - val_accuracy: 0.6385\n",
      "Epoch 1499/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0239 - accuracy: 0.8442 - val_loss: 2.3556 - val_accuracy: 0.6370\n",
      "Epoch 1500/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0075 - accuracy: 0.8480 - val_loss: 2.3207 - val_accuracy: 0.6390\n",
      "Epoch 1501/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0142 - accuracy: 0.8432 - val_loss: 2.3416 - val_accuracy: 0.6367\n",
      "Epoch 1502/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0098 - accuracy: 0.8493 - val_loss: 2.4033 - val_accuracy: 0.6279\n",
      "Epoch 1503/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0204 - accuracy: 0.8449 - val_loss: 2.3723 - val_accuracy: 0.6306\n",
      "Epoch 1504/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0189 - accuracy: 0.8453 - val_loss: 2.3674 - val_accuracy: 0.6338\n",
      "Epoch 1505/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0281 - accuracy: 0.8445 - val_loss: 2.3530 - val_accuracy: 0.6319\n",
      "Epoch 1506/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0198 - accuracy: 0.8433 - val_loss: 2.3688 - val_accuracy: 0.6326\n",
      "Epoch 1507/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0178 - accuracy: 0.8442 - val_loss: 2.3763 - val_accuracy: 0.6336\n",
      "Epoch 1508/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0481 - accuracy: 0.8394 - val_loss: 2.3426 - val_accuracy: 0.6340\n",
      "Epoch 1509/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0153 - accuracy: 0.8468 - val_loss: 2.3441 - val_accuracy: 0.6355\n",
      "Epoch 1510/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0192 - accuracy: 0.8438 - val_loss: 2.3021 - val_accuracy: 0.6375\n",
      "Epoch 1511/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0111 - accuracy: 0.8449 - val_loss: 2.3563 - val_accuracy: 0.6309\n",
      "Epoch 1512/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0335 - accuracy: 0.8422 - val_loss: 2.3609 - val_accuracy: 0.6307\n",
      "Epoch 1513/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0182 - accuracy: 0.8457 - val_loss: 2.3482 - val_accuracy: 0.6331\n",
      "Epoch 1514/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0228 - accuracy: 0.8465 - val_loss: 2.3151 - val_accuracy: 0.6346\n",
      "Epoch 1515/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0113 - accuracy: 0.8458 - val_loss: 2.3625 - val_accuracy: 0.6343\n",
      "Epoch 1516/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0183 - accuracy: 0.8470 - val_loss: 2.3067 - val_accuracy: 0.6394\n",
      "Epoch 1517/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0178 - accuracy: 0.8464 - val_loss: 2.3537 - val_accuracy: 0.6326\n",
      "Epoch 1518/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0117 - accuracy: 0.8469 - val_loss: 2.3974 - val_accuracy: 0.6279\n",
      "Epoch 1519/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0194 - accuracy: 0.8435 - val_loss: 2.3533 - val_accuracy: 0.6313\n",
      "Epoch 1520/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0126 - accuracy: 0.8466 - val_loss: 2.3703 - val_accuracy: 0.6318\n",
      "Epoch 1521/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0210 - accuracy: 0.8459 - val_loss: 2.3292 - val_accuracy: 0.6361\n",
      "Epoch 1522/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0087 - accuracy: 0.8482 - val_loss: 2.3651 - val_accuracy: 0.6308\n",
      "Epoch 1523/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0058 - accuracy: 0.8507 - val_loss: 2.3558 - val_accuracy: 0.6340\n",
      "Epoch 1524/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0167 - accuracy: 0.8455 - val_loss: 2.3253 - val_accuracy: 0.6363\n",
      "Epoch 1525/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0106 - accuracy: 0.8468 - val_loss: 2.3576 - val_accuracy: 0.6344\n",
      "Epoch 1526/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0060 - accuracy: 0.8507 - val_loss: 2.3222 - val_accuracy: 0.6376\n",
      "Epoch 1527/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0144 - accuracy: 0.8448 - val_loss: 2.3394 - val_accuracy: 0.6349\n",
      "Epoch 1528/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0210 - accuracy: 0.8445 - val_loss: 2.3557 - val_accuracy: 0.6359\n",
      "Epoch 1529/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0200 - accuracy: 0.8453 - val_loss: 2.3248 - val_accuracy: 0.6388\n",
      "Epoch 1530/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0150 - accuracy: 0.8475 - val_loss: 2.3246 - val_accuracy: 0.6381\n",
      "Epoch 1531/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0065 - accuracy: 0.8466 - val_loss: 2.3628 - val_accuracy: 0.6320\n",
      "Epoch 1532/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0083 - accuracy: 0.8466 - val_loss: 2.3160 - val_accuracy: 0.6377\n",
      "Epoch 1533/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0217 - accuracy: 0.8427 - val_loss: 2.3092 - val_accuracy: 0.6395\n",
      "Epoch 1534/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0159 - accuracy: 0.8484 - val_loss: 2.3970 - val_accuracy: 0.6282\n",
      "Epoch 1535/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0235 - accuracy: 0.8453 - val_loss: 2.3376 - val_accuracy: 0.6363\n",
      "Epoch 1536/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0120 - accuracy: 0.8468 - val_loss: 2.3246 - val_accuracy: 0.6389\n",
      "Epoch 1537/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0036 - accuracy: 0.8502 - val_loss: 2.3356 - val_accuracy: 0.6369\n",
      "Epoch 1538/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 1.0115 - accuracy: 0.8491 - val_loss: 2.3375 - val_accuracy: 0.6342\n",
      "Epoch 1539/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0101 - accuracy: 0.8459 - val_loss: 2.3221 - val_accuracy: 0.6403\n",
      "Epoch 1540/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0035 - accuracy: 0.8490 - val_loss: 2.3800 - val_accuracy: 0.6346\n",
      "Epoch 1541/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0063 - accuracy: 0.8517 - val_loss: 2.3678 - val_accuracy: 0.6293\n",
      "Epoch 1542/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0186 - accuracy: 0.8459 - val_loss: 2.3435 - val_accuracy: 0.6336\n",
      "Epoch 1543/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0092 - accuracy: 0.8432 - val_loss: 2.4025 - val_accuracy: 0.6273\n",
      "Epoch 1544/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0198 - accuracy: 0.8477 - val_loss: 2.3862 - val_accuracy: 0.6333\n",
      "Epoch 1545/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0343 - accuracy: 0.8466 - val_loss: 2.4013 - val_accuracy: 0.6268\n",
      "Epoch 1546/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0242 - accuracy: 0.8452 - val_loss: 2.3926 - val_accuracy: 0.6310\n",
      "Epoch 1547/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0133 - accuracy: 0.8455 - val_loss: 2.3636 - val_accuracy: 0.6364\n",
      "Epoch 1548/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0178 - accuracy: 0.8472 - val_loss: 2.3412 - val_accuracy: 0.6366\n",
      "Epoch 1549/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0122 - accuracy: 0.8466 - val_loss: 2.3469 - val_accuracy: 0.6342\n",
      "Epoch 1550/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0030 - accuracy: 0.8500 - val_loss: 2.3685 - val_accuracy: 0.6337\n",
      "Epoch 1551/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0061 - accuracy: 0.8492 - val_loss: 2.3602 - val_accuracy: 0.6346\n",
      "Epoch 1552/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0103 - accuracy: 0.8466 - val_loss: 2.3276 - val_accuracy: 0.6375\n",
      "Epoch 1553/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0085 - accuracy: 0.8500 - val_loss: 2.3302 - val_accuracy: 0.6328\n",
      "Epoch 1554/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9987 - accuracy: 0.8482 - val_loss: 2.3585 - val_accuracy: 0.6323\n",
      "Epoch 1555/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0056 - accuracy: 0.8457 - val_loss: 2.3202 - val_accuracy: 0.6367\n",
      "Epoch 1556/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0051 - accuracy: 0.8501 - val_loss: 2.3554 - val_accuracy: 0.6368\n",
      "Epoch 1557/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0076 - accuracy: 0.8502 - val_loss: 2.3775 - val_accuracy: 0.6283\n",
      "Epoch 1558/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0066 - accuracy: 0.8500 - val_loss: 2.3755 - val_accuracy: 0.6275\n",
      "Epoch 1559/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0161 - accuracy: 0.8450 - val_loss: 2.3920 - val_accuracy: 0.6289\n",
      "Epoch 1560/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0193 - accuracy: 0.8471 - val_loss: 2.3314 - val_accuracy: 0.6402\n",
      "Epoch 1561/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0073 - accuracy: 0.8492 - val_loss: 2.3243 - val_accuracy: 0.6355\n",
      "Epoch 1562/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0057 - accuracy: 0.8509 - val_loss: 2.4108 - val_accuracy: 0.6306\n",
      "Epoch 1563/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0113 - accuracy: 0.8470 - val_loss: 2.3546 - val_accuracy: 0.6305\n",
      "Epoch 1564/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0178 - accuracy: 0.8462 - val_loss: 2.3395 - val_accuracy: 0.6368\n",
      "Epoch 1565/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9996 - accuracy: 0.8499 - val_loss: 2.3428 - val_accuracy: 0.6355\n",
      "Epoch 1566/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0101 - accuracy: 0.8492 - val_loss: 2.4078 - val_accuracy: 0.6251\n",
      "Epoch 1567/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0108 - accuracy: 0.8506 - val_loss: 2.3127 - val_accuracy: 0.6414\n",
      "Epoch 1568/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0158 - accuracy: 0.8480 - val_loss: 2.3625 - val_accuracy: 0.6357\n",
      "Epoch 1569/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0105 - accuracy: 0.8465 - val_loss: 2.3469 - val_accuracy: 0.6321\n",
      "Epoch 1570/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0096 - accuracy: 0.8465 - val_loss: 2.3470 - val_accuracy: 0.6339\n",
      "Epoch 1571/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0092 - accuracy: 0.8472 - val_loss: 2.3756 - val_accuracy: 0.6313\n",
      "Epoch 1572/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0046 - accuracy: 0.8503 - val_loss: 2.3374 - val_accuracy: 0.6380\n",
      "Epoch 1573/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0064 - accuracy: 0.8491 - val_loss: 2.4122 - val_accuracy: 0.6264\n",
      "Epoch 1574/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0060 - accuracy: 0.8471 - val_loss: 2.3946 - val_accuracy: 0.6291\n",
      "Epoch 1575/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0100 - accuracy: 0.8479 - val_loss: 2.3775 - val_accuracy: 0.6285\n",
      "Epoch 1576/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0108 - accuracy: 0.8483 - val_loss: 2.3502 - val_accuracy: 0.6321\n",
      "Epoch 1577/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0030 - accuracy: 0.8504 - val_loss: 2.3674 - val_accuracy: 0.6281\n",
      "Epoch 1578/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0076 - accuracy: 0.8475 - val_loss: 2.3799 - val_accuracy: 0.6329\n",
      "Epoch 1579/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0149 - accuracy: 0.8452 - val_loss: 2.3561 - val_accuracy: 0.6346\n",
      "Epoch 1580/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0034 - accuracy: 0.8498 - val_loss: 2.3167 - val_accuracy: 0.6423\n",
      "Epoch 1581/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0064 - accuracy: 0.8504 - val_loss: 2.3896 - val_accuracy: 0.6314\n",
      "Epoch 1582/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0091 - accuracy: 0.8451 - val_loss: 2.3542 - val_accuracy: 0.6371\n",
      "Epoch 1583/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0112 - accuracy: 0.8461 - val_loss: 2.3363 - val_accuracy: 0.6352\n",
      "Epoch 1584/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0038 - accuracy: 0.8451 - val_loss: 2.3935 - val_accuracy: 0.6290\n",
      "Epoch 1585/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0090 - accuracy: 0.8462 - val_loss: 2.3761 - val_accuracy: 0.6315\n",
      "Epoch 1586/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0141 - accuracy: 0.8505 - val_loss: 2.3765 - val_accuracy: 0.6310\n",
      "Epoch 1587/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0153 - accuracy: 0.8472 - val_loss: 2.3342 - val_accuracy: 0.6400\n",
      "Epoch 1588/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0106 - accuracy: 0.8458 - val_loss: 2.3214 - val_accuracy: 0.6385\n",
      "Epoch 1589/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0038 - accuracy: 0.8508 - val_loss: 2.3269 - val_accuracy: 0.6401\n",
      "Epoch 1590/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0136 - accuracy: 0.8452 - val_loss: 2.3447 - val_accuracy: 0.6316\n",
      "Epoch 1591/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0091 - accuracy: 0.8497 - val_loss: 2.4050 - val_accuracy: 0.6320\n",
      "Epoch 1592/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0020 - accuracy: 0.8518 - val_loss: 2.4167 - val_accuracy: 0.6299\n",
      "Epoch 1593/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0171 - accuracy: 0.8477 - val_loss: 2.3590 - val_accuracy: 0.6367\n",
      "Epoch 1594/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0171 - accuracy: 0.8456 - val_loss: 2.3205 - val_accuracy: 0.6383\n",
      "Epoch 1595/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0047 - accuracy: 0.8482 - val_loss: 2.3260 - val_accuracy: 0.6367\n",
      "Epoch 1596/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0054 - accuracy: 0.8497 - val_loss: 2.3741 - val_accuracy: 0.6322\n",
      "Epoch 1597/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0043 - accuracy: 0.8484 - val_loss: 2.3590 - val_accuracy: 0.6342\n",
      "Epoch 1598/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0239 - accuracy: 0.8453 - val_loss: 2.3718 - val_accuracy: 0.6325\n",
      "Epoch 1599/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0008 - accuracy: 0.8499 - val_loss: 2.3742 - val_accuracy: 0.6353\n",
      "Epoch 1600/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0113 - accuracy: 0.8464 - val_loss: 2.3442 - val_accuracy: 0.6353\n",
      "Epoch 1601/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0042 - accuracy: 0.8493 - val_loss: 2.4061 - val_accuracy: 0.6260\n",
      "Epoch 1602/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0026 - accuracy: 0.8510 - val_loss: 2.3436 - val_accuracy: 0.6342\n",
      "Epoch 1603/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0121 - accuracy: 0.8491 - val_loss: 2.3596 - val_accuracy: 0.6337\n",
      "Epoch 1604/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0095 - accuracy: 0.8516 - val_loss: 2.4002 - val_accuracy: 0.6298\n",
      "Epoch 1605/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0206 - accuracy: 0.8457 - val_loss: 2.3606 - val_accuracy: 0.6289\n",
      "Epoch 1606/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0023 - accuracy: 0.8496 - val_loss: 2.3474 - val_accuracy: 0.6331\n",
      "Epoch 1607/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0162 - accuracy: 0.8464 - val_loss: 2.3826 - val_accuracy: 0.6298\n",
      "Epoch 1608/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0113 - accuracy: 0.8453 - val_loss: 2.3670 - val_accuracy: 0.6318\n",
      "Epoch 1609/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0100 - accuracy: 0.8447 - val_loss: 2.3388 - val_accuracy: 0.6348\n",
      "Epoch 1610/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0057 - accuracy: 0.8488 - val_loss: 2.3665 - val_accuracy: 0.6324\n",
      "Epoch 1611/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0001 - accuracy: 0.8493 - val_loss: 2.3549 - val_accuracy: 0.6367\n",
      "Epoch 1612/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0083 - accuracy: 0.8501 - val_loss: 2.3673 - val_accuracy: 0.6337\n",
      "Epoch 1613/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0068 - accuracy: 0.8475 - val_loss: 2.3922 - val_accuracy: 0.6286\n",
      "Epoch 1614/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0025 - accuracy: 0.8492 - val_loss: 2.3715 - val_accuracy: 0.6273\n",
      "Epoch 1615/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0221 - accuracy: 0.8479 - val_loss: 2.3925 - val_accuracy: 0.6232\n",
      "Epoch 1616/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0177 - accuracy: 0.8473 - val_loss: 2.3810 - val_accuracy: 0.6271\n",
      "Epoch 1617/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0070 - accuracy: 0.8496 - val_loss: 2.3849 - val_accuracy: 0.6305\n",
      "Epoch 1618/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0124 - accuracy: 0.8478 - val_loss: 2.3887 - val_accuracy: 0.6273\n",
      "Epoch 1619/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0013 - accuracy: 0.8511 - val_loss: 2.3740 - val_accuracy: 0.6337\n",
      "Epoch 1620/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0102 - accuracy: 0.8486 - val_loss: 2.3670 - val_accuracy: 0.6324\n",
      "Epoch 1621/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0064 - accuracy: 0.8495 - val_loss: 2.4092 - val_accuracy: 0.6258\n",
      "Epoch 1622/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0011 - accuracy: 0.8520 - val_loss: 2.4271 - val_accuracy: 0.6241\n",
      "Epoch 1623/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9955 - accuracy: 0.8503 - val_loss: 2.3410 - val_accuracy: 0.6357\n",
      "Epoch 1624/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0004 - accuracy: 0.8515 - val_loss: 2.3591 - val_accuracy: 0.6361\n",
      "Epoch 1625/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0046 - accuracy: 0.8498 - val_loss: 2.3855 - val_accuracy: 0.6283\n",
      "Epoch 1626/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9956 - accuracy: 0.8520 - val_loss: 2.3583 - val_accuracy: 0.6326\n",
      "Epoch 1627/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0010 - accuracy: 0.8507 - val_loss: 2.3523 - val_accuracy: 0.6382\n",
      "Epoch 1628/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9936 - accuracy: 0.8522 - val_loss: 2.3362 - val_accuracy: 0.6402\n",
      "Epoch 1629/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9995 - accuracy: 0.8489 - val_loss: 2.4054 - val_accuracy: 0.6331\n",
      "Epoch 1630/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0090 - accuracy: 0.8525 - val_loss: 2.3444 - val_accuracy: 0.6358\n",
      "Epoch 1631/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9942 - accuracy: 0.8516 - val_loss: 2.3769 - val_accuracy: 0.6331\n",
      "Epoch 1632/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0003 - accuracy: 0.8491 - val_loss: 2.3920 - val_accuracy: 0.6310\n",
      "Epoch 1633/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9930 - accuracy: 0.8520 - val_loss: 2.3370 - val_accuracy: 0.6349\n",
      "Epoch 1634/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0141 - accuracy: 0.8478 - val_loss: 2.3803 - val_accuracy: 0.6373\n",
      "Epoch 1635/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0132 - accuracy: 0.8507 - val_loss: 2.3971 - val_accuracy: 0.6324\n",
      "Epoch 1636/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9920 - accuracy: 0.8534 - val_loss: 2.3952 - val_accuracy: 0.6297\n",
      "Epoch 1637/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9923 - accuracy: 0.8496 - val_loss: 2.3759 - val_accuracy: 0.6356\n",
      "Epoch 1638/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0064 - accuracy: 0.8503 - val_loss: 2.3641 - val_accuracy: 0.6346\n",
      "Epoch 1639/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0100 - accuracy: 0.8481 - val_loss: 2.4033 - val_accuracy: 0.6323\n",
      "Epoch 1640/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9885 - accuracy: 0.8525 - val_loss: 2.3696 - val_accuracy: 0.6355\n",
      "Epoch 1641/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0098 - accuracy: 0.8457 - val_loss: 2.3814 - val_accuracy: 0.6316\n",
      "Epoch 1642/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9915 - accuracy: 0.8539 - val_loss: 2.3331 - val_accuracy: 0.6399\n",
      "Epoch 1643/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0004 - accuracy: 0.8507 - val_loss: 2.3534 - val_accuracy: 0.6396\n",
      "Epoch 1644/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9965 - accuracy: 0.8513 - val_loss: 2.3539 - val_accuracy: 0.6396\n",
      "Epoch 1645/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9958 - accuracy: 0.8518 - val_loss: 2.3613 - val_accuracy: 0.6355\n",
      "Epoch 1646/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9945 - accuracy: 0.8517 - val_loss: 2.3806 - val_accuracy: 0.6337\n",
      "Epoch 1647/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9894 - accuracy: 0.8543 - val_loss: 2.3458 - val_accuracy: 0.6391\n",
      "Epoch 1648/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9929 - accuracy: 0.8561 - val_loss: 2.3325 - val_accuracy: 0.6378\n",
      "Epoch 1649/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9882 - accuracy: 0.8545 - val_loss: 2.3606 - val_accuracy: 0.6364\n",
      "Epoch 1650/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9975 - accuracy: 0.8502 - val_loss: 2.3617 - val_accuracy: 0.6345\n",
      "Epoch 1651/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9997 - accuracy: 0.8531 - val_loss: 2.3662 - val_accuracy: 0.6349\n",
      "Epoch 1652/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0020 - accuracy: 0.8493 - val_loss: 2.3995 - val_accuracy: 0.6285\n",
      "Epoch 1653/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9915 - accuracy: 0.8527 - val_loss: 2.3573 - val_accuracy: 0.6390\n",
      "Epoch 1654/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0045 - accuracy: 0.8492 - val_loss: 2.3525 - val_accuracy: 0.6384\n",
      "Epoch 1655/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9959 - accuracy: 0.8543 - val_loss: 2.3535 - val_accuracy: 0.6381\n",
      "Epoch 1656/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0093 - accuracy: 0.8484 - val_loss: 2.4399 - val_accuracy: 0.6235\n",
      "Epoch 1657/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0217 - accuracy: 0.8507 - val_loss: 2.3569 - val_accuracy: 0.6333\n",
      "Epoch 1658/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0052 - accuracy: 0.8498 - val_loss: 2.4145 - val_accuracy: 0.6282\n",
      "Epoch 1659/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9970 - accuracy: 0.8492 - val_loss: 2.3737 - val_accuracy: 0.6310\n",
      "Epoch 1660/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0050 - accuracy: 0.8500 - val_loss: 2.3519 - val_accuracy: 0.6365\n",
      "Epoch 1661/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9896 - accuracy: 0.8532 - val_loss: 2.4092 - val_accuracy: 0.6292\n",
      "Epoch 1662/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9984 - accuracy: 0.8491 - val_loss: 2.3744 - val_accuracy: 0.6346\n",
      "Epoch 1663/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9985 - accuracy: 0.8539 - val_loss: 2.3577 - val_accuracy: 0.6350\n",
      "Epoch 1664/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9811 - accuracy: 0.8556 - val_loss: 2.3267 - val_accuracy: 0.6403\n",
      "Epoch 1665/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0073 - accuracy: 0.8472 - val_loss: 2.3723 - val_accuracy: 0.6358\n",
      "Epoch 1666/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0054 - accuracy: 0.8500 - val_loss: 2.3411 - val_accuracy: 0.6355\n",
      "Epoch 1667/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0044 - accuracy: 0.8487 - val_loss: 2.3499 - val_accuracy: 0.6389\n",
      "Epoch 1668/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0007 - accuracy: 0.8486 - val_loss: 2.3554 - val_accuracy: 0.6389\n",
      "Epoch 1669/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0111 - accuracy: 0.8500 - val_loss: 2.3514 - val_accuracy: 0.6386\n",
      "Epoch 1670/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0021 - accuracy: 0.8506 - val_loss: 2.3825 - val_accuracy: 0.6332\n",
      "Epoch 1671/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9989 - accuracy: 0.8497 - val_loss: 2.4062 - val_accuracy: 0.6317\n",
      "Epoch 1672/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9947 - accuracy: 0.8509 - val_loss: 2.3854 - val_accuracy: 0.6335\n",
      "Epoch 1673/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9906 - accuracy: 0.8504 - val_loss: 2.3682 - val_accuracy: 0.6395\n",
      "Epoch 1674/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9963 - accuracy: 0.8523 - val_loss: 2.3740 - val_accuracy: 0.6355\n",
      "Epoch 1675/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0008 - accuracy: 0.8551 - val_loss: 2.3377 - val_accuracy: 0.6384\n",
      "Epoch 1676/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0042 - accuracy: 0.8533 - val_loss: 2.3925 - val_accuracy: 0.6377\n",
      "Epoch 1677/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9989 - accuracy: 0.8524 - val_loss: 2.3870 - val_accuracy: 0.6376\n",
      "Epoch 1678/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 1.0023 - accuracy: 0.8498 - val_loss: 2.3477 - val_accuracy: 0.6402\n",
      "Epoch 1679/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9932 - accuracy: 0.8518 - val_loss: 2.3672 - val_accuracy: 0.6379\n",
      "Epoch 1680/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9958 - accuracy: 0.8486 - val_loss: 2.3399 - val_accuracy: 0.6373\n",
      "Epoch 1681/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9946 - accuracy: 0.8518 - val_loss: 2.3319 - val_accuracy: 0.6395\n",
      "Epoch 1682/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9763 - accuracy: 0.8569 - val_loss: 2.3516 - val_accuracy: 0.6405\n",
      "Epoch 1683/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9944 - accuracy: 0.8514 - val_loss: 2.3679 - val_accuracy: 0.6350\n",
      "Epoch 1684/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9896 - accuracy: 0.8533 - val_loss: 2.3837 - val_accuracy: 0.6363\n",
      "Epoch 1685/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9920 - accuracy: 0.8554 - val_loss: 2.3910 - val_accuracy: 0.6336\n",
      "Epoch 1686/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9983 - accuracy: 0.8503 - val_loss: 2.3804 - val_accuracy: 0.6335\n",
      "Epoch 1687/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 1.0005 - accuracy: 0.8509 - val_loss: 2.3685 - val_accuracy: 0.6347\n",
      "Epoch 1688/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9996 - accuracy: 0.8513 - val_loss: 2.3538 - val_accuracy: 0.6374\n",
      "Epoch 1689/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0054 - accuracy: 0.8483 - val_loss: 2.4030 - val_accuracy: 0.6338\n",
      "Epoch 1690/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9941 - accuracy: 0.8524 - val_loss: 2.3912 - val_accuracy: 0.6372\n",
      "Epoch 1691/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9989 - accuracy: 0.8522 - val_loss: 2.3487 - val_accuracy: 0.6369\n",
      "Epoch 1692/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9892 - accuracy: 0.8530 - val_loss: 2.3486 - val_accuracy: 0.6411\n",
      "Epoch 1693/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9974 - accuracy: 0.8543 - val_loss: 2.3804 - val_accuracy: 0.6341\n",
      "Epoch 1694/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9873 - accuracy: 0.8536 - val_loss: 2.3307 - val_accuracy: 0.6416\n",
      "Epoch 1695/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9951 - accuracy: 0.8524 - val_loss: 2.3784 - val_accuracy: 0.6347\n",
      "Epoch 1696/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9948 - accuracy: 0.8531 - val_loss: 2.3620 - val_accuracy: 0.6363\n",
      "Epoch 1697/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9910 - accuracy: 0.8532 - val_loss: 2.3110 - val_accuracy: 0.6406\n",
      "Epoch 1698/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9862 - accuracy: 0.8517 - val_loss: 2.3551 - val_accuracy: 0.6357\n",
      "Epoch 1699/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9989 - accuracy: 0.8509 - val_loss: 2.3896 - val_accuracy: 0.6339\n",
      "Epoch 1700/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0012 - accuracy: 0.8495 - val_loss: 2.4079 - val_accuracy: 0.6292\n",
      "Epoch 1701/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9917 - accuracy: 0.8532 - val_loss: 2.4293 - val_accuracy: 0.6288\n",
      "Epoch 1702/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9910 - accuracy: 0.8522 - val_loss: 2.3845 - val_accuracy: 0.6357\n",
      "Epoch 1703/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9921 - accuracy: 0.8530 - val_loss: 2.3820 - val_accuracy: 0.6292\n",
      "Epoch 1704/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9929 - accuracy: 0.8531 - val_loss: 2.3788 - val_accuracy: 0.6324\n",
      "Epoch 1705/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9961 - accuracy: 0.8521 - val_loss: 2.3466 - val_accuracy: 0.6385\n",
      "Epoch 1706/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9982 - accuracy: 0.8548 - val_loss: 2.3625 - val_accuracy: 0.6338\n",
      "Epoch 1707/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9859 - accuracy: 0.8549 - val_loss: 2.3504 - val_accuracy: 0.6396\n",
      "Epoch 1708/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9964 - accuracy: 0.8527 - val_loss: 2.4146 - val_accuracy: 0.6284\n",
      "Epoch 1709/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9983 - accuracy: 0.8541 - val_loss: 2.3696 - val_accuracy: 0.6357\n",
      "Epoch 1710/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9901 - accuracy: 0.8519 - val_loss: 2.3480 - val_accuracy: 0.6383\n",
      "Epoch 1711/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9991 - accuracy: 0.8504 - val_loss: 2.3720 - val_accuracy: 0.6339\n",
      "Epoch 1712/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9909 - accuracy: 0.8526 - val_loss: 2.4137 - val_accuracy: 0.6352\n",
      "Epoch 1713/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0015 - accuracy: 0.8509 - val_loss: 2.4226 - val_accuracy: 0.6330\n",
      "Epoch 1714/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9966 - accuracy: 0.8532 - val_loss: 2.3727 - val_accuracy: 0.6319\n",
      "Epoch 1715/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9980 - accuracy: 0.8511 - val_loss: 2.3568 - val_accuracy: 0.6422\n",
      "Epoch 1716/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9953 - accuracy: 0.8521 - val_loss: 2.3934 - val_accuracy: 0.6321\n",
      "Epoch 1717/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9894 - accuracy: 0.8526 - val_loss: 2.3685 - val_accuracy: 0.6357\n",
      "Epoch 1718/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9940 - accuracy: 0.8532 - val_loss: 2.3526 - val_accuracy: 0.6345\n",
      "Epoch 1719/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0057 - accuracy: 0.8531 - val_loss: 2.4492 - val_accuracy: 0.6317\n",
      "Epoch 1720/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0043 - accuracy: 0.8519 - val_loss: 2.3464 - val_accuracy: 0.6363\n",
      "Epoch 1721/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9978 - accuracy: 0.8527 - val_loss: 2.3930 - val_accuracy: 0.6327\n",
      "Epoch 1722/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9952 - accuracy: 0.8511 - val_loss: 2.3980 - val_accuracy: 0.6291\n",
      "Epoch 1723/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9905 - accuracy: 0.8523 - val_loss: 2.3733 - val_accuracy: 0.6317\n",
      "Epoch 1724/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9872 - accuracy: 0.8543 - val_loss: 2.3595 - val_accuracy: 0.6382\n",
      "Epoch 1725/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9938 - accuracy: 0.8522 - val_loss: 2.3737 - val_accuracy: 0.6391\n",
      "Epoch 1726/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9900 - accuracy: 0.8521 - val_loss: 2.3624 - val_accuracy: 0.6365\n",
      "Epoch 1727/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9935 - accuracy: 0.8516 - val_loss: 2.3953 - val_accuracy: 0.6326\n",
      "Epoch 1728/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9946 - accuracy: 0.8539 - val_loss: 2.3366 - val_accuracy: 0.6378\n",
      "Epoch 1729/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9942 - accuracy: 0.8503 - val_loss: 2.3980 - val_accuracy: 0.6281\n",
      "Epoch 1730/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9873 - accuracy: 0.8525 - val_loss: 2.3589 - val_accuracy: 0.6390\n",
      "Epoch 1731/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0020 - accuracy: 0.8511 - val_loss: 2.3491 - val_accuracy: 0.6363\n",
      "Epoch 1732/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9915 - accuracy: 0.8507 - val_loss: 2.3466 - val_accuracy: 0.6386\n",
      "Epoch 1733/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9796 - accuracy: 0.8563 - val_loss: 2.4048 - val_accuracy: 0.6325\n",
      "Epoch 1734/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9735 - accuracy: 0.8580 - val_loss: 2.3636 - val_accuracy: 0.6373\n",
      "Epoch 1735/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9842 - accuracy: 0.8533 - val_loss: 2.4119 - val_accuracy: 0.6302\n",
      "Epoch 1736/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9919 - accuracy: 0.8535 - val_loss: 2.3603 - val_accuracy: 0.6391\n",
      "Epoch 1737/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9888 - accuracy: 0.8538 - val_loss: 2.4106 - val_accuracy: 0.6298\n",
      "Epoch 1738/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0057 - accuracy: 0.8504 - val_loss: 2.3637 - val_accuracy: 0.6370\n",
      "Epoch 1739/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0025 - accuracy: 0.8487 - val_loss: 2.3399 - val_accuracy: 0.6379\n",
      "Epoch 1740/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9816 - accuracy: 0.8540 - val_loss: 2.3758 - val_accuracy: 0.6361\n",
      "Epoch 1741/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0000 - accuracy: 0.8500 - val_loss: 2.3759 - val_accuracy: 0.6382\n",
      "Epoch 1742/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9919 - accuracy: 0.8550 - val_loss: 2.4106 - val_accuracy: 0.6326\n",
      "Epoch 1743/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9849 - accuracy: 0.8541 - val_loss: 2.3890 - val_accuracy: 0.6344\n",
      "Epoch 1744/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9858 - accuracy: 0.8535 - val_loss: 2.3701 - val_accuracy: 0.6395\n",
      "Epoch 1745/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0015 - accuracy: 0.8479 - val_loss: 2.3664 - val_accuracy: 0.6367\n",
      "Epoch 1746/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9869 - accuracy: 0.8532 - val_loss: 2.3545 - val_accuracy: 0.6409\n",
      "Epoch 1747/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9856 - accuracy: 0.8555 - val_loss: 2.3698 - val_accuracy: 0.6395\n",
      "Epoch 1748/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9954 - accuracy: 0.8517 - val_loss: 2.3387 - val_accuracy: 0.6438\n",
      "Epoch 1749/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9908 - accuracy: 0.8550 - val_loss: 2.4059 - val_accuracy: 0.6358\n",
      "Epoch 1750/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9945 - accuracy: 0.8539 - val_loss: 2.3220 - val_accuracy: 0.6433\n",
      "Epoch 1751/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9833 - accuracy: 0.8540 - val_loss: 2.3510 - val_accuracy: 0.6422\n",
      "Epoch 1752/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9965 - accuracy: 0.8519 - val_loss: 2.3625 - val_accuracy: 0.6374\n",
      "Epoch 1753/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0074 - accuracy: 0.8510 - val_loss: 2.3930 - val_accuracy: 0.6367\n",
      "Epoch 1754/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9946 - accuracy: 0.8542 - val_loss: 2.3569 - val_accuracy: 0.6372\n",
      "Epoch 1755/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9859 - accuracy: 0.8532 - val_loss: 2.3454 - val_accuracy: 0.6436\n",
      "Epoch 1756/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9826 - accuracy: 0.8528 - val_loss: 2.3796 - val_accuracy: 0.6360\n",
      "Epoch 1757/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9904 - accuracy: 0.8571 - val_loss: 2.3834 - val_accuracy: 0.6343\n",
      "Epoch 1758/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9984 - accuracy: 0.8526 - val_loss: 2.4065 - val_accuracy: 0.6337\n",
      "Epoch 1759/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0009 - accuracy: 0.8509 - val_loss: 2.4166 - val_accuracy: 0.6288\n",
      "Epoch 1760/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9779 - accuracy: 0.8581 - val_loss: 2.3188 - val_accuracy: 0.6452\n",
      "Epoch 1761/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9849 - accuracy: 0.8554 - val_loss: 2.3637 - val_accuracy: 0.6357\n",
      "Epoch 1762/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9854 - accuracy: 0.8555 - val_loss: 2.3705 - val_accuracy: 0.6354\n",
      "Epoch 1763/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9831 - accuracy: 0.8571 - val_loss: 2.4150 - val_accuracy: 0.6330\n",
      "Epoch 1764/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9923 - accuracy: 0.8509 - val_loss: 2.4080 - val_accuracy: 0.6323\n",
      "Epoch 1765/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9893 - accuracy: 0.8555 - val_loss: 2.4169 - val_accuracy: 0.6315\n",
      "Epoch 1766/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9934 - accuracy: 0.8522 - val_loss: 2.4401 - val_accuracy: 0.6304\n",
      "Epoch 1767/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9879 - accuracy: 0.8551 - val_loss: 2.3879 - val_accuracy: 0.6337\n",
      "Epoch 1768/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9892 - accuracy: 0.8541 - val_loss: 2.4065 - val_accuracy: 0.6281\n",
      "Epoch 1769/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9857 - accuracy: 0.8541 - val_loss: 2.3809 - val_accuracy: 0.6365\n",
      "Epoch 1770/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9762 - accuracy: 0.8598 - val_loss: 2.3597 - val_accuracy: 0.6402\n",
      "Epoch 1771/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9796 - accuracy: 0.8552 - val_loss: 2.3659 - val_accuracy: 0.6396\n",
      "Epoch 1772/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9935 - accuracy: 0.8526 - val_loss: 2.3320 - val_accuracy: 0.6402\n",
      "Epoch 1773/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9866 - accuracy: 0.8551 - val_loss: 2.3898 - val_accuracy: 0.6378\n",
      "Epoch 1774/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 1.0147 - accuracy: 0.8496 - val_loss: 2.3593 - val_accuracy: 0.6392\n",
      "Epoch 1775/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9888 - accuracy: 0.8542 - val_loss: 2.3384 - val_accuracy: 0.6414\n",
      "Epoch 1776/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9797 - accuracy: 0.8578 - val_loss: 2.4433 - val_accuracy: 0.6338\n",
      "Epoch 1777/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 1.0017 - accuracy: 0.8531 - val_loss: 2.3565 - val_accuracy: 0.6372\n",
      "Epoch 1778/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9881 - accuracy: 0.8517 - val_loss: 2.4074 - val_accuracy: 0.6388\n",
      "Epoch 1779/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9952 - accuracy: 0.8546 - val_loss: 2.3707 - val_accuracy: 0.6347\n",
      "Epoch 1780/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9877 - accuracy: 0.8517 - val_loss: 2.3868 - val_accuracy: 0.6312\n",
      "Epoch 1781/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9836 - accuracy: 0.8572 - val_loss: 2.3976 - val_accuracy: 0.6353\n",
      "Epoch 1782/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9828 - accuracy: 0.8579 - val_loss: 2.3685 - val_accuracy: 0.6385\n",
      "Epoch 1783/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9873 - accuracy: 0.8533 - val_loss: 2.3807 - val_accuracy: 0.6359\n",
      "Epoch 1784/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9748 - accuracy: 0.8560 - val_loss: 2.3571 - val_accuracy: 0.6370\n",
      "Epoch 1785/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 1.0008 - accuracy: 0.8543 - val_loss: 2.3986 - val_accuracy: 0.6343\n",
      "Epoch 1786/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9866 - accuracy: 0.8556 - val_loss: 2.3687 - val_accuracy: 0.6421\n",
      "Epoch 1787/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9827 - accuracy: 0.8563 - val_loss: 2.3482 - val_accuracy: 0.6439\n",
      "Epoch 1788/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9984 - accuracy: 0.8544 - val_loss: 2.3836 - val_accuracy: 0.6398\n",
      "Epoch 1789/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9825 - accuracy: 0.8569 - val_loss: 2.3791 - val_accuracy: 0.6319\n",
      "Epoch 1790/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9829 - accuracy: 0.8554 - val_loss: 2.3863 - val_accuracy: 0.6373\n",
      "Epoch 1791/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9869 - accuracy: 0.8560 - val_loss: 2.3988 - val_accuracy: 0.6390\n",
      "Epoch 1792/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9891 - accuracy: 0.8540 - val_loss: 2.3558 - val_accuracy: 0.6394\n",
      "Epoch 1793/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9859 - accuracy: 0.8551 - val_loss: 2.4014 - val_accuracy: 0.6313\n",
      "Epoch 1794/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9794 - accuracy: 0.8550 - val_loss: 2.3670 - val_accuracy: 0.6406\n",
      "Epoch 1795/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9944 - accuracy: 0.8517 - val_loss: 2.4159 - val_accuracy: 0.6293\n",
      "Epoch 1796/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9849 - accuracy: 0.8560 - val_loss: 2.3265 - val_accuracy: 0.6390\n",
      "Epoch 1797/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9893 - accuracy: 0.8557 - val_loss: 2.4032 - val_accuracy: 0.6346\n",
      "Epoch 1798/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9914 - accuracy: 0.8561 - val_loss: 2.3868 - val_accuracy: 0.6381\n",
      "Epoch 1799/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9909 - accuracy: 0.8523 - val_loss: 2.3846 - val_accuracy: 0.6390\n",
      "Epoch 1800/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9784 - accuracy: 0.8572 - val_loss: 2.3740 - val_accuracy: 0.6357\n",
      "Epoch 1801/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9956 - accuracy: 0.8554 - val_loss: 2.4115 - val_accuracy: 0.6311\n",
      "Epoch 1802/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9763 - accuracy: 0.8560 - val_loss: 2.4147 - val_accuracy: 0.6350\n",
      "Epoch 1803/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9963 - accuracy: 0.8509 - val_loss: 2.4102 - val_accuracy: 0.6338\n",
      "Epoch 1804/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9874 - accuracy: 0.8576 - val_loss: 2.3758 - val_accuracy: 0.6372\n",
      "Epoch 1805/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9938 - accuracy: 0.8567 - val_loss: 2.3545 - val_accuracy: 0.6389\n",
      "Epoch 1806/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9816 - accuracy: 0.8549 - val_loss: 2.3670 - val_accuracy: 0.6348\n",
      "Epoch 1807/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9891 - accuracy: 0.8577 - val_loss: 2.3464 - val_accuracy: 0.6424\n",
      "Epoch 1808/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9913 - accuracy: 0.8540 - val_loss: 2.3600 - val_accuracy: 0.6380\n",
      "Epoch 1809/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9848 - accuracy: 0.8529 - val_loss: 2.3971 - val_accuracy: 0.6336\n",
      "Epoch 1810/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9720 - accuracy: 0.8596 - val_loss: 2.4150 - val_accuracy: 0.6310\n",
      "Epoch 1811/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9713 - accuracy: 0.8601 - val_loss: 2.3899 - val_accuracy: 0.6367\n",
      "Epoch 1812/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9752 - accuracy: 0.8583 - val_loss: 2.4039 - val_accuracy: 0.6368\n",
      "Epoch 1813/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9955 - accuracy: 0.8556 - val_loss: 2.3947 - val_accuracy: 0.6352\n",
      "Epoch 1814/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9856 - accuracy: 0.8560 - val_loss: 2.3829 - val_accuracy: 0.6348\n",
      "Epoch 1815/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9833 - accuracy: 0.8553 - val_loss: 2.3439 - val_accuracy: 0.6425\n",
      "Epoch 1816/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9812 - accuracy: 0.8546 - val_loss: 2.3759 - val_accuracy: 0.6361\n",
      "Epoch 1817/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9899 - accuracy: 0.8570 - val_loss: 2.3638 - val_accuracy: 0.6401\n",
      "Epoch 1818/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9779 - accuracy: 0.8573 - val_loss: 2.3859 - val_accuracy: 0.6317\n",
      "Epoch 1819/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9910 - accuracy: 0.8515 - val_loss: 2.3652 - val_accuracy: 0.6368\n",
      "Epoch 1820/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9941 - accuracy: 0.8565 - val_loss: 2.4046 - val_accuracy: 0.6358\n",
      "Epoch 1821/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9840 - accuracy: 0.8550 - val_loss: 2.3751 - val_accuracy: 0.6374\n",
      "Epoch 1822/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9804 - accuracy: 0.8546 - val_loss: 2.3981 - val_accuracy: 0.6309\n",
      "Epoch 1823/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9838 - accuracy: 0.8545 - val_loss: 2.3882 - val_accuracy: 0.6370\n",
      "Epoch 1824/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9806 - accuracy: 0.8564 - val_loss: 2.3500 - val_accuracy: 0.6406\n",
      "Epoch 1825/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9815 - accuracy: 0.8556 - val_loss: 2.3323 - val_accuracy: 0.6444\n",
      "Epoch 1826/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9865 - accuracy: 0.8564 - val_loss: 2.3716 - val_accuracy: 0.6376\n",
      "Epoch 1827/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9700 - accuracy: 0.8596 - val_loss: 2.3709 - val_accuracy: 0.6367\n",
      "Epoch 1828/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9841 - accuracy: 0.8532 - val_loss: 2.3721 - val_accuracy: 0.6379\n",
      "Epoch 1829/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9748 - accuracy: 0.8588 - val_loss: 2.3732 - val_accuracy: 0.6380\n",
      "Epoch 1830/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9765 - accuracy: 0.8569 - val_loss: 2.3658 - val_accuracy: 0.6402\n",
      "Epoch 1831/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9888 - accuracy: 0.8541 - val_loss: 2.3648 - val_accuracy: 0.6351\n",
      "Epoch 1832/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9773 - accuracy: 0.8553 - val_loss: 2.3743 - val_accuracy: 0.6344\n",
      "Epoch 1833/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9894 - accuracy: 0.8532 - val_loss: 2.3773 - val_accuracy: 0.6389\n",
      "Epoch 1834/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9812 - accuracy: 0.8572 - val_loss: 2.3758 - val_accuracy: 0.6392\n",
      "Epoch 1835/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9927 - accuracy: 0.8537 - val_loss: 2.3775 - val_accuracy: 0.6360\n",
      "Epoch 1836/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9819 - accuracy: 0.8578 - val_loss: 2.3805 - val_accuracy: 0.6364\n",
      "Epoch 1837/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9966 - accuracy: 0.8574 - val_loss: 2.3780 - val_accuracy: 0.6372\n",
      "Epoch 1838/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9685 - accuracy: 0.8577 - val_loss: 2.3227 - val_accuracy: 0.6404\n",
      "Epoch 1839/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9839 - accuracy: 0.8544 - val_loss: 2.3579 - val_accuracy: 0.6377\n",
      "Epoch 1840/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9636 - accuracy: 0.8587 - val_loss: 2.4050 - val_accuracy: 0.6283\n",
      "Epoch 1841/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9858 - accuracy: 0.8553 - val_loss: 2.3777 - val_accuracy: 0.6363\n",
      "Epoch 1842/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9782 - accuracy: 0.8551 - val_loss: 2.3517 - val_accuracy: 0.6376\n",
      "Epoch 1843/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9772 - accuracy: 0.8574 - val_loss: 2.3871 - val_accuracy: 0.6372\n",
      "Epoch 1844/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9756 - accuracy: 0.8544 - val_loss: 2.3654 - val_accuracy: 0.6327\n",
      "Epoch 1845/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9782 - accuracy: 0.8552 - val_loss: 2.4010 - val_accuracy: 0.6315\n",
      "Epoch 1846/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9959 - accuracy: 0.8521 - val_loss: 2.4101 - val_accuracy: 0.6348\n",
      "Epoch 1847/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9936 - accuracy: 0.8543 - val_loss: 2.3416 - val_accuracy: 0.6447\n",
      "Epoch 1848/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9873 - accuracy: 0.8541 - val_loss: 2.3372 - val_accuracy: 0.6399\n",
      "Epoch 1849/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9889 - accuracy: 0.8570 - val_loss: 2.3952 - val_accuracy: 0.6362\n",
      "Epoch 1850/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9905 - accuracy: 0.8543 - val_loss: 2.3359 - val_accuracy: 0.6429\n",
      "Epoch 1851/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9908 - accuracy: 0.8529 - val_loss: 2.3750 - val_accuracy: 0.6382\n",
      "Epoch 1852/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9716 - accuracy: 0.8581 - val_loss: 2.3657 - val_accuracy: 0.6384\n",
      "Epoch 1853/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9960 - accuracy: 0.8539 - val_loss: 2.3867 - val_accuracy: 0.6395\n",
      "Epoch 1854/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9858 - accuracy: 0.8570 - val_loss: 2.3532 - val_accuracy: 0.6425\n",
      "Epoch 1855/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9730 - accuracy: 0.8551 - val_loss: 2.3802 - val_accuracy: 0.6398\n",
      "Epoch 1856/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9821 - accuracy: 0.8546 - val_loss: 2.3734 - val_accuracy: 0.6379\n",
      "Epoch 1857/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9728 - accuracy: 0.8588 - val_loss: 2.2877 - val_accuracy: 0.6454\n",
      "Epoch 1858/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9729 - accuracy: 0.8589 - val_loss: 2.2930 - val_accuracy: 0.6475\n",
      "Epoch 1859/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 1.0018 - accuracy: 0.8521 - val_loss: 2.3283 - val_accuracy: 0.6438\n",
      "Epoch 1860/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9923 - accuracy: 0.8542 - val_loss: 2.3795 - val_accuracy: 0.6378\n",
      "Epoch 1861/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9851 - accuracy: 0.8560 - val_loss: 2.3668 - val_accuracy: 0.6407\n",
      "Epoch 1862/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9981 - accuracy: 0.8572 - val_loss: 2.3100 - val_accuracy: 0.6431\n",
      "Epoch 1863/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9866 - accuracy: 0.8543 - val_loss: 2.3073 - val_accuracy: 0.6481\n",
      "Epoch 1864/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9810 - accuracy: 0.8557 - val_loss: 2.3414 - val_accuracy: 0.6420\n",
      "Epoch 1865/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9654 - accuracy: 0.8612 - val_loss: 2.3448 - val_accuracy: 0.6426\n",
      "Epoch 1866/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9848 - accuracy: 0.8561 - val_loss: 2.3567 - val_accuracy: 0.6383\n",
      "Epoch 1867/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9803 - accuracy: 0.8564 - val_loss: 2.3952 - val_accuracy: 0.6336\n",
      "Epoch 1868/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9771 - accuracy: 0.8568 - val_loss: 2.3751 - val_accuracy: 0.6357\n",
      "Epoch 1869/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9802 - accuracy: 0.8563 - val_loss: 2.3663 - val_accuracy: 0.6349\n",
      "Epoch 1870/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9780 - accuracy: 0.8556 - val_loss: 2.3615 - val_accuracy: 0.6426\n",
      "Epoch 1871/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9838 - accuracy: 0.8523 - val_loss: 2.3958 - val_accuracy: 0.6337\n",
      "Epoch 1872/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9784 - accuracy: 0.8567 - val_loss: 2.3370 - val_accuracy: 0.6423\n",
      "Epoch 1873/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9803 - accuracy: 0.8552 - val_loss: 2.3488 - val_accuracy: 0.6420\n",
      "Epoch 1874/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9745 - accuracy: 0.8566 - val_loss: 2.3565 - val_accuracy: 0.6374\n",
      "Epoch 1875/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9830 - accuracy: 0.8556 - val_loss: 2.3521 - val_accuracy: 0.6387\n",
      "Epoch 1876/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9917 - accuracy: 0.8578 - val_loss: 2.4216 - val_accuracy: 0.6342\n",
      "Epoch 1877/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9796 - accuracy: 0.8553 - val_loss: 2.3988 - val_accuracy: 0.6358\n",
      "Epoch 1878/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9783 - accuracy: 0.8570 - val_loss: 2.3798 - val_accuracy: 0.6371\n",
      "Epoch 1879/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9716 - accuracy: 0.8594 - val_loss: 2.3554 - val_accuracy: 0.6372\n",
      "Epoch 1880/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9800 - accuracy: 0.8544 - val_loss: 2.3778 - val_accuracy: 0.6401\n",
      "Epoch 1881/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9775 - accuracy: 0.8558 - val_loss: 2.3748 - val_accuracy: 0.6390\n",
      "Epoch 1882/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9742 - accuracy: 0.8578 - val_loss: 2.3571 - val_accuracy: 0.6407\n",
      "Epoch 1883/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9728 - accuracy: 0.8598 - val_loss: 2.3588 - val_accuracy: 0.6382\n",
      "Epoch 1884/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9800 - accuracy: 0.8592 - val_loss: 2.3455 - val_accuracy: 0.6437\n",
      "Epoch 1885/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9822 - accuracy: 0.8554 - val_loss: 2.4066 - val_accuracy: 0.6317\n",
      "Epoch 1886/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9806 - accuracy: 0.8562 - val_loss: 2.3531 - val_accuracy: 0.6404\n",
      "Epoch 1887/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9720 - accuracy: 0.8590 - val_loss: 2.3764 - val_accuracy: 0.6388\n",
      "Epoch 1888/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9669 - accuracy: 0.8597 - val_loss: 2.3915 - val_accuracy: 0.6375\n",
      "Epoch 1889/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9759 - accuracy: 0.8589 - val_loss: 2.4252 - val_accuracy: 0.6330\n",
      "Epoch 1890/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9831 - accuracy: 0.8557 - val_loss: 2.3584 - val_accuracy: 0.6424\n",
      "Epoch 1891/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9864 - accuracy: 0.8525 - val_loss: 2.3477 - val_accuracy: 0.6462\n",
      "Epoch 1892/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9681 - accuracy: 0.8589 - val_loss: 2.3990 - val_accuracy: 0.6359\n",
      "Epoch 1893/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9747 - accuracy: 0.8570 - val_loss: 2.3375 - val_accuracy: 0.6420\n",
      "Epoch 1894/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9756 - accuracy: 0.8551 - val_loss: 2.3208 - val_accuracy: 0.6454\n",
      "Epoch 1895/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9715 - accuracy: 0.8584 - val_loss: 2.3618 - val_accuracy: 0.6384\n",
      "Epoch 1896/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9896 - accuracy: 0.8558 - val_loss: 2.3738 - val_accuracy: 0.6389\n",
      "Epoch 1897/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9645 - accuracy: 0.8607 - val_loss: 2.3576 - val_accuracy: 0.6420\n",
      "Epoch 1898/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9929 - accuracy: 0.8550 - val_loss: 2.4390 - val_accuracy: 0.6290\n",
      "Epoch 1899/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9674 - accuracy: 0.8589 - val_loss: 2.3682 - val_accuracy: 0.6363\n",
      "Epoch 1900/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9726 - accuracy: 0.8576 - val_loss: 2.3435 - val_accuracy: 0.6400\n",
      "Epoch 1901/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9771 - accuracy: 0.8575 - val_loss: 2.3812 - val_accuracy: 0.6371\n",
      "Epoch 1902/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9878 - accuracy: 0.8554 - val_loss: 2.4477 - val_accuracy: 0.6295\n",
      "Epoch 1903/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9820 - accuracy: 0.8581 - val_loss: 2.3861 - val_accuracy: 0.6355\n",
      "Epoch 1904/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9797 - accuracy: 0.8559 - val_loss: 2.3290 - val_accuracy: 0.6434\n",
      "Epoch 1905/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9674 - accuracy: 0.8601 - val_loss: 2.3732 - val_accuracy: 0.6381\n",
      "Epoch 1906/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9806 - accuracy: 0.8584 - val_loss: 2.3673 - val_accuracy: 0.6379\n",
      "Epoch 1907/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9731 - accuracy: 0.8595 - val_loss: 2.3885 - val_accuracy: 0.6342\n",
      "Epoch 1908/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9816 - accuracy: 0.8566 - val_loss: 2.3903 - val_accuracy: 0.6329\n",
      "Epoch 1909/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9801 - accuracy: 0.8578 - val_loss: 2.3642 - val_accuracy: 0.6404\n",
      "Epoch 1910/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9671 - accuracy: 0.8595 - val_loss: 2.3723 - val_accuracy: 0.6344\n",
      "Epoch 1911/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9770 - accuracy: 0.8588 - val_loss: 2.3756 - val_accuracy: 0.6381\n",
      "Epoch 1912/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9767 - accuracy: 0.8558 - val_loss: 2.3664 - val_accuracy: 0.6373\n",
      "Epoch 1913/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9747 - accuracy: 0.8566 - val_loss: 2.3724 - val_accuracy: 0.6394\n",
      "Epoch 1914/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9813 - accuracy: 0.8583 - val_loss: 2.3757 - val_accuracy: 0.6395\n",
      "Epoch 1915/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9800 - accuracy: 0.8579 - val_loss: 2.3642 - val_accuracy: 0.6392\n",
      "Epoch 1916/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9742 - accuracy: 0.8574 - val_loss: 2.3778 - val_accuracy: 0.6389\n",
      "Epoch 1917/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9758 - accuracy: 0.8573 - val_loss: 2.3856 - val_accuracy: 0.6412\n",
      "Epoch 1918/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9765 - accuracy: 0.8545 - val_loss: 2.4311 - val_accuracy: 0.6357\n",
      "Epoch 1919/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9847 - accuracy: 0.8552 - val_loss: 2.3635 - val_accuracy: 0.6436\n",
      "Epoch 1920/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9836 - accuracy: 0.8610 - val_loss: 2.3678 - val_accuracy: 0.6354\n",
      "Epoch 1921/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9798 - accuracy: 0.8583 - val_loss: 2.3514 - val_accuracy: 0.6435\n",
      "Epoch 1922/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9672 - accuracy: 0.8577 - val_loss: 2.4151 - val_accuracy: 0.6329\n",
      "Epoch 1923/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9661 - accuracy: 0.8592 - val_loss: 2.4303 - val_accuracy: 0.6302\n",
      "Epoch 1924/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9699 - accuracy: 0.8594 - val_loss: 2.3759 - val_accuracy: 0.6348\n",
      "Epoch 1925/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9724 - accuracy: 0.8604 - val_loss: 2.4052 - val_accuracy: 0.6331\n",
      "Epoch 1926/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9687 - accuracy: 0.8594 - val_loss: 2.4503 - val_accuracy: 0.6270\n",
      "Epoch 1927/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9766 - accuracy: 0.8578 - val_loss: 2.3664 - val_accuracy: 0.6377\n",
      "Epoch 1928/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9777 - accuracy: 0.8561 - val_loss: 2.4014 - val_accuracy: 0.6341\n",
      "Epoch 1929/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9709 - accuracy: 0.8580 - val_loss: 2.3402 - val_accuracy: 0.6378\n",
      "Epoch 1930/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9712 - accuracy: 0.8584 - val_loss: 2.3422 - val_accuracy: 0.6422\n",
      "Epoch 1931/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9696 - accuracy: 0.8611 - val_loss: 2.3760 - val_accuracy: 0.6386\n",
      "Epoch 1932/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9674 - accuracy: 0.8595 - val_loss: 2.3788 - val_accuracy: 0.6435\n",
      "Epoch 1933/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9792 - accuracy: 0.8579 - val_loss: 2.4179 - val_accuracy: 0.6278\n",
      "Epoch 1934/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9794 - accuracy: 0.8507 - val_loss: 2.3931 - val_accuracy: 0.6348\n",
      "Epoch 1935/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9808 - accuracy: 0.8550 - val_loss: 2.3808 - val_accuracy: 0.6372\n",
      "Epoch 1936/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9797 - accuracy: 0.8546 - val_loss: 2.4005 - val_accuracy: 0.6346\n",
      "Epoch 1937/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9678 - accuracy: 0.8596 - val_loss: 2.3451 - val_accuracy: 0.6397\n",
      "Epoch 1938/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9700 - accuracy: 0.8579 - val_loss: 2.4148 - val_accuracy: 0.6332\n",
      "Epoch 1939/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9721 - accuracy: 0.8582 - val_loss: 2.3811 - val_accuracy: 0.6344\n",
      "Epoch 1940/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9747 - accuracy: 0.8595 - val_loss: 2.3675 - val_accuracy: 0.6425\n",
      "Epoch 1941/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9738 - accuracy: 0.8568 - val_loss: 2.3459 - val_accuracy: 0.6437\n",
      "Epoch 1942/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9587 - accuracy: 0.8594 - val_loss: 2.3696 - val_accuracy: 0.6379\n",
      "Epoch 1943/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9624 - accuracy: 0.8603 - val_loss: 2.3949 - val_accuracy: 0.6350\n",
      "Epoch 1944/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9720 - accuracy: 0.8566 - val_loss: 2.3751 - val_accuracy: 0.6388\n",
      "Epoch 1945/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9704 - accuracy: 0.8612 - val_loss: 2.3529 - val_accuracy: 0.6431\n",
      "Epoch 1946/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9693 - accuracy: 0.8625 - val_loss: 2.3803 - val_accuracy: 0.6384\n",
      "Epoch 1947/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9615 - accuracy: 0.8590 - val_loss: 2.3880 - val_accuracy: 0.6385\n",
      "Epoch 1948/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9619 - accuracy: 0.8648 - val_loss: 2.3837 - val_accuracy: 0.6385\n",
      "Epoch 1949/2500\n",
      "196/196 [==============================] - 17s 89ms/step - loss: 0.9665 - accuracy: 0.8613 - val_loss: 2.3828 - val_accuracy: 0.6360\n",
      "Epoch 1950/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9699 - accuracy: 0.8619 - val_loss: 2.3630 - val_accuracy: 0.6422\n",
      "Epoch 1951/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9874 - accuracy: 0.8546 - val_loss: 2.3436 - val_accuracy: 0.6432\n",
      "Epoch 1952/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9683 - accuracy: 0.8608 - val_loss: 2.4242 - val_accuracy: 0.6343\n",
      "Epoch 1953/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9745 - accuracy: 0.8573 - val_loss: 2.3619 - val_accuracy: 0.6434\n",
      "Epoch 1954/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9711 - accuracy: 0.8626 - val_loss: 2.3878 - val_accuracy: 0.6393\n",
      "Epoch 1955/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9630 - accuracy: 0.8586 - val_loss: 2.3618 - val_accuracy: 0.6354\n",
      "Epoch 1956/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9683 - accuracy: 0.8602 - val_loss: 2.3970 - val_accuracy: 0.6366\n",
      "Epoch 1957/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9800 - accuracy: 0.8595 - val_loss: 2.3845 - val_accuracy: 0.6368\n",
      "Epoch 1958/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9703 - accuracy: 0.8615 - val_loss: 2.3759 - val_accuracy: 0.6421\n",
      "Epoch 1959/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9819 - accuracy: 0.8571 - val_loss: 2.3647 - val_accuracy: 0.6429\n",
      "Epoch 1960/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9820 - accuracy: 0.8548 - val_loss: 2.3812 - val_accuracy: 0.6410\n",
      "Epoch 1961/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9826 - accuracy: 0.8575 - val_loss: 2.3592 - val_accuracy: 0.6419\n",
      "Epoch 1962/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9697 - accuracy: 0.8597 - val_loss: 2.3622 - val_accuracy: 0.6406\n",
      "Epoch 1963/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9689 - accuracy: 0.8583 - val_loss: 2.3664 - val_accuracy: 0.6411\n",
      "Epoch 1964/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9753 - accuracy: 0.8573 - val_loss: 2.3731 - val_accuracy: 0.6393\n",
      "Epoch 1965/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9718 - accuracy: 0.8595 - val_loss: 2.3525 - val_accuracy: 0.6414\n",
      "Epoch 1966/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9712 - accuracy: 0.8608 - val_loss: 2.3591 - val_accuracy: 0.6394\n",
      "Epoch 1967/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9772 - accuracy: 0.8590 - val_loss: 2.3240 - val_accuracy: 0.6430\n",
      "Epoch 1968/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9760 - accuracy: 0.8590 - val_loss: 2.3686 - val_accuracy: 0.6420\n",
      "Epoch 1969/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9678 - accuracy: 0.8591 - val_loss: 2.3615 - val_accuracy: 0.6404\n",
      "Epoch 1970/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9738 - accuracy: 0.8606 - val_loss: 2.4288 - val_accuracy: 0.6319\n",
      "Epoch 1971/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9711 - accuracy: 0.8590 - val_loss: 2.3722 - val_accuracy: 0.6393\n",
      "Epoch 1972/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9792 - accuracy: 0.8576 - val_loss: 2.3777 - val_accuracy: 0.6412\n",
      "Epoch 1973/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9719 - accuracy: 0.8597 - val_loss: 2.3729 - val_accuracy: 0.6389\n",
      "Epoch 1974/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9738 - accuracy: 0.8621 - val_loss: 2.4069 - val_accuracy: 0.6369\n",
      "Epoch 1975/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9567 - accuracy: 0.8626 - val_loss: 2.3646 - val_accuracy: 0.6411\n",
      "Epoch 1976/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9689 - accuracy: 0.8608 - val_loss: 2.3649 - val_accuracy: 0.6368\n",
      "Epoch 1977/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9788 - accuracy: 0.8590 - val_loss: 2.3879 - val_accuracy: 0.6416\n",
      "Epoch 1978/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9636 - accuracy: 0.8619 - val_loss: 2.3782 - val_accuracy: 0.6408\n",
      "Epoch 1979/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9693 - accuracy: 0.8614 - val_loss: 2.3702 - val_accuracy: 0.6416\n",
      "Epoch 1980/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9752 - accuracy: 0.8595 - val_loss: 2.3904 - val_accuracy: 0.6390\n",
      "Epoch 1981/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9734 - accuracy: 0.8607 - val_loss: 2.3586 - val_accuracy: 0.6428\n",
      "Epoch 1982/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9711 - accuracy: 0.8609 - val_loss: 2.3755 - val_accuracy: 0.6410\n",
      "Epoch 1983/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9744 - accuracy: 0.8591 - val_loss: 2.3321 - val_accuracy: 0.6481\n",
      "Epoch 1984/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9608 - accuracy: 0.8626 - val_loss: 2.3971 - val_accuracy: 0.6375\n",
      "Epoch 1985/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9665 - accuracy: 0.8616 - val_loss: 2.3660 - val_accuracy: 0.6395\n",
      "Epoch 1986/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9652 - accuracy: 0.8617 - val_loss: 2.3415 - val_accuracy: 0.6455\n",
      "Epoch 1987/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9689 - accuracy: 0.8611 - val_loss: 2.3759 - val_accuracy: 0.6403\n",
      "Epoch 1988/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9669 - accuracy: 0.8620 - val_loss: 2.3545 - val_accuracy: 0.6431\n",
      "Epoch 1989/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9701 - accuracy: 0.8611 - val_loss: 2.3989 - val_accuracy: 0.6380\n",
      "Epoch 1990/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9726 - accuracy: 0.8619 - val_loss: 2.3692 - val_accuracy: 0.6396\n",
      "Epoch 1991/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9691 - accuracy: 0.8596 - val_loss: 2.3585 - val_accuracy: 0.6428\n",
      "Epoch 1992/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9713 - accuracy: 0.8574 - val_loss: 2.3828 - val_accuracy: 0.6379\n",
      "Epoch 1993/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9781 - accuracy: 0.8562 - val_loss: 2.3565 - val_accuracy: 0.6411\n",
      "Epoch 1994/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9708 - accuracy: 0.8601 - val_loss: 2.3788 - val_accuracy: 0.6428\n",
      "Epoch 1995/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9769 - accuracy: 0.8608 - val_loss: 2.3313 - val_accuracy: 0.6483\n",
      "Epoch 1996/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9756 - accuracy: 0.8583 - val_loss: 2.3956 - val_accuracy: 0.6337\n",
      "Epoch 1997/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9729 - accuracy: 0.8588 - val_loss: 2.3770 - val_accuracy: 0.6371\n",
      "Epoch 1998/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9662 - accuracy: 0.8609 - val_loss: 2.3886 - val_accuracy: 0.6386\n",
      "Epoch 1999/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9646 - accuracy: 0.8590 - val_loss: 2.3116 - val_accuracy: 0.6456\n",
      "Epoch 2000/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9709 - accuracy: 0.8594 - val_loss: 2.3583 - val_accuracy: 0.6419\n",
      "Epoch 2001/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9621 - accuracy: 0.8628 - val_loss: 2.4250 - val_accuracy: 0.6325\n",
      "Epoch 2002/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9675 - accuracy: 0.8580 - val_loss: 2.3625 - val_accuracy: 0.6469\n",
      "Epoch 2003/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9623 - accuracy: 0.8616 - val_loss: 2.3532 - val_accuracy: 0.6436\n",
      "Epoch 2004/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9743 - accuracy: 0.8608 - val_loss: 2.3825 - val_accuracy: 0.6363\n",
      "Epoch 2005/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9594 - accuracy: 0.8624 - val_loss: 2.3910 - val_accuracy: 0.6418\n",
      "Epoch 2006/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9664 - accuracy: 0.8632 - val_loss: 2.3520 - val_accuracy: 0.6449\n",
      "Epoch 2007/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9604 - accuracy: 0.8624 - val_loss: 2.3768 - val_accuracy: 0.6366\n",
      "Epoch 2008/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9617 - accuracy: 0.8614 - val_loss: 2.3762 - val_accuracy: 0.6399\n",
      "Epoch 2009/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9716 - accuracy: 0.8610 - val_loss: 2.3679 - val_accuracy: 0.6425\n",
      "Epoch 2010/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9646 - accuracy: 0.8636 - val_loss: 2.3526 - val_accuracy: 0.6418\n",
      "Epoch 2011/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9705 - accuracy: 0.8604 - val_loss: 2.3625 - val_accuracy: 0.6442\n",
      "Epoch 2012/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9747 - accuracy: 0.8586 - val_loss: 2.3576 - val_accuracy: 0.6436\n",
      "Epoch 2013/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9617 - accuracy: 0.8627 - val_loss: 2.3920 - val_accuracy: 0.6400\n",
      "Epoch 2014/2500\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.9585 - accuracy: 0.8615 - val_loss: 2.3942 - val_accuracy: 0.6382\n",
      "Epoch 2015/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9654 - accuracy: 0.8603 - val_loss: 2.4032 - val_accuracy: 0.6397\n",
      "Epoch 2016/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9739 - accuracy: 0.8593 - val_loss: 2.3992 - val_accuracy: 0.6323\n",
      "Epoch 2017/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9681 - accuracy: 0.8620 - val_loss: 2.3614 - val_accuracy: 0.6391\n",
      "Epoch 2018/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9701 - accuracy: 0.8600 - val_loss: 2.4365 - val_accuracy: 0.6333\n",
      "Epoch 2019/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9579 - accuracy: 0.8631 - val_loss: 2.4155 - val_accuracy: 0.6323\n",
      "Epoch 2020/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9697 - accuracy: 0.8612 - val_loss: 2.4216 - val_accuracy: 0.6329\n",
      "Epoch 2021/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9669 - accuracy: 0.8616 - val_loss: 2.4248 - val_accuracy: 0.6353\n",
      "Epoch 2022/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9731 - accuracy: 0.8557 - val_loss: 2.4167 - val_accuracy: 0.6345\n",
      "Epoch 2023/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9679 - accuracy: 0.8611 - val_loss: 2.3712 - val_accuracy: 0.6443\n",
      "Epoch 2024/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9681 - accuracy: 0.8620 - val_loss: 2.3592 - val_accuracy: 0.6419\n",
      "Epoch 2025/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9583 - accuracy: 0.8624 - val_loss: 2.3515 - val_accuracy: 0.6436\n",
      "Epoch 2026/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9742 - accuracy: 0.8624 - val_loss: 2.3785 - val_accuracy: 0.6412\n",
      "Epoch 2027/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9673 - accuracy: 0.8614 - val_loss: 2.3830 - val_accuracy: 0.6452\n",
      "Epoch 2028/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9665 - accuracy: 0.8604 - val_loss: 2.3766 - val_accuracy: 0.6410\n",
      "Epoch 2029/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9608 - accuracy: 0.8597 - val_loss: 2.3561 - val_accuracy: 0.6419\n",
      "Epoch 2030/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9596 - accuracy: 0.8632 - val_loss: 2.3449 - val_accuracy: 0.6492\n",
      "Epoch 2031/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9586 - accuracy: 0.8624 - val_loss: 2.3503 - val_accuracy: 0.6438\n",
      "Epoch 2032/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9634 - accuracy: 0.8599 - val_loss: 2.3964 - val_accuracy: 0.6402\n",
      "Epoch 2033/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9627 - accuracy: 0.8600 - val_loss: 2.3820 - val_accuracy: 0.6414\n",
      "Epoch 2034/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9658 - accuracy: 0.8618 - val_loss: 2.3863 - val_accuracy: 0.6402\n",
      "Epoch 2035/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9656 - accuracy: 0.8598 - val_loss: 2.3561 - val_accuracy: 0.6412\n",
      "Epoch 2036/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9628 - accuracy: 0.8610 - val_loss: 2.3753 - val_accuracy: 0.6426\n",
      "Epoch 2037/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9674 - accuracy: 0.8606 - val_loss: 2.4136 - val_accuracy: 0.6353\n",
      "Epoch 2038/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9659 - accuracy: 0.8591 - val_loss: 2.3737 - val_accuracy: 0.6435\n",
      "Epoch 2039/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9672 - accuracy: 0.8593 - val_loss: 2.3922 - val_accuracy: 0.6400\n",
      "Epoch 2040/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9681 - accuracy: 0.8587 - val_loss: 2.3893 - val_accuracy: 0.6423\n",
      "Epoch 2041/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9504 - accuracy: 0.8636 - val_loss: 2.3731 - val_accuracy: 0.6426\n",
      "Epoch 2042/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9592 - accuracy: 0.8617 - val_loss: 2.4146 - val_accuracy: 0.6367\n",
      "Epoch 2043/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9594 - accuracy: 0.8611 - val_loss: 2.3729 - val_accuracy: 0.6422\n",
      "Epoch 2044/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9571 - accuracy: 0.8614 - val_loss: 2.4120 - val_accuracy: 0.6358\n",
      "Epoch 2045/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9689 - accuracy: 0.8614 - val_loss: 2.3663 - val_accuracy: 0.6442\n",
      "Epoch 2046/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9620 - accuracy: 0.8640 - val_loss: 2.3622 - val_accuracy: 0.6437\n",
      "Epoch 2047/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9645 - accuracy: 0.8624 - val_loss: 2.3818 - val_accuracy: 0.6433\n",
      "Epoch 2048/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9593 - accuracy: 0.8640 - val_loss: 2.3706 - val_accuracy: 0.6417\n",
      "Epoch 2049/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9618 - accuracy: 0.8619 - val_loss: 2.4034 - val_accuracy: 0.6381\n",
      "Epoch 2050/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9500 - accuracy: 0.8664 - val_loss: 2.3758 - val_accuracy: 0.6427\n",
      "Epoch 2051/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9633 - accuracy: 0.8631 - val_loss: 2.3874 - val_accuracy: 0.6402\n",
      "Epoch 2052/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9612 - accuracy: 0.8617 - val_loss: 2.3948 - val_accuracy: 0.6379\n",
      "Epoch 2053/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9618 - accuracy: 0.8596 - val_loss: 2.3824 - val_accuracy: 0.6454\n",
      "Epoch 2054/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9723 - accuracy: 0.8580 - val_loss: 2.3716 - val_accuracy: 0.6430\n",
      "Epoch 2055/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9722 - accuracy: 0.8607 - val_loss: 2.3754 - val_accuracy: 0.6418\n",
      "Epoch 2056/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9539 - accuracy: 0.8636 - val_loss: 2.4312 - val_accuracy: 0.6416\n",
      "Epoch 2057/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9571 - accuracy: 0.8627 - val_loss: 2.3796 - val_accuracy: 0.6412\n",
      "Epoch 2058/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9563 - accuracy: 0.8632 - val_loss: 2.3867 - val_accuracy: 0.6404\n",
      "Epoch 2059/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9537 - accuracy: 0.8631 - val_loss: 2.4263 - val_accuracy: 0.6365\n",
      "Epoch 2060/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9596 - accuracy: 0.8628 - val_loss: 2.4511 - val_accuracy: 0.6382\n",
      "Epoch 2061/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9795 - accuracy: 0.8608 - val_loss: 2.3990 - val_accuracy: 0.6377\n",
      "Epoch 2062/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9676 - accuracy: 0.8612 - val_loss: 2.3524 - val_accuracy: 0.6450\n",
      "Epoch 2063/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9731 - accuracy: 0.8590 - val_loss: 2.4045 - val_accuracy: 0.6366\n",
      "Epoch 2064/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9607 - accuracy: 0.8627 - val_loss: 2.3539 - val_accuracy: 0.6436\n",
      "Epoch 2065/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9664 - accuracy: 0.8637 - val_loss: 2.3618 - val_accuracy: 0.6448\n",
      "Epoch 2066/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9609 - accuracy: 0.8629 - val_loss: 2.3455 - val_accuracy: 0.6454\n",
      "Epoch 2067/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9672 - accuracy: 0.8594 - val_loss: 2.4121 - val_accuracy: 0.6377\n",
      "Epoch 2068/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9580 - accuracy: 0.8629 - val_loss: 2.4224 - val_accuracy: 0.6343\n",
      "Epoch 2069/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9578 - accuracy: 0.8653 - val_loss: 2.3771 - val_accuracy: 0.6469\n",
      "Epoch 2070/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9516 - accuracy: 0.8655 - val_loss: 2.4049 - val_accuracy: 0.6418\n",
      "Epoch 2071/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9663 - accuracy: 0.8594 - val_loss: 2.3515 - val_accuracy: 0.6440\n",
      "Epoch 2072/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9669 - accuracy: 0.8632 - val_loss: 2.4193 - val_accuracy: 0.6415\n",
      "Epoch 2073/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9585 - accuracy: 0.8638 - val_loss: 2.3764 - val_accuracy: 0.6411\n",
      "Epoch 2074/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9622 - accuracy: 0.8614 - val_loss: 2.3742 - val_accuracy: 0.6474\n",
      "Epoch 2075/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9613 - accuracy: 0.8606 - val_loss: 2.4142 - val_accuracy: 0.6359\n",
      "Epoch 2076/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9593 - accuracy: 0.8608 - val_loss: 2.4034 - val_accuracy: 0.6410\n",
      "Epoch 2077/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9613 - accuracy: 0.8623 - val_loss: 2.4197 - val_accuracy: 0.6379\n",
      "Epoch 2078/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9564 - accuracy: 0.8640 - val_loss: 2.3889 - val_accuracy: 0.6413\n",
      "Epoch 2079/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9654 - accuracy: 0.8604 - val_loss: 2.3844 - val_accuracy: 0.6409\n",
      "Epoch 2080/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9743 - accuracy: 0.8587 - val_loss: 2.3780 - val_accuracy: 0.6405\n",
      "Epoch 2081/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9597 - accuracy: 0.8616 - val_loss: 2.3874 - val_accuracy: 0.6422\n",
      "Epoch 2082/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9617 - accuracy: 0.8632 - val_loss: 2.3604 - val_accuracy: 0.6431\n",
      "Epoch 2083/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9596 - accuracy: 0.8623 - val_loss: 2.3600 - val_accuracy: 0.6436\n",
      "Epoch 2084/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9587 - accuracy: 0.8653 - val_loss: 2.3898 - val_accuracy: 0.6391\n",
      "Epoch 2085/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9697 - accuracy: 0.8619 - val_loss: 2.4106 - val_accuracy: 0.6372\n",
      "Epoch 2086/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9509 - accuracy: 0.8620 - val_loss: 2.3690 - val_accuracy: 0.6410\n",
      "Epoch 2087/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9632 - accuracy: 0.8623 - val_loss: 2.3866 - val_accuracy: 0.6414\n",
      "Epoch 2088/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9630 - accuracy: 0.8628 - val_loss: 2.4062 - val_accuracy: 0.6384\n",
      "Epoch 2089/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9678 - accuracy: 0.8613 - val_loss: 2.3840 - val_accuracy: 0.6423\n",
      "Epoch 2090/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9648 - accuracy: 0.8646 - val_loss: 2.4163 - val_accuracy: 0.6408\n",
      "Epoch 2091/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9605 - accuracy: 0.8634 - val_loss: 2.3994 - val_accuracy: 0.6371\n",
      "Epoch 2092/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9511 - accuracy: 0.8643 - val_loss: 2.4168 - val_accuracy: 0.6363\n",
      "Epoch 2093/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9680 - accuracy: 0.8604 - val_loss: 2.4032 - val_accuracy: 0.6368\n",
      "Epoch 2094/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9524 - accuracy: 0.8628 - val_loss: 2.3854 - val_accuracy: 0.6382\n",
      "Epoch 2095/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9652 - accuracy: 0.8587 - val_loss: 2.3568 - val_accuracy: 0.6463\n",
      "Epoch 2096/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9675 - accuracy: 0.8622 - val_loss: 2.4058 - val_accuracy: 0.6381\n",
      "Epoch 2097/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9684 - accuracy: 0.8592 - val_loss: 2.4290 - val_accuracy: 0.6329\n",
      "Epoch 2098/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9652 - accuracy: 0.8588 - val_loss: 2.3875 - val_accuracy: 0.6419\n",
      "Epoch 2099/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9697 - accuracy: 0.8614 - val_loss: 2.3982 - val_accuracy: 0.6378\n",
      "Epoch 2100/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9534 - accuracy: 0.8636 - val_loss: 2.3393 - val_accuracy: 0.6439\n",
      "Epoch 2101/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9624 - accuracy: 0.8646 - val_loss: 2.3856 - val_accuracy: 0.6353\n",
      "Epoch 2102/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9492 - accuracy: 0.8661 - val_loss: 2.3777 - val_accuracy: 0.6378\n",
      "Epoch 2103/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9435 - accuracy: 0.8638 - val_loss: 2.4159 - val_accuracy: 0.6376\n",
      "Epoch 2104/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9645 - accuracy: 0.8634 - val_loss: 2.4148 - val_accuracy: 0.6388\n",
      "Epoch 2105/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9529 - accuracy: 0.8677 - val_loss: 2.3722 - val_accuracy: 0.6411\n",
      "Epoch 2106/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9549 - accuracy: 0.8639 - val_loss: 2.4245 - val_accuracy: 0.6349\n",
      "Epoch 2107/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9630 - accuracy: 0.8600 - val_loss: 2.4340 - val_accuracy: 0.6330\n",
      "Epoch 2108/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9500 - accuracy: 0.8664 - val_loss: 2.4262 - val_accuracy: 0.6369\n",
      "Epoch 2109/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9709 - accuracy: 0.8604 - val_loss: 2.3890 - val_accuracy: 0.6429\n",
      "Epoch 2110/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9635 - accuracy: 0.8613 - val_loss: 2.3462 - val_accuracy: 0.6398\n",
      "Epoch 2111/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9592 - accuracy: 0.8635 - val_loss: 2.3553 - val_accuracy: 0.6430\n",
      "Epoch 2112/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9629 - accuracy: 0.8631 - val_loss: 2.4043 - val_accuracy: 0.6366\n",
      "Epoch 2113/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9548 - accuracy: 0.8639 - val_loss: 2.4002 - val_accuracy: 0.6388\n",
      "Epoch 2114/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9729 - accuracy: 0.8589 - val_loss: 2.4044 - val_accuracy: 0.6380\n",
      "Epoch 2115/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9582 - accuracy: 0.8642 - val_loss: 2.3944 - val_accuracy: 0.6381\n",
      "Epoch 2116/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9698 - accuracy: 0.8616 - val_loss: 2.3659 - val_accuracy: 0.6443\n",
      "Epoch 2117/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9618 - accuracy: 0.8624 - val_loss: 2.3696 - val_accuracy: 0.6407\n",
      "Epoch 2118/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9529 - accuracy: 0.8643 - val_loss: 2.3868 - val_accuracy: 0.6380\n",
      "Epoch 2119/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9686 - accuracy: 0.8596 - val_loss: 2.4064 - val_accuracy: 0.6390\n",
      "Epoch 2120/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9865 - accuracy: 0.8597 - val_loss: 2.3813 - val_accuracy: 0.6411\n",
      "Epoch 2121/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9564 - accuracy: 0.8622 - val_loss: 2.4126 - val_accuracy: 0.6336\n",
      "Epoch 2122/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9536 - accuracy: 0.8641 - val_loss: 2.3438 - val_accuracy: 0.6426\n",
      "Epoch 2123/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9469 - accuracy: 0.8661 - val_loss: 2.3756 - val_accuracy: 0.6372\n",
      "Epoch 2124/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9591 - accuracy: 0.8614 - val_loss: 2.3576 - val_accuracy: 0.6432\n",
      "Epoch 2125/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9745 - accuracy: 0.8594 - val_loss: 2.3689 - val_accuracy: 0.6417\n",
      "Epoch 2126/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9573 - accuracy: 0.8630 - val_loss: 2.3787 - val_accuracy: 0.6402\n",
      "Epoch 2127/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9487 - accuracy: 0.8639 - val_loss: 2.3826 - val_accuracy: 0.6406\n",
      "Epoch 2128/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9612 - accuracy: 0.8629 - val_loss: 2.3682 - val_accuracy: 0.6445\n",
      "Epoch 2129/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9534 - accuracy: 0.8666 - val_loss: 2.4047 - val_accuracy: 0.6371\n",
      "Epoch 2130/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9780 - accuracy: 0.8622 - val_loss: 2.4153 - val_accuracy: 0.6375\n",
      "Epoch 2131/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9613 - accuracy: 0.8615 - val_loss: 2.4277 - val_accuracy: 0.6357\n",
      "Epoch 2132/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9490 - accuracy: 0.8669 - val_loss: 2.3895 - val_accuracy: 0.6435\n",
      "Epoch 2133/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9534 - accuracy: 0.8647 - val_loss: 2.4102 - val_accuracy: 0.6401\n",
      "Epoch 2134/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9594 - accuracy: 0.8647 - val_loss: 2.3546 - val_accuracy: 0.6450\n",
      "Epoch 2135/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9520 - accuracy: 0.8642 - val_loss: 2.3926 - val_accuracy: 0.6380\n",
      "Epoch 2136/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9742 - accuracy: 0.8617 - val_loss: 2.4278 - val_accuracy: 0.6357\n",
      "Epoch 2137/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9539 - accuracy: 0.8636 - val_loss: 2.3543 - val_accuracy: 0.6449\n",
      "Epoch 2138/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9514 - accuracy: 0.8640 - val_loss: 2.3965 - val_accuracy: 0.6417\n",
      "Epoch 2139/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9409 - accuracy: 0.8677 - val_loss: 2.3843 - val_accuracy: 0.6440\n",
      "Epoch 2140/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9467 - accuracy: 0.8672 - val_loss: 2.3739 - val_accuracy: 0.6444\n",
      "Epoch 2141/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9563 - accuracy: 0.8639 - val_loss: 2.3773 - val_accuracy: 0.6437\n",
      "Epoch 2142/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9462 - accuracy: 0.8650 - val_loss: 2.3895 - val_accuracy: 0.6413\n",
      "Epoch 2143/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9557 - accuracy: 0.8623 - val_loss: 2.3630 - val_accuracy: 0.6445\n",
      "Epoch 2144/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9573 - accuracy: 0.8638 - val_loss: 2.3657 - val_accuracy: 0.6436\n",
      "Epoch 2145/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9596 - accuracy: 0.8639 - val_loss: 2.3702 - val_accuracy: 0.6441\n",
      "Epoch 2146/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9504 - accuracy: 0.8666 - val_loss: 2.4154 - val_accuracy: 0.6403\n",
      "Epoch 2147/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9597 - accuracy: 0.8632 - val_loss: 2.3507 - val_accuracy: 0.6449\n",
      "Epoch 2148/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9528 - accuracy: 0.8627 - val_loss: 2.4095 - val_accuracy: 0.6426\n",
      "Epoch 2149/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9521 - accuracy: 0.8651 - val_loss: 2.3925 - val_accuracy: 0.6381\n",
      "Epoch 2150/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9553 - accuracy: 0.8651 - val_loss: 2.3694 - val_accuracy: 0.6430\n",
      "Epoch 2151/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9603 - accuracy: 0.8591 - val_loss: 2.3637 - val_accuracy: 0.6437\n",
      "Epoch 2152/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9548 - accuracy: 0.8628 - val_loss: 2.3469 - val_accuracy: 0.6482\n",
      "Epoch 2153/2500\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.9676 - accuracy: 0.8606 - val_loss: 2.3995 - val_accuracy: 0.6374\n",
      "Epoch 2154/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9724 - accuracy: 0.8573 - val_loss: 2.3830 - val_accuracy: 0.6425\n",
      "Epoch 2155/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9582 - accuracy: 0.8655 - val_loss: 2.4123 - val_accuracy: 0.6405\n",
      "Epoch 2156/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9520 - accuracy: 0.8626 - val_loss: 2.3469 - val_accuracy: 0.6481\n",
      "Epoch 2157/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9468 - accuracy: 0.8652 - val_loss: 2.3521 - val_accuracy: 0.6440\n",
      "Epoch 2158/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9500 - accuracy: 0.8638 - val_loss: 2.2993 - val_accuracy: 0.6552\n",
      "Epoch 2159/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9626 - accuracy: 0.8606 - val_loss: 2.3889 - val_accuracy: 0.6441\n",
      "Epoch 2160/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9689 - accuracy: 0.8587 - val_loss: 2.3438 - val_accuracy: 0.6480\n",
      "Epoch 2161/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9538 - accuracy: 0.8633 - val_loss: 2.4115 - val_accuracy: 0.6413\n",
      "Epoch 2162/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9475 - accuracy: 0.8642 - val_loss: 2.3690 - val_accuracy: 0.6430\n",
      "Epoch 2163/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9534 - accuracy: 0.8635 - val_loss: 2.3503 - val_accuracy: 0.6435\n",
      "Epoch 2164/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9691 - accuracy: 0.8598 - val_loss: 2.3882 - val_accuracy: 0.6388\n",
      "Epoch 2165/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9540 - accuracy: 0.8635 - val_loss: 2.3716 - val_accuracy: 0.6465\n",
      "Epoch 2166/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9546 - accuracy: 0.8649 - val_loss: 2.3450 - val_accuracy: 0.6492\n",
      "Epoch 2167/2500\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.9414 - accuracy: 0.8686 - val_loss: 2.4215 - val_accuracy: 0.6401\n",
      "Epoch 2168/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9501 - accuracy: 0.8673 - val_loss: 2.3562 - val_accuracy: 0.6467\n",
      "Epoch 2169/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9431 - accuracy: 0.8684 - val_loss: 2.3931 - val_accuracy: 0.6421\n",
      "Epoch 2170/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9669 - accuracy: 0.8611 - val_loss: 2.3577 - val_accuracy: 0.6438\n",
      "Epoch 2171/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9535 - accuracy: 0.8641 - val_loss: 2.4356 - val_accuracy: 0.6336\n",
      "Epoch 2172/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9433 - accuracy: 0.8646 - val_loss: 2.3602 - val_accuracy: 0.6446\n",
      "Epoch 2173/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9585 - accuracy: 0.8644 - val_loss: 2.3223 - val_accuracy: 0.6475\n",
      "Epoch 2174/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9552 - accuracy: 0.8626 - val_loss: 2.3689 - val_accuracy: 0.6466\n",
      "Epoch 2175/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9489 - accuracy: 0.8669 - val_loss: 2.3705 - val_accuracy: 0.6464\n",
      "Epoch 2176/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9629 - accuracy: 0.8643 - val_loss: 2.3648 - val_accuracy: 0.6448\n",
      "Epoch 2177/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9585 - accuracy: 0.8609 - val_loss: 2.3545 - val_accuracy: 0.6444\n",
      "Epoch 2178/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9387 - accuracy: 0.8695 - val_loss: 2.3510 - val_accuracy: 0.6433\n",
      "Epoch 2179/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9582 - accuracy: 0.8614 - val_loss: 2.4019 - val_accuracy: 0.6414\n",
      "Epoch 2180/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9679 - accuracy: 0.8618 - val_loss: 2.3530 - val_accuracy: 0.6446\n",
      "Epoch 2181/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9636 - accuracy: 0.8648 - val_loss: 2.3587 - val_accuracy: 0.6459\n",
      "Epoch 2182/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9488 - accuracy: 0.8673 - val_loss: 2.3779 - val_accuracy: 0.6425\n",
      "Epoch 2183/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9580 - accuracy: 0.8650 - val_loss: 2.3659 - val_accuracy: 0.6422\n",
      "Epoch 2184/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9546 - accuracy: 0.8614 - val_loss: 2.4000 - val_accuracy: 0.6386\n",
      "Epoch 2185/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9559 - accuracy: 0.8623 - val_loss: 2.3721 - val_accuracy: 0.6449\n",
      "Epoch 2186/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9381 - accuracy: 0.8679 - val_loss: 2.3777 - val_accuracy: 0.6440\n",
      "Epoch 2187/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9577 - accuracy: 0.8632 - val_loss: 2.3965 - val_accuracy: 0.6391\n",
      "Epoch 2188/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9425 - accuracy: 0.8689 - val_loss: 2.3841 - val_accuracy: 0.6422\n",
      "Epoch 2189/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9381 - accuracy: 0.8690 - val_loss: 2.3561 - val_accuracy: 0.6466\n",
      "Epoch 2190/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9476 - accuracy: 0.8688 - val_loss: 2.3835 - val_accuracy: 0.6442\n",
      "Epoch 2191/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9386 - accuracy: 0.8655 - val_loss: 2.3896 - val_accuracy: 0.6455\n",
      "Epoch 2192/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9496 - accuracy: 0.8647 - val_loss: 2.3463 - val_accuracy: 0.6499\n",
      "Epoch 2193/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9491 - accuracy: 0.8662 - val_loss: 2.4226 - val_accuracy: 0.6351\n",
      "Epoch 2194/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9423 - accuracy: 0.8685 - val_loss: 2.3743 - val_accuracy: 0.6395\n",
      "Epoch 2195/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9477 - accuracy: 0.8662 - val_loss: 2.4109 - val_accuracy: 0.6376\n",
      "Epoch 2196/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9587 - accuracy: 0.8628 - val_loss: 2.3860 - val_accuracy: 0.6454\n",
      "Epoch 2197/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9547 - accuracy: 0.8635 - val_loss: 2.4121 - val_accuracy: 0.6389\n",
      "Epoch 2198/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9593 - accuracy: 0.8619 - val_loss: 2.3586 - val_accuracy: 0.6509\n",
      "Epoch 2199/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9544 - accuracy: 0.8636 - val_loss: 2.4313 - val_accuracy: 0.6411\n",
      "Epoch 2200/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9468 - accuracy: 0.8651 - val_loss: 2.4160 - val_accuracy: 0.6409\n",
      "Epoch 2201/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9432 - accuracy: 0.8675 - val_loss: 2.3878 - val_accuracy: 0.6482\n",
      "Epoch 2202/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9542 - accuracy: 0.8653 - val_loss: 2.3362 - val_accuracy: 0.6498\n",
      "Epoch 2203/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9611 - accuracy: 0.8647 - val_loss: 2.3868 - val_accuracy: 0.6429\n",
      "Epoch 2204/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9622 - accuracy: 0.8618 - val_loss: 2.3830 - val_accuracy: 0.6447\n",
      "Epoch 2205/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9462 - accuracy: 0.8693 - val_loss: 2.3288 - val_accuracy: 0.6514\n",
      "Epoch 2206/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9550 - accuracy: 0.8643 - val_loss: 2.3461 - val_accuracy: 0.6454\n",
      "Epoch 2207/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9469 - accuracy: 0.8654 - val_loss: 2.3970 - val_accuracy: 0.6411\n",
      "Epoch 2208/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9447 - accuracy: 0.8679 - val_loss: 2.3891 - val_accuracy: 0.6399\n",
      "Epoch 2209/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9432 - accuracy: 0.8685 - val_loss: 2.3702 - val_accuracy: 0.6420\n",
      "Epoch 2210/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9476 - accuracy: 0.8651 - val_loss: 2.3761 - val_accuracy: 0.6414\n",
      "Epoch 2211/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9489 - accuracy: 0.8648 - val_loss: 2.3848 - val_accuracy: 0.6409\n",
      "Epoch 2212/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9521 - accuracy: 0.8629 - val_loss: 2.3972 - val_accuracy: 0.6418\n",
      "Epoch 2213/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9645 - accuracy: 0.8613 - val_loss: 2.3372 - val_accuracy: 0.6485\n",
      "Epoch 2214/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9570 - accuracy: 0.8638 - val_loss: 2.4027 - val_accuracy: 0.6365\n",
      "Epoch 2215/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9459 - accuracy: 0.8671 - val_loss: 2.3768 - val_accuracy: 0.6433\n",
      "Epoch 2216/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9486 - accuracy: 0.8661 - val_loss: 2.3732 - val_accuracy: 0.6425\n",
      "Epoch 2217/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9493 - accuracy: 0.8680 - val_loss: 2.4313 - val_accuracy: 0.6366\n",
      "Epoch 2218/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9609 - accuracy: 0.8605 - val_loss: 2.3510 - val_accuracy: 0.6492\n",
      "Epoch 2219/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9395 - accuracy: 0.8685 - val_loss: 2.3560 - val_accuracy: 0.6471\n",
      "Epoch 2220/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9525 - accuracy: 0.8634 - val_loss: 2.4097 - val_accuracy: 0.6407\n",
      "Epoch 2221/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9437 - accuracy: 0.8675 - val_loss: 2.3672 - val_accuracy: 0.6485\n",
      "Epoch 2222/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9466 - accuracy: 0.8668 - val_loss: 2.4046 - val_accuracy: 0.6411\n",
      "Epoch 2223/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9519 - accuracy: 0.8642 - val_loss: 2.3640 - val_accuracy: 0.6426\n",
      "Epoch 2224/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9471 - accuracy: 0.8649 - val_loss: 2.3437 - val_accuracy: 0.6501\n",
      "Epoch 2225/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9411 - accuracy: 0.8658 - val_loss: 2.3999 - val_accuracy: 0.6452\n",
      "Epoch 2226/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9417 - accuracy: 0.8645 - val_loss: 2.3752 - val_accuracy: 0.6401\n",
      "Epoch 2227/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9549 - accuracy: 0.8656 - val_loss: 2.3502 - val_accuracy: 0.6476\n",
      "Epoch 2228/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9551 - accuracy: 0.8645 - val_loss: 2.3843 - val_accuracy: 0.6426\n",
      "Epoch 2229/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9454 - accuracy: 0.8684 - val_loss: 2.3662 - val_accuracy: 0.6479\n",
      "Epoch 2230/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9599 - accuracy: 0.8606 - val_loss: 2.3758 - val_accuracy: 0.6435\n",
      "Epoch 2231/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9555 - accuracy: 0.8628 - val_loss: 2.3590 - val_accuracy: 0.6470\n",
      "Epoch 2232/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9399 - accuracy: 0.8678 - val_loss: 2.4072 - val_accuracy: 0.6434\n",
      "Epoch 2233/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9490 - accuracy: 0.8676 - val_loss: 2.3287 - val_accuracy: 0.6553\n",
      "Epoch 2234/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9471 - accuracy: 0.8668 - val_loss: 2.3236 - val_accuracy: 0.6496\n",
      "Epoch 2235/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9460 - accuracy: 0.8665 - val_loss: 2.3830 - val_accuracy: 0.6467\n",
      "Epoch 2236/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9401 - accuracy: 0.8674 - val_loss: 2.3744 - val_accuracy: 0.6458\n",
      "Epoch 2237/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9365 - accuracy: 0.8698 - val_loss: 2.4019 - val_accuracy: 0.6434\n",
      "Epoch 2238/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9510 - accuracy: 0.8631 - val_loss: 2.3618 - val_accuracy: 0.6493\n",
      "Epoch 2239/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9501 - accuracy: 0.8659 - val_loss: 2.4319 - val_accuracy: 0.6403\n",
      "Epoch 2240/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9679 - accuracy: 0.8630 - val_loss: 2.3951 - val_accuracy: 0.6451\n",
      "Epoch 2241/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9641 - accuracy: 0.8638 - val_loss: 2.3634 - val_accuracy: 0.6450\n",
      "Epoch 2242/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9585 - accuracy: 0.8643 - val_loss: 2.4096 - val_accuracy: 0.6400\n",
      "Epoch 2243/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9601 - accuracy: 0.8624 - val_loss: 2.3469 - val_accuracy: 0.6493\n",
      "Epoch 2244/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9563 - accuracy: 0.8638 - val_loss: 2.4007 - val_accuracy: 0.6441\n",
      "Epoch 2245/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9486 - accuracy: 0.8658 - val_loss: 2.3660 - val_accuracy: 0.6462\n",
      "Epoch 2246/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9468 - accuracy: 0.8659 - val_loss: 2.3748 - val_accuracy: 0.6479\n",
      "Epoch 2247/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9499 - accuracy: 0.8639 - val_loss: 2.3791 - val_accuracy: 0.6418\n",
      "Epoch 2248/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9540 - accuracy: 0.8638 - val_loss: 2.3623 - val_accuracy: 0.6465\n",
      "Epoch 2249/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9544 - accuracy: 0.8673 - val_loss: 2.3459 - val_accuracy: 0.6462\n",
      "Epoch 2250/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9322 - accuracy: 0.8705 - val_loss: 2.4196 - val_accuracy: 0.6388\n",
      "Epoch 2251/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9455 - accuracy: 0.8668 - val_loss: 2.3866 - val_accuracy: 0.6485\n",
      "Epoch 2252/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9416 - accuracy: 0.8684 - val_loss: 2.3681 - val_accuracy: 0.6456\n",
      "Epoch 2253/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9656 - accuracy: 0.8632 - val_loss: 2.4115 - val_accuracy: 0.6412\n",
      "Epoch 2254/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9442 - accuracy: 0.8660 - val_loss: 2.4124 - val_accuracy: 0.6404\n",
      "Epoch 2255/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9424 - accuracy: 0.8696 - val_loss: 2.3721 - val_accuracy: 0.6484\n",
      "Epoch 2256/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9406 - accuracy: 0.8686 - val_loss: 2.3849 - val_accuracy: 0.6439\n",
      "Epoch 2257/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9498 - accuracy: 0.8622 - val_loss: 2.4041 - val_accuracy: 0.6434\n",
      "Epoch 2258/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9549 - accuracy: 0.8619 - val_loss: 2.4167 - val_accuracy: 0.6402\n",
      "Epoch 2259/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9443 - accuracy: 0.8660 - val_loss: 2.3765 - val_accuracy: 0.6430\n",
      "Epoch 2260/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9455 - accuracy: 0.8692 - val_loss: 2.3792 - val_accuracy: 0.6466\n",
      "Epoch 2261/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9461 - accuracy: 0.8674 - val_loss: 2.3402 - val_accuracy: 0.6515\n",
      "Epoch 2262/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9549 - accuracy: 0.8641 - val_loss: 2.3942 - val_accuracy: 0.6429\n",
      "Epoch 2263/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9592 - accuracy: 0.8643 - val_loss: 2.3827 - val_accuracy: 0.6422\n",
      "Epoch 2264/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9472 - accuracy: 0.8672 - val_loss: 2.4011 - val_accuracy: 0.6427\n",
      "Epoch 2265/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9468 - accuracy: 0.8673 - val_loss: 2.4046 - val_accuracy: 0.6411\n",
      "Epoch 2266/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9368 - accuracy: 0.8691 - val_loss: 2.3976 - val_accuracy: 0.6465\n",
      "Epoch 2267/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9506 - accuracy: 0.8671 - val_loss: 2.4011 - val_accuracy: 0.6404\n",
      "Epoch 2268/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9512 - accuracy: 0.8630 - val_loss: 2.4199 - val_accuracy: 0.6402\n",
      "Epoch 2269/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9413 - accuracy: 0.8670 - val_loss: 2.3899 - val_accuracy: 0.6426\n",
      "Epoch 2270/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9496 - accuracy: 0.8663 - val_loss: 2.3793 - val_accuracy: 0.6430\n",
      "Epoch 2271/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9485 - accuracy: 0.8680 - val_loss: 2.3802 - val_accuracy: 0.6387\n",
      "Epoch 2272/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9466 - accuracy: 0.8656 - val_loss: 2.4011 - val_accuracy: 0.6405\n",
      "Epoch 2273/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9447 - accuracy: 0.8672 - val_loss: 2.3808 - val_accuracy: 0.6404\n",
      "Epoch 2274/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9453 - accuracy: 0.8656 - val_loss: 2.4156 - val_accuracy: 0.6392\n",
      "Epoch 2275/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9491 - accuracy: 0.8640 - val_loss: 2.3933 - val_accuracy: 0.6408\n",
      "Epoch 2276/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9608 - accuracy: 0.8633 - val_loss: 2.3613 - val_accuracy: 0.6460\n",
      "Epoch 2277/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9451 - accuracy: 0.8669 - val_loss: 2.3715 - val_accuracy: 0.6409\n",
      "Epoch 2278/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9492 - accuracy: 0.8666 - val_loss: 2.3922 - val_accuracy: 0.6409\n",
      "Epoch 2279/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9415 - accuracy: 0.8675 - val_loss: 2.4136 - val_accuracy: 0.6396\n",
      "Epoch 2280/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9543 - accuracy: 0.8664 - val_loss: 2.3828 - val_accuracy: 0.6481\n",
      "Epoch 2281/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9541 - accuracy: 0.8680 - val_loss: 2.3757 - val_accuracy: 0.6470\n",
      "Epoch 2282/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9461 - accuracy: 0.8676 - val_loss: 2.3762 - val_accuracy: 0.6480\n",
      "Epoch 2283/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9491 - accuracy: 0.8663 - val_loss: 2.4183 - val_accuracy: 0.6370\n",
      "Epoch 2284/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9525 - accuracy: 0.8644 - val_loss: 2.3777 - val_accuracy: 0.6433\n",
      "Epoch 2285/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9509 - accuracy: 0.8643 - val_loss: 2.3657 - val_accuracy: 0.6462\n",
      "Epoch 2286/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9449 - accuracy: 0.8685 - val_loss: 2.4161 - val_accuracy: 0.6403\n",
      "Epoch 2287/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9345 - accuracy: 0.8696 - val_loss: 2.3992 - val_accuracy: 0.6440\n",
      "Epoch 2288/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9502 - accuracy: 0.8667 - val_loss: 2.4036 - val_accuracy: 0.6424\n",
      "Epoch 2289/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9356 - accuracy: 0.8682 - val_loss: 2.4108 - val_accuracy: 0.6435\n",
      "Epoch 2290/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9444 - accuracy: 0.8705 - val_loss: 2.3908 - val_accuracy: 0.6419\n",
      "Epoch 2291/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9424 - accuracy: 0.8659 - val_loss: 2.3899 - val_accuracy: 0.6421\n",
      "Epoch 2292/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9416 - accuracy: 0.8682 - val_loss: 2.3904 - val_accuracy: 0.6442\n",
      "Epoch 2293/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9483 - accuracy: 0.8645 - val_loss: 2.3933 - val_accuracy: 0.6485\n",
      "Epoch 2294/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9411 - accuracy: 0.8689 - val_loss: 2.4041 - val_accuracy: 0.6448\n",
      "Epoch 2295/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9470 - accuracy: 0.8674 - val_loss: 2.4245 - val_accuracy: 0.6404\n",
      "Epoch 2296/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9469 - accuracy: 0.8658 - val_loss: 2.3958 - val_accuracy: 0.6479\n",
      "Epoch 2297/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9395 - accuracy: 0.8689 - val_loss: 2.4124 - val_accuracy: 0.6394\n",
      "Epoch 2298/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9486 - accuracy: 0.8666 - val_loss: 2.3873 - val_accuracy: 0.6400\n",
      "Epoch 2299/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9478 - accuracy: 0.8671 - val_loss: 2.4091 - val_accuracy: 0.6407\n",
      "Epoch 2300/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9554 - accuracy: 0.8649 - val_loss: 2.4529 - val_accuracy: 0.6361\n",
      "Epoch 2301/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9503 - accuracy: 0.8686 - val_loss: 2.3893 - val_accuracy: 0.6446\n",
      "Epoch 2302/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9278 - accuracy: 0.8735 - val_loss: 2.3806 - val_accuracy: 0.6509\n",
      "Epoch 2303/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9473 - accuracy: 0.8662 - val_loss: 2.4129 - val_accuracy: 0.6387\n",
      "Epoch 2304/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9345 - accuracy: 0.8707 - val_loss: 2.3908 - val_accuracy: 0.6436\n",
      "Epoch 2305/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9490 - accuracy: 0.8673 - val_loss: 2.3966 - val_accuracy: 0.6483\n",
      "Epoch 2306/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9505 - accuracy: 0.8638 - val_loss: 2.3791 - val_accuracy: 0.6469\n",
      "Epoch 2307/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9449 - accuracy: 0.8668 - val_loss: 2.4064 - val_accuracy: 0.6401\n",
      "Epoch 2308/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9496 - accuracy: 0.8643 - val_loss: 2.3551 - val_accuracy: 0.6486\n",
      "Epoch 2309/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9420 - accuracy: 0.8662 - val_loss: 2.4314 - val_accuracy: 0.6409\n",
      "Epoch 2310/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9501 - accuracy: 0.8635 - val_loss: 2.4300 - val_accuracy: 0.6415\n",
      "Epoch 2311/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9402 - accuracy: 0.8661 - val_loss: 2.4218 - val_accuracy: 0.6456\n",
      "Epoch 2312/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9390 - accuracy: 0.8679 - val_loss: 2.3906 - val_accuracy: 0.6447\n",
      "Epoch 2313/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9468 - accuracy: 0.8690 - val_loss: 2.3775 - val_accuracy: 0.6492\n",
      "Epoch 2314/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9348 - accuracy: 0.8711 - val_loss: 2.3808 - val_accuracy: 0.6451\n",
      "Epoch 2315/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9417 - accuracy: 0.8681 - val_loss: 2.4175 - val_accuracy: 0.6416\n",
      "Epoch 2316/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9362 - accuracy: 0.8701 - val_loss: 2.4300 - val_accuracy: 0.6396\n",
      "Epoch 2317/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9333 - accuracy: 0.8679 - val_loss: 2.4582 - val_accuracy: 0.6355\n",
      "Epoch 2318/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9365 - accuracy: 0.8665 - val_loss: 2.4010 - val_accuracy: 0.6402\n",
      "Epoch 2319/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9341 - accuracy: 0.8713 - val_loss: 2.3845 - val_accuracy: 0.6442\n",
      "Epoch 2320/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9341 - accuracy: 0.8709 - val_loss: 2.3925 - val_accuracy: 0.6434\n",
      "Epoch 2321/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9337 - accuracy: 0.8709 - val_loss: 2.3428 - val_accuracy: 0.6469\n",
      "Epoch 2322/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9269 - accuracy: 0.8675 - val_loss: 2.3668 - val_accuracy: 0.6483\n",
      "Epoch 2323/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9359 - accuracy: 0.8687 - val_loss: 2.3613 - val_accuracy: 0.6508\n",
      "Epoch 2324/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9326 - accuracy: 0.8707 - val_loss: 2.4051 - val_accuracy: 0.6439\n",
      "Epoch 2325/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9392 - accuracy: 0.8649 - val_loss: 2.3773 - val_accuracy: 0.6478\n",
      "Epoch 2326/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9460 - accuracy: 0.8648 - val_loss: 2.3698 - val_accuracy: 0.6489\n",
      "Epoch 2327/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9451 - accuracy: 0.8679 - val_loss: 2.3853 - val_accuracy: 0.6434\n",
      "Epoch 2328/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9501 - accuracy: 0.8649 - val_loss: 2.3387 - val_accuracy: 0.6496\n",
      "Epoch 2329/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9527 - accuracy: 0.8658 - val_loss: 2.4313 - val_accuracy: 0.6418\n",
      "Epoch 2330/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9373 - accuracy: 0.8688 - val_loss: 2.3611 - val_accuracy: 0.6483\n",
      "Epoch 2331/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9454 - accuracy: 0.8644 - val_loss: 2.3962 - val_accuracy: 0.6419\n",
      "Epoch 2332/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9452 - accuracy: 0.8663 - val_loss: 2.3929 - val_accuracy: 0.6467\n",
      "Epoch 2333/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9349 - accuracy: 0.8699 - val_loss: 2.4057 - val_accuracy: 0.6424\n",
      "Epoch 2334/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9484 - accuracy: 0.8634 - val_loss: 2.3598 - val_accuracy: 0.6499\n",
      "Epoch 2335/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9445 - accuracy: 0.8689 - val_loss: 2.3838 - val_accuracy: 0.6444\n",
      "Epoch 2336/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9327 - accuracy: 0.8717 - val_loss: 2.3420 - val_accuracy: 0.6513\n",
      "Epoch 2337/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9516 - accuracy: 0.8628 - val_loss: 2.3239 - val_accuracy: 0.6504\n",
      "Epoch 2338/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9390 - accuracy: 0.8685 - val_loss: 2.3389 - val_accuracy: 0.6470\n",
      "Epoch 2339/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9441 - accuracy: 0.8691 - val_loss: 2.3315 - val_accuracy: 0.6507\n",
      "Epoch 2340/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9434 - accuracy: 0.8685 - val_loss: 2.3653 - val_accuracy: 0.6452\n",
      "Epoch 2341/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9446 - accuracy: 0.8665 - val_loss: 2.3958 - val_accuracy: 0.6382\n",
      "Epoch 2342/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9396 - accuracy: 0.8693 - val_loss: 2.3823 - val_accuracy: 0.6455\n",
      "Epoch 2343/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9355 - accuracy: 0.8684 - val_loss: 2.3808 - val_accuracy: 0.6478\n",
      "Epoch 2344/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9391 - accuracy: 0.8670 - val_loss: 2.3843 - val_accuracy: 0.6487\n",
      "Epoch 2345/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9380 - accuracy: 0.8729 - val_loss: 2.3936 - val_accuracy: 0.6432\n",
      "Epoch 2346/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9502 - accuracy: 0.8658 - val_loss: 2.4050 - val_accuracy: 0.6423\n",
      "Epoch 2347/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9348 - accuracy: 0.8700 - val_loss: 2.4233 - val_accuracy: 0.6388\n",
      "Epoch 2348/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9464 - accuracy: 0.8646 - val_loss: 2.3809 - val_accuracy: 0.6441\n",
      "Epoch 2349/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9442 - accuracy: 0.8660 - val_loss: 2.3820 - val_accuracy: 0.6421\n",
      "Epoch 2350/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9491 - accuracy: 0.8656 - val_loss: 2.3853 - val_accuracy: 0.6459\n",
      "Epoch 2351/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9546 - accuracy: 0.8654 - val_loss: 2.3330 - val_accuracy: 0.6484\n",
      "Epoch 2352/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9466 - accuracy: 0.8667 - val_loss: 2.3939 - val_accuracy: 0.6412\n",
      "Epoch 2353/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9441 - accuracy: 0.8658 - val_loss: 2.3599 - val_accuracy: 0.6439\n",
      "Epoch 2354/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9406 - accuracy: 0.8671 - val_loss: 2.3493 - val_accuracy: 0.6459\n",
      "Epoch 2355/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9355 - accuracy: 0.8694 - val_loss: 2.3757 - val_accuracy: 0.6493\n",
      "Epoch 2356/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9436 - accuracy: 0.8692 - val_loss: 2.3747 - val_accuracy: 0.6469\n",
      "Epoch 2357/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9444 - accuracy: 0.8665 - val_loss: 2.3855 - val_accuracy: 0.6463\n",
      "Epoch 2358/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9418 - accuracy: 0.8700 - val_loss: 2.4460 - val_accuracy: 0.6365\n",
      "Epoch 2359/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9361 - accuracy: 0.8675 - val_loss: 2.4059 - val_accuracy: 0.6415\n",
      "Epoch 2360/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9428 - accuracy: 0.8680 - val_loss: 2.3817 - val_accuracy: 0.6462\n",
      "Epoch 2361/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9352 - accuracy: 0.8699 - val_loss: 2.3304 - val_accuracy: 0.6475\n",
      "Epoch 2362/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9345 - accuracy: 0.8691 - val_loss: 2.3634 - val_accuracy: 0.6463\n",
      "Epoch 2363/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9427 - accuracy: 0.8678 - val_loss: 2.3738 - val_accuracy: 0.6507\n",
      "Epoch 2364/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9474 - accuracy: 0.8653 - val_loss: 2.3727 - val_accuracy: 0.6503\n",
      "Epoch 2365/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9474 - accuracy: 0.8664 - val_loss: 2.3840 - val_accuracy: 0.6448\n",
      "Epoch 2366/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9450 - accuracy: 0.8656 - val_loss: 2.3955 - val_accuracy: 0.6434\n",
      "Epoch 2367/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9351 - accuracy: 0.8699 - val_loss: 2.3587 - val_accuracy: 0.6459\n",
      "Epoch 2368/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9356 - accuracy: 0.8676 - val_loss: 2.4222 - val_accuracy: 0.6437\n",
      "Epoch 2369/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9427 - accuracy: 0.8677 - val_loss: 2.3675 - val_accuracy: 0.6450\n",
      "Epoch 2370/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9374 - accuracy: 0.8672 - val_loss: 2.3747 - val_accuracy: 0.6494\n",
      "Epoch 2371/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9436 - accuracy: 0.8697 - val_loss: 2.4379 - val_accuracy: 0.6407\n",
      "Epoch 2372/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9342 - accuracy: 0.8720 - val_loss: 2.3750 - val_accuracy: 0.6483\n",
      "Epoch 2373/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9371 - accuracy: 0.8703 - val_loss: 2.4217 - val_accuracy: 0.6464\n",
      "Epoch 2374/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9320 - accuracy: 0.8698 - val_loss: 2.3962 - val_accuracy: 0.6444\n",
      "Epoch 2375/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9342 - accuracy: 0.8700 - val_loss: 2.3831 - val_accuracy: 0.6494\n",
      "Epoch 2376/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9395 - accuracy: 0.8661 - val_loss: 2.3985 - val_accuracy: 0.6486\n",
      "Epoch 2377/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9275 - accuracy: 0.8686 - val_loss: 2.3935 - val_accuracy: 0.6511\n",
      "Epoch 2378/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9360 - accuracy: 0.8722 - val_loss: 2.3978 - val_accuracy: 0.6435\n",
      "Epoch 2379/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9412 - accuracy: 0.8702 - val_loss: 2.3827 - val_accuracy: 0.6481\n",
      "Epoch 2380/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9369 - accuracy: 0.8704 - val_loss: 2.3634 - val_accuracy: 0.6503\n",
      "Epoch 2381/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9403 - accuracy: 0.8710 - val_loss: 2.3452 - val_accuracy: 0.6525\n",
      "Epoch 2382/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9324 - accuracy: 0.8697 - val_loss: 2.3923 - val_accuracy: 0.6461\n",
      "Epoch 2383/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9216 - accuracy: 0.8730 - val_loss: 2.4072 - val_accuracy: 0.6396\n",
      "Epoch 2384/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9356 - accuracy: 0.8682 - val_loss: 2.3901 - val_accuracy: 0.6424\n",
      "Epoch 2385/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9465 - accuracy: 0.8652 - val_loss: 2.3725 - val_accuracy: 0.6459\n",
      "Epoch 2386/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9409 - accuracy: 0.8675 - val_loss: 2.3458 - val_accuracy: 0.6469\n",
      "Epoch 2387/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9379 - accuracy: 0.8682 - val_loss: 2.3980 - val_accuracy: 0.6439\n",
      "Epoch 2388/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9326 - accuracy: 0.8685 - val_loss: 2.3767 - val_accuracy: 0.6466\n",
      "Epoch 2389/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9394 - accuracy: 0.8666 - val_loss: 2.3846 - val_accuracy: 0.6477\n",
      "Epoch 2390/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9282 - accuracy: 0.8721 - val_loss: 2.3732 - val_accuracy: 0.6481\n",
      "Epoch 2391/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9385 - accuracy: 0.8682 - val_loss: 2.4200 - val_accuracy: 0.6405\n",
      "Epoch 2392/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9420 - accuracy: 0.8672 - val_loss: 2.4223 - val_accuracy: 0.6391\n",
      "Epoch 2393/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9451 - accuracy: 0.8670 - val_loss: 2.3922 - val_accuracy: 0.6446\n",
      "Epoch 2394/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9456 - accuracy: 0.8667 - val_loss: 2.3602 - val_accuracy: 0.6429\n",
      "Epoch 2395/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9537 - accuracy: 0.8656 - val_loss: 2.3753 - val_accuracy: 0.6433\n",
      "Epoch 2396/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9302 - accuracy: 0.8704 - val_loss: 2.4104 - val_accuracy: 0.6416\n",
      "Epoch 2397/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9366 - accuracy: 0.8730 - val_loss: 2.3646 - val_accuracy: 0.6485\n",
      "Epoch 2398/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9316 - accuracy: 0.8710 - val_loss: 2.3857 - val_accuracy: 0.6460\n",
      "Epoch 2399/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9362 - accuracy: 0.8685 - val_loss: 2.3950 - val_accuracy: 0.6435\n",
      "Epoch 2400/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9308 - accuracy: 0.8698 - val_loss: 2.4240 - val_accuracy: 0.6390\n",
      "Epoch 2401/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9424 - accuracy: 0.8667 - val_loss: 2.3876 - val_accuracy: 0.6442\n",
      "Epoch 2402/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9373 - accuracy: 0.8686 - val_loss: 2.3961 - val_accuracy: 0.6433\n",
      "Epoch 2403/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9453 - accuracy: 0.8699 - val_loss: 2.4498 - val_accuracy: 0.6373\n",
      "Epoch 2404/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9420 - accuracy: 0.8675 - val_loss: 2.4134 - val_accuracy: 0.6429\n",
      "Epoch 2405/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9381 - accuracy: 0.8677 - val_loss: 2.4302 - val_accuracy: 0.6386\n",
      "Epoch 2406/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9341 - accuracy: 0.8705 - val_loss: 2.4441 - val_accuracy: 0.6414\n",
      "Epoch 2407/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9411 - accuracy: 0.8683 - val_loss: 2.3727 - val_accuracy: 0.6448\n",
      "Epoch 2408/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9248 - accuracy: 0.8707 - val_loss: 2.3885 - val_accuracy: 0.6443\n",
      "Epoch 2409/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9432 - accuracy: 0.8686 - val_loss: 2.4162 - val_accuracy: 0.6409\n",
      "Epoch 2410/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9155 - accuracy: 0.8740 - val_loss: 2.4234 - val_accuracy: 0.6449\n",
      "Epoch 2411/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9346 - accuracy: 0.8705 - val_loss: 2.4273 - val_accuracy: 0.6416\n",
      "Epoch 2412/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9549 - accuracy: 0.8652 - val_loss: 2.4488 - val_accuracy: 0.6420\n",
      "Epoch 2413/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9450 - accuracy: 0.8670 - val_loss: 2.4357 - val_accuracy: 0.6413\n",
      "Epoch 2414/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9332 - accuracy: 0.8674 - val_loss: 2.4152 - val_accuracy: 0.6473\n",
      "Epoch 2415/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9332 - accuracy: 0.8687 - val_loss: 2.4218 - val_accuracy: 0.6441\n",
      "Epoch 2416/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9335 - accuracy: 0.8696 - val_loss: 2.4319 - val_accuracy: 0.6422\n",
      "Epoch 2417/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9325 - accuracy: 0.8692 - val_loss: 2.4135 - val_accuracy: 0.6393\n",
      "Epoch 2418/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9354 - accuracy: 0.8669 - val_loss: 2.3749 - val_accuracy: 0.6498\n",
      "Epoch 2419/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9305 - accuracy: 0.8697 - val_loss: 2.3767 - val_accuracy: 0.6521\n",
      "Epoch 2420/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9305 - accuracy: 0.8700 - val_loss: 2.3532 - val_accuracy: 0.6533\n",
      "Epoch 2421/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9359 - accuracy: 0.8707 - val_loss: 2.4235 - val_accuracy: 0.6411\n",
      "Epoch 2422/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9268 - accuracy: 0.8714 - val_loss: 2.3715 - val_accuracy: 0.6458\n",
      "Epoch 2423/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9383 - accuracy: 0.8691 - val_loss: 2.3957 - val_accuracy: 0.6489\n",
      "Epoch 2424/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9317 - accuracy: 0.8717 - val_loss: 2.3781 - val_accuracy: 0.6488\n",
      "Epoch 2425/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9382 - accuracy: 0.8681 - val_loss: 2.3890 - val_accuracy: 0.6436\n",
      "Epoch 2426/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9323 - accuracy: 0.8686 - val_loss: 2.3913 - val_accuracy: 0.6494\n",
      "Epoch 2427/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9239 - accuracy: 0.8709 - val_loss: 2.4340 - val_accuracy: 0.6401\n",
      "Epoch 2428/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9402 - accuracy: 0.8678 - val_loss: 2.3441 - val_accuracy: 0.6512\n",
      "Epoch 2429/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9472 - accuracy: 0.8704 - val_loss: 2.3663 - val_accuracy: 0.6505\n",
      "Epoch 2430/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9373 - accuracy: 0.8708 - val_loss: 2.4092 - val_accuracy: 0.6448\n",
      "Epoch 2431/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9395 - accuracy: 0.8678 - val_loss: 2.4200 - val_accuracy: 0.6433\n",
      "Epoch 2432/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9393 - accuracy: 0.8686 - val_loss: 2.3664 - val_accuracy: 0.6525\n",
      "Epoch 2433/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9278 - accuracy: 0.8694 - val_loss: 2.3879 - val_accuracy: 0.6469\n",
      "Epoch 2434/2500\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.9288 - accuracy: 0.8701 - val_loss: 2.3300 - val_accuracy: 0.6482\n",
      "Epoch 2435/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9363 - accuracy: 0.8691 - val_loss: 2.3724 - val_accuracy: 0.6493\n",
      "Epoch 2436/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9342 - accuracy: 0.8705 - val_loss: 2.3554 - val_accuracy: 0.6500\n",
      "Epoch 2437/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9317 - accuracy: 0.8714 - val_loss: 2.4234 - val_accuracy: 0.6433\n",
      "Epoch 2438/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9339 - accuracy: 0.8700 - val_loss: 2.4238 - val_accuracy: 0.6402\n",
      "Epoch 2439/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9397 - accuracy: 0.8715 - val_loss: 2.3821 - val_accuracy: 0.6441\n",
      "Epoch 2440/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9370 - accuracy: 0.8713 - val_loss: 2.3557 - val_accuracy: 0.6495\n",
      "Epoch 2441/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9401 - accuracy: 0.8670 - val_loss: 2.4046 - val_accuracy: 0.6459\n",
      "Epoch 2442/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9374 - accuracy: 0.8714 - val_loss: 2.4421 - val_accuracy: 0.6386\n",
      "Epoch 2443/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9403 - accuracy: 0.8652 - val_loss: 2.3874 - val_accuracy: 0.6481\n",
      "Epoch 2444/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9341 - accuracy: 0.8701 - val_loss: 2.3672 - val_accuracy: 0.6518\n",
      "Epoch 2445/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9401 - accuracy: 0.8667 - val_loss: 2.3979 - val_accuracy: 0.6415\n",
      "Epoch 2446/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9324 - accuracy: 0.8693 - val_loss: 2.4060 - val_accuracy: 0.6471\n",
      "Epoch 2447/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9474 - accuracy: 0.8680 - val_loss: 2.3919 - val_accuracy: 0.6494\n",
      "Epoch 2448/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9341 - accuracy: 0.8699 - val_loss: 2.3956 - val_accuracy: 0.6463\n",
      "Epoch 2449/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9347 - accuracy: 0.8708 - val_loss: 2.3997 - val_accuracy: 0.6450\n",
      "Epoch 2450/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9289 - accuracy: 0.8716 - val_loss: 2.4390 - val_accuracy: 0.6420\n",
      "Epoch 2451/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9354 - accuracy: 0.8695 - val_loss: 2.4651 - val_accuracy: 0.6381\n",
      "Epoch 2452/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9309 - accuracy: 0.8719 - val_loss: 2.3876 - val_accuracy: 0.6443\n",
      "Epoch 2453/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9274 - accuracy: 0.8720 - val_loss: 2.3723 - val_accuracy: 0.6488\n",
      "Epoch 2454/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9373 - accuracy: 0.8698 - val_loss: 2.3828 - val_accuracy: 0.6449\n",
      "Epoch 2455/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9233 - accuracy: 0.8730 - val_loss: 2.4339 - val_accuracy: 0.6385\n",
      "Epoch 2456/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9310 - accuracy: 0.8734 - val_loss: 2.3600 - val_accuracy: 0.6466\n",
      "Epoch 2457/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9304 - accuracy: 0.8699 - val_loss: 2.3814 - val_accuracy: 0.6513\n",
      "Epoch 2458/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9424 - accuracy: 0.8697 - val_loss: 2.3616 - val_accuracy: 0.6478\n",
      "Epoch 2459/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9293 - accuracy: 0.8738 - val_loss: 2.4131 - val_accuracy: 0.6416\n",
      "Epoch 2460/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9407 - accuracy: 0.8670 - val_loss: 2.3767 - val_accuracy: 0.6462\n",
      "Epoch 2461/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9426 - accuracy: 0.8662 - val_loss: 2.3937 - val_accuracy: 0.6416\n",
      "Epoch 2462/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9377 - accuracy: 0.8670 - val_loss: 2.4158 - val_accuracy: 0.6426\n",
      "Epoch 2463/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9391 - accuracy: 0.8673 - val_loss: 2.3863 - val_accuracy: 0.6461\n",
      "Epoch 2464/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9263 - accuracy: 0.8717 - val_loss: 2.4451 - val_accuracy: 0.6380\n",
      "Epoch 2465/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9373 - accuracy: 0.8683 - val_loss: 2.4005 - val_accuracy: 0.6464\n",
      "Epoch 2466/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9387 - accuracy: 0.8700 - val_loss: 2.3989 - val_accuracy: 0.6445\n",
      "Epoch 2467/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9458 - accuracy: 0.8709 - val_loss: 2.4146 - val_accuracy: 0.6470\n",
      "Epoch 2468/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9290 - accuracy: 0.8708 - val_loss: 2.4473 - val_accuracy: 0.6400\n",
      "Epoch 2469/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9281 - accuracy: 0.8700 - val_loss: 2.3815 - val_accuracy: 0.6463\n",
      "Epoch 2470/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9294 - accuracy: 0.8697 - val_loss: 2.3842 - val_accuracy: 0.6488\n",
      "Epoch 2471/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9291 - accuracy: 0.8675 - val_loss: 2.3998 - val_accuracy: 0.6470\n",
      "Epoch 2472/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9239 - accuracy: 0.8712 - val_loss: 2.3908 - val_accuracy: 0.6481\n",
      "Epoch 2473/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9195 - accuracy: 0.8725 - val_loss: 2.3505 - val_accuracy: 0.6536\n",
      "Epoch 2474/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9301 - accuracy: 0.8702 - val_loss: 2.4041 - val_accuracy: 0.6425\n",
      "Epoch 2475/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9208 - accuracy: 0.8712 - val_loss: 2.4392 - val_accuracy: 0.6447\n",
      "Epoch 2476/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9416 - accuracy: 0.8668 - val_loss: 2.3700 - val_accuracy: 0.6492\n",
      "Epoch 2477/2500\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.9324 - accuracy: 0.8689 - val_loss: 2.4301 - val_accuracy: 0.6400\n",
      "Epoch 2478/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9341 - accuracy: 0.8689 - val_loss: 2.4052 - val_accuracy: 0.6478\n",
      "Epoch 2479/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9303 - accuracy: 0.8712 - val_loss: 2.3916 - val_accuracy: 0.6460\n",
      "Epoch 2480/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9210 - accuracy: 0.8747 - val_loss: 2.3778 - val_accuracy: 0.6456\n",
      "Epoch 2481/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9257 - accuracy: 0.8708 - val_loss: 2.3968 - val_accuracy: 0.6450\n",
      "Epoch 2482/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9309 - accuracy: 0.8720 - val_loss: 2.3687 - val_accuracy: 0.6507\n",
      "Epoch 2483/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9298 - accuracy: 0.8703 - val_loss: 2.3666 - val_accuracy: 0.6509\n",
      "Epoch 2484/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9348 - accuracy: 0.8685 - val_loss: 2.3409 - val_accuracy: 0.6536\n",
      "Epoch 2485/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9346 - accuracy: 0.8704 - val_loss: 2.4060 - val_accuracy: 0.6478\n",
      "Epoch 2486/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9279 - accuracy: 0.8732 - val_loss: 2.3915 - val_accuracy: 0.6486\n",
      "Epoch 2487/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9409 - accuracy: 0.8673 - val_loss: 2.4162 - val_accuracy: 0.6408\n",
      "Epoch 2488/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9331 - accuracy: 0.8705 - val_loss: 2.3884 - val_accuracy: 0.6496\n",
      "Epoch 2489/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9259 - accuracy: 0.8714 - val_loss: 2.4117 - val_accuracy: 0.6464\n",
      "Epoch 2490/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9302 - accuracy: 0.8714 - val_loss: 2.4029 - val_accuracy: 0.6505\n",
      "Epoch 2491/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9404 - accuracy: 0.8697 - val_loss: 2.3296 - val_accuracy: 0.6566\n",
      "Epoch 2492/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9231 - accuracy: 0.8745 - val_loss: 2.4191 - val_accuracy: 0.6391\n",
      "Epoch 2493/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9245 - accuracy: 0.8728 - val_loss: 2.4448 - val_accuracy: 0.6381\n",
      "Epoch 2494/2500\n",
      "196/196 [==============================] - 16s 82ms/step - loss: 0.9372 - accuracy: 0.8698 - val_loss: 2.4472 - val_accuracy: 0.6403\n",
      "Epoch 2495/2500\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.9307 - accuracy: 0.8718 - val_loss: 2.4249 - val_accuracy: 0.6448\n",
      "Epoch 2496/2500\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.9289 - accuracy: 0.8714 - val_loss: 2.3980 - val_accuracy: 0.6501\n",
      "Epoch 2497/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9157 - accuracy: 0.8757 - val_loss: 2.3794 - val_accuracy: 0.6482\n",
      "Epoch 2498/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9356 - accuracy: 0.8690 - val_loss: 2.3785 - val_accuracy: 0.6504\n",
      "Epoch 2499/2500\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.9275 - accuracy: 0.8711 - val_loss: 2.4157 - val_accuracy: 0.6468\n",
      "Epoch 2500/2500\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 0.9236 - accuracy: 0.8740 - val_loss: 2.4018 - val_accuracy: 0.6455\n"
     ]
    }
   ],
   "source": [
    "# add skip connection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### full code - add skip connection and increase filters ###\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std  = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test  = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "baseMapNum = 32\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# model\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = inputs\n",
    "\n",
    "# block 1\n",
    "previous = x\n",
    "\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.concatenate([x, previous]) \n",
    "\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "# block 2\n",
    "previous = x\n",
    "\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.concatenate([x, previous]) \n",
    "\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "# block 3\n",
    "previous = x\n",
    "\n",
    "x = Conv2D(256, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.concatenate([x, previous]) \n",
    "\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "# block 4\n",
    "previous = x\n",
    "\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.concatenate([x, previous]) \n",
    "\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# block 5\n",
    "previous = x\n",
    "\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = tfa.layers.InstanceNormalization()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.concatenate([x, previous]) \n",
    "\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# dense block \n",
    "\n",
    "x = Flatten()(x)\n",
    "# x = Dense(1024)(x)\n",
    "x = Dense(512)(x)\n",
    "outputs = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "#training\n",
    "batch_size = 256\n",
    "epochs = 2500\n",
    "steps = x_train.shape[0] // batch_size\n",
    "\n",
    "boundaries = [steps*70, steps*110]\n",
    "values = [0.001, 0.0005, 0.0001]\n",
    "schedules = keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "opt_adam  = keras.optimizers.Adam(learning_rate=schedules)\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "def process_data(image, label):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.resize(image, (38, 38))\n",
    "        image = tf.image.random_crop(image, size=[32, 32, 3])\n",
    "      \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train_batches = (train_dataset.shuffle(256*4)\n",
    "                              .map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                              .batch(batch_size)\n",
    "                              .prefetch(tf.data.experimental.AUTOTUNE) )\n",
    "\n",
    "test_dataset = (test_dataset.batch(batch_size))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt_adam, metrics=['accuracy'])\n",
    "history = model.fit(train_batches, validation_data=test_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "1mluHnQhAB1P",
    "outputId": "fe18e05c-71fa-4ada-815f-d83d1ed99b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faa851abd68>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting \n",
    "fig, axs = plt.subplots(1, 2, figsize=(18,5))\n",
    "axs[0].plot(history.history['loss'], color='b', label='training')\n",
    "axs[0].set(xlabel='iteration', ylabel='losses')\n",
    "axs[0].plot(history.history['val_loss'], color='r', label='evaluation')\n",
    "axs[0].legend()\n",
    "axs[1].plot(history.history['accuracy'], color='b', label='training')\n",
    "axs[1].plot(history.history['val_accuracy'], color='r', label='evaluation')\n",
    "axs[1].set(xlabel='iteration', ylabel='sparse categorical accuracy')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vISs7sdKmcDI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFjGg9dsku1F"
   },
   "source": [
    "The following model was implemented based on [this paper](https://arxiv.org/abs/1409.6070)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm03kVRvvUaB",
    "outputId": "da7f114b-8ec7-4e33-e299-7564b670c540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 6s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 94, 94, 300)       8400      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 94, 94, 300)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 94, 94, 300)       1200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 300)       90300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 47, 47, 300)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 47, 47, 300)       1200      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 600)       720600    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 46, 46, 600)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 46, 46, 600)       2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 600)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 600)       360600    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 23, 23, 600)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 600)       2400      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 600)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 22, 22, 900)       2160900   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 22, 22, 900)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 22, 22, 900)       3600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 900)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 900)       810900    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 11, 11, 900)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 900)       3600      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 900)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 1200)      4321200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 10, 10, 1200)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 1200)      4800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 1200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 1200)        1441200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 5, 5, 1200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 1200)        4800      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 1200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 1500)        7201500   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 1500)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 1500)        6000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 1500)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 1500)        2251500   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 1500)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 1500)        6000      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 1500)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 1, 1800)        10801800  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 1, 1, 1800)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 1, 1800)        7200      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 1800)        3241800   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 1, 1, 1800)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1, 1800)        7200      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               180100    \n",
      "=================================================================\n",
      "Total params: 33,641,200\n",
      "Trainable params: 33,616,000\n",
      "Non-trainable params: 25,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "391/391 [==============================] - 151s 366ms/step - loss: 11.9928 - accuracy: 0.0712 - val_loss: 10.6668 - val_accuracy: 0.1109\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 9.7037 - accuracy: 0.1644 - val_loss: 8.4559 - val_accuracy: 0.1828\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 7.8975 - accuracy: 0.2120 - val_loss: 7.0147 - val_accuracy: 0.1829\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 6.9277 - accuracy: 0.2331 - val_loss: 6.1275 - val_accuracy: 0.2531\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 6.3782 - accuracy: 0.2596 - val_loss: 5.6408 - val_accuracy: 0.2642\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 5.9491 - accuracy: 0.2769 - val_loss: 5.9033 - val_accuracy: 0.2316\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 5.5906 - accuracy: 0.2944 - val_loss: 6.0610 - val_accuracy: 0.2548\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 6.3151 - accuracy: 0.2684 - val_loss: 5.4373 - val_accuracy: 0.2950\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 5.3319 - accuracy: 0.3193 - val_loss: 5.1583 - val_accuracy: 0.2901\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 5.2201 - accuracy: 0.3317 - val_loss: 4.9226 - val_accuracy: 0.3265\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 5.0341 - accuracy: 0.3494 - val_loss: 5.1027 - val_accuracy: 0.2852\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.9063 - accuracy: 0.3601 - val_loss: 5.6537 - val_accuracy: 0.2694\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.8587 - accuracy: 0.3719 - val_loss: 5.2652 - val_accuracy: 0.3267\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.8270 - accuracy: 0.3817 - val_loss: 4.7133 - val_accuracy: 0.3375\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.5388 - accuracy: 0.3938 - val_loss: 4.9769 - val_accuracy: 0.2737\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.3635 - accuracy: 0.4054 - val_loss: 7.6342 - val_accuracy: 0.2582\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.3236 - accuracy: 0.4038 - val_loss: 3.9911 - val_accuracy: 0.4358\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 4.0644 - accuracy: 0.4241 - val_loss: 4.2463 - val_accuracy: 0.3536\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.9432 - accuracy: 0.4307 - val_loss: 4.4454 - val_accuracy: 0.3888\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.8592 - accuracy: 0.4390 - val_loss: 4.0727 - val_accuracy: 0.3749\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.8101 - accuracy: 0.4350 - val_loss: 4.9809 - val_accuracy: 0.3406\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.5969 - accuracy: 0.4491 - val_loss: 3.8686 - val_accuracy: 0.4100\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.4440 - accuracy: 0.4618 - val_loss: 3.4136 - val_accuracy: 0.4700\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.3079 - accuracy: 0.4797 - val_loss: 3.2154 - val_accuracy: 0.4900\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.2515 - accuracy: 0.4822 - val_loss: 3.6171 - val_accuracy: 0.4312\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.1667 - accuracy: 0.4892 - val_loss: 3.3379 - val_accuracy: 0.4578\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.0951 - accuracy: 0.4972 - val_loss: 3.1474 - val_accuracy: 0.4977\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 3.0360 - accuracy: 0.5097 - val_loss: 3.0464 - val_accuracy: 0.5028\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.9922 - accuracy: 0.5112 - val_loss: 3.0789 - val_accuracy: 0.5012\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.9289 - accuracy: 0.5200 - val_loss: 2.9291 - val_accuracy: 0.5246\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.9087 - accuracy: 0.5194 - val_loss: 2.9901 - val_accuracy: 0.5132\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.8648 - accuracy: 0.5330 - val_loss: 2.9814 - val_accuracy: 0.5136\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.8157 - accuracy: 0.5384 - val_loss: 2.8044 - val_accuracy: 0.5488\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.7965 - accuracy: 0.5408 - val_loss: 2.8678 - val_accuracy: 0.5381\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.7681 - accuracy: 0.5467 - val_loss: 2.8112 - val_accuracy: 0.5387\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.7366 - accuracy: 0.5552 - val_loss: 2.8190 - val_accuracy: 0.5392\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.7196 - accuracy: 0.5540 - val_loss: 2.8433 - val_accuracy: 0.5363\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.7082 - accuracy: 0.5580 - val_loss: 2.7947 - val_accuracy: 0.5426\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.6791 - accuracy: 0.5605 - val_loss: 2.9059 - val_accuracy: 0.5244\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.6769 - accuracy: 0.5631 - val_loss: 2.6861 - val_accuracy: 0.5624\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.6362 - accuracy: 0.5736 - val_loss: 2.8300 - val_accuracy: 0.5327\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.6251 - accuracy: 0.5714 - val_loss: 2.8290 - val_accuracy: 0.5437\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.6000 - accuracy: 0.5813 - val_loss: 2.7135 - val_accuracy: 0.5604\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5783 - accuracy: 0.5816 - val_loss: 2.7412 - val_accuracy: 0.5574\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5656 - accuracy: 0.5836 - val_loss: 2.7106 - val_accuracy: 0.5607\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5541 - accuracy: 0.5864 - val_loss: 2.7357 - val_accuracy: 0.5598\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5343 - accuracy: 0.5938 - val_loss: 2.7131 - val_accuracy: 0.5594\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5315 - accuracy: 0.5923 - val_loss: 2.7647 - val_accuracy: 0.5554\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.5197 - accuracy: 0.5979 - val_loss: 2.6817 - val_accuracy: 0.5684\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4942 - accuracy: 0.5985 - val_loss: 2.7076 - val_accuracy: 0.5622\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4936 - accuracy: 0.6013 - val_loss: 2.6204 - val_accuracy: 0.5829\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4758 - accuracy: 0.6052 - val_loss: 2.6983 - val_accuracy: 0.5705\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4724 - accuracy: 0.6082 - val_loss: 2.6963 - val_accuracy: 0.5645\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4575 - accuracy: 0.6091 - val_loss: 2.6026 - val_accuracy: 0.5873\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4239 - accuracy: 0.6177 - val_loss: 2.6565 - val_accuracy: 0.5715\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4368 - accuracy: 0.6111 - val_loss: 2.6351 - val_accuracy: 0.5786\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4307 - accuracy: 0.6160 - val_loss: 2.6950 - val_accuracy: 0.5686\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4260 - accuracy: 0.6198 - val_loss: 2.6972 - val_accuracy: 0.5699\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4017 - accuracy: 0.6199 - val_loss: 2.6227 - val_accuracy: 0.5865\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4043 - accuracy: 0.6205 - val_loss: 2.6267 - val_accuracy: 0.5839\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.4023 - accuracy: 0.6256 - val_loss: 2.5861 - val_accuracy: 0.5955\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3708 - accuracy: 0.6298 - val_loss: 2.6060 - val_accuracy: 0.5902\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3865 - accuracy: 0.6284 - val_loss: 2.6233 - val_accuracy: 0.5874\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3548 - accuracy: 0.6325 - val_loss: 2.6097 - val_accuracy: 0.5885\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3583 - accuracy: 0.6321 - val_loss: 2.5369 - val_accuracy: 0.6028\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3583 - accuracy: 0.6330 - val_loss: 2.5621 - val_accuracy: 0.6040\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3529 - accuracy: 0.6363 - val_loss: 2.5950 - val_accuracy: 0.5960\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3413 - accuracy: 0.6380 - val_loss: 2.5502 - val_accuracy: 0.6052\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3331 - accuracy: 0.6405 - val_loss: 2.5974 - val_accuracy: 0.5987\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.3244 - accuracy: 0.6433 - val_loss: 2.3881 - val_accuracy: 0.6227\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.1081 - accuracy: 0.6835 - val_loss: 2.4218 - val_accuracy: 0.6121\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.0465 - accuracy: 0.6899 - val_loss: 2.3401 - val_accuracy: 0.6301\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 2.0174 - accuracy: 0.6965 - val_loss: 2.3563 - val_accuracy: 0.6280\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9968 - accuracy: 0.6971 - val_loss: 2.3255 - val_accuracy: 0.6264\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9609 - accuracy: 0.7049 - val_loss: 2.3320 - val_accuracy: 0.6278\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9448 - accuracy: 0.7072 - val_loss: 2.2613 - val_accuracy: 0.6419\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9397 - accuracy: 0.7067 - val_loss: 2.2963 - val_accuracy: 0.6396\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9182 - accuracy: 0.7100 - val_loss: 2.3118 - val_accuracy: 0.6350\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9239 - accuracy: 0.7094 - val_loss: 2.2637 - val_accuracy: 0.6398\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.9038 - accuracy: 0.7133 - val_loss: 2.3246 - val_accuracy: 0.6312\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8979 - accuracy: 0.7142 - val_loss: 2.2977 - val_accuracy: 0.6374\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8781 - accuracy: 0.7173 - val_loss: 2.3187 - val_accuracy: 0.6332\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8672 - accuracy: 0.7199 - val_loss: 2.2845 - val_accuracy: 0.6393\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8711 - accuracy: 0.7183 - val_loss: 2.2638 - val_accuracy: 0.6360\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8476 - accuracy: 0.7199 - val_loss: 2.2052 - val_accuracy: 0.6505\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8504 - accuracy: 0.7182 - val_loss: 2.3023 - val_accuracy: 0.6335\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8445 - accuracy: 0.7190 - val_loss: 2.2450 - val_accuracy: 0.6436\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8315 - accuracy: 0.7243 - val_loss: 2.2527 - val_accuracy: 0.6399\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8238 - accuracy: 0.7250 - val_loss: 2.2827 - val_accuracy: 0.6365\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8225 - accuracy: 0.7280 - val_loss: 2.2524 - val_accuracy: 0.6462\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8167 - accuracy: 0.7268 - val_loss: 2.2437 - val_accuracy: 0.6453\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8055 - accuracy: 0.7291 - val_loss: 2.2511 - val_accuracy: 0.6402\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8118 - accuracy: 0.7258 - val_loss: 2.3162 - val_accuracy: 0.6331\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7958 - accuracy: 0.7304 - val_loss: 2.2455 - val_accuracy: 0.6388\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.8082 - accuracy: 0.7281 - val_loss: 2.2414 - val_accuracy: 0.6453\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7872 - accuracy: 0.7302 - val_loss: 2.2574 - val_accuracy: 0.6408\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7731 - accuracy: 0.7358 - val_loss: 2.2786 - val_accuracy: 0.6344\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7761 - accuracy: 0.7316 - val_loss: 2.2852 - val_accuracy: 0.6431\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7747 - accuracy: 0.7334 - val_loss: 2.3028 - val_accuracy: 0.6318\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7622 - accuracy: 0.7382 - val_loss: 2.2632 - val_accuracy: 0.6428\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7695 - accuracy: 0.7359 - val_loss: 2.2472 - val_accuracy: 0.6425\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7485 - accuracy: 0.7422 - val_loss: 2.2347 - val_accuracy: 0.6467\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7658 - accuracy: 0.7334 - val_loss: 2.2394 - val_accuracy: 0.6465\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7549 - accuracy: 0.7394 - val_loss: 2.2580 - val_accuracy: 0.6448\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7468 - accuracy: 0.7404 - val_loss: 2.2418 - val_accuracy: 0.6425\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7467 - accuracy: 0.7387 - val_loss: 2.2124 - val_accuracy: 0.6491\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7430 - accuracy: 0.7416 - val_loss: 2.2894 - val_accuracy: 0.6361\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7481 - accuracy: 0.7429 - val_loss: 2.2137 - val_accuracy: 0.6518\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7296 - accuracy: 0.7436 - val_loss: 2.2431 - val_accuracy: 0.6423\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.7312 - accuracy: 0.7423 - val_loss: 2.0792 - val_accuracy: 0.6720\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.5611 - accuracy: 0.7795 - val_loss: 2.0414 - val_accuracy: 0.6803\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.5210 - accuracy: 0.7890 - val_loss: 2.0315 - val_accuracy: 0.6833\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.5060 - accuracy: 0.7926 - val_loss: 2.0301 - val_accuracy: 0.6846\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4752 - accuracy: 0.8021 - val_loss: 2.0184 - val_accuracy: 0.6862\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4633 - accuracy: 0.8037 - val_loss: 2.0209 - val_accuracy: 0.6863\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4503 - accuracy: 0.8064 - val_loss: 2.0253 - val_accuracy: 0.6864\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4261 - accuracy: 0.8095 - val_loss: 2.0231 - val_accuracy: 0.6900\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4308 - accuracy: 0.8078 - val_loss: 2.0235 - val_accuracy: 0.6873\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4203 - accuracy: 0.8109 - val_loss: 2.0391 - val_accuracy: 0.6844\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.4115 - accuracy: 0.8136 - val_loss: 2.0144 - val_accuracy: 0.6902\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3899 - accuracy: 0.8173 - val_loss: 2.0214 - val_accuracy: 0.6874\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3891 - accuracy: 0.8168 - val_loss: 2.0185 - val_accuracy: 0.6882\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3853 - accuracy: 0.8160 - val_loss: 2.0154 - val_accuracy: 0.6861\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3819 - accuracy: 0.8163 - val_loss: 2.0498 - val_accuracy: 0.6872\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3692 - accuracy: 0.8200 - val_loss: 2.0277 - val_accuracy: 0.6858\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3722 - accuracy: 0.8163 - val_loss: 2.0139 - val_accuracy: 0.6893\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3546 - accuracy: 0.8204 - val_loss: 2.0159 - val_accuracy: 0.6913\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3532 - accuracy: 0.8175 - val_loss: 2.0202 - val_accuracy: 0.6907\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3513 - accuracy: 0.8228 - val_loss: 2.0119 - val_accuracy: 0.6907\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3454 - accuracy: 0.8191 - val_loss: 2.0194 - val_accuracy: 0.6890\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3244 - accuracy: 0.8261 - val_loss: 2.0156 - val_accuracy: 0.6913\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3297 - accuracy: 0.8252 - val_loss: 2.0191 - val_accuracy: 0.6905\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3318 - accuracy: 0.8238 - val_loss: 2.0012 - val_accuracy: 0.6941\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3112 - accuracy: 0.8271 - val_loss: 2.0083 - val_accuracy: 0.6882\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3138 - accuracy: 0.8269 - val_loss: 2.0111 - val_accuracy: 0.6890\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3036 - accuracy: 0.8292 - val_loss: 2.0016 - val_accuracy: 0.6921\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.3035 - accuracy: 0.8286 - val_loss: 2.0206 - val_accuracy: 0.6884\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2912 - accuracy: 0.8307 - val_loss: 2.0230 - val_accuracy: 0.6880\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2974 - accuracy: 0.8295 - val_loss: 2.0164 - val_accuracy: 0.6874\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2963 - accuracy: 0.8292 - val_loss: 2.0189 - val_accuracy: 0.6903\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2932 - accuracy: 0.8294 - val_loss: 2.0150 - val_accuracy: 0.6910\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2888 - accuracy: 0.8279 - val_loss: 2.0134 - val_accuracy: 0.6897\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2858 - accuracy: 0.8325 - val_loss: 2.0100 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2763 - accuracy: 0.8351 - val_loss: 1.9887 - val_accuracy: 0.6905\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2769 - accuracy: 0.8299 - val_loss: 2.0060 - val_accuracy: 0.6875\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2696 - accuracy: 0.8366 - val_loss: 2.0084 - val_accuracy: 0.6883\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2580 - accuracy: 0.8366 - val_loss: 2.0060 - val_accuracy: 0.6917\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2600 - accuracy: 0.8350 - val_loss: 2.0167 - val_accuracy: 0.6869\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2655 - accuracy: 0.8329 - val_loss: 2.0087 - val_accuracy: 0.6875\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2493 - accuracy: 0.8380 - val_loss: 2.0245 - val_accuracy: 0.6874\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2540 - accuracy: 0.8336 - val_loss: 2.0040 - val_accuracy: 0.6897\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2578 - accuracy: 0.8330 - val_loss: 1.9986 - val_accuracy: 0.6911\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2352 - accuracy: 0.8394 - val_loss: 2.0035 - val_accuracy: 0.6906\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2450 - accuracy: 0.8381 - val_loss: 2.0076 - val_accuracy: 0.6866\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2422 - accuracy: 0.8344 - val_loss: 2.0169 - val_accuracy: 0.6892\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2391 - accuracy: 0.8363 - val_loss: 2.0052 - val_accuracy: 0.6889\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2323 - accuracy: 0.8415 - val_loss: 2.0060 - val_accuracy: 0.6912\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2240 - accuracy: 0.8407 - val_loss: 2.0016 - val_accuracy: 0.6889\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2262 - accuracy: 0.8374 - val_loss: 1.9988 - val_accuracy: 0.6883\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2190 - accuracy: 0.8397 - val_loss: 2.0123 - val_accuracy: 0.6895\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2273 - accuracy: 0.8379 - val_loss: 2.0169 - val_accuracy: 0.6888\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2230 - accuracy: 0.8388 - val_loss: 2.0029 - val_accuracy: 0.6909\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2156 - accuracy: 0.8400 - val_loss: 2.0055 - val_accuracy: 0.6906\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2189 - accuracy: 0.8406 - val_loss: 1.9967 - val_accuracy: 0.6916\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2117 - accuracy: 0.8422 - val_loss: 1.9953 - val_accuracy: 0.6919\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2176 - accuracy: 0.8401 - val_loss: 2.0055 - val_accuracy: 0.6877\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2048 - accuracy: 0.8421 - val_loss: 2.0104 - val_accuracy: 0.6877\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2069 - accuracy: 0.8406 - val_loss: 2.0060 - val_accuracy: 0.6902\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.2017 - accuracy: 0.8421 - val_loss: 2.0190 - val_accuracy: 0.6893\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1972 - accuracy: 0.8444 - val_loss: 2.0083 - val_accuracy: 0.6915\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1865 - accuracy: 0.8460 - val_loss: 2.0068 - val_accuracy: 0.6913\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1958 - accuracy: 0.8439 - val_loss: 2.0100 - val_accuracy: 0.6920\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1929 - accuracy: 0.8441 - val_loss: 2.0213 - val_accuracy: 0.6881\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1877 - accuracy: 0.8429 - val_loss: 2.0140 - val_accuracy: 0.6883\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1840 - accuracy: 0.8455 - val_loss: 2.0180 - val_accuracy: 0.6874\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1819 - accuracy: 0.8441 - val_loss: 2.0215 - val_accuracy: 0.6883\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1801 - accuracy: 0.8467 - val_loss: 2.0043 - val_accuracy: 0.6891\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1753 - accuracy: 0.8452 - val_loss: 1.9893 - val_accuracy: 0.6888\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1770 - accuracy: 0.8463 - val_loss: 2.0047 - val_accuracy: 0.6866\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1729 - accuracy: 0.8476 - val_loss: 2.0208 - val_accuracy: 0.6877\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1704 - accuracy: 0.8476 - val_loss: 1.9897 - val_accuracy: 0.6900\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1649 - accuracy: 0.8474 - val_loss: 1.9992 - val_accuracy: 0.6920\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1641 - accuracy: 0.8494 - val_loss: 1.9945 - val_accuracy: 0.6908\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1609 - accuracy: 0.8516 - val_loss: 2.0055 - val_accuracy: 0.6904\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1592 - accuracy: 0.8493 - val_loss: 2.0039 - val_accuracy: 0.6880\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1596 - accuracy: 0.8473 - val_loss: 2.0086 - val_accuracy: 0.6890\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1598 - accuracy: 0.8483 - val_loss: 2.0154 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1532 - accuracy: 0.8512 - val_loss: 2.0100 - val_accuracy: 0.6879\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1571 - accuracy: 0.8484 - val_loss: 2.0007 - val_accuracy: 0.6882\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1493 - accuracy: 0.8497 - val_loss: 2.0244 - val_accuracy: 0.6858\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1512 - accuracy: 0.8513 - val_loss: 1.9984 - val_accuracy: 0.6892\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1604 - accuracy: 0.8475 - val_loss: 1.9956 - val_accuracy: 0.6915\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1385 - accuracy: 0.8537 - val_loss: 1.9966 - val_accuracy: 0.6888\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1450 - accuracy: 0.8502 - val_loss: 2.0365 - val_accuracy: 0.6884\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1366 - accuracy: 0.8565 - val_loss: 1.9945 - val_accuracy: 0.6894\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1418 - accuracy: 0.8518 - val_loss: 1.9972 - val_accuracy: 0.6914\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1323 - accuracy: 0.8548 - val_loss: 2.0075 - val_accuracy: 0.6900\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1301 - accuracy: 0.8522 - val_loss: 1.9936 - val_accuracy: 0.6920\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1364 - accuracy: 0.8517 - val_loss: 2.0146 - val_accuracy: 0.6931\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 1.1342 - accuracy: 0.8531 - val_loss: 2.0203 - val_accuracy: 0.6885\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, ZeroPadding2D, LeakyReLU, ReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras import regularizers, optimizers, initializers\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std  = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test  = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "baseMapNum = 32\n",
    "weight_decay = 1e-5\n",
    "\n",
    "initializer = initializers.HeNormal\n",
    "\n",
    "# model\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = ZeroPadding2D(padding=32)(inputs)\n",
    "\n",
    "# block 1\n",
    "x = Conv2D(300, (3,3), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(300, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# block 2\n",
    "x = Conv2D(600, (2,2), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(600, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# block 3\n",
    "x = Conv2D(900, (2,2), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(900, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# block 4\n",
    "x = Conv2D(1200, (2,2), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(1200, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# block 5\n",
    "x = Conv2D(1500, (2,2), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(1500, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# block 6\n",
    "x = Conv2D(1800, (2,2), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(1800, (1,1), kernel_initializer=initializer(),\n",
    "           kernel_regularizer=regularizers.l1_l2(weight_decay, weight_decay))(x)\n",
    "x = LeakyReLU(alpha=1/3.0)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# FCL\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "#training\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "steps = x_train.shape[0] // batch_size\n",
    "\n",
    "boundaries = [steps*70, steps*110]\n",
    "values = [0.001, 0.0005, 0.0001]\n",
    "schedules = keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "opt_adam  = keras.optimizers.Adam(learning_rate=schedules)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# data augmentation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "def process_data(image, label):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.resize(image, (38, 38))\n",
    "        image = tf.image.random_crop(image, size=[32, 32, 3])\n",
    "      \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train_batches = (train_dataset.shuffle(128*4)\n",
    "                              .map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                              .batch(batch_size)\n",
    "                              .prefetch(tf.data.experimental.AUTOTUNE) )\n",
    "\n",
    "test_dataset = (test_dataset.batch(batch_size))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt_adam, metrics=['accuracy'])\n",
    "history = model.fit(train_batches, validation_data=test_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg26Nk_S8o1W",
    "outputId": "dae296d3-2aa7-4bae-931f-f1a61a8413c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7febeac5eef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting \n",
    "fig, axs = plt.subplots(1, 2, figsize=(18,5))\n",
    "axs[0].plot(history.history['loss'], color='b', label='training')\n",
    "axs[0].set(xlabel='iteration', ylabel='losses')\n",
    "axs[0].plot(history.history['val_loss'], color='r', label='evaluation')\n",
    "axs[0].legend()\n",
    "axs[1].plot(history.history['accuracy'], color='b', label='training')\n",
    "axs[1].plot(history.history['val_accuracy'], color='r', label='evaluation')\n",
    "axs[1].set(xlabel='iteration', ylabel='sparse categorical accuracy')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cXXlIDFcga6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
