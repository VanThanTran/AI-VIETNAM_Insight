{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_AI_INSIGHT_HW13_Khoa_Nguyen_KT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhX2Xa4Qs3NG"
      },
      "source": [
        "Class: AI INSIGHT \n",
        "\n",
        "Name: Nguyen Tho Anh Khoa\n",
        "\n",
        "Facebook: Khoa Nguyen KT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FcSVtFDtJW8"
      },
      "source": [
        "# CNN Training – Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wSOUXxtJbW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clw_xkV6tJds"
      },
      "source": [
        "## 1) Đọc hiểu các đoạn code trong file ‘Cifar_10_CNN_Training_Overfitting.ipynb’ kết hợp với xem lại nội dung bài giảng để thấy được những khó khăn và cách giải quyết khi train cho một model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuCzV09KtJgU"
      },
      "source": [
        "Nội dung code trong file 'Cifar_10_CNN_Training_Overfitting.ipynb' thể hiện các vấn đề xoay quanh việc overfitting và các cách cầu hình để giải quyết vấn đề này. Tập data được sử dụng là Cifar10\n",
        "\n",
        "**conv: Convolution layer (khởi đầu bằng 64 kernels và tăng dần bằng cách gấp đôi số kernels của layers trước), và sử dụng kernel_size = 3**\n",
        "\n",
        "**mp: Max pooling layer, reduce size bằng 2**\n",
        "\n",
        "1/ Sử dụng shallow network (2 blocks mỗi block (1conv+1mp)) + sigmoid activate function \n",
        "\n",
        "2/ 3 block layers + sigmoid\n",
        "\n",
        "3/ 3 block layers mỗi block (2conv+1mp) + sigmoid\n",
        "\n",
        "4/ 3 block layers mỗi block (2conv+1mp) + relu\n",
        "\n",
        "5/ 4 block layers mỗi block (2conv+1mp) + relu\n",
        "\n",
        "6/ 4 block layers mỗi block (3conv+1mp) + relu\n",
        "\n",
        "7/ 4 block layers mỗi block (3conv+1mp) + relu + he_init\n",
        "\n",
        "8/ 4 block layers mỗi block (3conv+1mp) + relu + he_init + batch_norm mỗi conv\n",
        "\n",
        "9/ 4 block layers mỗi block (3conv+1mp) + relu + he_init + batch_norm mỗi conv + skip connection mỗi block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUjzi7rJz2TT"
      },
      "source": [
        "|Network| #params | #epochs |train_loss | train_acc | val_loss | val_acc |\n",
        "| ---| ---| ---| --- | ---| ---| ---|\n",
        "|(1) 2x(1conv+1mp)+sigmoid| 157K | 50 |0.88 | 0.69 | 1.02 | 0.65 |\n",
        "|(2) 3x(1conv+1mp)+sigmoid | 411K | 50 | 0.24 | 0.94 | 1.03 | 0.69|\n",
        "|(3) 3x(2conv+1mp)+sigmoid | 3.2M | 20 | 2.3 | 0.1 | 2.3 | 0.1 |\n",
        "|(4) 3x(2conv+1mp)+relu | 3.2M | 50 | 0.03 | 0.99 | 1.77 | 0.78 |\n",
        "|(5) 4x(2conv+1mp)+relu | 5.7M | 50 | 0.04 | 0.99 | 1.49 | 0.79 |\n",
        "|(6) 4x(3conv+1mp)+relu | 8.8M | **10** | 2.3 | 0.1 | 2.3 | 0.1 |\n",
        "|(7) 4x(3conv+1mp)+relu+he_init | 8.8M | 50 | 0.06 | 0.98 | 1.48 | 0.79 |\n",
        "|(8) 4x(3conv+1mp)+relu+he_init+batch_norm/conv | 8.8M | 50 | **0.01** | **1.0** | **0.89** | **0.85** |\n",
        "|(9) 4x(3conv+1mp)+relu+he_init+batch_norm/conv+skip_connection/block | **10.4M** | 50 | 0.03 | 0.99 | 1.93 | 0.77 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqMvrCEAx8rl"
      },
      "source": [
        "Nhìn chung, từ bảng ở trên có thể thấy được model **(1)** là trường hợp duy nhất bị underfit (không đủ capacity để giải quyết được độ phức tạp của data), còn các trường hợp còn lại đều là overfit (model dư khả năng học được tốt với tập train và trở nên mất đi tính tổng quát), ngoại trừ model **(3)** và **(6)** là model đã không thể học được bất cứ thông tin gì về tập data này. Hơn thế nữa có thể quan sát thấy số lượng paramater tăng dần theo từng model thể hiện hiện việc capacity được tăng liên tục nhưng có rất nhiều biến động trong acc/loss trong tập train và val.\n",
        "\n",
        "- Model **(1)** acc của train và val chỉ tầm dưới 0.7, chỉ thể hiện hiện model không đủ khả năng học tốt trên data này.\n",
        "\n",
        "- Model **(2)** train_acc là 0.94 trong khi val_acc là 0.69, cho thấy model đã đươc cải thiện bằng việc tăng thêm một block layer dẫn đến việc dư sức học data train đến mức học cực kỳ chi tiết và làm mất đi tính tổng quát, không thể predict tốt cho tập val.\n",
        "\n",
        "- Model **(3)** và **(6)** đã không học được gì từ data, có thể nguyên nhân là vanishing gradient khi thực hiện backward làm cho weight không được update, ở model **(3)** vì dùng hàm sigmoid nên giá trị input càng lớn (xa dần theo 2 cực âm/dường) thì output sẽ rơi vào vùng saturation nơi mà đạo hàm gần như bằng không, do đó để khắc phục lỗi này **relu** được dùng thay cho sigmoid. Ở model **(6)** model quá deep và khởi tạo weigh không tốt sẽ dẫn đến vanishing gradient khi phải qua nhiều layer.\n",
        "\n",
        "- Model **(4)** và **(5)** thay thế  sigmoid bằng **relu** đã giải quyết được vấn đề vanishing nhưng lại quay về overfitting mặc dù val_acc đã cao hơn so với **(2)**\n",
        "\n",
        "- Model **(7)** giải quyết vanishing của **(6)** bằng cách khởi tọ theo HE initialization.\n",
        "\n",
        "- Model **(8)** cho ra kết quả tốt nhất từ acc của train đến val, bằng cách thêm **Batch Normalization** theo sau các conv layers. Bởi vì khi mỗi lần qua 1 layer distribution từ kết quả của layer trước sẽ bị thay đổi dẫn đến việc học chậm hơn vì các layer phía sau phải học và update theo distribution mới liên tục. Do đó Batch Normlization đã giải quyết được khá tốt vấn đề này bừng cách làm cho fix distribution sau khi qua các conv layer.\n",
        "\n",
        "- Model **(9)** thêm skip conenction, qua các thực nghiệm skip connection cải thiện rất tốt cho các kiến trúc netowrk nhưng tại đây kết quả cho ra tệ hơn có thể bắt nguồn từ việc các phương pháp của model trước đã giải quyết tốt các vấn đề để train model tổng quát hơn. Vì vậy ở đâu khi sử dụng thêm skip conenction đã làm model bị overfitting đông nghĩa với việc khi ta làm phức tạp thêm data có thể model này sẽ cho ra kết quả tốt hơn các cái còn lại.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZOI9yNLxH-B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W4KWzMTxL0v"
      },
      "source": [
        "## 2) (Optional) Các bạn đọc thêm để hiểu rõ hơn về\n",
        "## - Batch normalization\n",
        "## - Skip connection\n",
        "## - He Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OVJKAa5tJmk"
      },
      "source": [
        "### **Batch normalization**\n",
        "\n",
        "- Khi train một model càng sâu thì việc initial weight và lựa chọn learning rate sẽ cần phải kỹ lưỡng vì làm chậm việc học hoặc thậm chí không học được gì. Một trong những nguyên nhân là distribution của input các layers thay đổi (internal covariance shift), vì sau mỗi mini batch các parameter trong network được update mà đối với một deep network chỉ cần sự thay đổi nhỏ trong parameter của layer trước sẽ dẫn đến sự thay đổi nhỏ trong layer của hiện tại và sự thay đổi lớn dần khi càng đi sâu qua từng layer. Do đó, các layers sẽ phải liên tục học các distribuition mới để thích nghi khi distribution của input thay đổi dẫn đến việc học rất chậm.\n",
        "\n",
        "- Batch normalization (BN) ra đời để giải quyết vấn đề này, đây là 1 kỹ thuật input của các layer cho mỗi mini-batch đem lại các lợi ích sau:\n",
        "     - Cho phép sử dụng learning lớn cái mà có thể dẫn đến việc không hội tụ nếu không dùng BN, bằng cách làm giảm sự phụ thuộc củ gradient vào sacle của parameter và initial value.\n",
        "     - Có tính năng như regularization và giảm sự càn thiết sử dụng dropout.\n",
        "     - Làm giảm được generalization error.\n",
        "     - Có thể cho phép train được với các saturating activation như sigmoid,...\n",
        "     - Làm tăng tốc độ hội tụ do cố định mean và var của layer input làm cho distribution hạn chế việc thay đổi.\n",
        "\n",
        "Problem:\n",
        "- Trong training có 1 vấn đề là model sẽ được update backward từ output dến input bằng cách đi qua mỗi layer dựa trên hàm lỗi với giả sử rằng weights của các layer trước đó là không đổi nhưng trong thực tế các weight được update cùng lúc. Bởi vì tất cả weight thay đổi nên việc học cứ phải chạy theo 1 mục tiêu di chuyển liên tục. ví dụ 1 layer cập nhật weight theo 1 distribution của layer trước, nhưng distribution đã là cái mà đã bị thay đổi khi layer trước đó cập nhật. Việc này dẫn đến làm chậm training vì nó yêu cầu laerning rate thấp, cẩn trọng trong việc khởi tạo weight và đối với saturating nonlinearities thì càng khó hơn.\n",
        "\n",
        "Standardize Layer Inputs:\n",
        "- Kỹ thuật này rescaling output của một layer trước khi nó đi vào layer tiêp theo, để có được zero mean và unit standard deviation. Và trong xử lý ảnh (lĩnh vực computer vision) quy trình này được gọi là **whitening**. Kỹ thuật này giúp cố định distribution của input và xóa bỏ các ảnh hưởng của internal covariance shif, ổn định quá trình training và làm tăng tốc độ hội tụ. Ngoài ra BN cũng có công dụng trong việc làm phẳng bề mặt của loss giúp cho gradient có thể trượt với learning rate lớn hơn để model hội tụ nhanh hơn.\n",
        "\n",
        "Implementation:\n",
        "- BN được hiểu đơn giản là sẽ normalize các batches trong network (giữa các layers).\n",
        "- Mỗi input variable của 1 layer sẽ được tính mean và standard deviation trên mỗi mini-batch. Ngoài ra còn có 1 cách sử average mean và standard deviation cho các mini-batch nhưng nó có thể dẫn đến training không ổn định\n",
        "\n",
        "- formulas: $$Z^N=(\\frac{z-\\mu_z}{\\sigma_z})$$, trong đó z là output trước khi qua activation, N số lượng samples trong 1 mini-batch, $\\mu_z$ và $\\sigma_x$ là mean và standard deviation của mini-batch \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FEYu8SGtJpE"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdw-5Idy2Ay7"
      },
      "source": [
        "- Công thức cho 1 mạng NN bình thường: $$z = g(w,x) +b \\quad and \\quad  a = f(z)$$\n",
        "- Công thức cho 1 mạng NN sử dụng batch normalization:\n",
        "$$z=g(w,x) \\quad then \\quad Z^N=(\\frac{z-\\mu_z}{\\sigma_z})\\gamma +\\beta \\quad then \\quad a=f(z^N)$$\n",
        "\n",
        "- Hình trên là 1 mạng neuron network với input x đi qua linear transformation g() với weight w, tiếp theo nó sẽ đi qua batch norm trước khi đi vào activtion function với 2 thông số được sử dụng ở forward state là $\\mu_z$ và $\\sigma_z$. Ngoài ra có thêm 2 paramter tham gia vào quá trình học ở giai đoạn backward là $\\gamma$ và $\\beta$ dùng để shift mean và standard deviation của mini-batch. Hơn thế , bias không được sử dụng trong BN vì khi trừ đi mean, các hằng số trong z sẽ bị trừ đi chính nó. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqYB_AGdnjVN"
      },
      "source": [
        "Advantages\n",
        "- Distribution khi qua các layer được cố định dẫn đến việc học nhanh hơn, normalize để các giá trị cùng scale không chỉ ở layer input mà các layer khác cũng cùng scale.\n",
        "- Vì sử dụng mini-batch thay vì toàn bộ data nên sẽ có nhiễu trong các batch này và nó được vào trong quá trình học nên xem như có regularize (chỉ 1 phần nhỏ)\n",
        "- Giảm sự phụ thuộc của griadient vào các tỉ lệ các parameters, hoặc giá trị khởi tạo weight, có thể sử dụng learning rate cao hơn và tránh được việc không hộ tụ.\n",
        "- Có thể sử dụng saturating activation.\n",
        "\n",
        "Disadvantages\n",
        "- Mini-batch = 1 thì có standard deviation =0 dẫn đên batch norm không hoạt động.\n",
        "- Nếu Mini-batch quá nhỏ đôi khi có thể dẫn đến thêm nhiễu vào model và làm giảm performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV4NB5yFnjYj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtNQwwtSnjbH"
      },
      "source": [
        "###**Skip Connection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUk4USNinjgB"
      },
      "source": [
        "Problem \n",
        "- Mục đích Backpropagation là làm giảm thiểu loss (là 1 thước đo định lượng (quantitative measure) giữa 2 tensor ground truth và predict) bằng cách update parmeters trong network. Backpropagation hiểu được hướng nên thay đổi weigts trong network để  thay đổi làm giảm thiểu loss bằng các tính đạo hàm riêng. Thông thường những giá trị trong khi backpropagation đi qua 1 layer sẽ nhỏ hơn 1 bất kể về dấu (+-), và backpropagation sử dụng theo chain rule nên tất cả các output sau khi backpropagation của từng layer được nhân lại với nhau. Trong trường hợp tổng quát, điều này có thể giúp mạng học ổn định vì các lần update sẽ không quá nhanh cái mà có thể tạo ra hỗn loạn và không thể hội tụ, tuy nhiên nó cũng đồng nghĩa với việc khi đi qua các mạng quá sâu giá trị sẽ nhỏ dần và dẫn đến vấn đề  Vanishing gradient. Từ đó skip connection được tạo ra để gải quyêt vẫn đề này.\n",
        "\n",
        "- Skip connection thường được đề cập như là 1 block các layers, trong các block này ngoài việc các layer kết nối theo chuỗi liên tiếp nhau thì sẽ có 1 hoặc 1 vài layer sẽ kết nối với layer khác bằng cách bỏ qua các layer ở giữa. Bằng cách này nó cho phép gradient có thể được diễn ra tốt hơn trong backpropagation và hội tụ tốt hơn. Thông thường có 2 cách để thực hiện skip connection\n",
        "\n",
        "    - **Additon:** output của một layer sẽ được dùng như input của 1 layer khác (không phải layer theo chuỗi liên tiếp) và được cộng vào với output hiện tại của layer đó. Vì khi backpropagation hiện tượng vanishing gradient sẽ tác động làm cho các layers trước (top layers) học được nhanh hơn các layers sau (bottom layers), việc add thêm connection khi skip 1 vài layers giúp tăng cường cho gradient để có thể lan truyền đến các bottom layers. Thông thường output của các block sau khi qua  sẽ có dạng $y=f(x)$ còn khi dùng skip connection (adding) $y=f(x) + x$ trong đó x sẽ được backpropagtion tốt hơn.\n",
        "\n",
        "     ![res_skip](https://paperswithcode.com/media/methods/resnet-e1548261477164_2_mD02h5A.png)\n",
        "    - **Concatenation:**output của một layer sẽ được dùng như input của 1 layer khác (có thể không phải layer theo chuỗi liên tiếp) và được nối vào với output hiện tại của layer đó (làm tăng lên số lượng filter hay channel).\n",
        "    ![con_skip](https://paperswithcode.com/media/methods/Screen_Shot_2020-06-20_at_11.33.17_PM_Mt0HOZL.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQkfWmrDnjin"
      },
      "source": [
        "Implementation\n",
        "- **Addition:** Một kiến trúc network (architecture network) cùng với learning rate và hyperparameters sẽ cho ra được một tập các lớp function $F$, với mỗi một set parameter (wiegth và bias) sẽ cho ra một $f \\in F$ thông qua việc training trên 1 tập dataset. Điều mong muốn nhất là $f^*$ (function ta muốn tìm cho tập dataset của mình) sẽ nằm trong $F$ nhưng trong thực tế hầu như là không thể, do đó cái ta cần tìm là $f_F^*$ tốt nhất cho tập dataset của mình được train. Nếu 1 architecture netowrk mạnh hơn được thiết kế $F^{'}$ (ví dụ tưng capacity của model) thường được mong đợi sẽ cho kết quả tốt hơn $F$, tuy nhiên trong thực tế điều đó không đúng khi $F \\not\\subset F^{'}$. ví dụ hình bên dưới, ảnh trái non-nested function classes $F_3$ gần nhất với $f^*$ so với $F_1$ cho đến $F_6$. Việc tăng capacity của model sẽ giúp đạt được kết quả chỉ đúng khi $F_1 \\subset F_2 \\subset ... \\subset F_6$ như ảnh bên phải nested-function classes. Do đó câu hỏi được đặt ra liệu identity function $f(\\pmb{x})= \\pmb{x}$ khi được thêm vào trong qua training sẽ cho ra kết quả ít nhất là bằng với model ban đầu? Và nếu có thể nó se giúp model đơn giảng hơn, train nhanh hơn, giảm đươc error tốt hơn. Như vậy ý tưởng của skip connection bằng residual block là dùng một model rất sâu chia thành nhiều block mỗi block này được add thêm identity function để đảm bảo nếu larger function không chứa smaller function thì vẫn có thể học tốt được nhờ vào indetity function. <br/>![nested_f](https://d2l.ai/_images/functionclasses.svg)\n",
        "    - Với ý tưởng là add identity function $f(\\pmb{x})=\\pmb{x}$ vì có thể optimization fucntion lại là $\\pmb{x}$, do đó, model thường thì (ảnh dưới trái) sẽ cố học cách map để cho ra $f(\\pmb{x})$ và sau đó sẽ đi qua acitvation function, nhưng với residual block thì sẽ cố học residual mapping $f(\\pmb{x})-\\pmb{x}$ và cộng thêm identity mapping $g(\\pmb{x})=\\pmb{x}$. Cách hoạt động này dựa trên giả thuyết rằng residual mapping sẽ dễ  optimize hơn so với original mapping $f(\\pmb{x})-\\pmb{x} + g(\\pmb{x})$. Hơn nữa, if identity mapping là optimal thì nó sẽ dễ dàng hơn bằng cách set residual bằng 0. <br/> ![res](https://d2l.ai/_images/residual-block.svg)\n",
        "    - Bởi vì là element-wise addition, nên bắt bưộc output của residual mapping và identity mapping phải có cùng width, height, depth. Nhưng trong 1 số trường hợp, cả 2 có thể khác dimension (thường là khác về  depth), do đó trong identity mapping sẽ đi qua 1 conv có size 1x1 để thay đổi channel bằng với output của residual mapping như ảnh dưới bên phải.<br/>\n",
        "![2res](https://d2l.ai/_images/resnet-block.svg)\n",
        "\n",
        "- **Concatenation:** Tương tự ý tưởng như **Addition** trong skip connection, nhưng thay vì thực hiện add trước khi vào activation thì phương pháp này concatenate (tức là gộp các feature map tạo ra một feature map mới có số lượng lơn hơn về depth). Ý tưởng này cũng dựa trên khai triên Taylor bằng cách phân giải 1 phương trình thành đa thức với bậc tăng dần, tượng tự nhưa kỹ thuật này function đươc phân giải thành $f(\\pmb{x}) = \\pmb{x} + g(\\pmb{x})$ 1 tuyến tính và 1 phi tuyến tinh phức tạp và sau đó nó sẽ được concatenate tăng dần lên. Có thành phần chính trong mạng **dense block** (concatenate input output) và **transition layer** điều khiển depth để nó không quá nhiều bằng cách sử dụng conv 1x1 để điều khiển số lượng depth, trong khi dùng average pooling để điều khiển height and width.  <br/>\n",
        "![den_add](https://d2l.ai/_images/densenet-block.svg)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOjn_f7PnjlQ"
      },
      "source": [
        "Advantages\n",
        "- Skip connection giúp cho việc backgropagation diễn ra dễ hơn và tốt hơn.\n",
        "- Đảm bảo được dù làm cho model deep hơn (tăng số lượng layer) thì vẫn tránh được vấn đề vanishing gradient, và function được xây dựng từ parmeters của model có kiến trúc phức tạp sẽ gần hơn với function mong muốn của 1 tập dataset cụ thể.\n",
        "- Nó có giúp cho việc giữ được low level feature sau khi được extract ra từ các layers đầu không bị trừu tượng hóa sau khi qua các layer phía sau\n",
        "\n",
        "Disadvantages:\n",
        "- Phải điều khiển số lượng depth hợp lý nếu không sẽ đẫn đến việc học rất chậm.\n",
        "- Phải đảm bảo trước khi operate trên skip connection các feature map phải cùng width, hieght, and depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ohSJ7yUnjn1"
      },
      "source": [
        "###**He Initialization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f_2HRHl2A7f"
      },
      "source": [
        "Problem:\n",
        "- Vấn đề liên quan đến việc khi model quá sâu sẽ bị 1 trong 2 trường hợp Exploding hoặc Vanishing, một trong những nguyên nhân là do weight được khởi tạo không tốt. Khi khởi tạo weight, nó được khuyến khích là phải random (vì nếu các unit có weight giống nhau, thì sẽ cùng học theo một hướng dẫn đến việc tăng lượng unit trong 1 layer cũng vô ích), do đó random theo normal distribution thường được hay sử dụng. Tuy nhiên, khi qua các layer sẽ có thay đổi ít nhiều về  variances (hoặc standard deviation ) , và sư thay đổi này được chồng chất lên khi số lượng layer càng nhiều lên. Ví dụ trong mạng MLP, $\\hat{\\pmb{y}} = \\pmb{W*X} + \\pmb{b} $ trong đó \\pbm{X và W} được khởi tạo theo Standard Normal Distribution với mean và standard deviation$\\mu = 0, \\sigma=1$. Bỏ qua nonlinear activation function (được xem như là tuyến tính), thì khi thực hiện tính cho ra kết quả $\\hat{y}$ thì **$\\sigma_y =$ # sqrt(operations của x\\*w\\)* standard deviation được khởi tạo trong x và w**. Ví dụ 10000 layers có 512 units, thì shape của input=512, W=512x512 để cho ra output có shape 512 thì phải thực hiện phép nhân ma trận với số lần sum của từnng element là 512. Do đó sau khi qua 10000 layers thì $ \\sigma_{10000} = \\sqrt(512) $. Để đảm bảo được standard deviation = 1 sau khi qua 10000 layers thì weight khởi tạo theo standard normal distribution chia cho $\\sqrt(512)$.\n",
        "\n",
        "- Cách giải quyết trên thực sự vẫn chưa tốt khi được áp dụng trong khởi tạo weight theo Uniform distribution, và vấn đề về điều khiển standard deviation khi thực hiện backpropagation. Do đó có 1 phương pháp tên là Xavier Initialization được tạo ra để khắc phục vấn đề này. Fully connected layers (không dùng non-linear activation fucntion)sẽ được tính theo công thức:\n",
        "  - $o_i = \\sum^{n_{in}}_{j=1}{w_{ij}*x_j}$, trong đó $o_i$ là unit thứ i của output layer, $n_{in}$ là số lượng unit trong input của layer, $w_{ij}$ là weight cho input element j của ouput unit i, và $x_j$ là input unit của layer.\n",
        "  - Giả sử khởi tạo weight theo distribution (không nhất thiết là Normal distribution) có zero mean và variance $\\sigma^2$, và input có distribution với zero mean và variance $\\gamma^2$. Giả sử $x_j, w_{ij}$ là independent. Để tính được mean và variance của $o_i$ ta thực hiện các phép tính sau: <br/>\n",
        "$E[o_i] = \\sum^{n_{in}}_{j=1}{E[w_{ij}*x_j]} \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}{E[w_{ij}]*E[x_j]} \n",
        "\\\\ = 0 $ $~~~~~~~~~~~~~~~~$\n",
        "$Var[o_i] = E[(o_i - E[o_i])^2]\n",
        "\\\\ = E[o_i^2 - 2*o_i*E(o_i) + E[o_i]^2]\n",
        "\\\\ = E[o_i^2] - 2*E[o_i]^2 + E[o_i]^2 \n",
        "\\\\ = E[o_i^2] -  E[o_i]^2 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[w_{ij}^2*x_{j}^2] -  E[o_i]^2 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[w_{ij}^2]*E[x_{j}^2] - 0 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[(w_{ij} - E[w_{ij}] )^2 ]*E[(x_{j} - E[x_{j}])^2] \n",
        "\\\\ =\\sum^{n_{in}}_{j=1}Var[w_{ij}]*Var[x_{j}]\n",
        "\\\\ = \\sum^{n_{in}}_{j=1}\\sigma^2 * \\gamma^2 \n",
        "\\\\= n_{in}*\\sigma^2 * \\gamma^2 $\n",
        "\n",
        "  - Tương tự ở backpropagation thì variance sẽ thu được là $n_{out}*\\sigma^2 * \\gamma^2 $\n",
        "\n",
        "  - Để duy trì variance gần như là constant để tránh trường hợp Explode và Vanishing, thì khởi tạo weight phải làm sao input variance là không đổi bằng cách $n_{in}*\\sigma^2 =1$ (forward) và $n_{out}*\\sigma^2 =1$ (backward). Nhưng không thể  đáp ứng yêu cầu cùng lúc cho cả 2. Do đó sẽ làm cho tích trung bình cộng của cả 2 và variance của weight = 1. <br/> \n",
        "  $\\frac{n_{in}+n_{out}}{2}*\\sigma^2 = 1$ hoặc $\\sigma=\\sqrt{\\frac{2}{n_{in}+n_{out}}}$\n",
        "  - Trong trường hợp muốn sử dụng Uniform distirbution U(-a, a) (cái mà có variance $\\frac{a^2}{3}$). Do đó U($-\\sqrt{\\frac{6}{n_{in}+n_{out}}}$, $\\sqrt{\\frac{6}{n_{in}+n_{out}}}$)\n",
        "  - **=>Xavier intialization khi sử dụng <br/> Gaussian distribution: $\\sigma=\\sqrt{\\frac{2}{n_{in}+n_{out}}}$ <br/>Uniform distribution: U($-\\sqrt{\\frac{6}{n_{in}+n_{out}}}$, $\\sqrt{\\frac{6}{n_{in}+n_{out}}}$) <br/> Mặc dù công thức trên được chứng minh khi không sử dụng non-linear activation function nhưng Xavier initialization vẫn hoạt động tốt với các symetric activation như sigmoid, tanh,...**\n",
        "\n",
        "- Tuy vậy, xavier initial vẫn không hoạt động tốt với Relu activation. Do đó, He initialization được tạo ra để giải quyêt vấn đề này.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqTneuZ12BBF"
      },
      "source": [
        "Implementation: \n",
        "\n",
        "- He Intialization hoạt động dựa trên 3 giả định:\n",
        "  - Các element trong Input, Weight, và Output trong mỗi layer phải có distribution gần giống nhau và là các independent variables (ví dụ input layer 1 có distribution giống layer 2). \n",
        "  - Mỗi element trong Weight, và mỗi element trong Input là độc lập không phụ thuộc lẫn nhau.\n",
        "  - Weight và Output có zero mean và **đối xứng qua 0** (gần giống normal distribution).\n",
        "  - Không cần thiêt phải khởi tạo bias cho từng layer, nên bias ban đầu sẽ = 0.\n",
        "\n",
        "- Một trong những vấn đề  Relu không thể sử dụng khi áp dụng với Xavier Initialization là do Relu không có zero mean, nên khi ouput của layer trước là input của layer sau khi qua Relu sẽ không còn là zero mean. \n",
        "\n",
        "- Triển khai thì chỉ có Weight là zero mean, còn Input thì không, vì sẽ bao gồm activation function nền sẽ không còn $x_j$ mà là $a_j$: <br/>\n",
        "$E[o_i] = \\sum^{n_{in}}_{j=1}{E[w_{ij}*a_j]} \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}{E[w_{ij}]*E[a_j]} \n",
        "\\\\ = 0 $ $~~~~~~~~~~~~~~~~$\n",
        "$Var[o_i] = E[(o_i - E[o_i])^2] \n",
        "\\\\ = E[o_i^2 - 2*o_i*E(o_i) + E[o_i]^2] \n",
        "\\\\ = E[o_i^2] - 2*E[o_i]^2 + E[o_i]^2 \n",
        "\\\\ = E[o_i^2] -  E[o_i]^2 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[w_{ij}^2*a_{j}^2] -  E[o_i]^2 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[w_{ij}^2]*E[a_{j}^2] - 0 \n",
        "\\\\ = \\sum^{n_{in}}_{j=1}E[(w_{ij} - E[w_{ij}] )^2 ]*E[a_{j}^2] \n",
        "\\\\ = n_{in}*\\sigma^2 * E[a_{j}^2] $\n",
        "\n",
        "- Cần tìm mean của bình phương input trong continuos distribution <br/>\n",
        "$E(x) = \\int_{-\\infty}^{\\infty} {x*f(x)dx}, \\ \\text{(trong đó $f(x)$ là probability density function)}\n",
        "\\\\<=> E(a_j^2) = \\int_{-\\infty}^{\\infty} a_j^2*f(a_j)da_j\n",
        "\\\\ \\qquad \\qquad \\ = \\int_{-\\infty}^{\\infty} max(0,y_j)^2*f(y_j)dy_j\n",
        "\\\\ \\qquad \\qquad \\ = \\int_{0}^{\\infty} y_j^2*f(y_j)dy_j \\quad \\text{(y đối xứng qua 0 và f(y) giả định đối xứng qua 0)}\n",
        "\\\\ \\qquad \\qquad \\ = \\frac{1}{2}\\int_{-\\infty}^{\\infty} y_j^2*f(y_j)dy_j\n",
        "\\\\ \\qquad \\qquad \\ = \\frac{1}{2}\\int_{-\\infty}^{\\infty} (y_j - E[y_j])^2*f(y_j)dy_j \\quad \\text{$E[y_j]$ = 0 vì phần linearity vẫn có gắng giữ distribution có zero mean (kế thừa từ Xavier)}\n",
        "\\\\ \\qquad \\qquad \\ = \\frac{1}{2} E[(y_j - E[y_j])]^2\n",
        "\\\\ \\qquad \\qquad \\ = \\frac{1}{2} Var(y_j)\n",
        "$.\n",
        "\n",
        "- $Var[o_i] = n_{in}*\\sigma^2*\\frac{1}{2}Var[y_j] \\quad \\text{($o_i$ chính là $a_{j+1}$)}$ <br/> \n",
        "$<=> Var[a_j] = n_{in}*\\sigma^2*\\frac{1}{2}Var[y_{j-1}]$\n",
        "\n",
        "- Đặt L là số lượng layer từ input đến output:<br/>\n",
        "$Var[\\pmb{a}^L] = Var[\\pmb{a^1}] \\prod_{l=2}^{l} \\frac{1}{2}n^{l} *Var[\\pmb{W}^l]  \n",
        "\\\\ \\qquad  \\quad \\ = \\prod_{l=1}^{l} \\frac{1}{2}n_{l} *Var[\\pmb{W}_l] \n",
        "$\n",
        "\n",
        "- Vì để tránh exploding hay vanishing thì cần phải giữ cho variance của input và output hạn chế thay đổi ít nhất.<br/>\n",
        "Cần $Var[a^L]=Var[a^1]$ <br/>\n",
        "=> $\\frac{1}{2}n^{l} *Var[\\pmb{W}^l] = 1, \\quad \\forall l $ <br/>\n",
        "=> $Var[\\pmb{W}^l] = \\frac{2}{n^l}, \\quad \\forall l $\n",
        "\n",
        "- **Nếu khởi tạo theo He với Normal Distribution thì $W\\text{~}N(0, \\frac{2}{n^l})$**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Disadvantages:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCbI6e9C08zA"
      },
      "source": [
        "## 3) (Optional) Dựa vào file ‘Cifar_10_CNN_Training_Overfitting.ipynb’, các bạn thực nghiệm tương tự cho dataset Cifar100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmYrbu5q087o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDnwTtwn09Bq",
        "outputId": "43edc4fd-499d-4f2e-8f8d-a50c16f79336"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "print(\"samples of train: \", x_train.shape)\n",
        "print(\"samples of test: \", x_test.shape)\n",
        "print(\"classes: \", len(np.unique(y_train)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "samples of train:  (50000, 32, 32, 3)\n",
            "samples of test:  (10000, 32, 32, 3)\n",
            "classes:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdTHZ9Wgfu_D"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MKDZuuTToxb"
      },
      "source": [
        "class NormalizeLayer(keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(NormalizeLayer, self).__init__()\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = None\n",
        "  @tf.function\n",
        "  def call(self, inputs):\n",
        "    b, h, w, c = inputs.shape\n",
        "    # inputs = tf.cast(inputs, dtype=tf.float64)\n",
        "    means = tf.math.reduce_mean(inputs, axis=(1,2))\n",
        "    means = tf.reshape(means, (-1, 1, c))\n",
        "    print(means)\n",
        "    stddv = tf.math.reduce_std(inputs, axis=(1,2))\n",
        "    stddv = tf.reshape(stddv, (-1, 1, c))\n",
        "    \n",
        "    inputs = tf.reshape(inputs, (-1, h*w, c))\n",
        "    inputs -= means\n",
        "    inputs /= stddv\n",
        "\n",
        "    inputs = tf.reshape(inputs, (-1, h,w,c))\n",
        "\n",
        "    # c1 = inputs[:,:,:,0] -  means[:,0]*tf.ones_like(inputs[:,:,:,0])\n",
        "    # c2 = inputs[:,:,:,1] -  means[:,1]*tf.ones_like(inputs[:,:,:,1])\n",
        "    # c3 = inputs[:,:,:,2] -  means[:,2]*tf.ones_like(inputs[:,:,:,2])\n",
        "\n",
        "    # c1 = c1 /  stddv[:,0]\n",
        "    # c2 = c2 /  stddv[:,1]\n",
        "    # c3 = c3 /  stddv[:,2]\n",
        "\n",
        "    # inputs /= 255.0\n",
        "    # inputs[:,:,:,0] -=  means[:,0]\n",
        "    # inputs[:,:,:,1] -=  means[:,1]\n",
        "    # inputs[:,:,:,2] -=  means[:,2]\n",
        "\n",
        "    # inputs[:,:,:,0] /=  stddv[:,0]\n",
        "    # inputs[:,:,:,1] /=  stddv[:,1]\n",
        "    # inputs[:,:,:,2] /=  stddv[:,2]\n",
        "    # outputs = tf.stack([(inputs[:,:,:,0]-  2),(inputs[:,:,:,1]-  2),(inputs[:,:,:,2]-  2)], axis=-1)\n",
        "    # outputs = tf.stack([c1,c2,c3], axis=-1)\n",
        "    # print(outputs.shape)\n",
        "    print(inputs)\n",
        "    return inputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR_AeqgpViWz"
      },
      "source": [
        "# a = keras.layers.Input((28, 28,3))\n",
        "# NormalizeLayer()(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJB5sgayVPaw"
      },
      "source": [
        "# NormalizeLayer()(x_train[0:2,:,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgm2cMf4aytg"
      },
      "source": [
        "### Buidle Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogvG4oAcOOvL",
        "outputId": "dece1ee8-742c-478e-b1d2-57e23fdceb1a"
      },
      "source": [
        "initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters):\n",
        "  filter1, filter2, filter3 = filters\n",
        "  bn_axis=3 # channels last\n",
        "  x = keras.layers.Conv2D(filters=filter1, kernel_size=(1,1), kernel_initializer='he_normal')(input_tensor)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=filter2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=filter3, kernel_size=(1,1), kernel_initializer='he_normal')(input_tensor)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = keras.layers.add([x, input_tensor])\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, strides=(2,2)):\n",
        "  filter1, filter2, filter3 = filters\n",
        "  bn_axis=3 # channels last\n",
        "  x = keras.layers.Conv2D(filters=filter1, kernel_size=(1,1), strides=strides, kernel_initializer='he_normal')(input_tensor)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=filter2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=filter3, kernel_size=(1,1), kernel_initializer='he_normal')(x)\n",
        "  x = keras.layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  shortcut = keras.layers.Conv2D(filters=filter3, kernel_size=(1,1), strides=strides, kernel_initializer='he_normal')(input_tensor)\n",
        "  shortcut = keras.layers.BatchNormalization(axis=bn_axis)(shortcut)\n",
        "  x = keras.layers.add([x, shortcut])\n",
        "  x = keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "input_layer = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = NormalizeLayer()(input_layer)\n",
        "x = conv_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
        "x = identity_block(x, 3, [64, 64, 256])\n",
        "x = identity_block(x, 3, [64, 64, 256])\n",
        "\n",
        "x = conv_block(x, 3, [128, 128, 512])\n",
        "x = identity_block(x, 3, [128, 128, 512])\n",
        "x = identity_block(x, 3, [128, 128, 512])\n",
        "x = identity_block(x, 3, [128, 128, 512])\n",
        "\n",
        "x = conv_block(x, 3, [256, 256, 1024])\n",
        "x = identity_block(x, 3, [256, 256, 1024])\n",
        "x = identity_block(x, 3, [256, 256, 1024])\n",
        "x = identity_block(x, 3, [256, 256, 1024])\n",
        "# x = identity_block(x, 3, [256, 256, 1024])\n",
        "# x = identity_block(x, 3, [256, 256, 1024])\n",
        "\n",
        "# x = conv_block(x, 3, [512, 512, 2048])\n",
        "# x = identity_block(x, 3, [512, 512, 2048])\n",
        "# x = identity_block(x, 3, [512, 512, 2048])\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# x = keras.layers.Conv2D(filters=2048, kernel_size=(4,4))(x)\n",
        "# x = keras.layers.BatchNormalization()(x)\n",
        "# x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "x = keras.layers.Reshape((1,1,1024))(x)\n",
        "x = keras.layers.Conv2D(filters=100, kernel_size=(1,1), activation='softmax')(x)\n",
        "x = keras.layers.Reshape((100,))(x)\n",
        "# x = keras.layers.Dense(100, activation='softmax')(x)\n",
        "model = keras.Model(input_layer, x)\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(None, 1, 3), dtype=float32)\n",
            "Tensor(\"Reshape_3:0\", shape=(None, 32, 32, 3), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "normalize_layer_1 (NormalizeLay (None, 32, 32, 3)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   256         normalize_layer_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 256)  16640       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 256)  1024        normalize_layer_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 256)  0           batch_normalization_2[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 256)  65792       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 256)  65792       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 128)  32896       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  66048       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  131584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 512)  262656      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 512)  2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 512)  0           batch_normalization_16[0][0]     \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 512)  262656      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 512)  2048        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 512)  0           batch_normalization_19[0][0]     \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 512)  262656      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 512)  2048        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 512)  0           batch_normalization_22[0][0]     \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 256)    131328      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 256)    1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 256)    590080      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 1024)   263168      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 1024)   525312      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 1024)   4096        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 1024)   4096        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 1024)   1049600     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 1024)   4096        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_29[0][0]     \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 1024)   1049600     activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 1024)   4096        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_32[0][0]     \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 1024)   1049600     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 1024)   4096        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_35[0][0]     \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 1, 1024)   0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 1, 1, 100)    102500      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 100)          0           conv2d_36[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,152,100\n",
            "Trainable params: 6,132,900\n",
            "Non-trainable params: 19,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EZjN-dOK9QS"
      },
      "source": [
        "### Train Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8uyG7APHdeK"
      },
      "source": [
        "cifar100_train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzEHkivZLevK"
      },
      "source": [
        "cifar100_train_ds = cifar100_train_ds.shuffle(50000).batch(512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwIrhBNxm-L6"
      },
      "source": [
        "cifar100_test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MpQuNEIK9x4"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4XDJvOTq2F4",
        "outputId": "05421b69-638b-43f3-eacf-4be6196e5590"
      },
      "source": [
        "history = model.fit(cifar100_train_ds, validation_data=cifar100_test_ds, epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 127s 1s/step - loss: 4.1336 - accuracy: 0.1072 - val_loss: 14.7119 - val_accuracy: 0.0267\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 2.8985 - accuracy: 0.2840 - val_loss: 5.7966 - val_accuracy: 0.1233\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 2.4037 - accuracy: 0.3778 - val_loss: 4.7627 - val_accuracy: 0.1733\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 2.0454 - accuracy: 0.4576 - val_loss: 3.3225 - val_accuracy: 0.2625\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 1.7533 - accuracy: 0.5231 - val_loss: 3.0558 - val_accuracy: 0.3105\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 1.5171 - accuracy: 0.5815 - val_loss: 3.2031 - val_accuracy: 0.3122\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 1.2813 - accuracy: 0.6394 - val_loss: 2.8662 - val_accuracy: 0.3602\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 1.0472 - accuracy: 0.7049 - val_loss: 2.6102 - val_accuracy: 0.3806\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.8529 - accuracy: 0.7588 - val_loss: 3.5426 - val_accuracy: 0.3140\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.6430 - accuracy: 0.8250 - val_loss: 3.2458 - val_accuracy: 0.3466\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.4545 - accuracy: 0.8829 - val_loss: 3.0302 - val_accuracy: 0.3809\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.3156 - accuracy: 0.9279 - val_loss: 2.9564 - val_accuracy: 0.4115\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.1927 - accuracy: 0.9658 - val_loss: 2.9495 - val_accuracy: 0.3993\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.1098 - accuracy: 0.9848 - val_loss: 2.8702 - val_accuracy: 0.4240\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0492 - accuracy: 0.9972 - val_loss: 2.5704 - val_accuracy: 0.4629\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 2.5791 - val_accuracy: 0.4782\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0217 - accuracy: 0.9981 - val_loss: 2.4524 - val_accuracy: 0.4956\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0124 - accuracy: 0.9996 - val_loss: 2.4959 - val_accuracy: 0.4946\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0099 - accuracy: 0.9997 - val_loss: 2.4076 - val_accuracy: 0.5027\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0081 - accuracy: 0.9997 - val_loss: 2.4419 - val_accuracy: 0.5035\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 2.5100 - val_accuracy: 0.5004\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 2.4914 - val_accuracy: 0.5042\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 2.5931 - val_accuracy: 0.4895\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 2.5318 - val_accuracy: 0.4982\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 2.6890 - val_accuracy: 0.4936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPYYnzZx2BGJ"
      },
      "source": [
        "## References\n",
        "\n",
        "2.1/\n",
        "- https://arxiv.org/pdf/1502.03167.pdf\n",
        "- https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/\n",
        "- https://viblo.asia/p/normalization-and-normalization-techniques-in-deep-learning-QpmleJyn5rd\n",
        "- https://www.baeldung.com/cs/batch-normalization-cnn\n",
        "\n",
        "2.2/\n",
        "- https://arxiv.org/pdf/1512.03385.pdf\n",
        "- https://theaisummer.com/skip-connections/#:~:text=Skip%20connections%20for%20the%20win,module%20in%20many%20convolutional%20architectures.&text=Skip%20connections%20in%20deep%20architectures,of%20only%20the%20next%20one).\n",
        "- Multi-MemoryConvolutionalNeuralNetworkforVideoSuper-Resolution.pdf\n",
        "- https://paperswithcode.com/methods/category/skip-connection-blocks \n",
        "- https://viblo.asia/p/gioi-thieu-mang-resnet-vyDZOa7R5wj\n",
        "-https://forum.machinelearningcoban.com/t/01-03-2018-11-59-cho-em-hoi-tai-sao-trong-cnn-ap-dung-resnet/12497\n",
        "- https://d2l.aivivn.com/chapter_convolutional-modern/resnet_vn.html\n",
        "- https://towardsdatascience.com/foundations-of-ml-parameterized-functions-d2951a62272e#:~:text=A%20parameterized%20function%20is%20a,a%20is%20the%20constant%20one.\n",
        "\n",
        "2.3/\n",
        "- https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html\n",
        "- https://d2l.aivivn.com/chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html\n",
        "- https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79\n",
        "- https://paperswithcode.com/method/he-initialization\n",
        "- https://medium.com/@shoray.goel/kaiming-he-initialization-a8d9ed0b5899\n",
        "- https://stats.stackexchange.com/questions/138035/variance-calculation-relu-function-deep-learning\n",
        "- https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
        "- https://www.telesens.co/2018/04/09/initializing-weights-for-the-convolutional-and-fully-connected-layers/\n",
        "\n",
        "3/\n",
        "- https://www.tensorflow.org/guide/data#basic_mechanics\n",
        "- https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
        "- https://www.tensorflow.org/tfx/tutorials/transform/simple\n",
        "- https://www.tensorflow.org/tfx/transform/get_started\n",
        "- https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/\n",
        "- https://aihub.cloud.google.com/u/0/p/products%2Fee2b7309-ee34-41b1-a993-3d7522ccbfb9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuaflQDUOOpP"
      },
      "source": [
        "### Train Model Draft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg_ypGRkIKKh",
        "outputId": "694d8650-0f80-43a0-d114-4f81c65f414b"
      },
      "source": [
        "fmnist_train_ds = cifar100_train_ds.shuffle(5000).batch(2)\n",
        "for a, b in fmnist_train_ds:\n",
        "  print(a.shape)\n",
        "  print(b.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 32, 32, 3)\n",
            "(2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLx339_5t-DA",
        "outputId": "b5814f31-53dd-40f1-a0ea-95db2629f5f5"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "def loss(model, x, y, training):\n",
        "  # training=training is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  y_ = model(x, training=training)\n",
        "\n",
        "  return loss_object(y_true=y, y_pred=y_)\n",
        "for img, label in  fmnist_train_ds:\n",
        "  l = loss(model, img, label, training=False)\n",
        "  print(\"Loss test: {}\".format(l))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss test: 1826.7061767578125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv1_WgZjJMha"
      },
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDge842KkXC"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "D9x7p6M7t-JL",
        "outputId": "7a6eaa39-be2f-481e-bead-2f60f10f29f3"
      },
      "source": [
        "loss_res = []\n",
        "acc_res = []\n",
        "num_epochs = 10\n",
        "cifar100_train_ds = cifar100_train_ds.shuffle(50000).batch(128)\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  for x, y in cifar100_train_ds:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    # Track progress\n",
        "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
        "    # Compare predicted label to actual label\n",
        "    # training=True is needed only if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    epoch_accuracy.update_state(y, model(x, training=True))\n",
        "  # End epoch\n",
        "  loss_res.append(epoch_loss_avg.result())\n",
        "  acc_res.append(epoch_accuracy.result())\n",
        "  if epoch % 1 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-63fa1dd07c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mepoch_loss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mepoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcifar100_train_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "9kZ9JO2B09Ur",
        "outputId": "6594e286-45e0-4bd6-c1c0-c760b62c9240"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c8647190f3fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcifar100_train_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'TensorSliceDataset' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g3dGlXG2IB4"
      },
      "source": [
        "? implement and prove by code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCcpyf-Joyl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}