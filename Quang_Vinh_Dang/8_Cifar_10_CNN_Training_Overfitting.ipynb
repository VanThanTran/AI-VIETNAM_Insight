{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bSZk-yNAu1-y",
    "outputId": "daeb3ca2-df76-425d-f374-b01fe51a5c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 157,578\n",
      "Trainable params: 157,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 2.3560 - accuracy: 0.1132 - val_loss: 2.2705 - val_accuracy: 0.2083\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 2.1757 - accuracy: 0.2081 - val_loss: 2.0417 - val_accuracy: 0.2911\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.9791 - accuracy: 0.2946 - val_loss: 1.8707 - val_accuracy: 0.3384\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.8312 - accuracy: 0.3567 - val_loss: 1.7882 - val_accuracy: 0.3774\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.7493 - accuracy: 0.3850 - val_loss: 1.7050 - val_accuracy: 0.4040\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.6600 - accuracy: 0.4143 - val_loss: 1.6583 - val_accuracy: 0.4113\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.5795 - accuracy: 0.4405 - val_loss: 1.5497 - val_accuracy: 0.4485\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.5196 - accuracy: 0.4628 - val_loss: 1.5109 - val_accuracy: 0.4585\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.4736 - accuracy: 0.4799 - val_loss: 1.4398 - val_accuracy: 0.4869\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.4327 - accuracy: 0.4940 - val_loss: 1.4308 - val_accuracy: 0.4885\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.4115 - accuracy: 0.5004 - val_loss: 1.4346 - val_accuracy: 0.4906\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.3797 - accuracy: 0.5133 - val_loss: 1.3633 - val_accuracy: 0.5181\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.3580 - accuracy: 0.5208 - val_loss: 1.3437 - val_accuracy: 0.5242\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.3344 - accuracy: 0.5301 - val_loss: 1.3572 - val_accuracy: 0.5226\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.3146 - accuracy: 0.5374 - val_loss: 1.3237 - val_accuracy: 0.5283\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2925 - accuracy: 0.5445 - val_loss: 1.2981 - val_accuracy: 0.5408\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2819 - accuracy: 0.5467 - val_loss: 1.2831 - val_accuracy: 0.5437\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2597 - accuracy: 0.5573 - val_loss: 1.2609 - val_accuracy: 0.5504\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2501 - accuracy: 0.5599 - val_loss: 1.2549 - val_accuracy: 0.5573\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2245 - accuracy: 0.5680 - val_loss: 1.2431 - val_accuracy: 0.5557\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.2083 - accuracy: 0.5741 - val_loss: 1.2211 - val_accuracy: 0.5651\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.1866 - accuracy: 0.5863 - val_loss: 1.2073 - val_accuracy: 0.5731\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.1756 - accuracy: 0.5877 - val_loss: 1.2012 - val_accuracy: 0.5738\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.1522 - accuracy: 0.5989 - val_loss: 1.1821 - val_accuracy: 0.5832\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.1416 - accuracy: 0.5995 - val_loss: 1.1647 - val_accuracy: 0.5823\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.1159 - accuracy: 0.6112 - val_loss: 1.1507 - val_accuracy: 0.5903\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.1120 - accuracy: 0.6108 - val_loss: 1.1711 - val_accuracy: 0.5863\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0923 - accuracy: 0.6185 - val_loss: 1.1536 - val_accuracy: 0.5890\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0785 - accuracy: 0.6233 - val_loss: 1.1307 - val_accuracy: 0.5956\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0712 - accuracy: 0.6248 - val_loss: 1.1205 - val_accuracy: 0.5977\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0547 - accuracy: 0.6310 - val_loss: 1.1132 - val_accuracy: 0.6052\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0410 - accuracy: 0.6359 - val_loss: 1.1063 - val_accuracy: 0.6007\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0322 - accuracy: 0.6405 - val_loss: 1.0991 - val_accuracy: 0.6106\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0202 - accuracy: 0.6423 - val_loss: 1.1051 - val_accuracy: 0.6064\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0081 - accuracy: 0.6478 - val_loss: 1.0961 - val_accuracy: 0.6088\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0000 - accuracy: 0.6502 - val_loss: 1.0860 - val_accuracy: 0.6140\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9879 - accuracy: 0.6528 - val_loss: 1.0801 - val_accuracy: 0.6187\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9806 - accuracy: 0.6574 - val_loss: 1.0581 - val_accuracy: 0.6269\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9704 - accuracy: 0.6632 - val_loss: 1.1025 - val_accuracy: 0.6096\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9571 - accuracy: 0.6672 - val_loss: 1.0930 - val_accuracy: 0.6159\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9529 - accuracy: 0.6671 - val_loss: 1.0611 - val_accuracy: 0.6266\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9425 - accuracy: 0.6718 - val_loss: 1.0389 - val_accuracy: 0.6342\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9321 - accuracy: 0.6741 - val_loss: 1.0530 - val_accuracy: 0.6266\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9281 - accuracy: 0.6753 - val_loss: 1.0226 - val_accuracy: 0.6382\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9168 - accuracy: 0.6786 - val_loss: 1.0539 - val_accuracy: 0.6284\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.9096 - accuracy: 0.6847 - val_loss: 1.0224 - val_accuracy: 0.6422\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8990 - accuracy: 0.6887 - val_loss: 1.0364 - val_accuracy: 0.6386\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8947 - accuracy: 0.6888 - val_loss: 1.0357 - val_accuracy: 0.6369\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8866 - accuracy: 0.6907 - val_loss: 1.0131 - val_accuracy: 0.6473\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8809 - accuracy: 0.6930 - val_loss: 1.0192 - val_accuracy: 0.6459\n"
     ]
    }
   ],
   "source": [
    "# sigmoid for cifar-10\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDyvbW8QQPC_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sX5X52ijV5s-",
    "outputId": "c9061fb0-ea43-46c7-b61c-a9d8d276601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 411,786\n",
      "Trainable params: 411,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.3406 - accuracy: 0.1054 - val_loss: 2.2915 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 2.0573 - accuracy: 0.2558 - val_loss: 1.9157 - val_accuracy: 0.3097\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.7947 - accuracy: 0.3559 - val_loss: 1.6770 - val_accuracy: 0.3885\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.6066 - accuracy: 0.4240 - val_loss: 1.5577 - val_accuracy: 0.4403\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.5004 - accuracy: 0.4631 - val_loss: 1.4662 - val_accuracy: 0.4773\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.4160 - accuracy: 0.4949 - val_loss: 1.3855 - val_accuracy: 0.5077\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.3595 - accuracy: 0.5187 - val_loss: 1.3434 - val_accuracy: 0.5163\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.3016 - accuracy: 0.5405 - val_loss: 1.2926 - val_accuracy: 0.5368\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.2491 - accuracy: 0.5594 - val_loss: 1.2407 - val_accuracy: 0.5535\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.1993 - accuracy: 0.5784 - val_loss: 1.2212 - val_accuracy: 0.5585\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.1582 - accuracy: 0.5944 - val_loss: 1.1830 - val_accuracy: 0.5782\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.1193 - accuracy: 0.6065 - val_loss: 1.2124 - val_accuracy: 0.5729\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.0829 - accuracy: 0.6230 - val_loss: 1.1304 - val_accuracy: 0.5957\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.0492 - accuracy: 0.6347 - val_loss: 1.1079 - val_accuracy: 0.6043\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.0137 - accuracy: 0.6473 - val_loss: 1.0904 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.9792 - accuracy: 0.6603 - val_loss: 1.0719 - val_accuracy: 0.6209\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.9461 - accuracy: 0.6736 - val_loss: 1.0604 - val_accuracy: 0.6214\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.9174 - accuracy: 0.6811 - val_loss: 1.0653 - val_accuracy: 0.6206\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.8860 - accuracy: 0.6950 - val_loss: 1.0181 - val_accuracy: 0.6409\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.8575 - accuracy: 0.7044 - val_loss: 1.0187 - val_accuracy: 0.6431\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.8281 - accuracy: 0.7143 - val_loss: 1.0024 - val_accuracy: 0.6514\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.8098 - accuracy: 0.7223 - val_loss: 1.0083 - val_accuracy: 0.6484\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.7789 - accuracy: 0.7319 - val_loss: 0.9773 - val_accuracy: 0.6592\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.7568 - accuracy: 0.7405 - val_loss: 0.9789 - val_accuracy: 0.6570\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.7292 - accuracy: 0.7510 - val_loss: 0.9658 - val_accuracy: 0.6660\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.7029 - accuracy: 0.7618 - val_loss: 0.9640 - val_accuracy: 0.6668\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.6761 - accuracy: 0.7715 - val_loss: 0.9533 - val_accuracy: 0.6744\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.6570 - accuracy: 0.7759 - val_loss: 0.9463 - val_accuracy: 0.6771\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.6304 - accuracy: 0.7873 - val_loss: 0.9706 - val_accuracy: 0.6636\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.6077 - accuracy: 0.7959 - val_loss: 0.9786 - val_accuracy: 0.6668\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.5841 - accuracy: 0.8052 - val_loss: 0.9427 - val_accuracy: 0.6799\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.5646 - accuracy: 0.8114 - val_loss: 0.9318 - val_accuracy: 0.6850\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.5419 - accuracy: 0.8202 - val_loss: 0.9551 - val_accuracy: 0.6795\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.5240 - accuracy: 0.8264 - val_loss: 0.9397 - val_accuracy: 0.6848\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.5021 - accuracy: 0.8339 - val_loss: 0.9549 - val_accuracy: 0.6791\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.4800 - accuracy: 0.8418 - val_loss: 0.9545 - val_accuracy: 0.6824\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.4612 - accuracy: 0.8506 - val_loss: 0.9878 - val_accuracy: 0.6738\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.4442 - accuracy: 0.8561 - val_loss: 0.9510 - val_accuracy: 0.6833\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.4238 - accuracy: 0.8655 - val_loss: 0.9508 - val_accuracy: 0.6861\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.4016 - accuracy: 0.8741 - val_loss: 1.0208 - val_accuracy: 0.6670\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3841 - accuracy: 0.8795 - val_loss: 0.9696 - val_accuracy: 0.6890\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3666 - accuracy: 0.8874 - val_loss: 0.9845 - val_accuracy: 0.6823\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3475 - accuracy: 0.8954 - val_loss: 0.9846 - val_accuracy: 0.6857\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3369 - accuracy: 0.8990 - val_loss: 1.0028 - val_accuracy: 0.6843\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3164 - accuracy: 0.9060 - val_loss: 1.0114 - val_accuracy: 0.6818\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.2968 - accuracy: 0.9164 - val_loss: 1.0217 - val_accuracy: 0.6838\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.2846 - accuracy: 0.9204 - val_loss: 1.0113 - val_accuracy: 0.6843\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.2665 - accuracy: 0.9270 - val_loss: 1.0190 - val_accuracy: 0.6861\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.2551 - accuracy: 0.9308 - val_loss: 1.0342 - val_accuracy: 0.6836\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.2375 - accuracy: 0.9385 - val_loss: 1.0286 - val_accuracy: 0.6873\n"
     ]
    }
   ],
   "source": [
    "# sigmoid for cifar-10: adding layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzRcmWTbQPF3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tEEeAJkFg0k_",
    "outputId": "96523db8-850c-4009-8c68-f448eac7bc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,248,202\n",
      "Trainable params: 3,248,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 21s 107ms/step - loss: 2.3570 - accuracy: 0.1018 - val_loss: 2.3080 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 2.3141 - accuracy: 0.0990 - val_loss: 2.3195 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 2.3117 - accuracy: 0.0988 - val_loss: 2.3077 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3123 - accuracy: 0.1001 - val_loss: 2.3232 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3126 - accuracy: 0.0991 - val_loss: 2.3056 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3109 - accuracy: 0.1020 - val_loss: 2.3077 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3097 - accuracy: 0.1008 - val_loss: 2.3070 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3089 - accuracy: 0.0993 - val_loss: 2.3105 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3080 - accuracy: 0.1004 - val_loss: 2.3056 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 2.3070 - accuracy: 0.1024 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 2.3065 - accuracy: 0.1007 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3068 - accuracy: 0.1001 - val_loss: 2.3049 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3054 - accuracy: 0.1000 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3050 - accuracy: 0.0990 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3054 - accuracy: 0.1004 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3050 - accuracy: 0.1016 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3042 - accuracy: 0.1001 - val_loss: 2.3049 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 2.3042 - accuracy: 0.1005 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 2.3043 - accuracy: 0.0982 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 2.3038 - accuracy: 0.0998 - val_loss: 2.3030 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# sigmoid for cifar-10: Keep adding layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPVVNHOAg0nx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wMb2xLjQp4EK",
    "outputId": "5d17dd37-5ef4-41f7-96ed-fbacef0df6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,248,202\n",
      "Trainable params: 3,248,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 1.8134 - accuracy: 0.3230 - val_loss: 1.4157 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 1.1855 - accuracy: 0.5731 - val_loss: 1.0497 - val_accuracy: 0.6243\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.9049 - accuracy: 0.6798 - val_loss: 0.8617 - val_accuracy: 0.6936\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.7441 - accuracy: 0.7393 - val_loss: 0.8246 - val_accuracy: 0.7074\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.6251 - accuracy: 0.7788 - val_loss: 0.6861 - val_accuracy: 0.7615\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.5201 - accuracy: 0.8192 - val_loss: 0.6558 - val_accuracy: 0.7747\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.4238 - accuracy: 0.8518 - val_loss: 0.6738 - val_accuracy: 0.7730\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.3397 - accuracy: 0.8818 - val_loss: 0.6625 - val_accuracy: 0.7862\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.2597 - accuracy: 0.9084 - val_loss: 0.7228 - val_accuracy: 0.7853\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.1968 - accuracy: 0.9288 - val_loss: 0.8032 - val_accuracy: 0.7851\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.1569 - accuracy: 0.9445 - val_loss: 0.8487 - val_accuracy: 0.7871\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.1080 - accuracy: 0.9623 - val_loss: 1.0038 - val_accuracy: 0.7761\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0850 - accuracy: 0.9709 - val_loss: 1.0331 - val_accuracy: 0.7964\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0702 - accuracy: 0.9753 - val_loss: 1.1101 - val_accuracy: 0.7806\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 1.1595 - val_accuracy: 0.7791\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0627 - accuracy: 0.9782 - val_loss: 1.1707 - val_accuracy: 0.7822\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 1.2028 - val_accuracy: 0.7818\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 1.2888 - val_accuracy: 0.7805\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 1.1886 - val_accuracy: 0.7920\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0417 - accuracy: 0.9854 - val_loss: 1.3665 - val_accuracy: 0.7890\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0553 - accuracy: 0.9808 - val_loss: 1.2199 - val_accuracy: 0.7814\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 1.3225 - val_accuracy: 0.7860\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 1.2801 - val_accuracy: 0.7949\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 1.3643 - val_accuracy: 0.7848\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 1.3854 - val_accuracy: 0.7897\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 1.2884 - val_accuracy: 0.7893\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0452 - accuracy: 0.9850 - val_loss: 1.3876 - val_accuracy: 0.7860\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 1.4879 - val_accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 1.4035 - val_accuracy: 0.7798\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 1.4740 - val_accuracy: 0.7863\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0376 - accuracy: 0.9871 - val_loss: 1.4750 - val_accuracy: 0.7870\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 1.4265 - val_accuracy: 0.7813\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 1.5558 - val_accuracy: 0.7846\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 1.4365 - val_accuracy: 0.7921\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 1.5376 - val_accuracy: 0.7856\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 1.5541 - val_accuracy: 0.7751\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0461 - accuracy: 0.9849 - val_loss: 1.4518 - val_accuracy: 0.7878\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 1.6430 - val_accuracy: 0.7730\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 1.5844 - val_accuracy: 0.7916\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 1.6552 - val_accuracy: 0.7874\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 1.5141 - val_accuracy: 0.7906\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 1.5615 - val_accuracy: 0.7832\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 1.6582 - val_accuracy: 0.7810\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 1.6127 - val_accuracy: 0.7906\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 1.6620 - val_accuracy: 0.7838\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0364 - accuracy: 0.9881 - val_loss: 1.5714 - val_accuracy: 0.7830\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 1.6755 - val_accuracy: 0.7936\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 1.6031 - val_accuracy: 0.7860\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 1.8549 - val_accuracy: 0.7766\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 1.7705 - val_accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# relu for cifar-10\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPdxjhvKp4G2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7pT320LnQKGx",
    "outputId": "dc176f17-8489-4242-b55a-d857a6669650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 5,739,594\n",
      "Trainable params: 5,739,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 26s 134ms/step - loss: 1.9503 - accuracy: 0.2577 - val_loss: 1.5155 - val_accuracy: 0.4299\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 1.3412 - accuracy: 0.5043 - val_loss: 1.1583 - val_accuracy: 0.5822\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 1.0207 - accuracy: 0.6345 - val_loss: 0.9226 - val_accuracy: 0.6768\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.8138 - accuracy: 0.7120 - val_loss: 0.7927 - val_accuracy: 0.7232\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.6650 - accuracy: 0.7668 - val_loss: 0.7561 - val_accuracy: 0.7346\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.5497 - accuracy: 0.8070 - val_loss: 0.6572 - val_accuracy: 0.7748\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.4510 - accuracy: 0.8427 - val_loss: 0.6716 - val_accuracy: 0.7746\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.3600 - accuracy: 0.8732 - val_loss: 0.7109 - val_accuracy: 0.7808\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.2879 - accuracy: 0.8985 - val_loss: 0.6774 - val_accuracy: 0.7947\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.2228 - accuracy: 0.9213 - val_loss: 0.7385 - val_accuracy: 0.7943\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.1793 - accuracy: 0.9371 - val_loss: 0.8466 - val_accuracy: 0.7890\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.1390 - accuracy: 0.9510 - val_loss: 0.8504 - val_accuracy: 0.8019\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.1065 - accuracy: 0.9621 - val_loss: 0.9895 - val_accuracy: 0.7883\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.1062 - accuracy: 0.9631 - val_loss: 0.9532 - val_accuracy: 0.7846\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0918 - accuracy: 0.9685 - val_loss: 0.9568 - val_accuracy: 0.7914\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0939 - accuracy: 0.9680 - val_loss: 1.0290 - val_accuracy: 0.7912\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0631 - accuracy: 0.9785 - val_loss: 1.1090 - val_accuracy: 0.7779\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0623 - accuracy: 0.9785 - val_loss: 1.1999 - val_accuracy: 0.7942\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0623 - accuracy: 0.9792 - val_loss: 1.1580 - val_accuracy: 0.7871\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 26s 132ms/step - loss: 0.0656 - accuracy: 0.9789 - val_loss: 1.1828 - val_accuracy: 0.7859\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 1.2098 - val_accuracy: 0.7885\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0604 - accuracy: 0.9789 - val_loss: 1.1380 - val_accuracy: 0.7933\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0583 - accuracy: 0.9796 - val_loss: 1.1974 - val_accuracy: 0.7905\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0546 - accuracy: 0.9817 - val_loss: 1.2842 - val_accuracy: 0.7887\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 1.1340 - val_accuracy: 0.7871\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 1.2245 - val_accuracy: 0.7900\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 1.2096 - val_accuracy: 0.7935\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0481 - accuracy: 0.9835 - val_loss: 1.2378 - val_accuracy: 0.7974\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 1.1523 - val_accuracy: 0.7893\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0510 - accuracy: 0.9828 - val_loss: 1.2073 - val_accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 1.2737 - val_accuracy: 0.7975\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 1.2760 - val_accuracy: 0.7906\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 1.2151 - val_accuracy: 0.7974\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 1.3451 - val_accuracy: 0.7910\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 1.3078 - val_accuracy: 0.7896\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 1.4248 - val_accuracy: 0.7935\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0401 - accuracy: 0.9869 - val_loss: 1.3888 - val_accuracy: 0.7928\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 1.3355 - val_accuracy: 0.7914\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 26s 132ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 1.4838 - val_accuracy: 0.7863\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0397 - accuracy: 0.9869 - val_loss: 1.3769 - val_accuracy: 0.7878\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0394 - accuracy: 0.9873 - val_loss: 1.3917 - val_accuracy: 0.7991\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 1.4114 - val_accuracy: 0.7917\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 1.4026 - val_accuracy: 0.7869\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 26s 132ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 1.5689 - val_accuracy: 0.7896\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 26s 132ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 1.3514 - val_accuracy: 0.7991\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 26s 132ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 1.3506 - val_accuracy: 0.7975\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 1.5460 - val_accuracy: 0.7880\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 26s 133ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 1.4616 - val_accuracy: 0.7980\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 27s 135ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 1.4272 - val_accuracy: 0.7918\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 27s 136ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 1.4883 - val_accuracy: 0.7904\n"
     ]
    }
   ],
   "source": [
    "# relu for cifar-10: more layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA08WNgJXcTq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dUKqOh61xmuu",
    "outputId": "55987a07-6e23-466c-cc90-9ece5d35103b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 8,873,994\n",
      "Trainable params: 8,873,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 41s 208ms/step - loss: 2.3031 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 40s 206ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 41s 207ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 40s 206ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 41s 207ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 40s 207ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 40s 206ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 41s 207ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 41s 207ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 41s 207ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# relu for cifar-10: more layers\n",
    "# too deep\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFT2k-b01Js7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "l_eRq4K11Jvc",
    "outputId": "9c72a698-c5f2-4377-8f1f-6217c571ceeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 8,873,994\n",
      "Trainable params: 8,873,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 1.9876 - accuracy: 0.2664 - val_loss: 1.6392 - val_accuracy: 0.3944\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 41s 208ms/step - loss: 1.4464 - accuracy: 0.4595 - val_loss: 1.3350 - val_accuracy: 0.5172\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 1.1407 - accuracy: 0.5857 - val_loss: 1.0729 - val_accuracy: 0.6195\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.9096 - accuracy: 0.6749 - val_loss: 0.8671 - val_accuracy: 0.6986\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.7371 - accuracy: 0.7393 - val_loss: 0.7739 - val_accuracy: 0.7297\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.6142 - accuracy: 0.7862 - val_loss: 0.7570 - val_accuracy: 0.7469\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.5170 - accuracy: 0.8191 - val_loss: 0.6945 - val_accuracy: 0.7640\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.4204 - accuracy: 0.8527 - val_loss: 0.7111 - val_accuracy: 0.7765\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.3563 - accuracy: 0.8746 - val_loss: 0.7096 - val_accuracy: 0.7789\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.2916 - accuracy: 0.8975 - val_loss: 0.7418 - val_accuracy: 0.7867\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.2513 - accuracy: 0.9106 - val_loss: 0.7414 - val_accuracy: 0.7922\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.2127 - accuracy: 0.9256 - val_loss: 0.7628 - val_accuracy: 0.7883\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1766 - accuracy: 0.9390 - val_loss: 0.8679 - val_accuracy: 0.7870\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.1509 - accuracy: 0.9478 - val_loss: 0.8912 - val_accuracy: 0.7782\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1395 - accuracy: 0.9517 - val_loss: 0.8633 - val_accuracy: 0.7963\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1202 - accuracy: 0.9586 - val_loss: 0.8793 - val_accuracy: 0.7885\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.1067 - accuracy: 0.9620 - val_loss: 1.1219 - val_accuracy: 0.7766\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0999 - accuracy: 0.9665 - val_loss: 0.9236 - val_accuracy: 0.7850\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0986 - accuracy: 0.9672 - val_loss: 0.9266 - val_accuracy: 0.7942\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 1.0010 - val_accuracy: 0.7975\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0852 - accuracy: 0.9713 - val_loss: 1.0582 - val_accuracy: 0.7803\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0878 - accuracy: 0.9705 - val_loss: 0.9352 - val_accuracy: 0.7915\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0775 - accuracy: 0.9740 - val_loss: 1.0033 - val_accuracy: 0.7902\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 1.0994 - val_accuracy: 0.7938\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0695 - accuracy: 0.9772 - val_loss: 1.3595 - val_accuracy: 0.7859\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0733 - accuracy: 0.9760 - val_loss: 1.1697 - val_accuracy: 0.7871\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 1.0640 - val_accuracy: 0.7872\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 1.1797 - val_accuracy: 0.7980\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 1.2773 - val_accuracy: 0.7942\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 1.0562 - val_accuracy: 0.7869\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0631 - accuracy: 0.9794 - val_loss: 1.0237 - val_accuracy: 0.7984\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0673 - accuracy: 0.9781 - val_loss: 1.1856 - val_accuracy: 0.7925\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0662 - accuracy: 0.9784 - val_loss: 1.2446 - val_accuracy: 0.7946\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 1.2038 - val_accuracy: 0.7932\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 1.2328 - val_accuracy: 0.7840\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0633 - accuracy: 0.9797 - val_loss: 1.1889 - val_accuracy: 0.7947\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 1.2549 - val_accuracy: 0.7961\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0613 - accuracy: 0.9807 - val_loss: 1.2187 - val_accuracy: 0.7974\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0608 - accuracy: 0.9802 - val_loss: 1.2102 - val_accuracy: 0.7964\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0620 - accuracy: 0.9803 - val_loss: 1.2800 - val_accuracy: 0.7940\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 1.2190 - val_accuracy: 0.7963\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0587 - accuracy: 0.9803 - val_loss: 1.2466 - val_accuracy: 0.7939\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 1.2162 - val_accuracy: 0.7994\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 1.2681 - val_accuracy: 0.7890\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 1.2565 - val_accuracy: 0.7918\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 1.3641 - val_accuracy: 0.7932\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0646 - accuracy: 0.9793 - val_loss: 1.3113 - val_accuracy: 0.7986\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0573 - accuracy: 0.9827 - val_loss: 1.3940 - val_accuracy: 0.8011\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 1.3268 - val_accuracy: 0.7852\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0582 - accuracy: 0.9828 - val_loss: 1.4792 - val_accuracy: 0.7926\n"
     ]
    }
   ],
   "source": [
    "# too deep: Using strong initializer\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "initializer = tf.keras.initializers.he_normal()\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu', kernel_initializer=initializer))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Q6Y660Z3XD1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nVLsZ2lU3XGa",
    "outputId": "ffe04f03-dd9b-4bcc-d577-5d1166e3ecd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 8,885,514\n",
      "Trainable params: 8,879,754\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 47s 242ms/step - loss: 1.6985 - accuracy: 0.4686 - val_loss: 2.9952 - val_accuracy: 0.1384\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.9137 - accuracy: 0.6778 - val_loss: 2.7255 - val_accuracy: 0.2806\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.6801 - accuracy: 0.7621 - val_loss: 1.0624 - val_accuracy: 0.6845\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.5393 - accuracy: 0.8150 - val_loss: 0.7012 - val_accuracy: 0.7680\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4339 - accuracy: 0.8511 - val_loss: 0.6438 - val_accuracy: 0.7839\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.3530 - accuracy: 0.8795 - val_loss: 0.8270 - val_accuracy: 0.7258\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.3126 - accuracy: 0.8951 - val_loss: 0.7120 - val_accuracy: 0.7851\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.2454 - accuracy: 0.9170 - val_loss: 0.8619 - val_accuracy: 0.7793\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.2128 - accuracy: 0.9268 - val_loss: 0.9924 - val_accuracy: 0.7215\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.1715 - accuracy: 0.9404 - val_loss: 0.7166 - val_accuracy: 0.8061\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.1483 - accuracy: 0.9497 - val_loss: 0.7203 - val_accuracy: 0.8080\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: 0.7113 - val_accuracy: 0.8176\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0927 - accuracy: 0.9691 - val_loss: 0.6800 - val_accuracy: 0.8370\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0815 - accuracy: 0.9716 - val_loss: 0.8659 - val_accuracy: 0.8036\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0718 - accuracy: 0.9759 - val_loss: 0.7150 - val_accuracy: 0.8344\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.1019 - accuracy: 0.9659 - val_loss: 0.7035 - val_accuracy: 0.8356\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0591 - accuracy: 0.9798 - val_loss: 0.8958 - val_accuracy: 0.8009\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.8057 - val_accuracy: 0.8274\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0669 - accuracy: 0.9775 - val_loss: 0.7858 - val_accuracy: 0.8328\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.0659 - accuracy: 0.9799 - val_loss: 0.7280 - val_accuracy: 0.8356\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.7695 - val_accuracy: 0.8415\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0681 - accuracy: 0.9780 - val_loss: 1.0926 - val_accuracy: 0.7491\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0636 - accuracy: 0.9791 - val_loss: 0.7476 - val_accuracy: 0.8420\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.8174 - val_accuracy: 0.8404\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.8452 - val_accuracy: 0.8278\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0741 - accuracy: 0.9764 - val_loss: 0.8255 - val_accuracy: 0.8305\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.8662 - val_accuracy: 0.8345\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.8652 - val_accuracy: 0.8321\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.8260 - val_accuracy: 0.8378\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 48s 247ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.7794 - val_accuracy: 0.8428\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 51s 260ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.8814 - val_accuracy: 0.8338\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 50s 254ms/step - loss: 0.0610 - accuracy: 0.9818 - val_loss: 0.8528 - val_accuracy: 0.8327\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 52s 267ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.7668 - val_accuracy: 0.8401\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 51s 261ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 1.2417 - val_accuracy: 0.7588\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 50s 253ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.8176 - val_accuracy: 0.8347\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.7981 - val_accuracy: 0.8531\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.8265 - val_accuracy: 0.8418\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.7889 - val_accuracy: 0.8478\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 1.0912 - val_accuracy: 0.7929\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.2228 - accuracy: 0.9413 - val_loss: 0.7171 - val_accuracy: 0.8205\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.7378 - val_accuracy: 0.8550\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.8373 - val_accuracy: 0.8572\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.9934 - val_accuracy: 0.8314\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.8282 - val_accuracy: 0.8487\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.8768 - val_accuracy: 0.8251\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 46s 234ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.8763 - val_accuracy: 0.8469\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.8985 - val_accuracy: 0.8419\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.0268 - val_accuracy: 0.8308\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.8354 - val_accuracy: 0.8501\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.8941 - val_accuracy: 0.8516\n"
     ]
    }
   ],
   "source": [
    "# too deep: batch norm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmb2YXNv786r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L6iO9HU-789f",
    "outputId": "eb12703d-0a74-49b1-a368-93d4f8910e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 8,873,994\n",
      "Trainable params: 8,873,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 1.9528 - accuracy: 0.2458 - val_loss: 1.5678 - val_accuracy: 0.4034\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 1.4301 - accuracy: 0.4634 - val_loss: 1.2638 - val_accuracy: 0.5382\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 1.1396 - accuracy: 0.5850 - val_loss: 1.0250 - val_accuracy: 0.6304\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.9248 - accuracy: 0.6663 - val_loss: 0.9541 - val_accuracy: 0.6663\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.7745 - accuracy: 0.7259 - val_loss: 0.8183 - val_accuracy: 0.7186\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.6690 - accuracy: 0.7670 - val_loss: 0.7688 - val_accuracy: 0.7328\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.5796 - accuracy: 0.7985 - val_loss: 0.7574 - val_accuracy: 0.7497\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.4983 - accuracy: 0.8265 - val_loss: 0.7189 - val_accuracy: 0.7582\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.4322 - accuracy: 0.8487 - val_loss: 0.6903 - val_accuracy: 0.7763\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.3701 - accuracy: 0.8718 - val_loss: 0.7795 - val_accuracy: 0.7636\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.3173 - accuracy: 0.8886 - val_loss: 0.7401 - val_accuracy: 0.7823\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 41s 211ms/step - loss: 0.2793 - accuracy: 0.9018 - val_loss: 0.8039 - val_accuracy: 0.7802\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.2401 - accuracy: 0.9169 - val_loss: 0.8112 - val_accuracy: 0.7722\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.2190 - accuracy: 0.9233 - val_loss: 0.9668 - val_accuracy: 0.7657\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.2006 - accuracy: 0.9290 - val_loss: 0.8881 - val_accuracy: 0.7806\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1730 - accuracy: 0.9402 - val_loss: 0.8806 - val_accuracy: 0.7820\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1488 - accuracy: 0.9486 - val_loss: 0.8893 - val_accuracy: 0.7843\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1393 - accuracy: 0.9523 - val_loss: 0.9891 - val_accuracy: 0.7797\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.1288 - accuracy: 0.9547 - val_loss: 1.1518 - val_accuracy: 0.7723\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1149 - accuracy: 0.9604 - val_loss: 1.0399 - val_accuracy: 0.7784\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1075 - accuracy: 0.9631 - val_loss: 1.1903 - val_accuracy: 0.7668\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.1132 - accuracy: 0.9617 - val_loss: 1.0241 - val_accuracy: 0.7869\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0984 - accuracy: 0.9672 - val_loss: 1.0610 - val_accuracy: 0.7822\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0973 - accuracy: 0.9670 - val_loss: 1.0676 - val_accuracy: 0.7790\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 41s 208ms/step - loss: 0.0947 - accuracy: 0.9688 - val_loss: 1.0402 - val_accuracy: 0.7895\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0887 - accuracy: 0.9699 - val_loss: 1.1450 - val_accuracy: 0.7683\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 41s 208ms/step - loss: 0.0774 - accuracy: 0.9741 - val_loss: 1.0828 - val_accuracy: 0.7791\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 1.1464 - val_accuracy: 0.7815\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0790 - accuracy: 0.9741 - val_loss: 1.1311 - val_accuracy: 0.7882\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0745 - accuracy: 0.9753 - val_loss: 1.0759 - val_accuracy: 0.7943\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 1.2339 - val_accuracy: 0.7803\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 1.2782 - val_accuracy: 0.7845\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0737 - accuracy: 0.9755 - val_loss: 1.1997 - val_accuracy: 0.7886\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0708 - accuracy: 0.9767 - val_loss: 1.1737 - val_accuracy: 0.7874\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0668 - accuracy: 0.9778 - val_loss: 1.2563 - val_accuracy: 0.7801\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 1.3698 - val_accuracy: 0.7781\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0752 - accuracy: 0.9755 - val_loss: 1.1101 - val_accuracy: 0.7839\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0694 - accuracy: 0.9772 - val_loss: 1.1209 - val_accuracy: 0.7748\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0596 - accuracy: 0.9807 - val_loss: 1.2518 - val_accuracy: 0.7803\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 1.0568 - val_accuracy: 0.7812\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 1.3991 - val_accuracy: 0.7881\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0674 - accuracy: 0.9789 - val_loss: 1.0902 - val_accuracy: 0.7915\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0588 - accuracy: 0.9806 - val_loss: 1.3250 - val_accuracy: 0.7876\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0630 - accuracy: 0.9803 - val_loss: 1.2454 - val_accuracy: 0.7881\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 1.3618 - val_accuracy: 0.7815\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 41s 210ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 1.2018 - val_accuracy: 0.7864\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 1.4190 - val_accuracy: 0.7976\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 1.1941 - val_accuracy: 0.7807\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0721 - accuracy: 0.9773 - val_loss: 1.2706 - val_accuracy: 0.7726\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 41s 209ms/step - loss: 0.0532 - accuracy: 0.9834 - val_loss: 1.1627 - val_accuracy: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# too deep: normalization\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize  \n",
    "mean = np.array([[[[125.30691805, 122.95039414, 113.86538318]]]])\n",
    "std  = np.array([[[[62.99321928, 62.08870764, 66.70489964]]]])\n",
    "\n",
    "x_train = (x_train - mean) / std\n",
    "x_test  = (x_test - mean) / std\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NZRC-g2U79Gi",
    "outputId": "c158e824-93d6-48cd-f4c9-bc62ad70844c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E6BT8Zo88ati",
    "outputId": "97f3b8ec-7162-4d38-b540-92ef59ed6543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 32, 32, 64)   1792        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 32, 32, 64)   36928       conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 32, 32, 64)   36928       conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 64)   1792        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 64)   0           max_pooling2d_43[0][0]           \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 128)  73856       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 8, 8, 128)    0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 128)    73856       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 128)    0           max_pooling2d_44[0][0]           \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 256)    295168      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 4, 4, 256)    0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 256)    295168      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 256)    0           max_pooling2d_45[0][0]           \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 512)    1180160     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 2, 2, 512)    0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 2, 2, 512)    1180160     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 2, 512)    0           max_pooling2d_46[0][0]           \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2048)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          1049088     flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 10)           5130        dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,424,970\n",
      "Trainable params: 10,424,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 1.9505 - accuracy: 0.2703 - val_loss: 1.5305 - val_accuracy: 0.4365\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 1.3217 - accuracy: 0.5201 - val_loss: 1.1608 - val_accuracy: 0.5847\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 1.0278 - accuracy: 0.6343 - val_loss: 1.0057 - val_accuracy: 0.6402\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.8294 - accuracy: 0.7078 - val_loss: 0.8474 - val_accuracy: 0.6986\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.6787 - accuracy: 0.7610 - val_loss: 0.7782 - val_accuracy: 0.7320\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 0.5642 - accuracy: 0.8000 - val_loss: 0.7381 - val_accuracy: 0.7504\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.4391 - accuracy: 0.8460 - val_loss: 0.7509 - val_accuracy: 0.7574\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.3355 - accuracy: 0.8813 - val_loss: 0.8132 - val_accuracy: 0.7567\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.2379 - accuracy: 0.9150 - val_loss: 0.8456 - val_accuracy: 0.7621\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.1783 - accuracy: 0.9376 - val_loss: 0.9834 - val_accuracy: 0.7603\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.1367 - accuracy: 0.9516 - val_loss: 1.0208 - val_accuracy: 0.7360\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 0.1036 - accuracy: 0.9647 - val_loss: 1.2042 - val_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0871 - accuracy: 0.9693 - val_loss: 1.2844 - val_accuracy: 0.7485\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 0.0843 - accuracy: 0.9716 - val_loss: 1.1518 - val_accuracy: 0.7633\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 1.3173 - val_accuracy: 0.7640\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0632 - accuracy: 0.9783 - val_loss: 1.5031 - val_accuracy: 0.7514\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0699 - accuracy: 0.9761 - val_loss: 1.3752 - val_accuracy: 0.7641\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0479 - accuracy: 0.9843 - val_loss: 1.4832 - val_accuracy: 0.7518\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 1.2937 - val_accuracy: 0.7611\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 1.4191 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0528 - accuracy: 0.9828 - val_loss: 1.5614 - val_accuracy: 0.7607\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0459 - accuracy: 0.9845 - val_loss: 1.5444 - val_accuracy: 0.7578\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0478 - accuracy: 0.9835 - val_loss: 1.3964 - val_accuracy: 0.7603\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 1.5359 - val_accuracy: 0.7614\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 1.4423 - val_accuracy: 0.7518\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 1.5326 - val_accuracy: 0.7603\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 1.5624 - val_accuracy: 0.7659\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0488 - accuracy: 0.9834 - val_loss: 1.5506 - val_accuracy: 0.7570\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 1.6945 - val_accuracy: 0.7562\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 1.5726 - val_accuracy: 0.7559\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 1.5722 - val_accuracy: 0.7686\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 1.6646 - val_accuracy: 0.7605\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 1.7004 - val_accuracy: 0.7580\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 1.5966 - val_accuracy: 0.7594\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 52s 264ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 1.6370 - val_accuracy: 0.7595\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0396 - accuracy: 0.9867 - val_loss: 1.7070 - val_accuracy: 0.7654\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 1.8135 - val_accuracy: 0.7605\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 1.6385 - val_accuracy: 0.7565\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0360 - accuracy: 0.9873 - val_loss: 1.6408 - val_accuracy: 0.7584\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 1.7806 - val_accuracy: 0.7542\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 52s 264ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 1.5935 - val_accuracy: 0.7633\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 52s 266ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 1.6551 - val_accuracy: 0.7606\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 1.6604 - val_accuracy: 0.7581\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 52s 267ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 1.9207 - val_accuracy: 0.7479\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 1.7981 - val_accuracy: 0.7603\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.9181 - val_accuracy: 0.7463\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 1.8344 - val_accuracy: 0.7584\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 1.6629 - val_accuracy: 0.7615\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 1.7418 - val_accuracy: 0.7698\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 52s 265ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 1.9299 - val_accuracy: 0.7655\n"
     ]
    }
   ],
   "source": [
    "# too deep: skip connection\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = inputs\n",
    "\n",
    "# block 1\n",
    "previous = x\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "residual = keras.layers.Conv2D(64, (3, 3), strides=2, padding='same', activation='relu')(previous)\n",
    "x = keras.layers.add([x, residual]) \n",
    "\n",
    "\n",
    "# block 2\n",
    "previous = x\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "residual = keras.layers.Conv2D(128, (3, 3), strides=2, padding='same', activation='relu')(previous)\n",
    "x = keras.layers.add([x, residual]) \n",
    "\n",
    "\n",
    "# block 3\n",
    "previous = x\n",
    "x = keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "residual = keras.layers.Conv2D(256, (3, 3), strides=2, padding='same', activation='relu')(previous)\n",
    "x = keras.layers.add([x, residual]) \n",
    "\n",
    "\n",
    "# block 4\n",
    "previous = x\n",
    "x = keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "residual = keras.layers.Conv2D(512, (3, 3), strides=2, padding='same', activation='relu')(previous)\n",
    "x = keras.layers.add([x, residual]) \n",
    "\n",
    "\n",
    "# flatten\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iAoW4nB_Zec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbWA7ax__YPG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "326moma7_YYS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "G8wsI8kB_ZhA",
    "outputId": "9f55594e-c18b-4e5f-a0e1-293c7d3d3fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.03199983 52.00799704 63.43200207 70.77999711 76.10200047 80.00400066\n",
      " 84.59799886 88.12999725 91.50400162 93.76400113 95.16199827 96.4680016\n",
      " 96.92999721 97.16200233 97.82800078 97.82999754 97.60599732 98.43000174\n",
      " 97.78400064 98.26999903 98.27799797 98.44599962 98.34799767 98.42799902\n",
      " 98.52600098 98.44999909 98.43400121 98.33599925 98.68599772 98.5220015\n",
      " 98.83800149 98.90400171 98.73600006 98.83000255 98.71399999 98.67399931\n",
      " 98.89400005 98.66799712 98.73399734 98.98999929 98.7860024  98.90599847\n",
      " 98.76400232 99.0719974  98.84799719 99.11000133 98.83599877 98.81600142\n",
      " 99.18000102 98.96600246]\n",
      "[43.65000129 58.46999884 64.02000189 69.85999942 73.19999933 75.04000068\n",
      " 75.73999763 75.66999793 76.20999813 76.02999806 73.60000014 75.\n",
      " 74.84999895 76.33000016 76.39999986 75.13999939 76.41000152 75.18000007\n",
      " 76.10999942 76.3199985  76.06999874 75.7799983  76.02999806 76.13999844\n",
      " 75.18000007 76.02999806 76.59000158 75.70000291 75.62000155 75.59000254\n",
      " 76.8599987  76.05000138 75.80000162 75.94000101 75.95000267 76.53999925\n",
      " 76.05000138 75.65000057 75.8400023  75.41999817 76.33000016 76.05999708\n",
      " 75.80999732 74.79000092 76.02999806 74.62999821 75.8400023  76.1500001\n",
      " 76.98000073 76.55000091]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "accs = np.array(history.history['accuracy'])*100\n",
    "print(accs)\n",
    "\n",
    "val_as = np.array(history.history['val_accuracy'])*100\n",
    "print(val_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvyBdG0RUHS2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "8.Cifar-10-CNN-Training Overfitting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
