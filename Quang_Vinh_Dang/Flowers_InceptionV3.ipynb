{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1949,
     "status": "ok",
     "timestamp": 1614238831939,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "jznFLPIRsFZ_",
    "outputId": "a2e2dbf2-d716-43f2-d190-c9a7957cf615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2433,
     "status": "ok",
     "timestamp": 1614238832985,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "4uSZjGcNsKIn",
    "outputId": "b76fb863-aff8-4d5e-b48e-373f64c0b394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "PATH = '/content/gdrive/My Drive/data/flower_photos/'\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = (160, 160)\n",
    "BUFFER_SIZE = BATCH_SIZE*5\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                              PATH,\n",
    "                                              validation_split=0.2,\n",
    "                                              subset=\"training\",\n",
    "                                              seed=123,\n",
    "                                              image_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                                  PATH,\n",
    "                                                  validation_split=0.2,\n",
    "                                                  subset=\"validation\",\n",
    "                                                  seed=123,\n",
    "                                                  image_size=IMG_SIZE,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=BUFFER_SIZE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1545002,
     "status": "ok",
     "timestamp": 1614248908760,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "1FH3F6qDsFaF",
    "outputId": "4a0ca646-3d16-4d12-e81a-0027d99f3e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "23/23 [==============================] - 13s 316ms/step - loss: 1.7715 - accuracy: 0.2410 - val_loss: 1.6076 - val_accuracy: 0.2398\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.4740 - accuracy: 0.3783 - val_loss: 1.6058 - val_accuracy: 0.2398\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.3849 - accuracy: 0.4244 - val_loss: 1.6022 - val_accuracy: 0.2398\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.2936 - accuracy: 0.4756 - val_loss: 1.6055 - val_accuracy: 0.2398\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.2600 - accuracy: 0.4971 - val_loss: 1.6134 - val_accuracy: 0.2398\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.2553 - accuracy: 0.4882 - val_loss: 1.6328 - val_accuracy: 0.2398\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.1874 - accuracy: 0.5513 - val_loss: 1.6670 - val_accuracy: 0.2398\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.1759 - accuracy: 0.5218 - val_loss: 1.7094 - val_accuracy: 0.2398\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.1364 - accuracy: 0.5454 - val_loss: 1.7767 - val_accuracy: 0.2411\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.1284 - accuracy: 0.5514 - val_loss: 1.9057 - val_accuracy: 0.2398\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.1087 - accuracy: 0.5639 - val_loss: 2.0159 - val_accuracy: 0.2398\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.0951 - accuracy: 0.5682 - val_loss: 2.1370 - val_accuracy: 0.2398\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.0716 - accuracy: 0.5762 - val_loss: 2.1000 - val_accuracy: 0.2411\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.0870 - accuracy: 0.5805 - val_loss: 2.0249 - val_accuracy: 0.2466\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.0498 - accuracy: 0.5861 - val_loss: 1.8948 - val_accuracy: 0.2643\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.0247 - accuracy: 0.6085 - val_loss: 1.7390 - val_accuracy: 0.3215\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.0526 - accuracy: 0.5896 - val_loss: 1.5462 - val_accuracy: 0.3610\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 1.0188 - accuracy: 0.6046 - val_loss: 1.4465 - val_accuracy: 0.4087\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.0299 - accuracy: 0.6046 - val_loss: 1.3466 - val_accuracy: 0.4523\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 1.0195 - accuracy: 0.5982 - val_loss: 1.2687 - val_accuracy: 0.4986\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9921 - accuracy: 0.6193 - val_loss: 1.1825 - val_accuracy: 0.5095\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9922 - accuracy: 0.6120 - val_loss: 1.1279 - val_accuracy: 0.5286\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9967 - accuracy: 0.6063 - val_loss: 1.0962 - val_accuracy: 0.5477\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9756 - accuracy: 0.6216 - val_loss: 1.1095 - val_accuracy: 0.5722\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9718 - accuracy: 0.6182 - val_loss: 1.1350 - val_accuracy: 0.5545\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9425 - accuracy: 0.6227 - val_loss: 1.1707 - val_accuracy: 0.5381\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9466 - accuracy: 0.6290 - val_loss: 1.2092 - val_accuracy: 0.5381\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9390 - accuracy: 0.6326 - val_loss: 1.1924 - val_accuracy: 0.5613\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9440 - accuracy: 0.6381 - val_loss: 1.2210 - val_accuracy: 0.5395\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9034 - accuracy: 0.6485 - val_loss: 1.2178 - val_accuracy: 0.5477\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9117 - accuracy: 0.6439 - val_loss: 1.2062 - val_accuracy: 0.5463\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.9018 - accuracy: 0.6508 - val_loss: 1.2353 - val_accuracy: 0.5450\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.8922 - accuracy: 0.6577 - val_loss: 1.2374 - val_accuracy: 0.5654\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.8823 - accuracy: 0.6659 - val_loss: 1.2605 - val_accuracy: 0.5518\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8957 - accuracy: 0.6554 - val_loss: 1.3140 - val_accuracy: 0.5477\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9125 - accuracy: 0.6521 - val_loss: 1.2695 - val_accuracy: 0.5395\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.9096 - accuracy: 0.6425 - val_loss: 1.2631 - val_accuracy: 0.5450\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.8778 - accuracy: 0.6652 - val_loss: 1.3136 - val_accuracy: 0.5341\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8703 - accuracy: 0.6610 - val_loss: 1.2570 - val_accuracy: 0.5395\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8812 - accuracy: 0.6583 - val_loss: 1.3122 - val_accuracy: 0.5490\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8622 - accuracy: 0.6641 - val_loss: 1.3002 - val_accuracy: 0.5613\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.8361 - accuracy: 0.6762 - val_loss: 1.2687 - val_accuracy: 0.5477\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8476 - accuracy: 0.6805 - val_loss: 1.2958 - val_accuracy: 0.5463\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8476 - accuracy: 0.6679 - val_loss: 1.2291 - val_accuracy: 0.5668\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8243 - accuracy: 0.6727 - val_loss: 1.2410 - val_accuracy: 0.5722\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8179 - accuracy: 0.6802 - val_loss: 1.1923 - val_accuracy: 0.5722\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8210 - accuracy: 0.6856 - val_loss: 1.2076 - val_accuracy: 0.5872\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8402 - accuracy: 0.6734 - val_loss: 1.1610 - val_accuracy: 0.5763\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8299 - accuracy: 0.6757 - val_loss: 1.1895 - val_accuracy: 0.5845\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8435 - accuracy: 0.6685 - val_loss: 1.2738 - val_accuracy: 0.5777\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7807 - accuracy: 0.6952 - val_loss: 1.2343 - val_accuracy: 0.5845\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.7957 - accuracy: 0.6908 - val_loss: 1.2626 - val_accuracy: 0.5845\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.8069 - accuracy: 0.6842 - val_loss: 1.2522 - val_accuracy: 0.5831\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7732 - accuracy: 0.6980 - val_loss: 1.2316 - val_accuracy: 0.5817\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7927 - accuracy: 0.6827 - val_loss: 1.2858 - val_accuracy: 0.5790\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7822 - accuracy: 0.6923 - val_loss: 1.2687 - val_accuracy: 0.5763\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.7882 - accuracy: 0.6937 - val_loss: 1.2932 - val_accuracy: 0.5872\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7725 - accuracy: 0.6990 - val_loss: 1.2971 - val_accuracy: 0.5668\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7707 - accuracy: 0.7061 - val_loss: 1.2135 - val_accuracy: 0.5763\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7757 - accuracy: 0.6980 - val_loss: 1.2586 - val_accuracy: 0.5708\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7709 - accuracy: 0.6875 - val_loss: 1.2177 - val_accuracy: 0.5777\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7554 - accuracy: 0.7100 - val_loss: 1.2757 - val_accuracy: 0.5695\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7769 - accuracy: 0.6997 - val_loss: 1.1673 - val_accuracy: 0.5926\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7609 - accuracy: 0.7106 - val_loss: 1.3186 - val_accuracy: 0.5627\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7427 - accuracy: 0.7176 - val_loss: 1.2228 - val_accuracy: 0.5777\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7303 - accuracy: 0.7188 - val_loss: 1.2841 - val_accuracy: 0.5858\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7346 - accuracy: 0.7316 - val_loss: 1.3490 - val_accuracy: 0.5763\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7600 - accuracy: 0.7117 - val_loss: 1.2466 - val_accuracy: 0.5749\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7392 - accuracy: 0.7076 - val_loss: 1.2474 - val_accuracy: 0.5940\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.7337 - accuracy: 0.7124 - val_loss: 1.2487 - val_accuracy: 0.5886\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7214 - accuracy: 0.7267 - val_loss: 1.2392 - val_accuracy: 0.5831\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7411 - accuracy: 0.7063 - val_loss: 1.1776 - val_accuracy: 0.6049\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7139 - accuracy: 0.7173 - val_loss: 1.1645 - val_accuracy: 0.5995\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6964 - accuracy: 0.7349 - val_loss: 1.1904 - val_accuracy: 0.6049\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7117 - accuracy: 0.7198 - val_loss: 1.1963 - val_accuracy: 0.5886\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7240 - accuracy: 0.7247 - val_loss: 1.2543 - val_accuracy: 0.5845\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7116 - accuracy: 0.7183 - val_loss: 1.2233 - val_accuracy: 0.5722\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.7046 - accuracy: 0.7284 - val_loss: 1.2550 - val_accuracy: 0.5736\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6774 - accuracy: 0.7413 - val_loss: 1.2098 - val_accuracy: 0.5872\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6692 - accuracy: 0.7393 - val_loss: 1.2940 - val_accuracy: 0.5845\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6863 - accuracy: 0.7424 - val_loss: 1.2932 - val_accuracy: 0.5995\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6856 - accuracy: 0.7341 - val_loss: 1.2234 - val_accuracy: 0.6022\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6605 - accuracy: 0.7498 - val_loss: 1.1786 - val_accuracy: 0.6076\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6619 - accuracy: 0.7534 - val_loss: 1.1681 - val_accuracy: 0.6158\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6689 - accuracy: 0.7398 - val_loss: 1.2769 - val_accuracy: 0.6104\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6704 - accuracy: 0.7427 - val_loss: 1.2117 - val_accuracy: 0.6035\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6637 - accuracy: 0.7378 - val_loss: 1.2292 - val_accuracy: 0.5981\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6639 - accuracy: 0.7421 - val_loss: 1.1525 - val_accuracy: 0.5886\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6730 - accuracy: 0.7361 - val_loss: 1.1273 - val_accuracy: 0.6049\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6545 - accuracy: 0.7477 - val_loss: 1.2362 - val_accuracy: 0.6117\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6441 - accuracy: 0.7452 - val_loss: 1.1406 - val_accuracy: 0.6104\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6472 - accuracy: 0.7463 - val_loss: 1.1863 - val_accuracy: 0.5886\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6502 - accuracy: 0.7491 - val_loss: 1.2735 - val_accuracy: 0.5872\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.6400 - accuracy: 0.7512 - val_loss: 1.2119 - val_accuracy: 0.5954\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.6506 - accuracy: 0.7604 - val_loss: 1.2285 - val_accuracy: 0.6049\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6046 - accuracy: 0.7755 - val_loss: 1.2815 - val_accuracy: 0.6022\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6284 - accuracy: 0.7599 - val_loss: 1.1549 - val_accuracy: 0.6104\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6289 - accuracy: 0.7638 - val_loss: 1.1297 - val_accuracy: 0.6199\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6215 - accuracy: 0.7618 - val_loss: 1.1562 - val_accuracy: 0.6253\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6196 - accuracy: 0.7675 - val_loss: 1.1253 - val_accuracy: 0.6172\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6129 - accuracy: 0.7637 - val_loss: 1.1436 - val_accuracy: 0.6076\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6156 - accuracy: 0.7634 - val_loss: 1.0947 - val_accuracy: 0.6213\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6114 - accuracy: 0.7660 - val_loss: 1.1359 - val_accuracy: 0.5995\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.6027 - accuracy: 0.7692 - val_loss: 1.1257 - val_accuracy: 0.6158\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5877 - accuracy: 0.7823 - val_loss: 1.1261 - val_accuracy: 0.6144\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.6050 - accuracy: 0.7603 - val_loss: 1.1290 - val_accuracy: 0.6213\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5966 - accuracy: 0.7754 - val_loss: 1.1444 - val_accuracy: 0.6213\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5777 - accuracy: 0.7776 - val_loss: 1.1024 - val_accuracy: 0.6267\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.5739 - accuracy: 0.7726 - val_loss: 1.1450 - val_accuracy: 0.6049\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5648 - accuracy: 0.7800 - val_loss: 1.1038 - val_accuracy: 0.6144\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.5762 - accuracy: 0.7749 - val_loss: 1.1634 - val_accuracy: 0.5940\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5990 - accuracy: 0.7682 - val_loss: 1.1629 - val_accuracy: 0.6117\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5689 - accuracy: 0.7886 - val_loss: 1.1970 - val_accuracy: 0.6104\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5562 - accuracy: 0.7874 - val_loss: 1.1913 - val_accuracy: 0.6117\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5720 - accuracy: 0.7919 - val_loss: 1.2633 - val_accuracy: 0.5954\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5623 - accuracy: 0.7854 - val_loss: 1.1735 - val_accuracy: 0.5954\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5631 - accuracy: 0.7875 - val_loss: 1.2455 - val_accuracy: 0.5926\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5589 - accuracy: 0.7903 - val_loss: 1.1811 - val_accuracy: 0.6131\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5363 - accuracy: 0.8058 - val_loss: 1.1752 - val_accuracy: 0.6035\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5342 - accuracy: 0.7981 - val_loss: 1.1570 - val_accuracy: 0.6172\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5443 - accuracy: 0.8040 - val_loss: 1.1829 - val_accuracy: 0.6063\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5305 - accuracy: 0.8038 - val_loss: 1.2091 - val_accuracy: 0.6172\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5288 - accuracy: 0.8081 - val_loss: 1.1724 - val_accuracy: 0.6226\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5275 - accuracy: 0.7898 - val_loss: 1.1751 - val_accuracy: 0.6063\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5210 - accuracy: 0.8059 - val_loss: 1.1820 - val_accuracy: 0.5995\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5177 - accuracy: 0.8023 - val_loss: 1.1699 - val_accuracy: 0.6035\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5164 - accuracy: 0.8110 - val_loss: 1.1927 - val_accuracy: 0.5954\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.5118 - accuracy: 0.8035 - val_loss: 1.1406 - val_accuracy: 0.6253\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4993 - accuracy: 0.8177 - val_loss: 1.2486 - val_accuracy: 0.5940\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4925 - accuracy: 0.8155 - val_loss: 1.1800 - val_accuracy: 0.6131\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4967 - accuracy: 0.8083 - val_loss: 1.1984 - val_accuracy: 0.6104\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4944 - accuracy: 0.8189 - val_loss: 1.2007 - val_accuracy: 0.6022\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4962 - accuracy: 0.8139 - val_loss: 1.2328 - val_accuracy: 0.6049\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4806 - accuracy: 0.8231 - val_loss: 1.1617 - val_accuracy: 0.6131\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4787 - accuracy: 0.8170 - val_loss: 1.1762 - val_accuracy: 0.6131\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4777 - accuracy: 0.8216 - val_loss: 1.2398 - val_accuracy: 0.6172\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4965 - accuracy: 0.8218 - val_loss: 1.2943 - val_accuracy: 0.6240\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4744 - accuracy: 0.8182 - val_loss: 1.1929 - val_accuracy: 0.6294\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4764 - accuracy: 0.8192 - val_loss: 1.2415 - val_accuracy: 0.6104\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4707 - accuracy: 0.8226 - val_loss: 1.1703 - val_accuracy: 0.6281\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4879 - accuracy: 0.8158 - val_loss: 1.1774 - val_accuracy: 0.6267\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4781 - accuracy: 0.8113 - val_loss: 1.1672 - val_accuracy: 0.6213\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4533 - accuracy: 0.8257 - val_loss: 1.1587 - val_accuracy: 0.6267\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4624 - accuracy: 0.8313 - val_loss: 1.2861 - val_accuracy: 0.6104\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4691 - accuracy: 0.8167 - val_loss: 1.2294 - val_accuracy: 0.6417\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4642 - accuracy: 0.8408 - val_loss: 1.2748 - val_accuracy: 0.6158\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4587 - accuracy: 0.8237 - val_loss: 1.3031 - val_accuracy: 0.6172\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4403 - accuracy: 0.8396 - val_loss: 1.2787 - val_accuracy: 0.6090\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4339 - accuracy: 0.8344 - val_loss: 1.2634 - val_accuracy: 0.6104\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4374 - accuracy: 0.8362 - val_loss: 1.2161 - val_accuracy: 0.6131\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4156 - accuracy: 0.8430 - val_loss: 1.3402 - val_accuracy: 0.6063\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4196 - accuracy: 0.8429 - val_loss: 1.1730 - val_accuracy: 0.6090\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4282 - accuracy: 0.8401 - val_loss: 1.3258 - val_accuracy: 0.5967\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4107 - accuracy: 0.8464 - val_loss: 1.1437 - val_accuracy: 0.6199\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4380 - accuracy: 0.8265 - val_loss: 1.2739 - val_accuracy: 0.6199\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4382 - accuracy: 0.8330 - val_loss: 1.2090 - val_accuracy: 0.6240\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4150 - accuracy: 0.8492 - val_loss: 1.1920 - val_accuracy: 0.6281\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.4180 - accuracy: 0.8435 - val_loss: 1.1582 - val_accuracy: 0.6240\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3964 - accuracy: 0.8523 - val_loss: 1.2110 - val_accuracy: 0.6158\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3999 - accuracy: 0.8481 - val_loss: 1.2046 - val_accuracy: 0.6063\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3841 - accuracy: 0.8566 - val_loss: 1.2357 - val_accuracy: 0.6090\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3758 - accuracy: 0.8538 - val_loss: 1.2672 - val_accuracy: 0.6294\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4137 - accuracy: 0.8542 - val_loss: 1.3402 - val_accuracy: 0.6185\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.4021 - accuracy: 0.8434 - val_loss: 1.2743 - val_accuracy: 0.6131\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3935 - accuracy: 0.8528 - val_loss: 1.2738 - val_accuracy: 0.6144\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3743 - accuracy: 0.8672 - val_loss: 1.1867 - val_accuracy: 0.6335\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3669 - accuracy: 0.8635 - val_loss: 1.1906 - val_accuracy: 0.6253\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3696 - accuracy: 0.8618 - val_loss: 1.4153 - val_accuracy: 0.6185\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3680 - accuracy: 0.8660 - val_loss: 1.2252 - val_accuracy: 0.6267\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3714 - accuracy: 0.8641 - val_loss: 1.1917 - val_accuracy: 0.6308\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3974 - accuracy: 0.8547 - val_loss: 1.2336 - val_accuracy: 0.6403\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3762 - accuracy: 0.8583 - val_loss: 1.1718 - val_accuracy: 0.6253\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3608 - accuracy: 0.8652 - val_loss: 1.2849 - val_accuracy: 0.6267\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3779 - accuracy: 0.8634 - val_loss: 1.3096 - val_accuracy: 0.6294\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3509 - accuracy: 0.8695 - val_loss: 1.2709 - val_accuracy: 0.6308\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3513 - accuracy: 0.8740 - val_loss: 1.2506 - val_accuracy: 0.6444\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3712 - accuracy: 0.8683 - val_loss: 1.3238 - val_accuracy: 0.6294\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3536 - accuracy: 0.8639 - val_loss: 1.3847 - val_accuracy: 0.6158\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3285 - accuracy: 0.8838 - val_loss: 1.2385 - val_accuracy: 0.6444\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3371 - accuracy: 0.8722 - val_loss: 1.2598 - val_accuracy: 0.6458\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3329 - accuracy: 0.8693 - val_loss: 1.1962 - val_accuracy: 0.6512\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3444 - accuracy: 0.8785 - val_loss: 1.2432 - val_accuracy: 0.6526\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.3219 - accuracy: 0.8853 - val_loss: 1.2054 - val_accuracy: 0.6540\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3066 - accuracy: 0.8890 - val_loss: 1.2797 - val_accuracy: 0.6335\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3190 - accuracy: 0.8880 - val_loss: 1.2702 - val_accuracy: 0.6444\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3353 - accuracy: 0.8771 - val_loss: 1.2369 - val_accuracy: 0.6499\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3380 - accuracy: 0.8771 - val_loss: 1.2289 - val_accuracy: 0.6458\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3077 - accuracy: 0.8826 - val_loss: 1.2469 - val_accuracy: 0.6390\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3218 - accuracy: 0.8773 - val_loss: 1.2605 - val_accuracy: 0.6335\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3139 - accuracy: 0.8836 - val_loss: 1.2689 - val_accuracy: 0.6376\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2945 - accuracy: 0.8848 - val_loss: 1.2994 - val_accuracy: 0.6335\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3005 - accuracy: 0.8952 - val_loss: 1.2645 - val_accuracy: 0.6567\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3034 - accuracy: 0.8860 - val_loss: 1.2605 - val_accuracy: 0.6458\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3046 - accuracy: 0.8849 - val_loss: 1.3058 - val_accuracy: 0.6431\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.3022 - accuracy: 0.8916 - val_loss: 1.3248 - val_accuracy: 0.6308\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2823 - accuracy: 0.8970 - val_loss: 1.3506 - val_accuracy: 0.6431\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2799 - accuracy: 0.9036 - val_loss: 1.3736 - val_accuracy: 0.6403\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2912 - accuracy: 0.8897 - val_loss: 1.3615 - val_accuracy: 0.6431\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2896 - accuracy: 0.8922 - val_loss: 1.2741 - val_accuracy: 0.6526\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2802 - accuracy: 0.8926 - val_loss: 1.3418 - val_accuracy: 0.6376\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2785 - accuracy: 0.9028 - val_loss: 1.3341 - val_accuracy: 0.6390\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2775 - accuracy: 0.8910 - val_loss: 1.3439 - val_accuracy: 0.6335\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2698 - accuracy: 0.8994 - val_loss: 1.3077 - val_accuracy: 0.6294\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2759 - accuracy: 0.8989 - val_loss: 1.2966 - val_accuracy: 0.6349\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.2701 - accuracy: 0.9146 - val_loss: 1.3129 - val_accuracy: 0.6335\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2794 - accuracy: 0.8877 - val_loss: 1.2834 - val_accuracy: 0.6499\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2695 - accuracy: 0.9084 - val_loss: 1.2533 - val_accuracy: 0.6499\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2706 - accuracy: 0.9044 - val_loss: 1.3566 - val_accuracy: 0.6308\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2438 - accuracy: 0.9091 - val_loss: 1.3509 - val_accuracy: 0.6267\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2545 - accuracy: 0.9006 - val_loss: 1.3086 - val_accuracy: 0.6485\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.2588 - accuracy: 0.9053 - val_loss: 1.2885 - val_accuracy: 0.6349\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2352 - accuracy: 0.9139 - val_loss: 1.3384 - val_accuracy: 0.6431\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.2372 - accuracy: 0.9125 - val_loss: 1.3655 - val_accuracy: 0.6308\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2580 - accuracy: 0.9024 - val_loss: 1.3739 - val_accuracy: 0.6403\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2496 - accuracy: 0.9099 - val_loss: 1.4347 - val_accuracy: 0.6294\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.2423 - accuracy: 0.9108 - val_loss: 1.4261 - val_accuracy: 0.6267\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.2233 - accuracy: 0.9243 - val_loss: 1.4243 - val_accuracy: 0.6267\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2313 - accuracy: 0.9170 - val_loss: 1.4340 - val_accuracy: 0.6376\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2346 - accuracy: 0.9119 - val_loss: 1.4362 - val_accuracy: 0.6308\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2403 - accuracy: 0.9229 - val_loss: 1.3595 - val_accuracy: 0.6349\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2221 - accuracy: 0.9188 - val_loss: 1.3581 - val_accuracy: 0.6390\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2305 - accuracy: 0.9103 - val_loss: 1.4371 - val_accuracy: 0.6240\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2233 - accuracy: 0.9172 - val_loss: 1.4214 - val_accuracy: 0.6281\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2283 - accuracy: 0.9226 - val_loss: 1.4838 - val_accuracy: 0.6226\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2272 - accuracy: 0.9194 - val_loss: 1.4675 - val_accuracy: 0.6362\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2191 - accuracy: 0.9244 - val_loss: 1.4728 - val_accuracy: 0.6322\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2202 - accuracy: 0.9235 - val_loss: 1.5208 - val_accuracy: 0.6185\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2071 - accuracy: 0.9240 - val_loss: 1.3992 - val_accuracy: 0.6444\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2082 - accuracy: 0.9278 - val_loss: 1.3925 - val_accuracy: 0.6431\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2161 - accuracy: 0.9211 - val_loss: 1.4278 - val_accuracy: 0.6294\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1883 - accuracy: 0.9382 - val_loss: 1.4963 - val_accuracy: 0.6267\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1992 - accuracy: 0.9322 - val_loss: 1.4176 - val_accuracy: 0.6376\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.2045 - accuracy: 0.9217 - val_loss: 1.4284 - val_accuracy: 0.6362\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1852 - accuracy: 0.9400 - val_loss: 1.3997 - val_accuracy: 0.6308\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2110 - accuracy: 0.9269 - val_loss: 1.4198 - val_accuracy: 0.6308\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1972 - accuracy: 0.9319 - val_loss: 1.4573 - val_accuracy: 0.6308\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.1852 - accuracy: 0.9287 - val_loss: 1.3874 - val_accuracy: 0.6390\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1949 - accuracy: 0.9332 - val_loss: 1.4510 - val_accuracy: 0.6376\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1927 - accuracy: 0.9264 - val_loss: 1.4334 - val_accuracy: 0.6253\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1811 - accuracy: 0.9410 - val_loss: 1.4860 - val_accuracy: 0.6335\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1874 - accuracy: 0.9302 - val_loss: 1.4551 - val_accuracy: 0.6376\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1887 - accuracy: 0.9335 - val_loss: 1.3701 - val_accuracy: 0.6621\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.1895 - accuracy: 0.9360 - val_loss: 1.4369 - val_accuracy: 0.6458\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1858 - accuracy: 0.9386 - val_loss: 1.4284 - val_accuracy: 0.6226\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.1881 - accuracy: 0.9298 - val_loss: 1.4067 - val_accuracy: 0.6281\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1827 - accuracy: 0.9379 - val_loss: 1.4894 - val_accuracy: 0.6458\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1578 - accuracy: 0.9438 - val_loss: 1.4900 - val_accuracy: 0.6376\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.1721 - accuracy: 0.9404 - val_loss: 1.4517 - val_accuracy: 0.6349\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.1629 - accuracy: 0.9449 - val_loss: 1.3520 - val_accuracy: 0.6444\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1605 - accuracy: 0.9494 - val_loss: 1.4186 - val_accuracy: 0.6362\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### from scratch\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False, weights=None)\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = flatten(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# train\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=0.00001), \n",
    "              metrics=['accuracy'])\n",
    "history_fine = model.fit(train_dataset, epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 640727,
     "status": "ok",
     "timestamp": 1614241204480,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "OJPTr4fksFaH",
    "outputId": "393bbbdf-93fa-43a5-b5cd-2c589567ce8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 79, 79, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 79, 79, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 79, 79, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 77, 77, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 77, 77, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 77, 77, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 77, 77, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 77, 77, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 77, 77, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 38, 38, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 38, 38, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 38, 38, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 38, 38, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 36, 36, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 36, 36, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 36, 36, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 17, 17, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 17, 17, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 17, 17, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 17, 17, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 17, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 17, 17, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 17, 17, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 17, 17, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 17, 17, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 17, 17, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 17, 17, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 17, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 17, 17, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 17, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 17, 17, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 17, 17, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 17, 17, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 17, 17, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 17, 17, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 17, 17, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 17, 17, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 17, 17, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 17, 17, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 17, 17, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 17, 17, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 17, 17, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 17, 17, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 17, 17, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 17, 17, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 17, 17, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 17, 17, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 17, 17, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 17, 17, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 17, 17, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 17, 17, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 17, 17, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 17, 17, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 17, 17, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 17, 17, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 17, 17, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 17, 17, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 17, 17, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 17, 17, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 17, 17, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 17, 17, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 17, 17, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 17, 17, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 17, 17, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 17, 17, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 17, 17, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 17, 17, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 17, 17, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 17, 17, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 17, 17, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 17, 17, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 17, 17, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 17, 17, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 17, 17, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 8, 8, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 8, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "0\n",
      "2\n",
      "Epoch 1/250\n",
      "23/23 [==============================] - 8s 200ms/step - loss: 2.4060 - accuracy: 0.2303 - val_loss: 2.0335 - val_accuracy: 0.2834\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.9414 - accuracy: 0.3391 - val_loss: 1.6855 - val_accuracy: 0.3937\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.6817 - accuracy: 0.4187 - val_loss: 1.4553 - val_accuracy: 0.4564\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.4070 - accuracy: 0.4886 - val_loss: 1.2970 - val_accuracy: 0.5123\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.2892 - accuracy: 0.5329 - val_loss: 1.1808 - val_accuracy: 0.5477\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 1.2300 - accuracy: 0.5742 - val_loss: 1.0925 - val_accuracy: 0.5804\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.1308 - accuracy: 0.6038 - val_loss: 1.0244 - val_accuracy: 0.6240\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 1.0759 - accuracy: 0.6220 - val_loss: 0.9711 - val_accuracy: 0.6417\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 1.0450 - accuracy: 0.6221 - val_loss: 0.9221 - val_accuracy: 0.6635\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.9753 - accuracy: 0.6474 - val_loss: 0.8884 - val_accuracy: 0.6771\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.9267 - accuracy: 0.6704 - val_loss: 0.8562 - val_accuracy: 0.6866\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.8531 - accuracy: 0.6834 - val_loss: 0.8290 - val_accuracy: 0.6962\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.8834 - accuracy: 0.6898 - val_loss: 0.8023 - val_accuracy: 0.7071\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.8417 - accuracy: 0.6991 - val_loss: 0.7787 - val_accuracy: 0.7180\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.8391 - accuracy: 0.7006 - val_loss: 0.7625 - val_accuracy: 0.7221\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.7907 - accuracy: 0.7312 - val_loss: 0.7447 - val_accuracy: 0.7357\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.8153 - accuracy: 0.7139 - val_loss: 0.7281 - val_accuracy: 0.7425\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.7519 - accuracy: 0.7271 - val_loss: 0.7131 - val_accuracy: 0.7507\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.7255 - accuracy: 0.7396 - val_loss: 0.7046 - val_accuracy: 0.7534\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.7430 - accuracy: 0.7236 - val_loss: 0.6896 - val_accuracy: 0.7575\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.7180 - accuracy: 0.7432 - val_loss: 0.6779 - val_accuracy: 0.7616\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.7452 - accuracy: 0.7270 - val_loss: 0.6713 - val_accuracy: 0.7629\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.7207 - accuracy: 0.7444 - val_loss: 0.6585 - val_accuracy: 0.7738\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.6590 - accuracy: 0.7638 - val_loss: 0.6499 - val_accuracy: 0.7698\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6623 - accuracy: 0.7612 - val_loss: 0.6424 - val_accuracy: 0.7738\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.6669 - accuracy: 0.7615 - val_loss: 0.6373 - val_accuracy: 0.7779\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.6771 - accuracy: 0.7469 - val_loss: 0.6294 - val_accuracy: 0.7793\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6401 - accuracy: 0.7694 - val_loss: 0.6216 - val_accuracy: 0.7779\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.6591 - accuracy: 0.7679 - val_loss: 0.6160 - val_accuracy: 0.7807\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6394 - accuracy: 0.7793 - val_loss: 0.6088 - val_accuracy: 0.7888\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6487 - accuracy: 0.7653 - val_loss: 0.6081 - val_accuracy: 0.7793\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6078 - accuracy: 0.7788 - val_loss: 0.5997 - val_accuracy: 0.7847\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6001 - accuracy: 0.7826 - val_loss: 0.5962 - val_accuracy: 0.7875\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5943 - accuracy: 0.7940 - val_loss: 0.5921 - val_accuracy: 0.7902\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.5768 - accuracy: 0.7848 - val_loss: 0.5901 - val_accuracy: 0.7888\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5892 - accuracy: 0.7979 - val_loss: 0.5842 - val_accuracy: 0.7943\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5441 - accuracy: 0.8032 - val_loss: 0.5819 - val_accuracy: 0.7943\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5732 - accuracy: 0.7900 - val_loss: 0.5771 - val_accuracy: 0.7916\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5674 - accuracy: 0.7946 - val_loss: 0.5744 - val_accuracy: 0.7956\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5751 - accuracy: 0.7854 - val_loss: 0.5696 - val_accuracy: 0.7956\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5712 - accuracy: 0.7924 - val_loss: 0.5688 - val_accuracy: 0.7984\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5590 - accuracy: 0.8061 - val_loss: 0.5657 - val_accuracy: 0.8025\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5489 - accuracy: 0.8154 - val_loss: 0.5645 - val_accuracy: 0.7943\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5503 - accuracy: 0.8022 - val_loss: 0.5617 - val_accuracy: 0.8065\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5005 - accuracy: 0.8160 - val_loss: 0.5573 - val_accuracy: 0.8038\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5443 - accuracy: 0.8059 - val_loss: 0.5555 - val_accuracy: 0.8052\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5436 - accuracy: 0.8092 - val_loss: 0.5551 - val_accuracy: 0.8079\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5190 - accuracy: 0.8086 - val_loss: 0.5531 - val_accuracy: 0.8011\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5095 - accuracy: 0.8169 - val_loss: 0.5522 - val_accuracy: 0.8025\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.5038 - accuracy: 0.8203 - val_loss: 0.5450 - val_accuracy: 0.8120\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5072 - accuracy: 0.8171 - val_loss: 0.5468 - val_accuracy: 0.8106\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.5146 - accuracy: 0.8183 - val_loss: 0.5419 - val_accuracy: 0.8093\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4810 - accuracy: 0.8251 - val_loss: 0.5422 - val_accuracy: 0.8065\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5098 - accuracy: 0.8183 - val_loss: 0.5427 - val_accuracy: 0.8079\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5182 - accuracy: 0.8235 - val_loss: 0.5395 - val_accuracy: 0.8161\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4590 - accuracy: 0.8388 - val_loss: 0.5347 - val_accuracy: 0.8093\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4941 - accuracy: 0.8323 - val_loss: 0.5343 - val_accuracy: 0.8174\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.5008 - accuracy: 0.8194 - val_loss: 0.5345 - val_accuracy: 0.8174\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4676 - accuracy: 0.8297 - val_loss: 0.5291 - val_accuracy: 0.8106\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4556 - accuracy: 0.8393 - val_loss: 0.5291 - val_accuracy: 0.8134\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4647 - accuracy: 0.8315 - val_loss: 0.5315 - val_accuracy: 0.8134\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4673 - accuracy: 0.8328 - val_loss: 0.5257 - val_accuracy: 0.8120\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4750 - accuracy: 0.8325 - val_loss: 0.5276 - val_accuracy: 0.8134\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4719 - accuracy: 0.8372 - val_loss: 0.5262 - val_accuracy: 0.8161\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4990 - accuracy: 0.8227 - val_loss: 0.5252 - val_accuracy: 0.8134\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4610 - accuracy: 0.8421 - val_loss: 0.5258 - val_accuracy: 0.8065\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4634 - accuracy: 0.8413 - val_loss: 0.5235 - val_accuracy: 0.8106\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.4525 - accuracy: 0.8362 - val_loss: 0.5177 - val_accuracy: 0.8147\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.4600 - accuracy: 0.8259 - val_loss: 0.5175 - val_accuracy: 0.8202\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.4493 - accuracy: 0.8456 - val_loss: 0.5157 - val_accuracy: 0.8161\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4847 - accuracy: 0.8253 - val_loss: 0.5177 - val_accuracy: 0.8243\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4267 - accuracy: 0.8510 - val_loss: 0.5130 - val_accuracy: 0.8147\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4485 - accuracy: 0.8466 - val_loss: 0.5145 - val_accuracy: 0.8202\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4594 - accuracy: 0.8352 - val_loss: 0.5133 - val_accuracy: 0.8188\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4486 - accuracy: 0.8398 - val_loss: 0.5127 - val_accuracy: 0.8147\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4292 - accuracy: 0.8470 - val_loss: 0.5107 - val_accuracy: 0.8202\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.4142 - accuracy: 0.8499 - val_loss: 0.5124 - val_accuracy: 0.8188\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4255 - accuracy: 0.8494 - val_loss: 0.5071 - val_accuracy: 0.8215\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4618 - accuracy: 0.8314 - val_loss: 0.5086 - val_accuracy: 0.8215\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4079 - accuracy: 0.8509 - val_loss: 0.5056 - val_accuracy: 0.8215\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4097 - accuracy: 0.8574 - val_loss: 0.5055 - val_accuracy: 0.8202\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4134 - accuracy: 0.8504 - val_loss: 0.5032 - val_accuracy: 0.8243\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4351 - accuracy: 0.8425 - val_loss: 0.5043 - val_accuracy: 0.8174\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.4357 - accuracy: 0.8434 - val_loss: 0.5039 - val_accuracy: 0.8243\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3824 - accuracy: 0.8655 - val_loss: 0.5072 - val_accuracy: 0.8202\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4506 - accuracy: 0.8386 - val_loss: 0.5055 - val_accuracy: 0.8229\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4151 - accuracy: 0.8503 - val_loss: 0.5023 - val_accuracy: 0.8243\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4034 - accuracy: 0.8516 - val_loss: 0.5017 - val_accuracy: 0.8256\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4176 - accuracy: 0.8475 - val_loss: 0.4985 - val_accuracy: 0.8270\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3974 - accuracy: 0.8495 - val_loss: 0.5016 - val_accuracy: 0.8256\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.4110 - accuracy: 0.8531 - val_loss: 0.4985 - val_accuracy: 0.8243\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.4152 - accuracy: 0.8502 - val_loss: 0.5020 - val_accuracy: 0.8256\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.4092 - accuracy: 0.8474 - val_loss: 0.4995 - val_accuracy: 0.8215\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3963 - accuracy: 0.8556 - val_loss: 0.5010 - val_accuracy: 0.8283\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3912 - accuracy: 0.8581 - val_loss: 0.4987 - val_accuracy: 0.8256\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3938 - accuracy: 0.8633 - val_loss: 0.4969 - val_accuracy: 0.8283\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3802 - accuracy: 0.8654 - val_loss: 0.4983 - val_accuracy: 0.8256\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3866 - accuracy: 0.8665 - val_loss: 0.4939 - val_accuracy: 0.8256\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3944 - accuracy: 0.8569 - val_loss: 0.4949 - val_accuracy: 0.8283\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3654 - accuracy: 0.8632 - val_loss: 0.4952 - val_accuracy: 0.8283\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3764 - accuracy: 0.8607 - val_loss: 0.4926 - val_accuracy: 0.8283\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3975 - accuracy: 0.8594 - val_loss: 0.4931 - val_accuracy: 0.8256\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3990 - accuracy: 0.8562 - val_loss: 0.4924 - val_accuracy: 0.8283\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3779 - accuracy: 0.8621 - val_loss: 0.4964 - val_accuracy: 0.8256\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3549 - accuracy: 0.8722 - val_loss: 0.4914 - val_accuracy: 0.8351\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3776 - accuracy: 0.8670 - val_loss: 0.4948 - val_accuracy: 0.8297\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.3853 - accuracy: 0.8559 - val_loss: 0.4899 - val_accuracy: 0.8311\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3684 - accuracy: 0.8603 - val_loss: 0.4922 - val_accuracy: 0.8229\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3494 - accuracy: 0.8705 - val_loss: 0.4938 - val_accuracy: 0.8324\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3598 - accuracy: 0.8753 - val_loss: 0.4912 - val_accuracy: 0.8256\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3862 - accuracy: 0.8658 - val_loss: 0.4948 - val_accuracy: 0.8256\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3594 - accuracy: 0.8646 - val_loss: 0.4899 - val_accuracy: 0.8311\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3798 - accuracy: 0.8644 - val_loss: 0.4922 - val_accuracy: 0.8311\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3754 - accuracy: 0.8613 - val_loss: 0.4914 - val_accuracy: 0.8243\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3696 - accuracy: 0.8706 - val_loss: 0.4908 - val_accuracy: 0.8297\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3449 - accuracy: 0.8759 - val_loss: 0.4881 - val_accuracy: 0.8311\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3751 - accuracy: 0.8683 - val_loss: 0.4908 - val_accuracy: 0.8351\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3649 - accuracy: 0.8679 - val_loss: 0.4935 - val_accuracy: 0.8311\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3569 - accuracy: 0.8661 - val_loss: 0.4887 - val_accuracy: 0.8324\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3524 - accuracy: 0.8701 - val_loss: 0.4877 - val_accuracy: 0.8324\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3560 - accuracy: 0.8652 - val_loss: 0.4870 - val_accuracy: 0.8324\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3718 - accuracy: 0.8656 - val_loss: 0.4871 - val_accuracy: 0.8338\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3487 - accuracy: 0.8744 - val_loss: 0.4877 - val_accuracy: 0.8283\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3304 - accuracy: 0.8859 - val_loss: 0.4865 - val_accuracy: 0.8324\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3626 - accuracy: 0.8656 - val_loss: 0.4855 - val_accuracy: 0.8324\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3312 - accuracy: 0.8715 - val_loss: 0.4889 - val_accuracy: 0.8311\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3408 - accuracy: 0.8684 - val_loss: 0.4857 - val_accuracy: 0.8351\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3467 - accuracy: 0.8757 - val_loss: 0.4869 - val_accuracy: 0.8365\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3459 - accuracy: 0.8723 - val_loss: 0.4859 - val_accuracy: 0.8311\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3417 - accuracy: 0.8743 - val_loss: 0.4849 - val_accuracy: 0.8311\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3391 - accuracy: 0.8735 - val_loss: 0.4849 - val_accuracy: 0.8365\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3405 - accuracy: 0.8776 - val_loss: 0.4802 - val_accuracy: 0.8365\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3334 - accuracy: 0.8852 - val_loss: 0.4805 - val_accuracy: 0.8392\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3507 - accuracy: 0.8749 - val_loss: 0.4843 - val_accuracy: 0.8351\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3482 - accuracy: 0.8744 - val_loss: 0.4820 - val_accuracy: 0.8365\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3309 - accuracy: 0.8785 - val_loss: 0.4801 - val_accuracy: 0.8351\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3409 - accuracy: 0.8758 - val_loss: 0.4814 - val_accuracy: 0.8365\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3344 - accuracy: 0.8840 - val_loss: 0.4798 - val_accuracy: 0.8338\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3519 - accuracy: 0.8702 - val_loss: 0.4807 - val_accuracy: 0.8379\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3324 - accuracy: 0.8785 - val_loss: 0.4811 - val_accuracy: 0.8365\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3115 - accuracy: 0.8943 - val_loss: 0.4782 - val_accuracy: 0.8406\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3013 - accuracy: 0.8930 - val_loss: 0.4822 - val_accuracy: 0.8311\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3157 - accuracy: 0.8809 - val_loss: 0.4778 - val_accuracy: 0.8392\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3155 - accuracy: 0.8940 - val_loss: 0.4775 - val_accuracy: 0.8311\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3089 - accuracy: 0.8852 - val_loss: 0.4804 - val_accuracy: 0.8270\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3390 - accuracy: 0.8773 - val_loss: 0.4744 - val_accuracy: 0.8406\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3186 - accuracy: 0.8881 - val_loss: 0.4754 - val_accuracy: 0.8406\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3164 - accuracy: 0.8842 - val_loss: 0.4741 - val_accuracy: 0.8406\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3228 - accuracy: 0.8840 - val_loss: 0.4779 - val_accuracy: 0.8379\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3364 - accuracy: 0.8797 - val_loss: 0.4726 - val_accuracy: 0.8406\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3322 - accuracy: 0.8794 - val_loss: 0.4784 - val_accuracy: 0.8447\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3225 - accuracy: 0.8868 - val_loss: 0.4765 - val_accuracy: 0.8406\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3181 - accuracy: 0.8801 - val_loss: 0.4759 - val_accuracy: 0.8392\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3339 - accuracy: 0.8793 - val_loss: 0.4731 - val_accuracy: 0.8420\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.3065 - accuracy: 0.8836 - val_loss: 0.4759 - val_accuracy: 0.8433\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3070 - accuracy: 0.8860 - val_loss: 0.4764 - val_accuracy: 0.8420\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.3275 - accuracy: 0.8699 - val_loss: 0.4780 - val_accuracy: 0.8392\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3191 - accuracy: 0.8865 - val_loss: 0.4799 - val_accuracy: 0.8420\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.2999 - accuracy: 0.8975 - val_loss: 0.4769 - val_accuracy: 0.8406\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.2905 - accuracy: 0.9007 - val_loss: 0.4766 - val_accuracy: 0.8392\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.2864 - accuracy: 0.8974 - val_loss: 0.4799 - val_accuracy: 0.8406\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3089 - accuracy: 0.8814 - val_loss: 0.4753 - val_accuracy: 0.8379\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.2950 - accuracy: 0.8980 - val_loss: 0.4768 - val_accuracy: 0.8420\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.3058 - accuracy: 0.8909 - val_loss: 0.4780 - val_accuracy: 0.8365\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.3032 - accuracy: 0.8773 - val_loss: 0.4769 - val_accuracy: 0.8420\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.3030 - accuracy: 0.8843 - val_loss: 0.4752 - val_accuracy: 0.8365\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2975 - accuracy: 0.8948 - val_loss: 0.4769 - val_accuracy: 0.8365\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.3007 - accuracy: 0.8895 - val_loss: 0.4706 - val_accuracy: 0.8420\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2954 - accuracy: 0.8930 - val_loss: 0.4739 - val_accuracy: 0.8392\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.3127 - accuracy: 0.8913 - val_loss: 0.4749 - val_accuracy: 0.8406\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2945 - accuracy: 0.8909 - val_loss: 0.4730 - val_accuracy: 0.8379\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.3057 - accuracy: 0.8907 - val_loss: 0.4727 - val_accuracy: 0.8365\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.3134 - accuracy: 0.8928 - val_loss: 0.4712 - val_accuracy: 0.8433\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2837 - accuracy: 0.8993 - val_loss: 0.4724 - val_accuracy: 0.8379\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2938 - accuracy: 0.8924 - val_loss: 0.4724 - val_accuracy: 0.8447\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2832 - accuracy: 0.9010 - val_loss: 0.4739 - val_accuracy: 0.8392\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.3157 - accuracy: 0.8876 - val_loss: 0.4735 - val_accuracy: 0.8420\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2962 - accuracy: 0.8970 - val_loss: 0.4719 - val_accuracy: 0.8365\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2808 - accuracy: 0.8964 - val_loss: 0.4727 - val_accuracy: 0.8460\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.3001 - accuracy: 0.8818 - val_loss: 0.4688 - val_accuracy: 0.8420\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2807 - accuracy: 0.9036 - val_loss: 0.4738 - val_accuracy: 0.8379\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2895 - accuracy: 0.8898 - val_loss: 0.4701 - val_accuracy: 0.8420\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2912 - accuracy: 0.9023 - val_loss: 0.4699 - val_accuracy: 0.8447\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2742 - accuracy: 0.8976 - val_loss: 0.4756 - val_accuracy: 0.8406\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2725 - accuracy: 0.8998 - val_loss: 0.4698 - val_accuracy: 0.8392\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2895 - accuracy: 0.8917 - val_loss: 0.4710 - val_accuracy: 0.8392\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2949 - accuracy: 0.8988 - val_loss: 0.4699 - val_accuracy: 0.8460\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2898 - accuracy: 0.8957 - val_loss: 0.4724 - val_accuracy: 0.8420\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2725 - accuracy: 0.9065 - val_loss: 0.4678 - val_accuracy: 0.8433\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2969 - accuracy: 0.8952 - val_loss: 0.4703 - val_accuracy: 0.8488\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 2s 110ms/step - loss: 0.2979 - accuracy: 0.8878 - val_loss: 0.4708 - val_accuracy: 0.8447\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2706 - accuracy: 0.8970 - val_loss: 0.4695 - val_accuracy: 0.8433\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2956 - accuracy: 0.8919 - val_loss: 0.4703 - val_accuracy: 0.8420\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2738 - accuracy: 0.9038 - val_loss: 0.4750 - val_accuracy: 0.8433\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2687 - accuracy: 0.9085 - val_loss: 0.4704 - val_accuracy: 0.8420\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2683 - accuracy: 0.9036 - val_loss: 0.4716 - val_accuracy: 0.8433\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2550 - accuracy: 0.9112 - val_loss: 0.4684 - val_accuracy: 0.8447\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2669 - accuracy: 0.9085 - val_loss: 0.4708 - val_accuracy: 0.8406\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2874 - accuracy: 0.8976 - val_loss: 0.4675 - val_accuracy: 0.8433\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2724 - accuracy: 0.9033 - val_loss: 0.4678 - val_accuracy: 0.8474\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2889 - accuracy: 0.9041 - val_loss: 0.4691 - val_accuracy: 0.8447\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2795 - accuracy: 0.8895 - val_loss: 0.4702 - val_accuracy: 0.8488\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2676 - accuracy: 0.9054 - val_loss: 0.4705 - val_accuracy: 0.8406\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2709 - accuracy: 0.9011 - val_loss: 0.4687 - val_accuracy: 0.8460\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2898 - accuracy: 0.8927 - val_loss: 0.4669 - val_accuracy: 0.8474\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2819 - accuracy: 0.8908 - val_loss: 0.4723 - val_accuracy: 0.8474\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2588 - accuracy: 0.8989 - val_loss: 0.4697 - val_accuracy: 0.8488\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2704 - accuracy: 0.9058 - val_loss: 0.4679 - val_accuracy: 0.8460\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2815 - accuracy: 0.9084 - val_loss: 0.4733 - val_accuracy: 0.8460\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2720 - accuracy: 0.9070 - val_loss: 0.4679 - val_accuracy: 0.8460\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2866 - accuracy: 0.8931 - val_loss: 0.4702 - val_accuracy: 0.8474\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2612 - accuracy: 0.9008 - val_loss: 0.4704 - val_accuracy: 0.8460\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2670 - accuracy: 0.9069 - val_loss: 0.4717 - val_accuracy: 0.8474\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2543 - accuracy: 0.9036 - val_loss: 0.4682 - val_accuracy: 0.8460\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2582 - accuracy: 0.9092 - val_loss: 0.4739 - val_accuracy: 0.8420\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2555 - accuracy: 0.9012 - val_loss: 0.4707 - val_accuracy: 0.8460\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2493 - accuracy: 0.9135 - val_loss: 0.4728 - val_accuracy: 0.8447\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2743 - accuracy: 0.9020 - val_loss: 0.4710 - val_accuracy: 0.8447\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2515 - accuracy: 0.9075 - val_loss: 0.4689 - val_accuracy: 0.8515\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2704 - accuracy: 0.9079 - val_loss: 0.4720 - val_accuracy: 0.8474\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2553 - accuracy: 0.9030 - val_loss: 0.4727 - val_accuracy: 0.8474\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2511 - accuracy: 0.9097 - val_loss: 0.4707 - val_accuracy: 0.8433\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2503 - accuracy: 0.9060 - val_loss: 0.4698 - val_accuracy: 0.8406\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2484 - accuracy: 0.9050 - val_loss: 0.4701 - val_accuracy: 0.8433\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2838 - accuracy: 0.8950 - val_loss: 0.4729 - val_accuracy: 0.8433\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2604 - accuracy: 0.9052 - val_loss: 0.4701 - val_accuracy: 0.8433\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2565 - accuracy: 0.9078 - val_loss: 0.4680 - val_accuracy: 0.8460\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2501 - accuracy: 0.9083 - val_loss: 0.4684 - val_accuracy: 0.8460\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2612 - accuracy: 0.9078 - val_loss: 0.4721 - val_accuracy: 0.8406\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.2499 - accuracy: 0.9078 - val_loss: 0.4698 - val_accuracy: 0.8447\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2669 - accuracy: 0.9019 - val_loss: 0.4672 - val_accuracy: 0.8474\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2596 - accuracy: 0.9066 - val_loss: 0.4679 - val_accuracy: 0.8406\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2289 - accuracy: 0.9173 - val_loss: 0.4711 - val_accuracy: 0.8460\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2239 - accuracy: 0.9258 - val_loss: 0.4664 - val_accuracy: 0.8406\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.2467 - accuracy: 0.9109 - val_loss: 0.4653 - val_accuracy: 0.8420\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2430 - accuracy: 0.9130 - val_loss: 0.4660 - val_accuracy: 0.8474\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 3s 114ms/step - loss: 0.2511 - accuracy: 0.9104 - val_loss: 0.4670 - val_accuracy: 0.8460\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2537 - accuracy: 0.9109 - val_loss: 0.4636 - val_accuracy: 0.8447\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2432 - accuracy: 0.9055 - val_loss: 0.4632 - val_accuracy: 0.8501\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2402 - accuracy: 0.9147 - val_loss: 0.4668 - val_accuracy: 0.8488\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2439 - accuracy: 0.9144 - val_loss: 0.4674 - val_accuracy: 0.8447\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2499 - accuracy: 0.9063 - val_loss: 0.4697 - val_accuracy: 0.8474\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2611 - accuracy: 0.9035 - val_loss: 0.4648 - val_accuracy: 0.8447\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2364 - accuracy: 0.9175 - val_loss: 0.4654 - val_accuracy: 0.8447\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.2469 - accuracy: 0.9119 - val_loss: 0.4668 - val_accuracy: 0.8474\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2338 - accuracy: 0.9169 - val_loss: 0.4676 - val_accuracy: 0.8420\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2437 - accuracy: 0.9140 - val_loss: 0.4659 - val_accuracy: 0.8474\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2452 - accuracy: 0.9122 - val_loss: 0.4644 - val_accuracy: 0.8474\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.2568 - accuracy: 0.9059 - val_loss: 0.4640 - val_accuracy: 0.8488\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.2364 - accuracy: 0.9127 - val_loss: 0.4669 - val_accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHwCAYAAABpICzHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e+ZSe8VQhokdAg9gIAgICgiAiq6IihWlF3r6rq2n7rqquu6dtdde1dcFQVBQQSk904oCS0JkB7Sy2Tm/P44QxhCQksgwbyf58nDzJ0z575zE+a9p9xzldYaIYQQQjRNlsYOQAghhBB1k0QthBBCNGGSqIUQQogmTBK1EEII0YRJohZCCCGaMEnUQgghRBMmiVr8riilflJKTWnoso1JKbVPKTXiLNS7SCl1m/PxJKXUvFMpewb7iVVKFSulrGcaqxDNmSRq0eicX+JHfhxKqTKX55NOpy6t9WVa648bumxTpJR6WCm1uJbtYUqpSqVUwqnWpbX+XGt9SQPFdcyJhdY6VWvtp7W2N0T9texPKaX2KKWSzkb9QjQ2SdSi0Tm/xP201n5AKnCFy7bPj5RTSrk1XpRN0mfAQKVUXI3t1wFbtNZbGyGmxjAEaAHEK6X6nssdy9+kOBckUYsmSyk1VCmVrpT6q1IqA/hQKRWslPpRKZWtlMp3Po52eY9rd+5NSqmlSqmXnGX3KqUuO8OycUqpxUqpIqXUfKXUW0qpz+qI+1RifEYptcxZ3zylVJjL6zcopfYrpXKVUo/VdXy01unAAuCGGi/dCHxysjhqxHyTUmqpy/ORSqkdSqkCpdSbgHJ5ra1SaoEzvhyl1OdKqSDna58CscAsZ4/IQ0qpNkopfSSpKaUilVIzlVJ5SqkUpdTtLnU/pZT6Win1ifPYbFNKJdZ1DJymAD8Ac5yPXT9XV6XUL859ZSqlHnVutyqlHlVK7XbuZ51SKqZmrM6yNf9OlimlXlFK5QJPneh4ON8To5T6zvl7yFVKvamU8nDG1M2lXAulVKlSKvwkn1c0M5KoRVMXAYQArYGpmL/ZD53PY4Ey4M0TvL8/sBMIA14E3ldKqTMo+wWwGggFnuL45OjqVGK8HrgZ0xL0AB4EUEp1Ad521h/p3F+tydXpY9dYlFIdgZ7OeE/3WB2pIwz4Dngccyx2A4NciwDPO+PrDMRgjgla6xs4tlfkxVp28RWQ7nz/BOA5pdRwl9fHOssEATNPFLNSysdZx+fOn+uUUh7O1/yB+cDPzn21A351vvXPwERgNBAA3AKUnvDAHNUf2AO0BP5+ouOhzLj8j8B+oA0QBXylta50fsbJLvVOBH7VWmefYhyiudBay4/8NJkfYB8wwvl4KFAJeJ2gfE8g3+X5IuA25+ObgBSX13wADUScTllMkqsCfFxe/wz47BQ/U20xPu7y/I/Az87HT2C+yI+85us8BiPqqNsHKAQGOp//HfjhDI/VUufjG4GVLuUUJrHeVke944ENtf0Onc/bOI+lGyaJ2QF/l9efBz5yPn4KmO/yWheg7ATHdjKQ7azbCygArnS+NtE1rhrv2wmMq2V7dawnOE6pJ/l9Vx8PYMCR+Gop1x9zUqOcz9cC1zbm/z/5aZo/0qIWTV221rr8yBOllI9S6r/OruFCYDEQpOqeUZxx5IHW+kiLye80y0YCeS7bANLqCvgUY8xweVzqElOka91a6xIgt659OWP6H3Cjs/U/CfjkNOKoTc0YtOtzpVRLpdRXSqkDzno/w7S8T8WRY1nksm0/pqV5RM1j46XqHgueAnytta5y/p18y9Hu7xhMb0BtTvTayRzzuz/J8YgB9mutq2pWorVehfl8Q5VSnTAt/plnGJP4HZNELZq6mrd3ewDoCPTXWgdgJhKByxjqWXAICHF2sx4Rc4Ly9YnxkGvdzn2GnuQ9HwPXAiMBf2BWPeOoGYPi2M/7HOb30s1Z7+QadZ7olnwHMcfS32VbLHDgJDEdxznePhyYrJTKUGYewwRgtLP7Pg2Ir+PtaUDbWraXOP91/V1H1ChT8/Od6HikAbEnONH42Fn+BuAb15NSIY6QRC3ON/6YsdbDSqkQ4MmzvUOt9X5Mt+RTzklAA4ArzlKM3wBjlFIXOsdan+bk/0+XAIeBdzg6/lmfOGYDXZVSVzkTzD0cm6z8gWKgQCkVBfylxvszqSNBaq3TgOXA80opL6VUd+BWTCv0dN0A7MKcjPR0/nTAdNNPxIwNt1JK3aeU8lRK+Sul+jvf+x7wjFKqvTK6K6VCtRkfPoBJ/lal1C3UntBdneh4rMac+LyglPJ1fmbX8f7PgCsxyfqTMzgGohmQRC3ON68C3kAOsBIzUehcmIQZb8wFngWmAxV1lD3jGLXW24A/YSaDHQLyMYnnRO/RmC/51hz7ZX9GcWitc4BrgBcwn7c9sMylyN+A3pjx4NmYiWeungceV0odVko9WMsuJmLGgg8CM4AntdbzTyW2GqYA/9ZaZ7j+AP8Bpji710diTqoygGRgmPO9LwNfA/MwY/zvY44VwO2YZJsLdMWcWJxIncdDm2vHr8B0a6difpd/cHk9DViPaZEvOf1DIJqDI5MYhBCnQSk1HdihtT7rLXrx+6aU+gA4qLV+vLFjEU2TJGohToEyC2nkAXuBS4DvgQFa6w2NGpg4ryml2gAbgV5a672NG41oqqTrW4hTE4G5TKcYeB2YJkla1IdS6hlgK/BPSdLiRKRFLYQQQjRh0qIWQgghmjBJ1EIIIUQT1iTv/BIWFqbbtGnT2GEIIYQQ58S6detytNa13pClSSbqNm3asHbt2sYOQwghhDgnlFL763pNur6FEEKIJkwStRBCCNGESaIWQgghmjBJ1EIIIUQTJolaCCGEaMIkUQshhBBNmCRqIYQQ572MgnJu/nA1Ww8UNHYoDU4StRBCiPNGuc1OYbntmG12h+berzawcGc2T89Koq57WGiteW/JHi555Tfmbss46X7KbXYAsosqeG/JHoorqo6p61yp14InSqlRwGuAFXhPa/1CjddbAx8A4ZhbBE7WWqfXZ59CCCHOLbtD89uuLNqF+xMb6tMoMWit+SUpkydnbqO00s6LE7rTOSKALQcKmJeUwaq9eQxuH8aS5ByWpuQwuL1Z5KukooqPV+xj3b58coor2JReQIivB3d8uo4bLmjN38Z2xWJRFFdUMeWD1eSXVtItKpBFO7Opsjt4cmxX3luyh12ZxXy7/gCT+sfyzbp0/ji0LZd0jTgnn/2M756llLICu4CRQDqwBpiotU5yKfM/4Eet9cdKqeHAzVrrG05Wd2JiopaVyYQQov5SsooI8Hanhb8XAKWVVdz60Vou796KyRe0Pun71+3P577pG0jLKyM62JvZdw8m0Me91rJb0gt4dnYSD43qSJ/WIbw8bydlNjsT+sTwyYp97MgoYmDbUMZ0j6RjhD8A6fmlvPDTDq7vH8vAtmGAac2+/msy5TYHHm4WrBb4dXsWOzKK6BThj5tVsfVAYfV+3a2KSf1b88joTgz75yLcrBYGxIeSXVzB+tR8Dpfa6NDSDy93K1f3jmZiv1he/HkH7y3dy6T+sUwb2pZHZ2xlWUoO/eNCSDpUyOD24aTmlbIp7TCebhbuubg9by/aTXFFFe1a+PHQpR0bNFErpdZprRNrfa0eiXoA8JTW+lLn80cAtNbPu5TZBozSWqcppRRQoLUOOFndkqiFEM1Fld2Bm/XEo5CZheWs25/PZQkRmK/Suq3Ynct90zcQ5O1BsK87K/fk0TrUh1l3X0iAlzuPf7+Fz1amEu7vyfKHh+N+gn1rrbn89aXkl1Zy64Vx/OPnHVzUoQXv3NAHi0WxYncuZbYqvNytrNmbz78XpVBR5aB/XAhPje3KZa8tqa7LzaLoEhnA1gMFODT0iAmiW1QAszcfIr/Uhr+XG9//aRBtw/14d/Ee/j5nO36eblRWOai0O0iICmBS/9ZM6BONQ2u+XJWKu5uFblGBdIzwx9PNCsDCnVk8N3s7BWU2Qnw96NIqgMkDWtM7Nvi4z/aPn3fyn992V2974apuXNcvtvp5uc3Of37bzQXxoVwQH8q+nBJySyrpHRt00t/D6TpbiXoCJgnf5nx+A9Bfa32XS5kvgFVa69eUUlcB3wJhWuvcE9UtiVoI0VC01uzLLSUuzPec7G93djGFZTZ61UgMtVmeksPNH63h/pEduGNIfK1f/oXlNq7693JSsoqZ2C+GZ8d3w2pR/LDxAGv25fH02AS2ZxTy1MxttAzwYt62TKJDvGnp78WhgjJGdG7Jh8v3MaxjC7pGBvDar8n0jg1ifeph3p7Um7hwX+ZuzSSnuILR3VrRMyaIZ2cn4efpRp/WwUz9dB0vXdODCX2i+WDpXp7+MYkB8aFEBHoxY8OBY2Id3D6MblGB/HvRbhKiAtibXcJnt/Vn+e5cRiVE0Dbcj7ySSr5bn87sLYfYlVFEbKgvj47uxH1fbcTfy413bkzkundW0jUygE9v7Q+Y32FDJ8Yj9S7cmUVOUSXRwd4MbBfW4Ps4VY2ZqCOBN4E4YDFwNZCgtT5cS31TgakAsbGxffbvr3N9ciGEOGWfrNjHEz9sY3zPSP42NqHObtuTyS6qYN3+PEZ0blndArY7NKWVVfh7mToPHC7jijeWUlxRxQ9/GkTnVqYDsdxmx8NqwWI5mmy01ox/axnbDhZS5dBM7BfD0+MSqLJr5iVlsCOjiNKKKrYeLGRT2mHGdG/F9xsPclWvKB6+rBPDXlpESaWdZ8cn8MWqVNLyS/H3dKNtCz/emNiLIB+P6n0daaECXNgujHdvTGTEy7/h5W7h4OFyymx2vN2tlNnsRAV5c+BwGQAeVgstAjxZ+OBQ3K0WtNZMX5PGMz8mUWqzc8/w9lzUMZyi8ioSIgMI9fOkuKKKAc//SlF5FXcMieeR0Z3rPKauCXh9aj5TPlhNaaUdu0Mz448DT+lk5/ei0bq+a5T3A3ZoraNPVre0qIUQDUFrzahXl5BbUkF+qY0ALzfuvKgtNw+Kw8PNQnFFFUXlNiICvGptsWmtKa20s/VAAfd8tYHMwgrat/Djhau70ad1CA98vYkfNh5gZJeW9GkdzIwNB9ifW4qXu5UgH3duGtiGpck5LNiZRWSgF69d14uft2Ww41AhPWKCeHV+Mv+4uhupeaW8tXA3/eJCOFRQRlpeGW4Wha+nG3aH5okxXbi2bwyvzt/Fq/OTiQnxJqOgnA4t/Uk6VIjW8Pak3lzWrVWdx2H57lziw31pFegNwJsLknlp3i66tArgo1v64ufpxj9+2sHP2zJ44aru7M4u5tnZ23lxQneuTYw5pr5DBWXkl9joEln7SObLv+zivSV7WPTgUFoEeJ3y7yslq4jbPl5LQlQgb17f+5Tf93twthK1G2Yy2cXAAcxksuu11ttcyoQBeVprh1Lq74Bda/3EyeqWRC3E71NRuY1dmcXEBHtXf4GXVFThbrXg4Vb7WGm5zY7N7qhutZ6OjWmHGf/WMp67shs9YgJ58eed/LYrm6t6R3H/iA6Mf2sZuSWVhPl58t6URHrGBFW/N6uwnLu+2MDqfXkAxIR4M3VIW/77227ySiq5fXA8r/2azID4UHZkFJJfasPDauGtSb3xdrdywwer0BpaBngyonNL5iVlkl1UAUCIrwd5JZW0CfVh/p8vws1q4eu1aTz63RZiQ33429iu9I8LPe6YaK2596uNzNx0kDsvasuEPtGMfm0Jg9uH8d6UxNPqHi6uqOLrNWlMSIwmoI5je7i08piW+amyO3T1GPHpcjg0GrBaGr6ruyk7K4naWfFo4FXM5VkfaK3/rpR6GlirtZ7p7B5/HtCYru8/aa0rTlavJGohfn+Kym2MeWMp+3NLAXhmXFcm9InhstcWY7EoPr21P1FB3uzJLubFn3fSIcKf0d0imPbZekoqqvh22kBiQnwoqaji7UW7iQr2ZqLLxJ/8kkpW7c0lNa+UGwe0wcvdyiPfbeb7DQdZ/djF1Yn+lV928dqvyQT7uOPQcM/F7Xl/yR68PKzMuutCFuzIYt3+fGZvOURxeRVTh8TTKtCLUQkRBPl4kFVYzoT/rCA1r5QurQL44a5BWJWiuLIKBdX72XqggAAvd2JCvFFKkVFQzlsLUxjTvRXdo4P4ak0qvWKDjzk5yCwsJ9jHo86TFjAnLj9vzWBUQgRe7lZSc0tpEeCJl7v1LPzWxLly1hL12SKJWohzIzmziC9Wp/LIZZ3xcLOQlldKdLD3KbXMft2eSW5JJVf3jq5u/VRUmbHY2t5///SN/LDxAM+O78bsLQfZkGrGXb9em46vhxUfTzfahvuyPvUwVqUocy42EeLrgd2hCfJxZ0Tnlvy05RAHC8pRCj69pT8Xtg9jwY5M7v1qI0XlZkGKh0Z15NrEGC56cSGjElrxr2t7VMfhcGimfrqWhTuz+eSWfgxqF8bS5Bwmv7+KIB93Dpfa8PGwkhAVyNPjutIp4vju3dTcUp7/aTt/HtmB9i39z+jYC+FKErUQolY3frCaxbuy+dvYrsSG+HDzR2t45Q89uLLX8VNJtNZkF1UQ7u9JbkklQ15cSGmlnZ4xQbw9uTehvp6Mfn0JrQK9eH9KX16at5NdmUW8d2Mi85Iy+ePn67l/RAfuHdGe9PxSRr68mDKbnSt7RTF1SDx/m7UNu0PTroUf94/o4FxgIp37RrQnt6SSmz5YTaXdQbeoQO69uANP/7iNnOJKOkX4s2JPLp0jAnh6XFfeWJDCxrTDDGoXyi9Jmfx07xDatfA75rPY7A4yC8uJDj66eMdzc7Yzd1sGD1zSkTHdWh0z8UuIs00StRBN3KlcS9vQNqUdZtxby/B2t+LtYcXLzcLBgnL6tQnh6zsHoLVmU3oBP209RHpeGZvSD5OeX8awjuFEBXvz5eo0/nJpR17/NZl+cSFc3Lkl//f9VgDat/AjOasYgMcv78xHy/fh5+nGj3dfWP05P1+1n3cW7+F/dww4pQlHlVUOrBZV3Xo/MvEo0Nud/vGh3D+iA94eVrakF3DFm0sBmDa0LX8d1elsHD4hGtSJEnW9lhAVQtTfe0v28Nr8ZN6bkkj/+NDq7Ta7g+vfXUl+qY1BbUPx93KnS2QAo2vM7LU7NK/O30VReRXx4b5M6t8ai4Ld2SXEh/ke0zK0OzQfLd/HzoxCkrOKCfR25+3Jvbn+3VUoBaO7RTBnSwbbDxXyzI9JLN+di4fVQnSIN11aBTCyS0s+XLYPgOv6xnDnRW1xt1p45sckVu3JI7F1MIltQvjPb7v5Q2IMafmlPDvbXBb02a39jzkZmdS/Ndf3iz3lCVA1x23btfBn0V+GHVeuW3Qg43pGsintMHcPb3dKdQvRlEmiFqKB5JVUEuzjXmfi+W1XNvFhvsSEHO1uXZKczXNztmNRiqmfruPjW/rRPSoQi0Xx/tK9rNmXT5/WwUxfm0ZllQOHhmfGJzC2eyR7c0voGRPEb7uyeGNBCj4eVkor7azcY5Lr9xsPMiA+lH9e053oYB8OHi7j/ukbWbU3D39PN4oqqnjwkg4MbBvGg5d0wM/Tjcu6teLnrRlMfHclBWU2Hr+8M3/oG3PMjOv4MF8+XL6Pe0e0B2DKgNbM2JDO1gOFPHBJR/rHhXBJ15b0iA4iJauY0a8vYWiHcC5sf/xiEmdjEQuAV67tSaXdIROsxO+CdH0L0QCSM4u4/I2l3DEkngcu6Xjc64t2ZnHTh2voHxfC9DsGsG5/Pm8uSGbZ7lziQn15fWIvJr23kpziSrzdrQxuH8bi5GyGtA/nnRtNb5jN7mDaZ+v4dUcWbhaFza5554Y+TF+TxuYDBSx/eDgfL9/Hs7O3Y1Fwde9o5mw5RJVDM7pbKxbsyMJmd/DU2K5c0yeajMJyWvp7HTcWe/OHq1m4M5uHL+vEnRe1PaXPn5ZXytr9ebWObe/IKCQm2AdfT2kXCFEXGaMW4iy76cPVLNqZjaebhYUPDiXQ2x2rReHlbiWzsJzLXltCcXkVlXYHP959IVM/WUulXTOmeyvuuCieVoHeHCooY8muHDYfOMzcbZlU2Oz8fN8QIoO8q/dTbrPzxA9bCfByZ3FyNgVlNrKKKrhrWLvqE4TFu7Lx93KjV2wwaXml/HtRCt+uP0DnCH9eva7XSZfS3J9bwso9uVybGHPWWrxCiGNJohaC2tcL1lrz8i+7GN6pxWktV6i1ZvaWQ3yzLp2W/l5MX5vGTQPb8MXqVDpH+LMnp4TYEB+m3zGAWz9aw+b0Aj6+pR+T3ltJmJ8nhwrK+eK2/nWuLWx3aMpsdvxO0ApdvTePa/+7AouCJX8dTpRLQq+pssqBu1VJ4hWiiZLJZKJZs9kdPD5jK0uSs/lm2sBjWqjbDhbyxoIU9uaU8Ob1dSfq/bklfLhsH51b+RPs48HHK/axLCWXVoFeLEnOIS7Ml0dGd8LT3cJ/f9tD3zbBrN2fz6hXF5OeX8a/rulBv7gQLktoxcxNBxncPuyENwCwWtQJkzRAv7gQbh8ch82uT5ik4fiJWEKcc4UHIW8vtBnU2JGcdyRRi9+1Kue47vztWXhYLfzpi/VMnzqgOnF9uz4dMLcGdDg0j87YwobUwzx8WSeGdjQ3np+56SCPzdhKaWUVDmcHVLi/J0+M6cKUgW0orqjCosDTzcpfLunIVb2i6Rjhzxu/JvOvX3YxoU80V/cxY7e3XBjH0pScBrtk6LHLuzRIPeI84HDAijfBNwx6TIQz6R2pKILiLAhtCxlbYfNXMPhB8HaujlZ4CLJ3gHZA3h7ISoK2F0PH0WBxnuxpDbkpUFkMLROgNA/y90HLLuBZx+IvRZnwwaVwOBW6XwfdrwWvQIjqc2afQ2vI3Aah7cC9jkv7Cg6Arcx8VqXg4Eb4+kZAQ9wQGPooBESaekLiwcM5ydNhh4zNENHDfOacFChIhYpiOLAWglpD4i1nFvcZkq5vcd7ILa7gke+2MLFfLMM6tQBg+6FC7vtqI33aBNM1MoCswgoq7Q7C/Dy5cUDr6slVT17RhXB/T+76YgP940K49cI4hnZswcAXfqXc5qC4ooovb7+AGz9YhUJRaXfQpVUAoX4eLEnOoXdsEK9P7EV+iY3ckgoGtQs74X18wayAtXx3LoltgmX2cUPJSYaU+dB7ytEv1iNKcsDdGzzOze0sAZM8bSUmQZXlw+b/Qc/rwdNlgRWtYda9UFEIl70Ifi2Ovpa9C/YsgoSrTAKurtcOs+6BssMw+p/gHWLq2PyVeb3dSOg1GWIvAP8IsFdBcaZJPAD5eyF1lUmmvSab45IyH364C4oOmQSZsQXsldBlHAx/wiSxrG0cw80LqsrBK8g8BpP8KgrMY6uHqQNAWaD9JTDqBVj/Mez8GSK6QWAUJP9iEn/PSbD2A9Bm1Tk6joYrXjPHxGE3CV87zGslObD6Hdi/3CTFHhNh+P/BngWw4Fk4uMGcRFzzIcy6D9w8YcyrJnHvmA3/uxnsFeATCtH9YN9Sc0IS2cscC6s7BESZkxGfUEi42tSRNBMO74eECRA/1Bz3I/Eqi4kv8RYY/RJYGu7/tYxRi/NaWaUdbw8rT/ywlU9W7Ecp+MulHfnj0Hbc/OFqVu4xN00os9lRCtwtFirtDkZ0bsHKPXkktgnmw5v6opTio2V7efu33WQWVhAf5suenBKeuqILT81KomNLf3ZmFjHjjwPZfqiIz1buJy2vlPtGdmDKgNbnfEGS36UMsyAKEQnmX62PbZkUHIDkuWY7gLsPdBoNVk9Y8x4seMYkjtB2cPETEN4JNn0JW78zX67KCq16QJ8p4N8K1n0MXgEQ0w9iLjD7ytgKrQeaL+X5T0JYRxh4t6k/Y7NJNB6+Jgn/9gIcToO+t0FVGZTmQvtLTTKwV8FXE2H/CpMslvwLUleYJDjgLtjyP+hxnfkcX99o/vUJhTGvmFh+egiSvjfbfcPh4idNYvANg/l/g1Vvg8XdJEOHzSTEYY+BZwD8+rQ5QQAIjDGtWlsJeAeb95RkHT2mYR1NIty3xByvhAkmtogECG5j4nb3Mcn8wj9Dq+5mn/4REBBtYty35OjvxOpujrGHHxxcD34tTYs0fS2s+g/YzFruxA40ybkszxzP8f+BjqMgf785WUhbBQv+DhY3SLjSHMe83cf+vXgGmGRefhh2/Qwtu0HmFgiOg7bDTNL3CjInQdoBsQPM8dj6jUnIvW6A9DWQutIc12s+Miczubth9p/NyVWP683J0p6Fpo5WPc17V//XxHCk9e3mCS06w6IXYNmrMOxxuOgvZ/xfoSZJ1KLJsTs0q/bk0j8+FKtF8eXqVMoq7fSICSLU14PIIG883Cz857fdvDxvF9OGtuWthSlc1TuKcpuDmZsOclXvKL5bf4C/jurElIGtyS+10cLfE3erpfr+ux5uFubdN4Q2LjOdq+wOvlmXzvM/7cDdqlj+8MVc+upi9uaU0K6FH7/cPwSlFEf+bzTLCVi2ctO6Cm1nuiiPyNjqHGvcbVo7ngEw9g3TgizKNF/ytjLTNRrZ23xpL33FtDyqKmDlv03r8661sPlrWPk23DzbJAyAz681idqVh79JjCXZpsXWazLMfQwK0szrR1pyrQeZL+xdP5vWIoBfBDiqoDTn2DotbibRlB82z6P6wIF15nF0XxjyF9jyDWz52pwk2F3uJeTbArpdY5LNtu/MCUHRIfPaBX+Cte+bkwmrp0muXgEQGAtX/Re+/yMc2mgSo8MOg+41Ceenv5qTBFf9p0G/22HxSybJtBsB8ReZ16oqTfnUlSZu3zDzu8rYbOqN6Qcx/U1cM+8FNFwwDfrefmxXscMBX14HOTth0rcQVs8FYnJ3w+J/QtcrocOlJy+fkwxLXjbHOaKb6Sk50n1ucYO2w83x0xqWvGSS5IA/mRMWN09Y+Dwsfx2uesf83c282/xNdrgERv3j2J6N07X5f+Z3dfETZl+uNnwOnS4/OmTQACRRiyZBa43NrnG3Kh6dsYUvV6fxyGWdGNQujDFvLD2mbFyYL/+c0J1J763Cw2qhqKIKXw8ri/4yjFBfD+6dvpFZmw4S5ufB4oeG4eNx/HSL/61Nw9vDypjukbXGc7i0ktJKO5FB3jw2Ywufr0rlwUs6cAbfDIsAACAASURBVNfw9mfl89cpZb5pIV3xmjmTd1VRbFo6p9rFlrvbdNX5hpmuOTdP0yI8orLYfLEHxkDnMeaLOjfFJDP/CFP+lydg/ScmyQS1hhtmmHG+lf+Bn/96tK7ofmbMsTjj6LYjXYNgEhjK+boy3YddrzTdkpG9TUtH2yEqEW752bS03uwDF95vkhRAQbpp2VSWQL+ppnWjlEn6B9abk4m2w02L7gitTQuwLN85tupmWnZpq83rYR1MizJ/Hwx/3LTIV7xpWs1tLoTvph7tzh3+uElu22ealqPFzbQa9y42yXjwA6b1POte0xrue6vpkj2cauL69jbT7XvrLxDdB+w2k5jSVsGo5yHcec39kXHR9LXmd+Qbbrp6G6prtWbPhSuHw/zOrI04ZcleZT7ryU6KqyqOT5pVleDmcfSx1f2cjh83FEnU4qwpKLWxYGcmuzKLub5fbPWqWwVlNt5fsoe9uaW4WRSRQV7MT8oiJbuY+DBfkrOKCfYxq111jw5ifWo+300byP7cUjKLynl+zg5KKqvwdrcy7/4hzNlyiOhgn+rlMyurHPx9dhKD2oVxSdeIen+OZSk5/PHz9cy+58JjbtRwUg7H0Uk2tamqOPqlD6YV5/olUlEEb/aDooPmte5/gJxdzm7djvDvgaarbspMk7BL8+DH+02S8QmFsa+DfyRsnm667pJmmi8tW5npAq0qO5o4axpwl0l2qcuPbvMMMDH1vsEk0PlPmWQaGAOZW6HTGJNIPQMgvIOJZ/W75sQgINLU5+Fjym/41CTYy/5hulxLciC4NSx8Dn77hzkJGPyAGYvtOckcl81fw/3bjh3HPRcOp0FgtImh8KCZVOUdZE5QalNVacaEg2JOXK/DYXoC/Fs2fMzid0UStTgrHA7NyFd+Y3e2GSsL8HLjX9f2ZGSXljw2YwtfrE4lJtiHyioHGYXldI8OpF+bENbsyyOxTQhX9Ihk/FvLALhneDv+7LKi15p9edz28VruH9GemwbFndsPVppnWntpq8wXdmQv05XYogvkJptx0BadTKtz9oPQZaxJXJu+Ml2/fW4yY3LbfzRjZY6qo3WHdzaTd7Z+a7pdwzqYyTLXfmK6DHOSTaL18Ie4waZOgI6XmUlKC541l7jEX2TG9IJiIKK7mWTk1xLih8GIp0xrcsWbJvmEdzItXTBjjxEJJlFu+MzEPfQRCGhlWp3Zu0zXctxgUz57Fyx6DipLzWe76OH6t7xs5aYHoedE09356zOmWxNMwh7/7/rVL8R5SBK1aBAbUvMprbQzyHn977KUHCa9t4pnxnVlcPtw7v5yA9sPFfLihO489M1mrusXw7PjuwFmRa3aZj7f/slaVuzOZclDwwj29TjmNbtDmzslOezw3e2mK/XSv588UIfdXGLicJmpGdr26ASSqERTzy9PmDG+MS+bRLTxMzNTNmeneZ/FzUzOKcl2VqwA5/+XhKth2/em1Xs41bSaO40xXZcFqaaMu69JrsGtnR+oErZ8a7prW/UwY50pv5gu3dH/NN2TR7pA37/ETCDqf6dpec59xNTh4Q8TvzSJdPdC+HyCOREY9pgZVz3VLj+tzSShqMSTtwrPhT2LYPkbZlyxvuOkQpyHJFGL05ZVVE5hmY12LczEjsJyG0NeXMjhUhtDOoTzzwnd+cdPO/hleyZrHhuBl7uVgtJKJr81j/25pZS7+bP4L8OICDzx7QuLym3klVTSOrTGJTUF6fDjn80EmvICWPis2X7jDybhJn1vkl3PSabFuOQl2LfMzMrcOcd0DbuyOG8qYXEz3cFtBptxTDdvM9aINq3L2AGm9Rx7gRlH9fAx3aJpq8z1lmEdzBjvmndNa/Dmn0y9jiqT1O1VkL3dJNzgNsdPNtHadK0GRDq7WQ+Zbt6aY5FrPzSt6Un/M5NpcnebLunAGPA9eoctUuabceyu4094nIUQTZskanFaiiuquPz1JWQUlPPJLf3oHx/Kv+bt5I0FKUwdEs9nK/cTFeRNen4pr0QtZNSQC6HzFTDjzurrPNe3vJred75fewvP4YDkebBjlrkOsvPYY7tTs3bAZ1eZGatHxle7jDMzeUtyzMze4DYm4YGZ3bpviZlQlL/fdFUn3nJ0trK9Ag5tMuOKgx8wrdMt/zMTm0a/ZGaNBkSZLt9TvQY3Y6tpibrOiBZCiDMkiVrUqaSi6ri7Gt0/fSM/bDxAZKAX48pm0Ce+JW/tDiWyY1/emNSX5btzuOmDNYxjAf90f8eM2fa83kwe6n0jVVU23DZ/aa5hzN4BWdsBZbqJA6NM93DhgaOXvbRMgCmzTIt0zXsw7//MJRqTvzGTk3b/CuPeMrNpP73S1DvmFbMYxI/3mRm5Fz0MQx82if1kM2WrKsyJQruRda9qJIQQ59BZS9RKqVHAa4AVeE9r/UKN12OBj4EgZ5mHtdZzTlavJOqGV1JRxZQPVjMqIYJbL4xjwbaDvL9sP8v35vPs+AQmJ0bA9llMPxDCXxeVcd+I9kzxWUHwvHuq63C4+2JpPwL63s62lD20X/EQ7jF9UBWFprUbPxQmzzCt6O9uN63WkHjoMMp0DWdsMa3gqN7Q8XIzCWv7LPh+mrmO1c3LzFxuezGMe/PoKkuuSvNMQj/SUtfajCGf61nCQgjRgM5KolZKWYFdwEggHVgDTNRaJ7mUeQfYoLV+WynVBZijtW5zsrolUTe8L1al8ugMswhE5wh/nsl7gFhLLr94j0IXZ3ON7wY8y7PJ0kG8Hvcf/jahH9Z/94WQtlSMfwdH6iq8D642s5jLncsH+kfC7QvM4xVvmsUbjiRMu810N0f2OnkLd8s38O2tZhGIS/8OfW4+L6+DFEKIM3W27p7VD0jRWu9x7uQrYByQ5FJGAwHOx4HAwXrsT5whrTV7lnzJcp8PWRV9M/P2VZFo2YUO7cCk3M8ptXqxtKQzPzmu4mnPz3gm/0HUu8ok5CtexTMsDsLioPd1MPJps/JTYLRZau9I13HN2dhWd4iu9W/ueN0mmAQfFHt0hSohhBBA/VrUE4BRWuvbnM9vAPprre9yKdMKmAcEA77ACK31ujrqmwpMBYiNje2zf//+M4qrOXp1/i7crRbuGBJfvR51weHD+FGCtTCNw7++TND+uVRZPHFToINiUfYKuHs9lOaxq9iDRcl5DGwbRtfKTai5j5olD3tONJPEhBBCnFWNeT/qicBHWut/KaUGAJ8qpRK0Pn6pJK31O8A7YLq+z3JcvxvLd2XguehpEtReNq7wJm7IZIrKKghd+iRWVQaAh8WP1x3Xcutd/4fbhxejcpPNZCyrO/i3pIM/dGh15F7MQ+DOpXXvUAghxDlVn0R9AHBdKSHauc3VrcAoAK31CqWUFxAGZCFOzlbuXPc37NjtWdth4xfYfVtiWfg909zWkBeUQPHhVELn30sosEp3Ypb9Qm4c2pWrfw3g2kFd8A2LhT98Chu/MNcfCyGEaPLqk6jXAO2VUnGYBH0dcH2NMqnAxcBHSqnOgBeQjTg5uw0+vsLcMOGuNWZd531LzTW/yfNwYMWKnX5asa33k3Qd92dK80r4+2cfUF6Yx2V/mMaXH67l298s4AbThjrXLI69wPwIIYQ4L5xxotZaVyml7gLmYi69+kBrvU0p9TSwVms9E3gAeFcpdT9mYtlNuileuN0ULXwO0lejlQX18yNmYY0171LlFcpH7hN5u2QY/WP9GNY2gAkjLgQgOsSXR+++C7tD42a1cEX3Vny/8SDThrYlzM/zJDsUQgjRFNVrjNp5TfScGtuecHmcBAyqzz6ahdRVsG8xFGebGx/sWwabvmRNyBXsKPLmhi1fA1Da5w5GbhyCdvPmnTt60ad1yHFVKaVws5pLm+4f2QGHhjuH1HEHICGEEE1eI96AtJmqKDbLVCplFu+Y/YC5+TyY64hXl4K7D6W9buXW1YOpsGsuis4guvco7tieSG5lHrOm9qN9S/+T7qp1qC+vT+x10nJCCCGaLknU51JBOvx7gFkys/eN5l6/pbnOm9PfZm4KkZMMfi3477IcCu3JdI0M4Ircu+mxI4glydk8d2W3U0rSQgghfh9OcMd70eAWPmfu1JS5Fb6/E3xCzMpeQ/5ilsW0WCkPbs/GXAufr9rP8E4t+OeEHhSW21i3L4+/je3KxH5N4JaEQgghzhlpUZ8rhzaby6IG3sXy0Aksnvs1d0x6hODAo63jyioH495cxs7MIqwWxdQh8XSJDOCbOwcQFeRz0ltGCiGE+P2RRH227ZoHC54xN6TwCoTBD/D+9BR+LRxE9PY8Jl9wNFF/tz6dnZlFPH55Z0YlRBAd7ANQ66QxIYQQzYMk6rOlogjmPgbrP4awjuYWjF3Gc1j7sjjZXEo+c9NBLunSkvumb2RE55Z8sGwvPaIDufXCOJTclEIIIQSSqBuewwG7foKfH4HDqTDoPhj2KLiZ65jnrknFZteM7NKSX5IyufvLDazam8fy3bkAPDMuQZK0EEKIapKoG1LBAfjsasjebu7DfPNP0HrAMUVmbTpE61AfHhvdmV+SMlm1N4+/jupEdLA3KVnFDO0Y3kjBCyGEaIokUTcUhx2+m2pa0Ve9C12vNDe9cJFVWM7y3Tn8cWg72oT50q9NCOVVdm4fHFd91yshhBDClSTqhrL4n7B/KYx/G7pfW705JauI5+fs4OnxCczadBCHhqt6RwHw0S19UShJ0kIIIeokibohbP0OFj0P3a+DHhOrN2uteeKHbSzfnYv3nO0kHSoksXUw8eF+APh4yOEXQghxYpIp6uvAOphxJ8QOgCteA6XYkl7AL9szCfPzYPnuXDpF+PPj5kMA3HF1fCMHLIQQ4nwiibq+Fv0DvALgui/A3QuHQ/PQt5vZfqgQgLbhvky/YwAjX/6NovIqLu8e2cgBCyGEOJ9Ioq6PnBRIngtDHzHLgQLzkjLZfqiQxy/vjEUpLogPJdDbnbcn9yGvpBI/TznkQgghTp1kjfpY9R8cFg9u2tyVKS0z6RkTxGu/JhMX5stNA9scM0msT+vgRgxUCCHE+UoS9ZlK+gE2fMZK32EsPmhh8cdrUQq0htcn9pKZ3EIIIRqEJOoz8eszsOQlHBE9efTAFVzXN4aOEf4UlVcxvFMLEqICGztCIYQQvxOSqE9XTjIsfQW6XcuCjk+y77NNPNO9FYPby4piQgghGl69+meVUqOUUjuVUilKqYdref0VpdRG588updTh+uyvSZj/FLh7w6XPMXd7Lv5ebvSPC23sqIQQQvxOnXGLWillBd4CRgLpwBql1EytddKRMlrr+13K3w30qkesjS91Jez4kYohj/DDjnLmJWUyvFMLPNxkPFoIIcTZUZ8M0w9I0Vrv0VpXAl8B405QfiLwZT3217i0hnn/B34R/Dl1EA99sxkvdwu3DIpr7MiEEEL8jtVnjDoKSHN5ng70r62gUqo1EAcsqMf+Gtf2WZC+mvLLXuWXmcVMGdCap8Z2lVtSCiGEOKvOVZ/tdcA3Wmt7XQWUUlOVUmuVUmuzs7PPUVinqKrCjE2Hd2KR1wgq7Q5Gd2slSVoIIcRZV59EfQCIcXke7dxWm+s4Sbe31vodrXWi1joxPLyJzaBe+irk7YZL/868nbkEervLAiZCCCHOifok6jVAe6VUnFLKA5OMZ9YspJTqBAQDK+qxr8aTkwJLXoKEq7HHX8yindkM6xguC5oIIYQ4J84422itq4C7gLnAduBrrfU2pdTTSqmxLkWvA77SWuv6hdoItIbZ94ObN1z6PL8kZZBXUsnFnVs2dmRCCCGaiXoteKK1ngPMqbHtiRrPn6rPPhrV5umwdzFc/jKz9zq4b/oGOkX4c3HnFo0dmRBCiGZC+m/rUpYPcx+F6L4kRV7NfdM30CM6iOlTB+DjIQu6CSGEODck49Rl7YdQmovt+u944JstBPl48O6NiQT6uDd2ZEIIIZoRaVHXxm6D1e9C/FDeS/Fn+6FCnruyG8G+Ho0dmRBCiGZGEnVtkn6AooPo/tOYviaVgW1DGdlFJpAJIYQ49yRR12b1uxDSlq0+/dmXW8rYHpGNHZEQQohmShJ1TaV5kLYKul/Lj1sycLMoRiVENHZUQgghmilJ1DXtWQRoHPHD+XHzIYZ0CCfIR8amhRBCNA5J1DXtXgBegWywx3HgcBljurdq7IiEEEI0Y5KoXWkNuxdC3EXM3Z6Du1UxQiaRCSGEaESSqF3lJENhOrrtcOZuy2BA2zACvOS6aSGEEI1HErWr3b8CsCegL/tzSxnVVSaRCSGEaFySqF0l/QAtujIr1QOlkGunhRBCNDpJ1EcUHoTUFTi6jOfHzYfoExtMuL9nY0clhBCimZNEfUTSDwD85j6IlKxibhjQupEDEkIIISRRH7VtBrplAs+utNGhpR9justqZEIIIRqfJGqAkhxIW8X24OHszi7h/hEdsFpUY0clhBBCSKIGzGVZwP8OhdE23JdLZba3EEKIJkISNUD+XgAWZvkyqX9rLNKaFkII0UTUK1ErpUYppXYqpVKUUg/XUeZapVSSUmqbUuqL+uzvrMnbiwMLuW4tubp3dGNHI4QQQlRzO9M3KqWswFvASCAdWKOUmqm1TnIp0x54BBiktc5XSrWob8BnQ1XuHjJ0KKO6xxLoIyuRCSGEaDrq06LuB6RorfdorSuBr4BxNcrcDryltc4H0Fpn1WN/Z015Zgr7HC3kdpZCCCGanPok6iggzeV5unObqw5AB6XUMqXUSqXUqHrs76xxK9hPqm5J18jAxg5FCCGEOMYZd32fRv3tgaFANLBYKdVNa324ZkGl1FRgKkBsbOxZDstFeSFetnyy3SNpGSArkQkhhGha6tOiPgDEuDyPdm5zlQ7M1FrbtNZ7gV2YxH0crfU7WutErXVieHh4PcI6Tc4Z3wTHoZTM9hZCCNG01CdRrwHaK6XilFIewHXAzBplvse0plFKhWG6wvfUY58NrirHhOPbqtbzByGEEKJRnXGi1lpXAXcBc4HtwNda621KqaeVUmOdxeYCuUqpJGAh8BetdW59g25I+ek7AYho3bmRIxFCCCGOV68xaq31HGBOjW1PuDzWwJ+dP01ScUYySgfQoXWrxg5FCCGEOE6zX5lM5e0hjZbEh/k2dihCCCHEcZp3otaa0JJksrzicbM270MhhBCiaWre2anoEP6OIkqCOjV2JEIIIUStmnWiLk/fBICOSGjkSIQQQojaNetEXbB3PQB+MT0aORIhhBCids06UVcd2kq6DiM2SmZ8CyGEaJqadaL2yt3Odkdr2oTKjG8hhBBNU/NN1LYygsv2c8AjHm8Pa2NHI4QQQtSq+Sbq7B1YcFAQ2LGxIxFCCCHq1GwTtc7Yah607NK4gQghhBAncLZvc9lklR3YilW7ExglLWohhBBNV7NN1JWHkjigI4lrEdjYoQghhBB1arZd3+55O9mlo2kbLjO+hRBCNF3NM1GXF+BbnkmqtTVRQd6NHY0QQghRp+aZqLN3AWAL6YBSqpGDEUIIIerWLBN1VWYSAD7Rssa3EEKIpq1ZJuqC/Zsp0x5Exclds4QQQjRtzTJR2zKSSNGRdI0KbuxQhBBCiBNqlona53Aye1QMcWEy41sIIUTTVq9ErZQapZTaqZRKUUo9XMvrNymlspVSG50/t9Vnfw3CVkaALZsSvzisFplIJoQQomk74wVPlFJW4C1gJJAOrFFKzdRaJ9UoOl1rfVc9YmxQuvAgCvAKjWnsUIQQQoiTqk+Luh+QorXeo7WuBL4CxjVMWGdPSU4qAF6h0Y0ciRBCCHFy9UnUUUCay/N057aarlZKbVZKfaOUavRmbGlOOgBuQZKohRBCNH1nezLZLKCN1ro78AvwcV0FlVJTlVJrlVJrs7Ozz1pAlXnm3MInrNHPGYQQQoiTqk+iPgC4Zrto57ZqWutcrXWF8+l7QJ+6KtNav6O1TtRaJ4aHh9cjrBOrKjhIkfYmKCjkrO1DCCGEaCj1SdRrgPZKqTillAdwHTDTtYBSqpXL07HA9nrsr0FYig6RoUMI9fNo7FCEEEKIkzrjWd9a6yql1F3AXMAKfKC13qaUehpYq7WeCdyjlBoLVAF5wE0NEHO9eJRmsF8H089XErUQQoimr173o9ZazwHm1Nj2hMvjR4BH6rOPhuZdnkWetTOebtbGDkUIIYQ4qea1MpnDjp8th0L3Fo0diRBCCHFKmleiLs7CioMyL0nUQgghzg/NK1EXHQSg0ieikQMRQgghTk3zStSFJlFr/1YnKSiEEEI0Dc0qUTsKTKK2Bta2gJoQQgjR9NRr1vf5piI/Hau24hXUsrFDEUIIIU5Js0rUtvwD5BJMqL9XY4cihBBCnJLm1fVdlEm2DiLMz7OxQxFCCCFOSbNK1NaSTLJ0ECGyKpkQQojzRLNK1O5lOWTrQFnnWwghxHmj+SRquw0vWz7ZOogQH0nUQgghzg/NJ1EXZ5l/PEJxszafjy2EEOL81nwyVnEmABVeYY0ciBBCCHHqmlGiNi1qu49cQy2EEOL80YwSdQYAyk8StRBCiPNHM0rUpkXtHih3zhJCCHH+aDYrkzmKMijQfgT6+zd2KEIIIcQpazYtatvhQ2TpIMLkGmohhBDnkXolaqXUKKXUTqVUilLq4ROUu1oppZVSifXZX33YizLNYie+snyoEEKI88cZJ2qllBV4C7gM6AJMVEp1qaWcP3AvsOpM99UQLCVZZCPLhwohhDi/1KdF3Q9I0Vrv0VpXAl8B42op9wzwD6C8HvuqH61xL82Srm8hhBDnnfok6iggzeV5unNbNaVUbyBGaz27Hvupv4pCrI4KsnUQoXLnLCGEEOeRszaZTCllAV4GHjjF8lOVUmuVUmuzs7MbNpgisypZDkEEebs3bN1CCCHEWVSfRH0AiHF5Hu3cdoQ/kAAsUkrtAy4AZtY1oUxr/Y7WOlFrnRgeHl6PsGpRYq6hrvAMxWJRDVu3EEIIcRbVJ1GvAdorpeKUUh7AdcDMIy9qrQu01mFa6zZa6zbASmCs1nptvSI+E+WFAFh8gs/5roUQQoj6OONErbWuAu4C5gLbga+11tuUUk8rpcY2VIANoqIIAA+fwEYORAghhDg99VqZTGs9B5hTY9sTdZQdWp991UuFaVF7+UmiFkIIcX5pHiuTOVvUvgEhjRyIEEIIcXqaxVrf9rJCHNpKgJ9fY4cihBBCnJZmkagrSguowJtQf7mGWgghxPmlWXR9V5YUUIIXobJ8qBBCiPNMs2hR28sKKdLeBPtIohZCnBs2m4309HTKyxtv9WTR9Hh5eREdHY27+6kvvtUsErWuKKIYbwJkVTIhxDmSnp6Ov78/bdq0QSlZaEmA1prc3FzS09OJi4s75fc1i65vVVlMsfbG36tZnJcIIZqA8vJyQkNDJUmLakopQkNDT7uXpVkkaqutmGK88feSFrUQ4tyRJC1qOpO/iWaRqN1sxRRpb/w8pUUthGgecnNz6dmzJz179iQiIoKoqKjq55WVlSd879q1a7nnnntOuo+BAwc2VLgA3HfffURFReFwOBq03vNds8hcHvYSKq0+WOWGHEKIZiI0NJSNGzcC8NRTT+Hn58eDDz5Y/XpVVRVubrWngMTERBITa71/0jGWL1/eMMECDoeDGTNmEBMTw2+//cawYcMarG5XJ/rcTdXvv0XtsOPhKMPmJoudCCGat5tuuok777yT/v3789BDD7F69WoGDBhAr169GDhwIDt37gRg0aJFjBkzBjBJ/pZbbmHo0KHEx8fz+uuvV9fn51xEatGiRQwdOpQJEybQqVMnJk2ahNYagDlz5tCpUyf69OnDPffcU11vTYsWLaJr165MmzaNL7/8snp7ZmYmV155JT169KBHjx7VJweffPIJ3bt3p0ePHtxwww3Vn++bb76pNb7BgwczduxYunTpAsD48ePp06cPXbt25Z133ql+z88//0zv3r3p0aMHF198MQ6Hg/bt23Pk9ssOh4N27drR4LdjPoHz67TiTFQWA1AliVoI0Uj+NmsbSQcLG7TOLpEBPHlF19N+X3p6OsuXL8dqtVJYWMiSJUtwc3Nj/vz5PProo3z77bfHvWfHjh0sXLiQoqIiOnbsyLRp0467vGjDhg1s27aNyMhIBg0axLJly0hMTOSOO+5g8eLFxMXFMXHixDrj+vLLL5k4cSLjxo3j0UcfxWaz4e7uzj333MNFF13EjBkzsNvtFBcXs23bNp599lmWL19OWFgYeXl5J/3c69evZ+vWrdWzrT/44ANCQkIoKyujb9++XH311TgcDm6//fbqePPy8rBYLEyePJnPP/+c++67j/nz59OjRw8a/HbMJ/D7b1E71/m2e0iiFkKIa665BqvVCkBBQQHXXHMNCQkJ3H///Wzbtq3W91x++eV4enoSFhZGixYtyMzMPK5Mv379iI6OxmKx0LPn/7N333FWVOfjxz/P9l5g6R2lC0tZwIICxoKSgF2wgcTG15KYYklUjMboLzHRGFuwRqOgsRCMIBZUVEQp0otSVlk6u+yyvT6/P87seoHtXPZued6v133tvTNnZp6ZvbvPnDNn5gwmNTWVjRs30rNnz4rkWFWiLioqYt68eZx33nnExcUxcuRIFixYAMDChQuZPn06AMHBwcTHx7Nw4UIuvvhikpKSAGjVquZxHEaMGHHILVGPPfYYycnJnHjiiWzfvp3vvvuOJUuWcNppp1WUK1/vtGnTeOmllwCX4K+++uoat+dPzb9G7SVqDY8NcCDGmJaqPjXfYyU6Orri/d13383YsWN5++23SU1NZcyYMZUuEx7+4+OXg4ODKSkpqVeZqixYsIDMzEwGDhwIQF5eHpGRkVU2k1clJCSkoiNaWVnZIZ3mfPf7k08+4cMPP+TLL78kKiqKMWPGVHvLVJcuXWjXrh0LFy7k66+/5pVXXqlTXEerxdSogyxRG2PMIbKysujUqRMAL774E261jwAAIABJREFUot/X36dPH7Zu3UpqaioAr732WqXlZs2axbPPPktqaiqpqals27aNDz74gLy8PH7yk5/w1FNPAVBaWkpWVhann346//nPf0hPTweoaPru3r07y5cvB2Du3LkUFxdXur2srCwSExOJiopi48aNLFmyBIATTzyRRYsWsW3btkPWC3DNNddwxRVXHNIi0VBaQKJ214WCIixRG2OMr9tuu40777yTIUOG1KkGXFuRkZE8+eSTjBs3jmHDhhEbG0t8fPwhZfLy8njvvfcYP358xbTo6GhGjRrFO++8w9///nc+/vhjBg4cyLBhw1i/fj0DBgzg97//PaNHjyY5OZlf/epXAFx77bV8+umnJCcn8+WXXx5Si/Y1btw4SkpK6NevH3fccQcnnngiAG3atGHmzJlccMEFJCcnc+mll1YsM2HCBHJychq82RtAynvmNSYpKSm6bNky/6xs3Rz4zxSeOeEVrr2obs0oxhhTXxs2bKBfv36BDiPgcnJyiImJQVW58cYb6dWrF7feemugw6qzZcuWceutt/LZZ58d9boq+26IyHJVrfSeuGZfoy4pcDXq4Mj4GkoaY4zxt2eeeYbBgwczYMAAsrKyuP766wMdUp099NBDXHjhhTz44IMB2X6z70xWlJNJCBAeHRfoUIwxpsW59dZbm2QN2tcdd9zBHXfcEbDtH1WNWkTGicgmEdksIkfshYjcICJrRGSliHwuIv2PZnv1UZTnatQR0VajNsYY0/TUO1GLSDDwBHAO0B+YXEkiflVVB6rqYODPwN/qHWk9leRlkafhxERFNPSmjTHGmKN2NDXqEcBmVd2qqkXAbGCibwFV9X0UTzTQ4D3XSgvcWNSxNiCHMcaYJuhoslcnYLvP5zRg5OGFRORG4FdAGHB6VSsTkeuA6wC6du16FGEdSgsOemNR2xCXxhhjmp5j3utbVZ9Q1eOA24G7qik3U1VTVDXFr89QLfRq1BFWozbGtBxjx46teAxnuUcffbTicZyVGTNmDOW3xp577rlkZmYeUebee+/l4Ycfrnbbc+bMYf369RWf77nnHj788MO6hF+tljYc5tEk6h1AF5/Pnb1pVZkNnHcU26sXKcomVyMsURtjWpTJkycze/bsQ6bNnj272oExfM2bN4+EhIR6bfvwRH3fffdxxhln1Gtdhzt8OMxj5Vg8AKa+jiZRLwV6iUgPEQkDJgFzfQuISC+fj+OB745ie/USVJxLDpHEWKI2xrQgF110Ee+++27F865TU1PZuXMnp556KtOnTyclJYUBAwYwY8aMSpfv3r07+/fvB+CBBx6gd+/ejBo1qmIoTHD3SA8fPpzk5GQuvPBC8vLyWLx4MXPnzuW3v/0tgwcPZsuWLYcMP/nRRx8xZMgQBg4cyLRp0ygsLKzY3owZMxg6dCgDBw5k48aNlcbVEofDrHf2UtUSEbkJWAAEA8+r6joRuQ9YpqpzgZtE5AygGDgATDnqiOsopCSHPGlHeEjDPpvVGGMqzL8Ddq/x7zrbD4RzHqpydqtWrRgxYgTz589n4sSJzJ49m0suuQQR4YEHHqBVq1aUlpbyk5/8hNWrVzNo0KBK17N8+XJmz57NypUrKSkpYejQoQwbNgyACy64gGuvvRaAu+66i+eee46bb76ZCRMm8NOf/pSLLrrokHUVFBQwdepUPvroI3r37s1VV13FU089xS9/+UsAkpKSWLFiBU8++SQPP/wwzz777BHxtMThMI/qGrWqzlPV3qp6nKo+4E27x0vSqOovVHWAqg5W1bGqWvkYasfQN/FnsixkSENv1hhjAs63+du32fv1119n6NChDBkyhHXr1h3STH24zz77jPPPP5+oqCji4uKYMGFCxby1a9dy6qmnMnDgQF555ZUqh8kst2nTJnr06EHv3r0BmDJlCosWLaqYf8EFFwAwbNiwioE8fLXU4TCbfXvw24lXszYvK9BhGGNasmpqvsfSxIkTufXWW1mxYgV5eXkMGzaMbdu28fDDD7N06VISExOZOnVqtUM8Vmfq1KnMmTOH5ORkXnzxRT755JOjird8qMyqhslsqcNhNvtnfWcXFFtHMmNMixQTE8PYsWOZNm1aRW364MGDREdHEx8fz549e5g/f3616zjttNOYM2cO+fn5ZGdn884771TMy87OpkOHDhQXFx+SlGJjY8nOzj5iXX369CE1NZXNmzcD8PLLLzN69Oha709LHQ6z2SfqnIISYuxhJ8aYFmry5MmsWrWqIlEnJyczZMgQ+vbty2WXXcYpp5xS7fJDhw7l0ksvJTk5mXPOOYfhw4dXzLv//vsZOXIkp5xyCn379q2YPmnSJP7yl78wZMgQtmzZUjE9IiKCF154gYsvvpiBAwcSFBTEDTfcUKv9aMnDYTb7YS7PfmQR3ZOi+OeVlY4eZowxx4QNc9ky1WY4zLoOc9nsq5qu6dueSmaMMebYeuihh3jqqaf8dm26XLNP1DMmDCApJjzQYRhjjGnmjtVwmM0+UZ89oH2gQzDGGGPqrdl3JjPGmEBpjH2ATGDV5zthidoYY46BiIgI0tPTLVmbCqpKeno6ERERdVqu2Td9G2NMIHTu3Jm0tDS/POvZNB8RERF07ty5TstYojbGmGMgNDT0kEdRGlNf1vRtjDHGNGKWqI0xxphGzBK1McYY04g1ykeIisg+4Hs/rjIJ2O/H9bVEdgz9w47j0bNj6B92HI+eP49hN1WtdPDqRpmo/U1EllX1DFVTO3YM/cOO49GzY+gfdhyPXkMdQ2v6NsYYYxoxS9TGGGNMI9ZSEvXMQAfQDNgx9A87jkfPjqF/2HE8eg1yDFvENWpjjDGmqWopNWpjjDGmSWrWiVpExonIJhHZLCL+HyS0GRORVBFZIyIrRWSZN62ViHwgIt95PxMDHWdjIyLPi8heEVnrM63S4ybOY973c7WIDA1c5I1HFcfwXhHZ4X0fV4rIuT7z7vSO4SYROTswUTcuItJFRD4WkfUisk5EfuFNt+9iHVRzHBv0+9hsE7WIBANPAOcA/YHJItI/sFE1OWNVdbDP7Qd3AB+pai/gI++zOdSLwLjDplV13M4Benmv64CnGijGxu5FjjyGAI9438fBqjoPwPubngQM8JZ50vvbb+lKgF+ran/gROBG71jZd7FuqjqO0IDfx2abqIERwGZV3aqqRcBsYGKAY2rqJgL/8t7/CzgvgLE0Sqq6CMg4bHJVx20i8JI6S4AEEenQMJE2XlUcw6pMBGaraqGqbgM24/72WzRV3aWqK7z32cAGoBP2XayTao5jVY7J97E5J+pOwHafz2lUf4DNoRR4X0SWi8h13rR2qrrLe78baBeY0Jqcqo6bfUfr5iavWfZ5n8sudgxrICLdgSHAV9h3sd4OO47QgN/H5pyozdEZpapDcU1iN4rIab4z1d0uYLcM1JEdt3p7CjgOGAzsAv4a2HCaBhGJAd4EfqmqB33n2Xex9io5jg36fWzOiXoH0MXnc2dvmqkFVd3h/dwLvI1rvtlT3hzm/dwbuAiblKqOm31Ha0lV96hqqaqWAc/wY3OiHcMqiEgoLrm8oqpveZPtu1hHlR3Hhv4+NudEvRToJSI9RCQMd4F/boBjahJEJFpEYsvfA2cBa3HHb4pXbArw38BE2ORUddzmAld5PW5PBLJ8miWNj8Oul56P+z6CO4aTRCRcRHrgOkN93dDxNTYiIsBzwAZV/ZvPLPsu1kFVx7Ghv48hR7uCxkpVS0TkJmABEAw8r6rrAhxWU9EOeNt9RwkBXlXV90RkKfC6iPwcN7rZJQGMsVESkVnAGCBJRNKAGcBDVH7c5gHn4jqc5AFXN3jAjVAVx3CMiAzGNdWmAtcDqOo6EXkdWI/roXujqpYGIu5G5hTgSmCNiKz0pv0O+y7WVVXHcXJDfh/tyWTGGGNMI9acm76NMcaYJs8StTHGGNOIWaI2xhhjGjFL1MYYY0wjZonaGGOMacQsURtjjDGNmCVqY4wxphGzRG2MR0Tmi8iUmkvWrWwgiRtX/IxjsN5PROQa7/3lIvJ+bcrWYztdRSTHhq40LZklatOkef/Ey19lIpLv8/nyuqxLVc9R1X/VXLJuZRsjEblDRBZVMj1JRIpE5ITarktVX1HVs/wU1yEnFqr6g6rGHIunjYmIisjx/l6vMf5mido0ad4/8RhVjQF+AH7mM+2V8nIi0mwfl1tP/wZO9p5H7GsSsEZV11ayjDEmACxRm2ZJRMaISJqI3C4iu4EXRCRRRP4nIvtE5ID3vrPPMr7NuVNF5HMRedgru01Ezqln2R4iskhEskXkQxF5QkT+XUXctYnxfhH5wlvf+yKS5DP/ShH5XkTSReT3VR0fVU0DFuKeY+zrKuClmuI4LOapIvK5z+czRWSjiGSJyOOA+Mw7TkQWevHtF5FXRCTBm/cy0BV4x2sRuU1Euns13xCvTEcRmSsiGSKyWUSu9Vn3vSLyuoi85B2bdSKSUtUxqIqIxHvr2Ocdy7tEJMibd7yIfOrt234Rec2bLiLyiIjsFZGDIrKmLq0SxlTHErVpztoDrYBuwHW47/sL3ueuQD7weDXLjwQ2AUnAn4HnRETqUfZV3Ag6rYF7OTI5+qpNjJfhBk1oC4QBvwEQkf64cXKvBDp626s0uXr+5RuLiPTBja/7ai3jOIJ30vAWcBfuWGzBDWxQUQR40IuvH25IwHsBVPVKDm0V+XMlm5gNpHnLXwT8SURO95k/wSuTgBvJqMaYK/EPIB7oCYzGnbyUD1JxP/A+kIg7tv/wpp8FnAb09pa9BEivx7aNOYIlatOclQEzVLVQVfNVNV1V31TVPFXNBh7A/SOuyveq+ox3ffRfQAfcyGK1LisiXYHhwD2qWqSqn1PNcKu1jPEFVf1WVfOB13HJFVzi+p+qLlLVQuBu7xhU5W0vxpO9z1cB81V1Xz2OVblzgXWq+oaqFgOPArt99m+zqn7g/U72AX+r5XoRkS64pH+7qhao6krgWS/ucp+r6jzv9/AykFybdftsIxjX/H+nqmarairwV348oSnGnbx09GL43Gd6LNAXN9jRBhsm0viLJWrTnO1T1YLyDyISJSL/9JozDwKLgASpukexb4LJ897G1LFsRyDDZxrA9qoCrmWMu33e5/nE1NF33aqaSzW1Oi+m/+CNQwxcDrxUhzgqc3gM6vtZRNqJyGwR2eGt99+4mndtlB/LbJ9p3wOdfD4ffmwipG79E5KAUG+9lW3jNlyrwNde0/o0AFVdiKu9PwHsFZGZIhJXh+0aUyVL1KY5O3wM118DfYCRqhqHa6oEn2uox8AuoJWIRPlM61JN+aOJcZfvur1ttq5hmX/hmmnPxNUI3znKOA6PQTh0f/+E+70M9NZ7xWHrrG7c3Z24YxnrM60rsKOGmOpiPz/Wmo/YhqruVtVrVbUjbgziJ8XrOa6qj6nqMKA/rgn8t36My7RglqhNSxKLu9aaKSKtgBnHeoOq+j2wDLhXRMJE5CTgZ8coxjeAn4rIKBEJA+6j5r/xz4BMYCYwW1WLjjKOd4EBInKBV5O9BddXoFwskANkiUgnjkxme3DXho+gqtuBxcCDIhIhIoOAn+Nq5fUV5q0rQkQivGmvAw+ISKyIdAN+Vb4NEbnYp1PdAdyJRZmIDBeRkSISCuQCBVR/2cGYWrNEbVqSR4FIXK1pCfBeA233cuAkXDP0H4HXgMIqytY7RlVdB9yI6wy2C5dI0mpYRnHN3d28n0cVh6ruBy4GHsLtby/gC58ifwCGAlm4pP7WYat4ELhLRDJF5DeVbGIy0B1Xu34b1wfhw9rEVoV1uBOS8tfVwM24ZLsV+Bx3PJ/3yg8HvhKRHFxfg1+o6lYgDngGd8y/x+37X44iLmMqiPs7NcY0FO+Wno2qesxr9MaYps9q1MYcY16z6HEiEiQi44CJwJxAx2WMaRrsaU3GHHvtcU28rXFN0dNV9ZvAhmSMaSqs6dsYY4xpxKzp2xhjjGnELFEbY4wxjVijvEadlJSk3bt3D3QYxhhjTINYvnz5flVtU9m8Rpmou3fvzrJlywIdhjHGGNMgROT7quZZ07cxxhjTiFmiNsYYYxqxGhO1iHQRkY9FZL03WswvKilzuYis9gZLXywiyT7zUr3pK0XE2rONMcaYOqjNNeoS4NequsIbtWa5iHygqut9ymwDRqvqARE5B/eA/5E+88d6zwA2xhjjB8XFxaSlpVFQUFBzYdNoRERE0LlzZ0JDQ2u9TI2J2hv8fJf3PltENuDGZl3vU2axzyJLgM4YY4w5ZtLS0oiNjaV79+640URNY6eqpKenk5aWRo8ePWq9XJ2uUYtId2AI8FU1xX4OzPeNDXhfRJaLyHV12Z4xxpjKFRQU0Lp1a0vSTYiI0Lp16zq3gtT69iwRiQHeBH6pqgerKDMWl6hH+Uwepao7RKQt8IGIbFTVRZUsex1wHUDXrl3rsAvVu3fuOvq0j2XyCP+t0xhjGgNL0k1PfX5ntapRe4Ohvwm8oqqHjx9bXmYQ8CwwUVXTy6er6g7v517c+LEjKlteVWeqaoqqprRpU+k93/Xy4YY9LN2W4bf1GWOMgfT0dAYPHszgwYNp3749nTp1qvhcVFRU7bLLli3jlltuqXEbJ598sl9i/eSTT/jpT3/ql3UFQo01anHp/zlgg6r+rYoyXXGjA12pqt/6TI8Ggrxr29HAWcB9fom8lqLDQsgtKmnITRpjTLPXunVrVq5cCcC9995LTEwMv/nNbyrml5SUEBJSeYpJSUkhJSWlxm0sXry4xjItQW1q1KcAVwKne7dYrRSRc0XkBhG5wStzD24IvycPuw2rHfC5iKwCvgbeVdX3/L0T1YkKDyavqLQhN2mMMS3S1KlTueGGGxg5ciS33XYbX3/9NSeddBJDhgzh5JNPZtOmTcChNdx7772XadOmMWbMGHr27Mljjz1Wsb6YmJiK8mPGjOGiiy6ib9++XH755ZSP/Dhv3jz69u3LsGHDuOWWW+pUc541axYDBw7khBNO4PbbbwegtLSUqVOncsIJJzBw4EAeeeQRAB577DH69+/PoEGDmDRp0tEfrDqoTa/vz4FqG9VV9RrgmkqmbwWSj1yi4USFWaI2xpiGkpaWxuLFiwkODubgwYN89tlnhISE8OGHH/K73/2ON99884hlNm7cyMcff0x2djZ9+vRh+vTpR9y+9M0337Bu3To6duzIKaecwhdffEFKSgrXX389ixYtokePHkyePLnWce7cuZPbb7+d5cuXk5iYyFlnncWcOXPo0qULO3bsYO3atQBkZmYC8NBDD7Ft2zbCw8MrpjWURvmsb3+KCgshPScv0GEYY8wx84d31rF+Z6V9fOutf8c4ZvxsQJ2Xu/jiiwkODgYgKyuLKVOm8N133yEiFBcXV7rM+PHjCQ8PJzw8nLZt27Jnzx46dz70Lt8RI0ZUTBs8eDCpqanExMTQs2fPiludJk+ezMyZM2sV59KlSxkzZgzlfaIuv/xyFi1axN13383WrVu5+eabGT9+PGeddRYAgwYN4vLLL+e8887jvPPOq/NxORrN/hGi0VajNsaYBhMdHV3x/u6772bs2LGsXbuWd955p8rbksLDwyveBwcHU1JyZL+i2pTxh8TERFatWsWYMWN4+umnueYa11j87rvvcuONN7JixQqGDx9+zLZfmWZfo44MC7FEbYxp1upT820IWVlZdOrUCYAXX3zR7+vv06cPW7duJTU1le7du/Paa6/VetkRI0Zwyy23sH//fhITE5k1axY333wz+/fvJywsjAsvvJA+ffpwxRVXUFZWxvbt2xk7diyjRo1i9uzZ5OTkkJCQ4Pd9qkyzT9SuRm29vo0xpqHddtttTJkyhT/+8Y+MHz/e7+uPjIzkySefZNy4cURHRzN8+PAqy3700UeHNKf/5z//4aGHHmLs2LGoKuPHj2fixImsWrWKq6++mrKyMgAefPBBSktLueKKK8jKykJVueWWWxosSQNIec+5xiQlJUX9NR713z74lsc++o6tfzqXoCB7OIAxpnnYsGED/fr1C3QYAZeTk0NMTAyqyo033kivXr249dZbAx1WtSr73YnIclWt9J61Zn+NOirMdWooKLHmb2OMaW6eeeYZBg8ezIABA8jKyuL6668PdEh+1yKavgFyC0uJCmv2u2uMMS3Krbfe2uhr0EerBdSoXXK269TGGGOaohaQqH+sURtjjDFNTfNP1OGuRp1fbDVqY4wxTU+zT9TRVqM2xhjThDX7RB3pJWq7Rm2MMf4zduxYFixYcMi0Rx99lOnTp1e5zJgxYyi/9fbcc8+t9JnZ9957Lw8//HC1254zZw7r16+v+HzPPffw4Ycf1iX8SjXW4TCbfaKOruhMZjVqY4zxl8mTJzN79uxDps2ePbvWA2PMmzev3g8NOTxR33fffZxxxhn1WldT0OwTdavNb3By0FpyLVEbY4zfXHTRRbz77rsUFRUBkJqays6dOzn11FOZPn06KSkpDBgwgBkzZlS6fPfu3dm/fz8ADzzwAL1792bUqFEVQ2GCu0d6+PDhJCcnc+GFF5KXl8fixYuZO3cuv/3tbxk8eDBbtmxh6tSpvPHGG4B7AtmQIUMYOHAg06ZNo7CwsGJ7M2bMYOjQoQwcOJCNGzfWel8DPRxmjYlaRLqIyMcisl5E1onILyopIyLymIhsFpHVIjLUZ94UEfnOe03xS9R1ELP4z1wQ/Dl5hdb0bYwx/tKqVStGjBjB/PnzAVebvuSSSxARHnjgAZYtW8bq1av59NNPWb16dZXrWb58ObNnz2blypXMmzePpUuXVsy74IILWLp0KatWraJfv34899xznHzyyUyYMIG//OUvrFy5kuOOO66ifEFBAVOnTuW1115jzZo1lJSU8NRTT1XMT0pKYsWKFUyfPr3G5vVy5cNhLly4kJUrV7J06VLmzJnDypUrK4bDXLNmDVdffTXghsP85ptvWL16NU8//XSdjmlVavMEkBLg16q6QkRigeUi8oGqrvcpcw7Qy3uNBJ4CRopIK2AGkAKot+xcVT3gl+hrQcJjiSaf7VajNsY0V/PvgN1r/LvO9gPhnIeqLVLe/D1x4kRmz57Nc889B8Drr7/OzJkzKSkpYdeuXaxfv55BgwZVuo7PPvuM888/n6ioKAAmTJhQMW/t2rXcddddZGZmkpOTw9lnn11tPJs2baJHjx707t0bgClTpvDEE0/wy1/+EnCJH2DYsGG89dZbtTgIjWM4zBpr1Kq6S1VXeO+zgQ1Ap8OKTQReUmcJkCAiHYCzgQ9UNcNLzh8A4/wSeS1JeCxxQYXWmcwYY/xs4sSJfPTRR6xYsYK8vDyGDRvGtm3bePjhh/noo49YvXo148ePr3J4y5pMnTqVxx9/nDVr1jBjxox6r6dc+VCZ/hgmsyGHw6zTMzVFpDswBPjqsFmdgO0+n9O8aVVNr2zd1wHXAXTt2rUuYVUvPIY4OWDXqI0xzVcNNd9jJSYmhrFjxzJt2rSKTmQHDx4kOjqa+Ph49uzZw/z58xkzZkyV6zjttNOYOnUqd955JyUlJbzzzjsVz+vOzs6mQ4cOFBcX88orr1QMmRkbG0t2dvYR6+rTpw+pqals3ryZ448/npdffpnRo0cf1T42huEwa52oRSQGeBP4paoePKqtVkJVZwIzwY2e5bcVh8UQIwXkW6I2xhi/mzx5Mueff35FD/Dk5GSGDBlC37596dKlC6ecckq1yw8dOpRLL72U5ORk2rZte8hQlffffz8jR46kTZs2jBw5siI5T5o0iWuvvZbHHnusohMZQEREBC+88AIXX3wxJSUlDB8+nBtuuKFO+9MYh8Os1TCXIhIK/A9YoKp/q2T+P4FPVHWW93kTMKb8parXV1auKv4c5pI5/8feVQu4q8drzLyq0hHEjDGmybFhLpsuvw9zKSICPAdsqCxJe+YCV3m9v08EslR1F7AAOEtEEkUkETjLm9ZwvM5kdh+1McaYpqg2Td+nAFcCa0RkpTftd0BXAFV9GpgHnAtsBvKAq715GSJyP1De3/4+Vc3wX/i1EBZDpOaTV1jcoJs1xhhj/KHGRK2qnwNSQxkFbqxi3vPA8/WKzh/CYwiijNKivICFYIwxxtRXs38yGeGx7mfRkT0EjTGmKatNHyPTuNTnd9b8E3WYS9RBRbkBDsQYY/wnIiKC9PR0S9ZNiKqSnp5OREREnZar033UTVJ4DABBRTkBDsQYY/ync+fOpKWlsW/fvkCHYuogIiLikNu/aqMFJGpXow4tzaWsTAkKqvZyuzHGNAmhoaH06NEj0GGYBtACmr5djTqafPKL7RYtY4wxTUvzT9RejTqaAnLted/GGGOamOafqL0adazkk1doNWpjjDFNS/NP1BU1ans6mTHGmKan+SfqsGgUIUbyrenbGGNMk9P8E7UIZaHRxFBAZp49RtQYY0zT0vwTNaDhsURTQEZuYaBDMcYYY+qkRSTqoPAYYiSP/TlFgQ7FGGOMqZMWkqhjiQsqJCPXErUxxpimpTbjUT8vIntFZG0V838rIiu911oRKRWRVt68VBFZ481b5u/gay08loTgQtJzrOnbGGNM01KbGvWLwLiqZqrqX1R1sKoOBu4EPj1szOmx3vyUowv1KITHEiv5pFuN2hhjTBNTY6JW1UVARk3lPJOBWUcV0bEQFkMMBaTbNWpjjDFNjN+uUYtIFK7m/abPZAXeF5HlInKdv7ZVZ+GxRJJPuvX6NsYY08T4c/SsnwFfHNbsPUpVd4hIW+ADEdno1dCP4CXy6wC6du3qx7CA8BgiynLJKChEVRGxEbSMMcY0Df7s9T2Jw5q9VXWH93Mv8DYwoqqFVXWmqqaoakqbNm38GBYQFkOwlhJUWsTBAns6mTHGmKbDL4laROKB0cB/faZFi0hs+XvgLKDSnuPHnM8IWnaLljHGmKakxqZvEZkFjAGSRCRJ32igAAAgAElEQVQNmAGEAqjq016x84H3VTXXZ9F2wNteM3MI8Kqqvue/0OvAS9Qxkk96TiE9kqIDEoYxxhhTVzUmalWdXIsyL+Ju4/KdthVIrm9gfuUNdRmD3aJljDGmaWkRTyarqFGTb7doGWOMaVJaRqKOTAQgQXJsYA5jjDFNSstI1NFJAHQMzbWBOYwxxjQpLSNRR7YCoGNYnvX6NsYY06S0jEQdFgWhUbQPybWnkxljjGlSWkaiBohqTVJwjnUmM8YY06S0oETdikSyrenbGGNMk9KCEnVr4vQgWfnFgY7EGGOMqbUWlahjSrMoLCmjoLg00NEYY4wxtdKCEnUSkSVZAFarNsYY02S0oETdmrCSHEIpsURtjDGmyWhBidrdS51AtiVqY4wxTUYLStStAWgt2WTmWaI2xhjTNLS4RJ0oVqM2xhjTdNSYqEXkeRHZKyJrq5g/RkSyRGSl97rHZ944EdkkIptF5A5/Bl5nXqJuZU3fxhhjmpDa1KhfBMbVUOYzVR3sve4DEJFg4AngHKA/MFlE+h9NsEelPFFLNll59tATY4wxTUONiVpVFwEZ9Vj3CGCzqm5V1SJgNjCxHuvxD68zWfvQXKtRG2OMaTL8dY36JBFZJSLzRWSAN60TsN2nTJo3rVIicp2ILBORZfv27fNTWD6CQyEinnYhlqiNMcY0Hf5I1CuAbqqaDPwDmFOflajqTFVNUdWUNm3a+CGsSkS1pk1QDpmWqI0xxjQRR52oVfWgquZ47+cBoSKSBOwAuvgU7exNC5yo1u4atSVqY4wxTcRRJ2oRaS8i4r0f4a0zHVgK9BKRHiISBkwC5h7t9o5KVGvirde3McaYJiSkpgIiMgsYAySJSBowAwgFUNWngYuA6SJSAuQDk1RVgRIRuQlYAAQDz6vqumOyF7UVnUR86TKy7IEnxhhjmogaE7WqTq5h/uPA41XMmwfMq19ox0BcJ+JK0sktykdV8RoCjDHGmEar5TyZDCCuE4LSuiyDvCIb6tIYY0zj17ISdby7O6yDpFvPb2OMMU1CC0vUrhN6R0m369TGGGOahJaVqONcjbqjpFvPb2OMMU1Cy0rU4TGUhsXRQdLJyrfnfRtjjGn8WlaiBkpjO1mN2hhjTJPR4hJ1UEIXS9TGGGOajBaXqIMTOtNRMvghIy/QoRhjjDE1anGJWuI7kSjZrNq6K9ChGGOMMTVqcYm6/Bat3H3fk5FrHcqMMcY0bi0wUf/40JOvt6UHOBhjjDGmei0vUXv3UncLyWDJ1owAB2OMMcZUr4UmamFYfC5fbbNEbYwxpnGrMVGLyPMisldE1lYx/3IRWS0ia0RksYgk+8xL9aavFJFl/gy83kLCIKELJ0TsY+Pug2Tm2XVqY4wxjVdtatQvAuOqmb8NGK2qA4H7gZmHzR+rqoNVNaV+IR4DSb3pXJqGKnzzQ2agozHGGGOqVGOiVtVFQJVtxKq6WFUPeB+XAJ39FNuxk9SbqOxthAQpy78/UHN5Y4wxJkD8fY3658B8n88KvC8iy0XkOj9vq/6SeiHFeZzWrsgStTHGmEYtxF8rEpGxuEQ9ymfyKFXdISJtgQ9EZKNXQ69s+euA6wC6du3qr7Aql9QbgLGtM/nTpihKSssICW55/eqMMcY0fn7JTiIyCHgWmKiqFTcnq+oO7+de4G1gRFXrUNWZqpqiqilt2rTxR1hV8xL14Kh95BeXsnF39rHdnjHGGFNPR52oRaQr8BZwpap+6zM9WkRiy98DZwGV9hxvcNFtICKeHuwAsOZvY4wxjVaNTd8iMgsYAySJSBowAwgFUNWngXuA1sCTIgJQ4vXwbge87U0LAV5V1feOwT7UnQgk9Sb64Fbax0Ww7PsDTDm5e6CjMsYYY45QY6JW1ck1zL8GuKaS6VuB5COXaCSSeiNbFjKkawKrttstWsYYYxqnltuDKqkXZO8ipX0wP2TkccAG6DDGGNMItdxE3aYfACOidgOwekdWIKMxxhhjKtVyE3XHIQD0KnH939akWfO3McaYxqflJurYdhDXiYh9q+mZFM2qNKtRG2OMaXxabqIGV6vesYJBneNZbTVqY4wxjZAl6owtpLQLYs/BQvYcLAh0RMYYY8whLFEDIyJ+AGwkLWOMMY2PJWqgR9F3tIoO4z/Ltgc4IGOMMeZQLTtRR7WCxO6E7v6GKSd156ONe9lkz/02xhjTiLTsRA3QeQR8v5irTuxCZGgwMxdtDXRExhhjTAVL1D3HQN5+EnM2c+nwLvx35Q6y8ooDHZUxxhgDWKKGnqPdz22f8rPkjpSUKZ9+ty+wMRljjDEeS9TxnaF1L9j6CYO7JNAqOoyPN+4NdFTGGGMMYIna6TkGUr8guKyY0b3b8MmmvZSWaaCjMsYYY2qXqEXkeRHZKyJrq5gvIvKYiGwWkdUiMtRn3hQR+c57TfFX4H7VcwwU50LaUsb2bcuBvGJW2tCXxhhjGoHa1qhfBMZVM/8coJf3ug54CkBEWgEzgJHACGCGiCTWN9hjpsepEBQKm+YxulcbgoPEmr+NMcY0CrVK1Kq6CMiopshE4CV1lgAJItIBOBv4QFUzVPUA8AHVJ/zAiIiH406HdXOIjwhmRPdWvLtmF6rW/G2MMSaw/HWNuhPg+1ivNG9aVdOPICLXicgyEVm2b18Ael2fcAEcTIO0pZw/pBPb9ufaiFrGGGMCrtF0JlPVmaqaoqopbdq0afgA+pwLweGw7i3GDWxPeEgQb69Ia/g4jDHGGB/+StQ7gC4+nzt706qa3vhExEGvM2HdHOLCgjijfzveWb2L4tKyQEdmjDGmBfNXop4LXOX1/j4RyFLVXcAC4CwRSfQ6kZ3lTWucBl4EObth26ecP7gTGblFLPrWHn5ijDEmcGp7e9Ys4Eugj4ikicjPReQGEbnBKzIP2ApsBp4B/g9AVTOA+4Gl3us+b1rj1Psc17Fs1WxG92lDYlQob3/TOBsAjDHGtAwhtSmkqpNrmK/AjVXMex54vu6hBUBoBAy4AFa/Ruj4v/Kz5I68tnQ7BwuKiYsIDXR0xhhjWqBG05ms0UieDMV5sP6/nD+kE4UlZby3ZnegozLGGNNCWaI+XJcR7tnfS55icKdYureO4q1vrPe3McaYwLBEfTgRGHsn7FmLrH6NC4d2ZsnWDLbsywl0ZMYYY1ogS9SVGXABdBwKC//IpCFJhAUH8fKX3wc6KmOMMS2QJerKiMBZf4TsnbRZ+xzjB3XgjeVp5BSW2GNFjTHGNChL1FXpfop7WtnnjzJtSCw5hSWc9KePGPSH90k7kBfo6IwxxrQQlqirc8YfoDiPgZuf5qaxx3P2Ce3JLijhf6t3BToyY4wxLYQl6uq06Q0pV8PSZ/nNgBwevjiZQZ3jmb/WbtcyxhjTMCxR1+Qn90BsB5gzHYoLGHdCe1Ztz2RHZn6gIzPGGNMCWKKuSUQ8TPgH7N8En/yJc07oAMB7Vqs2xhjTACxR18bxP4FhU2HxP+iRv46+7WN57rOtLNmaHujIjDHGNHOWqGvrzPshrhPMmc6ffnY8wcHCpJlL+PN7Gykrs1u2jDHGHBuWqGsrIg4mPgHpWxi6+n7e/8VpTB7RhSc/2cKNr64gu6A40BEaY4xphmo7zOU4EdkkIptF5I5K5j8iIiu917cikukzr9Rn3lx/Bt/geo6G0bfDqleJXPMSfzp/IHeN78eCdbv56T8+Z01aVqAjNMYY08zUOMyliAQDTwBnAmnAUhGZq6rry8uo6q0+5W8GhvisIl9VB/sv5AAbfRvsWAb/+xVSWsw1p15PcpcEfjHrGy7+52IeuWQw5wzsEOgojTHGNBO1qVGPADar6lZVLQJmAxOrKT8ZmOWP4BqloGC49N/QdzzMvw0W/pHh3RKZe/Mo+neIY/orK5i3xh6IYowxxj9qk6g7Adt9Pqd5044gIt2AHsBCn8kRIrJMRJaIyHn1jrQxCY2ES16CoVfBor/Agt+RFB3Gq9eeyOAuCdz+5mp7zKgxxhi/8HdnsknAG6pa6jOtm6qmAJcBj4rIcZUtKCLXeQl92b59+/wc1jEQFAw/ewxGToclT8I7txARDI9NGoIqXPbMV/zqtZWs22nXrY0xxtRfbRL1DqCLz+fO3rTKTOKwZm9V3eH93Ap8wqHXr33LzVTVFFVNadOmTS3CagREYNyDcNpvYcVL8J+pdI2Fxy8bQvu4CD5Yv4dfzF5JaZmyZV8OX26x+66NMcbUTW0S9VKgl4j0EJEwXDI+ove2iPQFEoEvfaYliki49z4JOAVYf/iyTZoInH4XnPUAbHgHXhjHmNgdvH7DSTx44UA2783huc+3cuk/lzD5mSXc/7/1FJeWBTpqY4wxTUSNiVpVS4CbgAXABuB1VV0nIveJyASfopOA2XrogM39gGUisgr4GHjIt7d4s3LyTTB5NhxIhZlj4JVLOLdnGH3axfKneRvJLyrhwqGdee7zbcxctDXQ0RpjjGki5NC82jikpKTosmXLAh1G/RRkwdJn4ZP/B7Ht+WrEY1w5L59HLx3MuQM7cPHTizmYX8KCW08LdKTGGGMaCRFZ7vXnOoI9mczfIuLh1F/D1fOgpICRH17I+tFLObdnKADjB3Zg055sNu/NZm92AUtTM8gtLAlw0MYYYxqrGh94YuqpcwpM/xIW/I6QL/4KX/4dBlzAuaP+wB8E/vnpVj7csIcDecUECVw4tDO/PqsP7eMjAh25McaYRsSavhvCnnXwzSvw9UyITuLxoMv5+55BREZEcP95J/DND5m8+tUPhAYLd/20P62jw/h8835+eUZvWkWHBTp6Y4wxx1h1Td+WqBvSzpXw3xthz1r2aAJ5g6fR48z/g5g2/JCexx1vrWaxzy1cFw7tzF8vSQ5gwMYYYxqCJerGpKwMtiyk5It/EJL6CSDQcQgMvoyyQZN4d1M2ocFBfLP9AP/8dCv/vHIY4SFBDOmaSHxkaKCjN8YYcwxYom6s9m5w915veAd2r3Yd0YZcCUOvIi+uJ2c+8hk7MvMB6NchjteuP5G4CEvWxhjT3FiibuxUYfvX8NVTsH4uaCm0Oo49PS/g8+ARhEYn8Ov39jKka2tuG9eHoV0TCQqSQEdtjDHGTyxRNyUHd8Gmd2HdHEj9rGJydmxP/px5OktKehPWthcPXTyMgZ3jAxioMcYYf7FE3VSlb4Gd30BehnuW+J41ABQRwuayTgR3OIHeg0chfcdDYrcjFldVDuaXEB9lzeXGGNOYWaJuDlTdbV571lG4YzWb135N69zvaC8HAMiLbE9U2+Oh64nQ9SQK4o/jzoWZ/HfVTl68egSn9W4iA50YY0wLZIm6GVJVnv1sG4u+XsqJBV/QoWgr57TPIWLfasQbZXSfxrMqqB/ZEse5Jw0ivMMAiG0PUUmQ2B1C7B5tY4xpDCxRN3PpOYWc+cgi4iNDyc8+QLeiLZyelMl5rb8nIWM12VkZtJIcgvAZtUuCoW1/VwNv1QOiWlMWFIpExCHRSS6Zx7aHYGs2N8aYY626RG2PEG0GWseE84cJA7h51jec1LMDD5x/Jj3bxFTMf/mzrfx1/mr6h+4hpuQArTSTi7oXcFL4NoJWvgrFuUAlD36PSIBBl0BkIpQUQJcTofVxUFoEpcUQHAZJvSAkvOF21hhjWhirUTcj2zPy6JwYiciRt259uyebpz/dQru4CNJzCnl9WRpn9GvHP68Yys0vfMz6LdvoFBtKUe4BHj+vK+2CsmHbItgw1yXloBAoKz5yoxIMHZKh+ykQFgsS5Mbobj8QepwGoZGQnwkHd0KrnhBqzzI3xpjDHXXTt4iMA/4OBAPPqupDh82fCvwF2OFNelxVn/XmTQHu8qb/UVX/VdP2LFEfe89+tpU/vruBYd0SWf79Af4wYQDnDGzP6D9/whn92/GPyUNcweJ8l6S1zN3rnbPH1aSDQ6Eo13Vw+34xpC11938fQQDvOxYW457ClpfhpkUkuNp6aASUFEJkgkvmx5/pEn0lJxzGGNMcHVXTt4gEA08AZwJpwFIRmauq6w8r+pqq3nTYsq2AGUAK7r/1cm/ZA/XYD+NHPx/Vgw27snlzRRpj+7ThqpO6ISL8fFQPHv94MxOTO3JG/3Ys3ZHPwo17WbfzIHmFwZzZfwjXjz6O1WmZzP1uJ1NOPpcuZ0S5R6Oirnd6aSH88CVs95J3eCzEtIcfFsPute5WMglyNe3M793JQEi4S+A5u+Gj+yAkAoJCISrRJfjs3RDVyl1TLyuDknyX5CterdyO5e6DNn1duaIcCI1yy1VH1U4KjDGNVm2uUY8ANqvqVgARmQ1MBA5P1JU5G/hAVTO8ZT8AxgGz6heu8RcR4YHzT2BAxzjOG9Kporn8hjHHsei7ffzfKysY1i2RL7emExIk9O0QS15RKX9esIkxfdpy62sr2bIvl399mcofJpzAZSO7/rjy4BA4/gz38pV8ac2B5e6HTfNg/3euyT0/AwqzoctIyN4Fm+ZDSKSrhednQv6BKmryPqKSICzKJe34zq6FoDDHJeeCLNi3yU2Lbe+SfEIXVzaxO8S0dbEEh7kTjIytbpuJ3V0rQ2E2xLRz643t4K7ll5VAUh93HGpSWgJBwXaiYIypUm0SdSdgu8/nNGBkJeUuFJHTgG+BW1V1exXLdqpsIyJyHXAdQNeuXSsrYvwsIjSYaaN6HDItJjyEl6eN5LJnl7A6LZPfnduXy0d2Izo8hP05hYz5yydc9swS0nOLePCCgfx35Q7+NG8DZw9ox9vf7OCN5Wl0iI/gptOPZ1i3GmqynpLSMkKCva5s0Ukw9Kra74SqS5b5Ge59ZCLsXAG7Vrmm9aJc2P+ta1ovzoXM7S7BhsdCWSlEt3HX0gGytrvnr6d+7sqWlVS+TQly66hOWKxL/CUFUJznTgQSe0BEHCAuMWfvhj1rIa4jtB/kTgJCwqHbKW7bB3e6MmFRrkWifD+6n+JiyNkDweE/noQkdHX7n7EN0r9zy7cfCJ2GQXgchEW7ckHB3slBkOtjEBzqWi1y97qTkrhOLqbCg25fQiPdciER3k+7rc+YhlTjNWoRuQgYp6rXeJ+vBEb6NnOLSGsgR1ULReR64FJVPV1EfgNEqOofvXJ3A/mq+nB127Rr1IFXWFJKUUkZsYcNAvL4wu94+P1vObVXEi9NG8GWfTmc9cgihnVLZGnqAQZ0jGNfdiGlZcq8X5xKu7gjO48Vl5Z52yjjpldXsGVfDv+7+dTGNTpYWRlkproafuvjXe3+QKq7lS0y0SX1oBCX8HP2us8Hd7ravpbB9q/cyUN57b+kyC1flEPFJYLIBNcRL30r7NsArXu5k460r91ycR1csi/KdY+WbX2cS6rff+kSbWx71wO/ON+1EJTke8ELxHeB2HbuUkPFdD9p3Qs6D4egIDjwvTvZCI9zJwrxnd32Cw+6/QuNdtsvLnDHpVUPF3P5JZAOg92JQM4eyNoBXUa4yxbll0OCw9yANQBdT4b9m9xwsdFJ7nJHWBQkdHO/hwOp7tJHQRYUHIS8/W69UUnu2IWEu9/V/u8gqTe0P8GVy89wPyPi3DqjWkFRnjvB6jLCLVdaAkXZ7mdUK3f8q6LqTgLr0lJSmONO6qKT6vc7UXUtPTVd5mkIdimpXo6qM5mInATcq6pne5/vBFDVB6soHwxkqGq8iEwGxqjq9d68fwKfqGq1Td+WqBuv/KJSHv/4OyYN70qXVlEA3P7Gal5btp0TOsXxxg0nk3YgnwmPf85xbWIY2jWBgwUl5BaWkNI9kejwEB5esIniUiUhKpRdWQUAXDi0E7eP68vS1AOc2iuJ6PAjG3tU9ZAe7Yd/bjbK/8lXOb/M/SP03XdVl6TyMlwCDI1004sLIPMHd4JQlOteWuqSZlmpe1+ehCISXAI7uNMluPLaf3G+l2zz3YnEjuWwe42bF9vOtQYU50FWmmuxEHE19PwDbpnQSC8edbFIMLTp45J8UfaP+xAc7vo3VKW6loyq5gWFVnK3gk8Hx5qEx7vWhfTvfmxhkWC3f8GhLjGGRLiTg7ISd0zzM9zJCOJOViLiXUtIVGto28+daGSludaO2HYuSX+/2C3Tebg7ESzOc9soznW/j6Te7lbIrDR3yaesxP1+QiJ+/J3k7nMnSwnd3LS4Tu5kL2uHO1ls08/FX+x9D4rzf3yVn/jFtnffpc0fuXUkdHEnfaVFsOVjty89TnX7m7vvxxMacPuWux+2fuL2Na4DZO9x6y6PBXEtQ/kH3MlvZII7kYpKdL/DgoOQscW9T+zhXX5q57a//1v3WOXY9u6EL6G8r0sG7N3ovmPdR7mTxeAwF1dRrlu2dS+3rqAQt/7937rYc/dB9k53bDoOcSdLRbnu76XQO6mOTnItb1Gt3fHOz4R9G6HTULfPfnK0iToE15z9E1yv7qXAZaq6zqdMB1Xd5b0/H7hdVU/0OpMtB4Z6RVcAw8qvWVfFEnXTsje7gEc++Jb/G3N8RfKeu2ond765muAgIT4qlNDgILbuc/drD++eyPFtY9mw6yC3/OR4lqYe4KlPthAZGkx+cSlJMWFcdVJ3xvZpy4COcezIzOemV1fQrXU0f580GBFh895spr24jNP7tuXeCQMCufumLkq8RFxeSz2Y5v3DbuX+af/wpbv8EB7rXTbIdw/mKSuGbZ+5ZNXtFCjIdMmiKNc19RdkQqvj3D/xiHj3Ku9omH/A1bZLi11iTezh/tGmb3bbjGzltleYDXnp7h9/aLRL/BvecZ/b9nMJQ4LdSUxRrjupyEt3J0ORCS5xS5B3J0O0SxAFmS75hIS7hLt3A7Tr72LdvcbFFhQMPUa7dXy7wO1raLSLJzTC7dOe9W4fErq4hBEU4va/pNAl9Lb9vJOAFZCzz13myPzBtSDEd3YnRJk/uGNfcbkk+seTqNIid5mlINOV6TDY9bnI2u5dLiqFnmNcvNu/dokrpq13OSXSnTjsWe/We/wZLvacPW4d5ZdxDu50JzJt+rhlJchtLy/jxztBQiPdnR+qcGCb2+f8A+64J3Z3Jyw5e7zpXhoJCnGJuCDLJd26kCD3+8/bX/fv8hn3wqhb675cVaH44fasc4FHcbdnPa+qD4jIfcAyVZ0rIg8CE4ASIAOYrqobvWWnAb/zVvWAqr5Q0/YsUTcPh9d4t+3PZWdmPicf1/qQ6QXFpVzzr2W0ig5j/KAOvPzl93y+2f3htIoOo7RMyS0soaRM+fukwbSLi2D6v5eTXeCmPXNVCmf2b3fE9ktKy1AgNPiIR7lUbLe0TIkOD2Hb/lz+/uG33HfeCTbmt2mcjrZJuTjftTBU18mxuMCdIEUmVL3thm7aLitzl1kOV+i1xpT3u1B1d5Hkprt9CIt2J2AirsNoVpo7UUjo4jqNhse5E7qQMDdv30Z38hIe405+wmPd+nP3e61V6e7EKDzG63TarXYdRmvJHiFqmpx92YV8vnkfi77dT0ZuEXf/tB+/fWM163cepLCkjG6to3huSgo3z1rJzsx8Urol0rNNNDeN7UV8VCgHcou4dOaXRIeH8Pr1Jx2SrDfuPsg9/13HNz8coGNCJAt/PYYH3t3A819s4/rTenLnuf5rzjLGmNqwRG2ahc17c7j2pWWcc0J7bjr9eKLCQti8N5vfv72W7IISNu4+SKvoMM4f0omvUw+wbkcWJWXKLacfz6/O6gPAwo17uGXWSiLDghnePZF5a3bz0rQR3PHmanYdLCA0KIgPfzWa+MhQ3lm9k11Z+Uw7pQetY+wxqcaYY8cStWkR1u3M4qH5G/lqWwalZcqTlw/lg/V7eGtFGmf2b8e+7EJW/JBJ3/axPD91OK2iwxjxwId0iI9k055sfnt2Hx5fuJkyVQpLfuyY1Do6jItTuhAVFszy7w8QFRbMQxcOaly91I0xTZoNymFahAEd43n55yMpLCmloLiM+MhQTj6uNSWlZazd6e4J/sOEAVyS0oXIMNer+mfJHXnlqx8ICRKuGNmNbq2jWLwlnU4JkYzu3YbQ4CB+//Yanv1sKyVlSs820aRl5HPlc19x/8QTCBLhq23plJYpp/dty/FtY7zObjnsPVhA96RoOiZEHhLn3oMFtIkNb5491o0xfmc1atOiffPDAc5/cjGje7fhX9NGVFlOVckvLiUqLISPNuxh+r9XUFR65O1AAzrG0SMpmnfX7KL8T2vyiK7M+Fl/IkKDmfX1D9z51hr6to/lhtHHcd6QSp//Y4xpYaxGbUwVBndJ4OejenBWJb3GfYkIUWHuz+Un/drx/q2n8d3eHIpLyxjSNQFBWLBuN7O+/oH31+3h2lN7clqvNizcuJfnv9jGqu2Z/HxUD/7wzjqSO8dTVKr88rWVrN91kDvG9UWB15dt59NN+9iVlU/f9nGMH9SB03q3qYihrEw5WFBMQlQY2zPymLdmF19ty6Bb66j/396dx1dVngkc/z335iY3O9khAUJYZZMEFWhdAC0VrAV17Cgq09Za7VSd1rZWne6dRVtnrFa7WB0rrYpVXNsyboyKWmURWcISSAMJCSQQsucmN3d55o97jEESBROSm/B8Px8+uec9JyfvfT7v5bnnPe95X25bNJnYGBeqyveeLSYzKY6bPjPBrtqNGQLsitqYPqSqhML6wZSowMvba/jBs8VUN7WTkRjL/37zbDIS4/jx89v44zvljEj1khrvYWd1M/kZCeSmxlO8v5Hm9iC/XFrE4hm5HG7xc/XyDWze10BOShw1TZHnkfMzEig/7OOs8Zncu7SIP2/Zzw+fi0xxcPP5k7h+/ngg8iharNuFy2WJ25hoZIPJjBlgbR0hHl9fQdHoNApHRZ5RVVVWba3m2U1VlB9u5fr541k8IxcRwR8MsezBdWyqbGDpGaN4teQQNU3tXHN2Afvq2hifncQlM/MYmZbAyncrueWpLcR73ARCYeaMzSAtwcOzm/aTGu/B63FR0+QnPTGWqbkp+ANh2oMhvGNNeMsAABCwSURBVB43314wkdljM1j+t72kxnu4qCiP3TXNPPJOOf5gmHmTslg4bcTHvr99dT52Vjd3+zy7MebjWaI2ZhCqb+3gigfXUnaohfHZSfxk8VROH9P9XM4l1c38cvVudlY3seLaOQyLj+Xx9RXsrmmhLRBiZFo8VfVt7KhuIikuBq/HTUl1M4FQmJsWTOR7zxTjcQvPfP1Mrn9sI9WN7Xg9bhrbAsyflMWwhFhGpsVzw7njKT/s44Xiaq6ak0+KN4YV6yr4z1U7aQuEuOfyQkanJ/BfL5VQkJlIQWYSVfVtTB6RzOdOHdF5++CTqGpoIzs5rscJbIwZzCxRGzNIqSqqnJAu65LqZhbf9yb+YJgpIyJTtb4/Yn7FV+dwxpg07l9Txu/WlJEY62Z/YzsTspMor/PREQyTluAhJd5D+WEfZ0/IxNcRYseBJgSIj3Xj6wjh64h0uXeEIqPwf//lM5g5Og2A4qpG/rr1AIumDWd6Xmrn/fRwWI96vy9vr+G6P27gzPGZ/G7Z6Z2j9gEa2wK4XUJSN/PDGzNYWKI2xnTrifX7+NVrpfzh6lm8U3aYW57ayrI5+fzbRdOOOvaF4mpuXrmZWWPSuebssdz36m7aA2GuPWcsn52SQ02TnwvvfYO0hFgeuWY2wxI8tLQHSU+MZf3eem5euZkGX4B7lxbR3B7k5pWb8XVE1hI/Y0waX583ngffLKOkuoXvnj+J08ekUdPkZ09tKz/9yzZyUrxU1PkoyEykIximwRcgFI6Mxo/3uLnzC6dy4am5ANy+agcv76jh9PzIecdkJh7xXtoDIaoa2hiXlXTig2zMMbBEbYz5WKrK22WHOS0/jbiY7lfvOmLt8G40+gJ4Y13d/v6+Oh+X/vZvnQPhJo9I4d6lRbxVWsvdr+yi3hcgOS6GgqxEtlQ2HvG7YzMTeeJrn+Kt0loefGMP+RkJZCd7EYGclDheKK5mY0UDX/r0GMZnJ/H9Z4uZmpvC3tpWclK8PH/jWZ1X3K3+IF98aB0byuv52txxfH3+OFzO1bzHLQjC0xsreX3XIW5aMJGJOclHxEhEKK5q5OqH1/P5GbnctGCiXc2bXrNEbYyJCrUtft6raCAUDnPWhKzOBFff2sGzm6q4YPoIspPjeGXHQZrbAwxP8ZKd4mV0egKxMT1/QfAHQ9y+aifL396LKswqSOexa2azfm89Vz74DnMnZjEhJ5lGX4BtBxrZcaCZeROzWL3z4FHncgmENZK03S7hxnMnMKsgnQfWlLF+bx13XVbI7at2sL+hnRZ/kNxUL3ddVkiK18PGinoWF+bS0BrgxhUbGZEazyUz81gwJee4H5XbvK8BhSMGH760vYZd1c3EeVxcOTu/2+VgzeBkidoYc1J4r6Kele9W8o3PTCA72QvAr18r5ecvlBAb4yLNWXL1loWn8PkZuby+6xC7qj9YE7sjFKbVH2RWQTpTclP4zpNbWLPrEADxHjdZyXFU1EXWX374y2eQ7PXwnSc3s6e2tfMc+RkJBIJhWvxBYmPc1Lb4mTsxixvPHU+SN4a1ZXVsrWqkpT1IXlo8swvSGZuVSOnBVh5fX0EwFHle/v1ehaLRw5gxchjb9jeyfm99599ZOms0P7hwMrc9vZXhKV6umpOPCGQmxeH1HNmjoapsrGhgel7qR37hORbhsLKq+ACBUJiLi0b26lzmA32xzOVC4B4iy1w+qKp3fGj/t4BriCxzeQi4WlXLnX0hYKtzaIWqLv64v2eJ2hjTlxp8HSR7Pbg/waC8fXU+NlbUM6sgnQRPDDev3Mz47CS+u/AUINKV/sAbZSTFxTAuO4lbn9qCPxjm0WtmMyknmUfeKednL5TQFgh1njM7OY6UeA8VzsC89+UNiyc7JY5QWLn0tJGowop1FVQ1tBHvcfOtBRO5ZOZI7nxxJw+8sYepuSnsOBCZHjfs/Feem+rlsa/O6bwv3xEMc+tTW3j6vSqm5aVw3TnjeLe8nuKqRqqb2pk1Jp0lRXmcMyGTJzdUsvLdSr67cBKnj0mnuT1AUlxMZ2/Auj11/PC5YnY6X26euO5TzCpIP2pJ295Ysa6CtATPMT0WOJT0KlGLiBvYBSwAKoH1wFJV3d7lmPnAWlX1icg/A/NU9TJnX4uqHteIDUvUxpjBqsUfxB8IHbHiWk1TO9v2N9LUFuTUkamMdQaxtQdCbNvfSGV9G0lxMcyblH1MXybaOkIsumcNew/7+Nk/TGfO2AxW7zhIjFu4+5XdxLiE2WMzqGlqp+Kwj+qmdi4/YxQvbqum3hfA63Fxat4wMpJiebvsMA2+AOOzkyg92EJcjItAKMzwFC/7G9uZMTKV8ybnUFLdzF+3HiBvWDzfWjCRu1fvIsblYuboNF4tOcgdl0zn3FOyeaO0lrVlddQ0tTNpeDKxbheNbQFmFaTjcbv40/p9eNzCKcOTyR0Wz6ThyeRnRL5U/P6tPfzkz9txCdx3xUwWTRt+wp56iDa9TdSfAn6squc727cBqOrtPRxfBNynqmc625aojTGmj5UfbqWstpX5k7KPKC+pbuZfVryHPxgiO8XL8BQvF0wfzsJpI6ht8VN6sIXCUcM6u8cDoTAr1lXwm9f+zoWnjuCGcydwzyu7qW6KjIr/69YDlB1qJSs5jiXO4LnEuBjeKq3lygfXEut2kZcWz97DrWQkxlHb4ifGJWQkxXYOHOwq2RtDjEuo9wU6yyZkJxEf62ZLZSOfnZJDva+DjRUNuF2CS2Dm6DRmF2QwqyCdotHDeLe8np+/WEJ2chyLZ+SyaNrwzkGOTe0B3thVS52vA4DUeA+zxqQzPNV7RD22VDbwZmktDb5AZw/BHZdMJ3dYPP5giLgYN+2BED/583am5qZwUVEetz29FX8gxL1XFPU44PKT6m2ivhRYqKrXONvLgNmqekMPx98HVKvqvzvbQWATkW7xO1T12Y+rsCVqY4yJDuGw4guEuh3Z/ubuWkanJ5CdEscPnyvmYLOfy88YzdyJWcTHumnwdRBW8HpcrNlVS6s/yKLpw4n3uDnU4qe6sZ0Ne+t5bdchhEjC/s75k/AHw/z61VIA/MEw6/bUsaO6CXUG+QVCyqj0eDqCYWqa/BRkJnLtOWOZMiKFbzz+HnsP+46q6+QRKcyflMX8U7Kpbmzn209spiMUJjbGxbisJCrrfCR7Yxifk8yaXYe4uCiPBl8Hr5ZExiikeGNo8QcJKywpzOXuywr7dC79fkvUInIVcAMwV1X9TlmeqlaJyFjg/4DzVPXv3fzutcC1AKNHjz6tvLz8eN6jMcaYIayxLcC75XWs3VNHitfDV84qINbt4uUdNdz9yu7Oe/UZibHcdVkhk4cng8DBJj9vltby6s6DbCivJ+TczD89P437l51GemJs5yN3X/r9OlRh7sQsnt+8n2BY+Y+Lp9EeCPPY2nJ+9PmpbK1q5M4XS7h10Sl8be64Pnt//dL1LSKfAe4lkqSPfuYhcszDwF9UdeVH/U27ojbGGHOsVJUtlY28XXaYz00fwaj0hG6Pa2wL8FZpLfsb2rhydv4RM9xBZHxBjEvwetzsrG7iQGP7UbcWVJX715Rxycy8zicL+kJvE3UMkcFk5wFVRAaTXaGq27ocUwSsJHLlvbtLeRrgU1W/iGQCbwNLug5E644lamOMMSeTXq1HrapBEbkBeJHI41kPqeo2EfkpsEFVnwfuBJKAJ50++/cfw5oM3C8iYcBF5B71RyZpY4wxxnzAJjwxxhhjBthHXVHbenHGGGNMFLNEbYwxxkQxS9TGGGNMFLNEbYwxxkQxS9TGGGNMFIvKUd8icgjoy6nJMoHaPjzfychi2Dcsjr1nMewbFsfe68sY5qtqVnc7ojJR9zUR2dDTsHdzbCyGfcPi2HsWw75hcey9/oqhdX0bY4wxUcwStTHGGBPFTpZE/buBrsAQYDHsGxbH3rMY9g2LY+/1SwxPinvUxhhjzGB1slxRG2OMMYPSkE7UIrJQREpEpFREbh3o+gwmIrJXRLaKyCYR2eCUpYvIyyKy2/mZNtD1jDYi8pCIHBSR4i5l3cZNIn7ptM8tIjJz4GoePXqI4Y9FpMppj5tE5IIu+25zYlgiIucPTK2ji4iMEpFXRWS7iGwTkW845dYWj8NHxLFf2+OQTdQi4gZ+BSwCpgBLRWTKwNZq0JmvqoVdHj+4FVitqhOA1c62OdLDwMIPlfUUt0XABOfftcBv+qmO0e5hjo4hwC+c9lioqqsAnM/05cBU53d+7Xz2T3ZB4NuqOgWYA1zvxMra4vHpKY7Qj+1xyCZqYBZQqqplqtoBPA4sGeA6DXZLgOXO6+XARQNYl6ikqmuAug8V9xS3JcAfNOIdYJiIjOifmkavHmLYkyXA46rqV9U9QCmRz/5JTVUPqOpG53UzsAPIw9ricfmIOPbkhLTHoZyo84B9XbYr+egAmyMp8JKIvCsi1zplOap6wHldDeQMTNUGnZ7iZm30+NzgdMs+1OW2i8XwY4jIGKAIWIu1xU/sQ3GEfmyPQzlRm945S1VnEukSu15Ezum6UyOPC9gjA8fJ4vaJ/QYYBxQCB4D/HtjqDA4ikgQ8BXxTVZu67rO2eOy6iWO/tsehnKirgFFdtkc6ZeYYqGqV8/Mg8AyR7pua97vDnJ8HB66Gg0pPcbM2eoxUtUZVQ6oaBh7gg+5Ei2EPRMRDJLk8qqpPO8XWFo9Td3Hs7/Y4lBP1emCCiBSISCyRG/zPD3CdBgURSRSR5PdfA58FionE74vOYV8EnhuYGg46PcXteeCfnBG3c4DGLt2SposP3S+9mEh7hEgMLxeROBEpIDIYal1/1y/aiIgA/wPsUNW7uuyytngceopjf7fHmN6eIFqpalBEbgBeBNzAQ6q6bYCrNVjkAM9E2igxwGOq+oKIrAeeEJGvEFnd7B8HsI5RSURWAPOATBGpBH4E3EH3cVsFXEBkwIkP+HK/VzgK9RDDeSJSSKSrdi9wHYCqbhORJ4DtREboXq+qoYGod5Q5E1gGbBWRTU7Zv2Jt8Xj1FMel/dkebWYyY4wxJooN5a5vY4wxZtCzRG2MMcZEMUvUxhhjTBSzRG2MMcZEMUvUxhhjTBSzRG2MOWYiMk9E/jLQ9TDmZGKJ2hhjjIlilqiNGYJE5CoRWeeslXu/iLhFpEVEfuGsq7taRLKcYwtF5B1ngYFnuqxRPF5EXhGRzSKyUUTGOadPEpGVIrJTRB51Zm8yxpwglqiNGWJEZDJwGXCmqhYCIeBKIBHYoKpTgdeJzPgF8AfgFlU9FdjapfxR4FeqOgP4NJHFByCygtA3iazzPpbI7E3GmBNkyE4hasxJ7DzgNGC9c7EbT2TxhTDwJ+eYR4CnRSQVGKaqrzvly4Ennbne81T1GQBVbQdwzrdOVSud7U3AGODNE/+2jDk5WaI2ZugRYLmq3nZEocgPPnTcJ50/2N/ldQj7f8SYE8q6vo0ZelYDl4pINoCIpItIPpHP+6XOMVcAb6pqI1AvImc75cuA11W1GagUkYucc8SJSEK/vgtjDGDfhI0ZclR1u4h8H3hJRFxAALgeaAVmOfsOErmPDZHlDn/rJOIyPlg5aRlwv4j81DnHF/rxbRhjHLZ6ljEnCRFpUdWkga6HMeb4WNe3McYYE8XsitoYY4yJYnZFbYwxxkQxS9TGGGNMFLNEbYwxxkQxS9TGGGNMFLNEbYwxxkQxS9TGGGNMFPt/QS+Sy8XPPhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transfer learning\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "# freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = flatten(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(len(base_model.trainable_variables))\n",
    "print(len(model.trainable_variables))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 932732,
     "status": "ok",
     "timestamp": 1614242523855,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "nyvMpuJ2sFaI",
    "outputId": "0f19091d-3446-4439-9b79-ed4668b29c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "98\n",
      "Epoch 1/250\n",
      "23/23 [==============================] - 10s 243ms/step - loss: 1.6955 - accuracy: 0.2908 - val_loss: 1.5760 - val_accuracy: 0.4619\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.2907 - accuracy: 0.4773 - val_loss: 1.1527 - val_accuracy: 0.5681\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0392 - accuracy: 0.6282 - val_loss: 0.9128 - val_accuracy: 0.6689\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.8709 - accuracy: 0.6771 - val_loss: 0.7920 - val_accuracy: 0.7084\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.7819 - accuracy: 0.7247 - val_loss: 0.6965 - val_accuracy: 0.7480\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.7057 - accuracy: 0.7560 - val_loss: 0.6366 - val_accuracy: 0.7711\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.6416 - accuracy: 0.7831 - val_loss: 0.5982 - val_accuracy: 0.7929\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.5944 - accuracy: 0.8016 - val_loss: 0.5677 - val_accuracy: 0.8106\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.5425 - accuracy: 0.8185 - val_loss: 0.5472 - val_accuracy: 0.8120\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.5062 - accuracy: 0.8278 - val_loss: 0.5332 - val_accuracy: 0.8093\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.4706 - accuracy: 0.8456 - val_loss: 0.5183 - val_accuracy: 0.8174\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.4632 - accuracy: 0.8464 - val_loss: 0.5071 - val_accuracy: 0.8202\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.4252 - accuracy: 0.8553 - val_loss: 0.4949 - val_accuracy: 0.8311\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.4082 - accuracy: 0.8617 - val_loss: 0.4848 - val_accuracy: 0.8270\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.3670 - accuracy: 0.8752 - val_loss: 0.4759 - val_accuracy: 0.8324\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.3597 - accuracy: 0.8742 - val_loss: 0.4659 - val_accuracy: 0.8392\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.3444 - accuracy: 0.8819 - val_loss: 0.4596 - val_accuracy: 0.8406\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.3263 - accuracy: 0.8898 - val_loss: 0.4517 - val_accuracy: 0.8460\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.2940 - accuracy: 0.9063 - val_loss: 0.4465 - val_accuracy: 0.8488\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.2730 - accuracy: 0.9156 - val_loss: 0.4395 - val_accuracy: 0.8583\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2760 - accuracy: 0.8999 - val_loss: 0.4284 - val_accuracy: 0.8556\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2465 - accuracy: 0.9211 - val_loss: 0.4245 - val_accuracy: 0.8515\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2473 - accuracy: 0.9177 - val_loss: 0.4224 - val_accuracy: 0.8556\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2319 - accuracy: 0.9220 - val_loss: 0.4153 - val_accuracy: 0.8569\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2229 - accuracy: 0.9261 - val_loss: 0.4139 - val_accuracy: 0.8583\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2021 - accuracy: 0.9393 - val_loss: 0.4087 - val_accuracy: 0.8638\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2014 - accuracy: 0.9437 - val_loss: 0.4066 - val_accuracy: 0.8651\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1880 - accuracy: 0.9408 - val_loss: 0.4046 - val_accuracy: 0.8665\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1873 - accuracy: 0.9387 - val_loss: 0.4028 - val_accuracy: 0.8706\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1774 - accuracy: 0.9442 - val_loss: 0.3978 - val_accuracy: 0.8624\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1556 - accuracy: 0.9462 - val_loss: 0.3975 - val_accuracy: 0.8638\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1620 - accuracy: 0.9485 - val_loss: 0.3962 - val_accuracy: 0.8638\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.1539 - accuracy: 0.9499 - val_loss: 0.3929 - val_accuracy: 0.8638\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.1400 - accuracy: 0.9652 - val_loss: 0.3927 - val_accuracy: 0.8678\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1356 - accuracy: 0.9594 - val_loss: 0.3873 - val_accuracy: 0.8719\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.1220 - accuracy: 0.9672 - val_loss: 0.3897 - val_accuracy: 0.8747\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1356 - accuracy: 0.9574 - val_loss: 0.3867 - val_accuracy: 0.8760\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1195 - accuracy: 0.9659 - val_loss: 0.3873 - val_accuracy: 0.8787\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1112 - accuracy: 0.9675 - val_loss: 0.3867 - val_accuracy: 0.8828\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0975 - accuracy: 0.9742 - val_loss: 0.3810 - val_accuracy: 0.8828\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1036 - accuracy: 0.9749 - val_loss: 0.3822 - val_accuracy: 0.8828\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0875 - accuracy: 0.9784 - val_loss: 0.3834 - val_accuracy: 0.8801\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0931 - accuracy: 0.9781 - val_loss: 0.3837 - val_accuracy: 0.8842\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0934 - accuracy: 0.9735 - val_loss: 0.3839 - val_accuracy: 0.8801\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.3796 - val_accuracy: 0.8828\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0820 - accuracy: 0.9787 - val_loss: 0.3800 - val_accuracy: 0.8815\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0762 - accuracy: 0.9829 - val_loss: 0.3781 - val_accuracy: 0.8828\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0670 - accuracy: 0.9845 - val_loss: 0.3830 - val_accuracy: 0.8815\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.3775 - val_accuracy: 0.8856\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0705 - accuracy: 0.9845 - val_loss: 0.3769 - val_accuracy: 0.8869\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0635 - accuracy: 0.9863 - val_loss: 0.3776 - val_accuracy: 0.8869\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0545 - accuracy: 0.9895 - val_loss: 0.3747 - val_accuracy: 0.8828\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0577 - accuracy: 0.9884 - val_loss: 0.3738 - val_accuracy: 0.8856\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0484 - accuracy: 0.9919 - val_loss: 0.3750 - val_accuracy: 0.8842\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0462 - accuracy: 0.9894 - val_loss: 0.3791 - val_accuracy: 0.8883\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0465 - accuracy: 0.9905 - val_loss: 0.3767 - val_accuracy: 0.8842\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0454 - accuracy: 0.9907 - val_loss: 0.3761 - val_accuracy: 0.8883\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.3772 - val_accuracy: 0.8883\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0396 - accuracy: 0.9941 - val_loss: 0.3770 - val_accuracy: 0.8883\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 0.3761 - val_accuracy: 0.8910\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0370 - accuracy: 0.9929 - val_loss: 0.3747 - val_accuracy: 0.8937\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0477 - accuracy: 0.9887 - val_loss: 0.3715 - val_accuracy: 0.8924\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0375 - accuracy: 0.9907 - val_loss: 0.3747 - val_accuracy: 0.8951\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0337 - accuracy: 0.9923 - val_loss: 0.3764 - val_accuracy: 0.8924\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0325 - accuracy: 0.9949 - val_loss: 0.3797 - val_accuracy: 0.8951\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0259 - accuracy: 0.9974 - val_loss: 0.3864 - val_accuracy: 0.8951\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0314 - accuracy: 0.9946 - val_loss: 0.3841 - val_accuracy: 0.8992\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0261 - accuracy: 0.9965 - val_loss: 0.3858 - val_accuracy: 0.8992\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0226 - accuracy: 0.9984 - val_loss: 0.3863 - val_accuracy: 0.8978\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.3829 - val_accuracy: 0.8992\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.3840 - val_accuracy: 0.9005\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0302 - accuracy: 0.9958 - val_loss: 0.3849 - val_accuracy: 0.9019\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.3834 - val_accuracy: 0.9033\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0198 - accuracy: 0.9970 - val_loss: 0.3825 - val_accuracy: 0.9033\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.3841 - val_accuracy: 0.9060\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.3872 - val_accuracy: 0.9046\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0178 - accuracy: 0.9989 - val_loss: 0.3871 - val_accuracy: 0.9046\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0164 - accuracy: 0.9986 - val_loss: 0.3856 - val_accuracy: 0.9033\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0276 - accuracy: 0.9938 - val_loss: 0.3928 - val_accuracy: 0.8978\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0235 - accuracy: 0.9953 - val_loss: 0.3852 - val_accuracy: 0.9046\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.3887 - val_accuracy: 0.9033\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0189 - accuracy: 0.9980 - val_loss: 0.3923 - val_accuracy: 0.9019\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0151 - accuracy: 0.9993 - val_loss: 0.3913 - val_accuracy: 0.8992\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.3918 - val_accuracy: 0.9005\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.3929 - val_accuracy: 0.9019\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.3922 - val_accuracy: 0.9019\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.3930 - val_accuracy: 0.9033\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0148 - accuracy: 0.9982 - val_loss: 0.3952 - val_accuracy: 0.9019\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.3917 - val_accuracy: 0.9019\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0106 - accuracy: 0.9998 - val_loss: 0.3917 - val_accuracy: 0.9019\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.3931 - val_accuracy: 0.9019\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.3922 - val_accuracy: 0.9005\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.3978 - val_accuracy: 0.8978\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.4037 - val_accuracy: 0.8965\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.4028 - val_accuracy: 0.8965\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 0.4025 - val_accuracy: 0.8965\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 0.4046 - val_accuracy: 0.8978\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.4078 - val_accuracy: 0.8965\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.4026 - val_accuracy: 0.8978\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.3972 - val_accuracy: 0.8992\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.3964 - val_accuracy: 0.9019\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0077 - accuracy: 0.9997 - val_loss: 0.4012 - val_accuracy: 0.8937\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0084 - accuracy: 0.9999 - val_loss: 0.4031 - val_accuracy: 0.8951\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.4041 - val_accuracy: 0.8951\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.3976 - val_accuracy: 0.8992\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.3961 - val_accuracy: 0.9033\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4011 - val_accuracy: 0.8992\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.4020 - val_accuracy: 0.8992\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9005\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.3963 - val_accuracy: 0.9046\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.3956 - val_accuracy: 0.9074\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.3952 - val_accuracy: 0.9087\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9074\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.3998 - val_accuracy: 0.9033\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.3967 - val_accuracy: 0.9033\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.4021 - val_accuracy: 0.8992\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8992\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.4038 - val_accuracy: 0.8978\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 0.3999 - val_accuracy: 0.9046\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.4005 - val_accuracy: 0.9033\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.4016 - val_accuracy: 0.9060\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.4070 - val_accuracy: 0.9033\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.4065 - val_accuracy: 0.9046\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.4057 - val_accuracy: 0.9046\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.4088 - val_accuracy: 0.9019\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.4136 - val_accuracy: 0.8992\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.4145 - val_accuracy: 0.8992\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.4198 - val_accuracy: 0.9019\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.4168 - val_accuracy: 0.9033\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.4160 - val_accuracy: 0.9005\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.4182 - val_accuracy: 0.8992\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.4171 - val_accuracy: 0.9033\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.4170 - val_accuracy: 0.9033\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9033\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9060\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9033\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.4168 - val_accuracy: 0.9033\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.4142 - val_accuracy: 0.9033\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9033\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.4234 - val_accuracy: 0.9046\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 4s 163ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.4303 - val_accuracy: 0.9046\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9046\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.4230 - val_accuracy: 0.9005\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.4242 - val_accuracy: 0.9033\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4228 - val_accuracy: 0.9060\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9046\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9060\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9033\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9046\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9046\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9046\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.4268 - val_accuracy: 0.9033\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9033\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4193 - val_accuracy: 0.9060\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9060\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4263 - val_accuracy: 0.9033\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4276 - val_accuracy: 0.9019\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9005\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9019\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.4316 - val_accuracy: 0.9005\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.4327 - val_accuracy: 0.9005\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9005\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9005\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9019\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4427 - val_accuracy: 0.9033\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9033\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9033\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9046\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9046\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.4386 - val_accuracy: 0.9033\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4291 - val_accuracy: 0.9019\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9033\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9019\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9019\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9046\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9033\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9046\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9005\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.4424 - val_accuracy: 0.9033\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9019\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9033\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.4345 - val_accuracy: 0.9046\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9033\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9046\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 9.8870e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9005\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9033\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9019\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 7.8216e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9019\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4422 - val_accuracy: 0.9019\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9019\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9019\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9019\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9005\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 9.5500e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9019\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9033\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 9.9934e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9033\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 9.3021e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9033\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 7.7360e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9060\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 9.9454e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9046\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.8178e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9087\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.7269e-04 - accuracy: 0.9999 - val_loss: 0.4408 - val_accuracy: 0.9074\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9033\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 7.4590e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9033\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 7.4995e-04 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9019\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 7.6477e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9019\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.2743e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9019\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.4604e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9033\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.8316e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9033\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9046\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0018 - accuracy: 0.9986 - val_loss: 0.4438 - val_accuracy: 0.9046\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.7901e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8992\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 7.9031e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9019\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.4531 - val_accuracy: 0.9005\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 6.7072e-04 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9005\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.3838e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9019\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.5332e-04 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9019\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.1636e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9019\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.8167e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9046\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 9.6753e-04 - accuracy: 0.9999 - val_loss: 0.4505 - val_accuracy: 0.9074\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.9149e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9087\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.0436e-04 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9087\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 6.5796e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9074\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9087\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.5146e-04 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9060\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 8.5702e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9060\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.7823e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9060\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 4.9785e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9060\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.4485 - val_accuracy: 0.9060\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.5752e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9019\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.0987e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9019\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.7751e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9019\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.4922e-04 - accuracy: 0.9998 - val_loss: 0.4640 - val_accuracy: 0.9033\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 4.5989e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9046\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 5.6916e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9046\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.8892e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9005\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.2782e-04 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9019\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 4.4133e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9019\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 8.2798e-04 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9019\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.8474e-04 - accuracy: 0.9999 - val_loss: 0.4692 - val_accuracy: 0.8992\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 3.9618e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9005\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 5.5212e-04 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9005\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 3.5870e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9005\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 6.4113e-04 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9019\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4678 - val_accuracy: 0.9060\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 4.8211e-04 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9046\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 8.3958e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9046\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 3.8171e-04 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9019\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 3.4828e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9019\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 4.3937e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9019\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 3.8052e-04 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9019\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fine tuning\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "#base_model.summary()\n",
    "\n",
    "# Freeze some first the layers\n",
    "fine_tune_at = 150\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "\n",
    "print(len(base_model.trainable_variables))\n",
    "\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = flatten(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "print(len(model.trainable_variables))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2467992,
     "status": "ok",
     "timestamp": 1614244088175,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "871mR8dTsFaJ",
    "outputId": "1dc219d2-5bc1-44f6-ee7e-241d1adff8a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1222 (Conv2D)            (None, 79, 79, 32)   864         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1222 (Batch (None, 79, 79, 32)   96          conv2d_1222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1222 (Activation)    (None, 79, 79, 32)   0           batch_normalization_1222[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1223 (Conv2D)            (None, 77, 77, 32)   9216        activation_1222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1223 (Batch (None, 77, 77, 32)   96          conv2d_1223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1223 (Activation)    (None, 77, 77, 32)   0           batch_normalization_1223[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1224 (Conv2D)            (None, 77, 77, 64)   18432       activation_1223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1224 (Batch (None, 77, 77, 64)   192         conv2d_1224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1224 (Activation)    (None, 77, 77, 64)   0           batch_normalization_1224[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 38, 38, 64)   0           activation_1224[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1225 (Conv2D)            (None, 38, 38, 80)   5120        max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1225 (Batch (None, 38, 38, 80)   240         conv2d_1225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1225 (Activation)    (None, 38, 38, 80)   0           batch_normalization_1225[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1226 (Conv2D)            (None, 36, 36, 192)  138240      activation_1225[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1226 (Batch (None, 36, 36, 192)  576         conv2d_1226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1226 (Activation)    (None, 36, 36, 192)  0           batch_normalization_1226[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling2D) (None, 17, 17, 192)  0           activation_1226[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1230 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1230 (Batch (None, 17, 17, 64)   192         conv2d_1230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1230 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1230[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1228 (Conv2D)            (None, 17, 17, 48)   9216        max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1231 (Conv2D)            (None, 17, 17, 96)   55296       activation_1230[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1228 (Batch (None, 17, 17, 48)   144         conv2d_1228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1231 (Batch (None, 17, 17, 96)   288         conv2d_1231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1228 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1228[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1231 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1231[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_117 (AverageP (None, 17, 17, 192)  0           max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1227 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1229 (Conv2D)            (None, 17, 17, 64)   76800       activation_1228[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1232 (Conv2D)            (None, 17, 17, 96)   82944       activation_1231[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1233 (Conv2D)            (None, 17, 17, 32)   6144        average_pooling2d_117[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1227 (Batch (None, 17, 17, 64)   192         conv2d_1227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1229 (Batch (None, 17, 17, 64)   192         conv2d_1229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1232 (Batch (None, 17, 17, 96)   288         conv2d_1232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1233 (Batch (None, 17, 17, 32)   96          conv2d_1233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1227 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1227[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1229 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1229[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1232 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1232[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1233 (Activation)    (None, 17, 17, 32)   0           batch_normalization_1233[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_1227[0][0]            \n",
      "                                                                 activation_1229[0][0]            \n",
      "                                                                 activation_1232[0][0]            \n",
      "                                                                 activation_1233[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1237 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1237 (Batch (None, 17, 17, 64)   192         conv2d_1237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1237 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1237[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1235 (Conv2D)            (None, 17, 17, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1238 (Conv2D)            (None, 17, 17, 96)   55296       activation_1237[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1235 (Batch (None, 17, 17, 48)   144         conv2d_1235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1238 (Batch (None, 17, 17, 96)   288         conv2d_1238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1235 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1235[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1238 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1238[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_118 (AverageP (None, 17, 17, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1234 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1236 (Conv2D)            (None, 17, 17, 64)   76800       activation_1235[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1239 (Conv2D)            (None, 17, 17, 96)   82944       activation_1238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1240 (Conv2D)            (None, 17, 17, 64)   16384       average_pooling2d_118[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1234 (Batch (None, 17, 17, 64)   192         conv2d_1234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1236 (Batch (None, 17, 17, 64)   192         conv2d_1236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1239 (Batch (None, 17, 17, 96)   288         conv2d_1239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1240 (Batch (None, 17, 17, 64)   192         conv2d_1240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1234 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1234[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1236 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1236[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1239 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1239[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1240 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1240[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_1234[0][0]            \n",
      "                                                                 activation_1236[0][0]            \n",
      "                                                                 activation_1239[0][0]            \n",
      "                                                                 activation_1240[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1244 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1244 (Batch (None, 17, 17, 64)   192         conv2d_1244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1244 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1244[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1242 (Conv2D)            (None, 17, 17, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1245 (Conv2D)            (None, 17, 17, 96)   55296       activation_1244[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1242 (Batch (None, 17, 17, 48)   144         conv2d_1242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1245 (Batch (None, 17, 17, 96)   288         conv2d_1245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1242 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1242[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1245 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1245[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_119 (AverageP (None, 17, 17, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1241 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1243 (Conv2D)            (None, 17, 17, 64)   76800       activation_1242[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1246 (Conv2D)            (None, 17, 17, 96)   82944       activation_1245[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1247 (Conv2D)            (None, 17, 17, 64)   18432       average_pooling2d_119[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1241 (Batch (None, 17, 17, 64)   192         conv2d_1241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1243 (Batch (None, 17, 17, 64)   192         conv2d_1243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1246 (Batch (None, 17, 17, 96)   288         conv2d_1246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1247 (Batch (None, 17, 17, 64)   192         conv2d_1247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1241 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1241[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1243 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1243[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1246 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1246[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1247 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1247[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_1241[0][0]            \n",
      "                                                                 activation_1243[0][0]            \n",
      "                                                                 activation_1246[0][0]            \n",
      "                                                                 activation_1247[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1249 (Conv2D)            (None, 17, 17, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1249 (Batch (None, 17, 17, 64)   192         conv2d_1249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1249 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1249[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1250 (Conv2D)            (None, 17, 17, 96)   55296       activation_1249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1250 (Batch (None, 17, 17, 96)   288         conv2d_1250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1250 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1250[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1248 (Conv2D)            (None, 8, 8, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1251 (Conv2D)            (None, 8, 8, 96)     82944       activation_1250[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1248 (Batch (None, 8, 8, 384)    1152        conv2d_1248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1251 (Batch (None, 8, 8, 96)     288         conv2d_1251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1248 (Activation)    (None, 8, 8, 384)    0           batch_normalization_1248[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1251 (Activation)    (None, 8, 8, 96)     0           batch_normalization_1251[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 8, 8, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_1248[0][0]            \n",
      "                                                                 activation_1251[0][0]            \n",
      "                                                                 max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1256 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1256 (Batch (None, 8, 8, 128)    384         conv2d_1256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1256 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1256[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1257 (Conv2D)            (None, 8, 8, 128)    114688      activation_1256[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1257 (Batch (None, 8, 8, 128)    384         conv2d_1257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1257 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1257[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1253 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1258 (Conv2D)            (None, 8, 8, 128)    114688      activation_1257[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1253 (Batch (None, 8, 8, 128)    384         conv2d_1253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1258 (Batch (None, 8, 8, 128)    384         conv2d_1258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1253 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1253[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1258 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1258[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1254 (Conv2D)            (None, 8, 8, 128)    114688      activation_1253[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1259 (Conv2D)            (None, 8, 8, 128)    114688      activation_1258[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1254 (Batch (None, 8, 8, 128)    384         conv2d_1254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1259 (Batch (None, 8, 8, 128)    384         conv2d_1259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1254 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1254[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1259 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1259[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_120 (AverageP (None, 8, 8, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1252 (Conv2D)            (None, 8, 8, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1255 (Conv2D)            (None, 8, 8, 192)    172032      activation_1254[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1260 (Conv2D)            (None, 8, 8, 192)    172032      activation_1259[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1261 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_120[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1252 (Batch (None, 8, 8, 192)    576         conv2d_1252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1255 (Batch (None, 8, 8, 192)    576         conv2d_1255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1260 (Batch (None, 8, 8, 192)    576         conv2d_1260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1261 (Batch (None, 8, 8, 192)    576         conv2d_1261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1252 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1252[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1255 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1255[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1260 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1260[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1261 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1261[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_1252[0][0]            \n",
      "                                                                 activation_1255[0][0]            \n",
      "                                                                 activation_1260[0][0]            \n",
      "                                                                 activation_1261[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1266 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1266 (Batch (None, 8, 8, 160)    480         conv2d_1266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1266 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1266[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1267 (Conv2D)            (None, 8, 8, 160)    179200      activation_1266[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1267 (Batch (None, 8, 8, 160)    480         conv2d_1267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1267 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1267[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1263 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1268 (Conv2D)            (None, 8, 8, 160)    179200      activation_1267[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1263 (Batch (None, 8, 8, 160)    480         conv2d_1263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1268 (Batch (None, 8, 8, 160)    480         conv2d_1268[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1263 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1263[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1268 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1268[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1264 (Conv2D)            (None, 8, 8, 160)    179200      activation_1263[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1269 (Conv2D)            (None, 8, 8, 160)    179200      activation_1268[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1264 (Batch (None, 8, 8, 160)    480         conv2d_1264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1269 (Batch (None, 8, 8, 160)    480         conv2d_1269[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1264 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1264[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1269 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1269[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_121 (AverageP (None, 8, 8, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1262 (Conv2D)            (None, 8, 8, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1265 (Conv2D)            (None, 8, 8, 192)    215040      activation_1264[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1270 (Conv2D)            (None, 8, 8, 192)    215040      activation_1269[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1271 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_121[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1262 (Batch (None, 8, 8, 192)    576         conv2d_1262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1265 (Batch (None, 8, 8, 192)    576         conv2d_1265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1270 (Batch (None, 8, 8, 192)    576         conv2d_1270[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1271 (Batch (None, 8, 8, 192)    576         conv2d_1271[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1262 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1262[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1265 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1265[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1270 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1270[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1271 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1271[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_1262[0][0]            \n",
      "                                                                 activation_1265[0][0]            \n",
      "                                                                 activation_1270[0][0]            \n",
      "                                                                 activation_1271[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1276 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1276 (Batch (None, 8, 8, 160)    480         conv2d_1276[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1276 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1276[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1277 (Conv2D)            (None, 8, 8, 160)    179200      activation_1276[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1277 (Batch (None, 8, 8, 160)    480         conv2d_1277[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1277 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1277[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1273 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1278 (Conv2D)            (None, 8, 8, 160)    179200      activation_1277[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1273 (Batch (None, 8, 8, 160)    480         conv2d_1273[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1278 (Batch (None, 8, 8, 160)    480         conv2d_1278[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1273 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1273[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1278 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1278[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1274 (Conv2D)            (None, 8, 8, 160)    179200      activation_1273[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1279 (Conv2D)            (None, 8, 8, 160)    179200      activation_1278[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1274 (Batch (None, 8, 8, 160)    480         conv2d_1274[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1279 (Batch (None, 8, 8, 160)    480         conv2d_1279[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1274 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1274[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1279 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1279[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_122 (AverageP (None, 8, 8, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1272 (Conv2D)            (None, 8, 8, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1275 (Conv2D)            (None, 8, 8, 192)    215040      activation_1274[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1280 (Conv2D)            (None, 8, 8, 192)    215040      activation_1279[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1281 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_122[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1272 (Batch (None, 8, 8, 192)    576         conv2d_1272[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1275 (Batch (None, 8, 8, 192)    576         conv2d_1275[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1280 (Batch (None, 8, 8, 192)    576         conv2d_1280[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1281 (Batch (None, 8, 8, 192)    576         conv2d_1281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1272 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1272[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1275 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1275[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1280 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1280[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1281 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1281[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_1272[0][0]            \n",
      "                                                                 activation_1275[0][0]            \n",
      "                                                                 activation_1280[0][0]            \n",
      "                                                                 activation_1281[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1286 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1286 (Batch (None, 8, 8, 192)    576         conv2d_1286[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1286 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1286[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1287 (Conv2D)            (None, 8, 8, 192)    258048      activation_1286[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1287 (Batch (None, 8, 8, 192)    576         conv2d_1287[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1287 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1287[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1283 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1288 (Conv2D)            (None, 8, 8, 192)    258048      activation_1287[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1283 (Batch (None, 8, 8, 192)    576         conv2d_1283[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1288 (Batch (None, 8, 8, 192)    576         conv2d_1288[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1283 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1283[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1288 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1288[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1284 (Conv2D)            (None, 8, 8, 192)    258048      activation_1283[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1289 (Conv2D)            (None, 8, 8, 192)    258048      activation_1288[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1284 (Batch (None, 8, 8, 192)    576         conv2d_1284[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1289 (Batch (None, 8, 8, 192)    576         conv2d_1289[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1284 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1284[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1289 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1289[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_123 (AverageP (None, 8, 8, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1282 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1285 (Conv2D)            (None, 8, 8, 192)    258048      activation_1284[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1290 (Conv2D)            (None, 8, 8, 192)    258048      activation_1289[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1291 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_123[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1282 (Batch (None, 8, 8, 192)    576         conv2d_1282[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1285 (Batch (None, 8, 8, 192)    576         conv2d_1285[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1290 (Batch (None, 8, 8, 192)    576         conv2d_1290[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1291 (Batch (None, 8, 8, 192)    576         conv2d_1291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1282 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1282[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1285 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1285[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1290 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1290[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1291 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1291[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_1282[0][0]            \n",
      "                                                                 activation_1285[0][0]            \n",
      "                                                                 activation_1290[0][0]            \n",
      "                                                                 activation_1291[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1294 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1294 (Batch (None, 8, 8, 192)    576         conv2d_1294[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1294 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1294[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1295 (Conv2D)            (None, 8, 8, 192)    258048      activation_1294[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1295 (Batch (None, 8, 8, 192)    576         conv2d_1295[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1295 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1295[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1292 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1296 (Conv2D)            (None, 8, 8, 192)    258048      activation_1295[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1292 (Batch (None, 8, 8, 192)    576         conv2d_1292[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1296 (Batch (None, 8, 8, 192)    576         conv2d_1296[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1292 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1292[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1296 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1296[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1293 (Conv2D)            (None, 3, 3, 320)    552960      activation_1292[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1297 (Conv2D)            (None, 3, 3, 192)    331776      activation_1296[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1293 (Batch (None, 3, 3, 320)    960         conv2d_1293[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1297 (Batch (None, 3, 3, 192)    576         conv2d_1297[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1293 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1293[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1297 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1297[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_1293[0][0]            \n",
      "                                                                 activation_1297[0][0]            \n",
      "                                                                 max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1302 (Conv2D)            (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1302 (Batch (None, 3, 3, 448)    1344        conv2d_1302[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1302 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1302[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1299 (Conv2D)            (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1303 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1302[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1299 (Batch (None, 3, 3, 384)    1152        conv2d_1299[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1303 (Batch (None, 3, 3, 384)    1152        conv2d_1303[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1299 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1299[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1303 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1303[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1300 (Conv2D)            (None, 3, 3, 384)    442368      activation_1299[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1301 (Conv2D)            (None, 3, 3, 384)    442368      activation_1299[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1304 (Conv2D)            (None, 3, 3, 384)    442368      activation_1303[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1305 (Conv2D)            (None, 3, 3, 384)    442368      activation_1303[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_124 (AverageP (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1298 (Conv2D)            (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1300 (Batch (None, 3, 3, 384)    1152        conv2d_1300[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1301 (Batch (None, 3, 3, 384)    1152        conv2d_1301[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1304 (Batch (None, 3, 3, 384)    1152        conv2d_1304[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1305 (Batch (None, 3, 3, 384)    1152        conv2d_1305[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1306 (Conv2D)            (None, 3, 3, 192)    245760      average_pooling2d_124[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1298 (Batch (None, 3, 3, 320)    960         conv2d_1298[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1300 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1300[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1301 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1301[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1304 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1304[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1305 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1305[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1306 (Batch (None, 3, 3, 192)    576         conv2d_1306[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1298 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1298[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_1300[0][0]            \n",
      "                                                                 activation_1301[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 3, 3, 768)    0           activation_1304[0][0]            \n",
      "                                                                 activation_1305[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1306 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1306[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_1298[0][0]            \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_26[0][0]             \n",
      "                                                                 activation_1306[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1311 (Conv2D)            (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1311 (Batch (None, 3, 3, 448)    1344        conv2d_1311[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1311 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1311[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1308 (Conv2D)            (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1312 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1311[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1308 (Batch (None, 3, 3, 384)    1152        conv2d_1308[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1312 (Batch (None, 3, 3, 384)    1152        conv2d_1312[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1308 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1308[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1312 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1312[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1309 (Conv2D)            (None, 3, 3, 384)    442368      activation_1308[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1310 (Conv2D)            (None, 3, 3, 384)    442368      activation_1308[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1313 (Conv2D)            (None, 3, 3, 384)    442368      activation_1312[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1314 (Conv2D)            (None, 3, 3, 384)    442368      activation_1312[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_125 (AverageP (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1307 (Conv2D)            (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1309 (Batch (None, 3, 3, 384)    1152        conv2d_1309[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1310 (Batch (None, 3, 3, 384)    1152        conv2d_1310[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1313 (Batch (None, 3, 3, 384)    1152        conv2d_1313[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1314 (Batch (None, 3, 3, 384)    1152        conv2d_1314[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1315 (Conv2D)            (None, 3, 3, 192)    393216      average_pooling2d_125[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1307 (Batch (None, 3, 3, 320)    960         conv2d_1307[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1309 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1309[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1310 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1310[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1313 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1313[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1314 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1314[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1315 (Batch (None, 3, 3, 192)    576         conv2d_1315[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1307 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1307[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_1309[0][0]            \n",
      "                                                                 activation_1310[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 3, 3, 768)    0           activation_1313[0][0]            \n",
      "                                                                 activation_1314[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1315 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1315[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_1307[0][0]            \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_27[0][0]             \n",
      "                                                                 activation_1315[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "188\n",
      "190\n",
      "Epoch 1/250\n",
      "23/23 [==============================] - 14s 340ms/step - loss: 1.7250 - accuracy: 0.2585 - val_loss: 1.4834 - val_accuracy: 0.4401\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 1.3424 - accuracy: 0.4308 - val_loss: 1.0614 - val_accuracy: 0.6022\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 1.0857 - accuracy: 0.5728 - val_loss: 0.8883 - val_accuracy: 0.6866\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.9449 - accuracy: 0.6644 - val_loss: 0.7647 - val_accuracy: 0.7262\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.8238 - accuracy: 0.7094 - val_loss: 0.6862 - val_accuracy: 0.7561\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.7574 - accuracy: 0.7294 - val_loss: 0.6319 - val_accuracy: 0.7820\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.6772 - accuracy: 0.7673 - val_loss: 0.5965 - val_accuracy: 0.7943\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.6097 - accuracy: 0.7988 - val_loss: 0.5642 - val_accuracy: 0.8120\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.5653 - accuracy: 0.8090 - val_loss: 0.5386 - val_accuracy: 0.8174\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.5098 - accuracy: 0.8309 - val_loss: 0.5188 - val_accuracy: 0.8297\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.4975 - accuracy: 0.8282 - val_loss: 0.4962 - val_accuracy: 0.8433\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.4541 - accuracy: 0.8442 - val_loss: 0.4773 - val_accuracy: 0.8474\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.4150 - accuracy: 0.8628 - val_loss: 0.4637 - val_accuracy: 0.8488\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.3891 - accuracy: 0.8677 - val_loss: 0.4544 - val_accuracy: 0.8501\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.3798 - accuracy: 0.8706 - val_loss: 0.4401 - val_accuracy: 0.8583\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.3339 - accuracy: 0.8794 - val_loss: 0.4276 - val_accuracy: 0.8569\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.3348 - accuracy: 0.8878 - val_loss: 0.4203 - val_accuracy: 0.8597\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.3110 - accuracy: 0.8993 - val_loss: 0.4074 - val_accuracy: 0.8651\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.2893 - accuracy: 0.9086 - val_loss: 0.3961 - val_accuracy: 0.8706\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2734 - accuracy: 0.9101 - val_loss: 0.3887 - val_accuracy: 0.8774\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.2612 - accuracy: 0.9223 - val_loss: 0.3840 - val_accuracy: 0.8719\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2403 - accuracy: 0.9241 - val_loss: 0.3786 - val_accuracy: 0.8760\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.2330 - accuracy: 0.9294 - val_loss: 0.3735 - val_accuracy: 0.8787\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.2179 - accuracy: 0.9372 - val_loss: 0.3724 - val_accuracy: 0.8719\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.2070 - accuracy: 0.9358 - val_loss: 0.3706 - val_accuracy: 0.8801\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1779 - accuracy: 0.9453 - val_loss: 0.3639 - val_accuracy: 0.8815\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1860 - accuracy: 0.9424 - val_loss: 0.3586 - val_accuracy: 0.8815\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1829 - accuracy: 0.9470 - val_loss: 0.3565 - val_accuracy: 0.8842\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1572 - accuracy: 0.9581 - val_loss: 0.3537 - val_accuracy: 0.8815\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.1551 - accuracy: 0.9545 - val_loss: 0.3513 - val_accuracy: 0.8828\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1405 - accuracy: 0.9624 - val_loss: 0.3481 - val_accuracy: 0.8856\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1321 - accuracy: 0.9649 - val_loss: 0.3492 - val_accuracy: 0.8896\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.1267 - accuracy: 0.9703 - val_loss: 0.3499 - val_accuracy: 0.8842\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1166 - accuracy: 0.9664 - val_loss: 0.3501 - val_accuracy: 0.8869\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1069 - accuracy: 0.9708 - val_loss: 0.3497 - val_accuracy: 0.8815\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1048 - accuracy: 0.9741 - val_loss: 0.3565 - val_accuracy: 0.8815\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.1066 - accuracy: 0.9694 - val_loss: 0.3551 - val_accuracy: 0.8828\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0996 - accuracy: 0.9719 - val_loss: 0.3442 - val_accuracy: 0.8896\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0834 - accuracy: 0.9799 - val_loss: 0.3429 - val_accuracy: 0.8856\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0865 - accuracy: 0.9799 - val_loss: 0.3440 - val_accuracy: 0.8856\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0678 - accuracy: 0.9865 - val_loss: 0.3440 - val_accuracy: 0.8883\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0813 - accuracy: 0.9812 - val_loss: 0.3392 - val_accuracy: 0.8910\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0673 - accuracy: 0.9861 - val_loss: 0.3417 - val_accuracy: 0.8924\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0614 - accuracy: 0.9888 - val_loss: 0.3432 - val_accuracy: 0.8910\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0601 - accuracy: 0.9876 - val_loss: 0.3399 - val_accuracy: 0.8910\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0578 - accuracy: 0.9866 - val_loss: 0.3437 - val_accuracy: 0.8910\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0521 - accuracy: 0.9915 - val_loss: 0.3433 - val_accuracy: 0.8896\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0540 - accuracy: 0.9887 - val_loss: 0.3434 - val_accuracy: 0.8910\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0436 - accuracy: 0.9915 - val_loss: 0.3432 - val_accuracy: 0.8896\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0483 - accuracy: 0.9896 - val_loss: 0.3447 - val_accuracy: 0.8910\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0479 - accuracy: 0.9942 - val_loss: 0.3462 - val_accuracy: 0.8924\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 0.3443 - val_accuracy: 0.8965\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0360 - accuracy: 0.9953 - val_loss: 0.3463 - val_accuracy: 0.8978\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0388 - accuracy: 0.9924 - val_loss: 0.3496 - val_accuracy: 0.8937\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0367 - accuracy: 0.9928 - val_loss: 0.3444 - val_accuracy: 0.8896\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0359 - accuracy: 0.9932 - val_loss: 0.3478 - val_accuracy: 0.8924\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0335 - accuracy: 0.9937 - val_loss: 0.3456 - val_accuracy: 0.8896\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0279 - accuracy: 0.9966 - val_loss: 0.3420 - val_accuracy: 0.8924\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0273 - accuracy: 0.9958 - val_loss: 0.3443 - val_accuracy: 0.8937\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0213 - accuracy: 0.9977 - val_loss: 0.3448 - val_accuracy: 0.8924\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0283 - accuracy: 0.9964 - val_loss: 0.3469 - val_accuracy: 0.8924\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0306 - accuracy: 0.9949 - val_loss: 0.3482 - val_accuracy: 0.8951\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0223 - accuracy: 0.9959 - val_loss: 0.3537 - val_accuracy: 0.8951\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.3512 - val_accuracy: 0.8978\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0225 - accuracy: 0.9960 - val_loss: 0.3550 - val_accuracy: 0.8951\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0192 - accuracy: 0.9980 - val_loss: 0.3578 - val_accuracy: 0.8937\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 0.3619 - val_accuracy: 0.8965\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.3612 - val_accuracy: 0.8937\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.3537 - val_accuracy: 0.8937\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.3551 - val_accuracy: 0.8965\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.3577 - val_accuracy: 0.8951\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.3597 - val_accuracy: 0.8951\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0187 - accuracy: 0.9964 - val_loss: 0.3569 - val_accuracy: 0.8978\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.3557 - val_accuracy: 0.8965\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0216 - accuracy: 0.9958 - val_loss: 0.3540 - val_accuracy: 0.9005\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.3577 - val_accuracy: 0.9005\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.3592 - val_accuracy: 0.9005\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0104 - accuracy: 0.9999 - val_loss: 0.3570 - val_accuracy: 0.8992\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.3560 - val_accuracy: 0.8978\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.3610 - val_accuracy: 0.8978\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 0.3634 - val_accuracy: 0.9005\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3604 - val_accuracy: 0.8992\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.3619 - val_accuracy: 0.8992\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.3657 - val_accuracy: 0.8965\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.3677 - val_accuracy: 0.8978\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.3730 - val_accuracy: 0.8992\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.3692 - val_accuracy: 0.9005\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9005\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.3614 - val_accuracy: 0.9005\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0064 - accuracy: 0.9999 - val_loss: 0.3640 - val_accuracy: 0.9005\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.3688 - val_accuracy: 0.9005\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9033\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.3710 - val_accuracy: 0.9033\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.3704 - val_accuracy: 0.9033\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.3720 - val_accuracy: 0.9033\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.3750 - val_accuracy: 0.9046\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9046\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.3774 - val_accuracy: 0.9033\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.3768 - val_accuracy: 0.9033\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.3802 - val_accuracy: 0.9046\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.3801 - val_accuracy: 0.9019\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3778 - val_accuracy: 0.9074\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.3788 - val_accuracy: 0.9019\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.3728 - val_accuracy: 0.8978\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.8978\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.3751 - val_accuracy: 0.9019\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.3824 - val_accuracy: 0.9005\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.3861 - val_accuracy: 0.8992\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9005\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8992\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3919 - val_accuracy: 0.8978\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.3882 - val_accuracy: 0.8951\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.3884 - val_accuracy: 0.8965\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.8992\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9019\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9005\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.3946 - val_accuracy: 0.9005\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.8978\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9005\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3874 - val_accuracy: 0.9019\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9033\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.3951 - val_accuracy: 0.9046\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.3978 - val_accuracy: 0.9046\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9033\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.3998 - val_accuracy: 0.9046\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9005\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.3999 - val_accuracy: 0.9046\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.4054 - val_accuracy: 0.9046\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9019\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9019\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9046\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.4052 - val_accuracy: 0.9046\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9060\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4094 - val_accuracy: 0.9033\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.4034 - val_accuracy: 0.9046\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9033\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9046\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9060\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9060\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.4033 - val_accuracy: 0.9060\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9060\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.4061 - val_accuracy: 0.9033\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4100 - val_accuracy: 0.9019\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.4142 - val_accuracy: 0.9019\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9005\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9005\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9033\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.4094 - val_accuracy: 0.8992\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8978\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.8978\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8992\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9005\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9019\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9019\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9005\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9019\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.4259 - val_accuracy: 0.9019\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9019\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.4243 - val_accuracy: 0.9046\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9046\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9060\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.4231 - val_accuracy: 0.9060\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9019\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4222 - val_accuracy: 0.9046\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9033\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9033\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9033\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 7.9881e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9033\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9033\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4411 - val_accuracy: 0.9005\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9005\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9019\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9019\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9046\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 8.8646e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9046\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 7.9504e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9033\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8992\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9005\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 5.5117e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9033\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 8.0417e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9005\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 9.8122e-04 - accuracy: 0.9999 - val_loss: 0.4386 - val_accuracy: 0.8992\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 9.0007e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8978\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 6.9268e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.8978\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 8.3088e-04 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8992\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4368 - val_accuracy: 0.9019\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9033\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.9791e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9033\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.5287e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9019\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 8.1086e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9019\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 8.7226e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9005\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 5.7257e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9005\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 5.9289e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9019\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.0138e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9005\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.6288e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9005\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9033\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.4462 - val_accuracy: 0.9033\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 5.1894e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9033\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 6.1751e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9033\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 5.9876e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9033\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.6495e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9019\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.4278e-04 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9033\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.8440e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9019\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.3780e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9019\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.7556e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9019\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.9184e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.8992\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.8981e-04 - accuracy: 0.9997 - val_loss: 0.4476 - val_accuracy: 0.9033\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.4045e-04 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9019\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.8579e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9019\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.3222e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9005\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.4958e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9005\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4594 - val_accuracy: 0.9005\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 9.1553e-04 - accuracy: 0.9995 - val_loss: 0.4585 - val_accuracy: 0.9005\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 5.2339e-04 - accuracy: 0.9998 - val_loss: 0.4506 - val_accuracy: 0.9046\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.9991e-04 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9046\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.2831e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9005\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.0315e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.8978\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 9.3660e-04 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.8978\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.6076e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8992\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.3753e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9005\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.9966e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8992\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.4260e-04 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.8992\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.6494e-04 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9019\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.0123e-04 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9019\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 3.7642e-04 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9005\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.0705e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9019\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.7784e-04 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9005\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.1653e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9005\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.4444e-04 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9005\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 5.5370e-04 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.8978\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.5549e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.8965\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.7884e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8965\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.4516e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8992\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.6920e-04 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8992\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.2425e-04 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8992\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.2270e-04 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9019\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.6866e-04 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9005\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.2905e-04 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9005\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.0187e-04 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9046\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.1298e-04 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9046\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.8495e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9046\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.7613e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9033\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.2873e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9033\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 2.2561e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9033\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 3.5472e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9019\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 2.7829e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9033\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 2.4547e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9005\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 1.7087e-04 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9005\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 2.5193e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9033\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 1.8717e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9019\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 3.4560e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flatten\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = flatten(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(len(base_model.trainable_variables))\n",
    "print(len(model.trainable_variables))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4041702,
     "status": "ok",
     "timestamp": 1614245665634,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "kj7B5xTAsFaK",
    "outputId": "79838237-fdd4-4b47-ed81-24f700f8c4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1316 (Conv2D)            (None, 79, 79, 32)   864         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1316 (Batch (None, 79, 79, 32)   96          conv2d_1316[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1316 (Activation)    (None, 79, 79, 32)   0           batch_normalization_1316[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1317 (Conv2D)            (None, 77, 77, 32)   9216        activation_1316[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1317 (Batch (None, 77, 77, 32)   96          conv2d_1317[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1317 (Activation)    (None, 77, 77, 32)   0           batch_normalization_1317[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1318 (Conv2D)            (None, 77, 77, 64)   18432       activation_1317[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1318 (Batch (None, 77, 77, 64)   192         conv2d_1318[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1318 (Activation)    (None, 77, 77, 64)   0           batch_normalization_1318[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling2D) (None, 38, 38, 64)   0           activation_1318[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1319 (Conv2D)            (None, 38, 38, 80)   5120        max_pooling2d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1319 (Batch (None, 38, 38, 80)   240         conv2d_1319[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1319 (Activation)    (None, 38, 38, 80)   0           batch_normalization_1319[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1320 (Conv2D)            (None, 36, 36, 192)  138240      activation_1319[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1320 (Batch (None, 36, 36, 192)  576         conv2d_1320[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1320 (Activation)    (None, 36, 36, 192)  0           batch_normalization_1320[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling2D) (None, 17, 17, 192)  0           activation_1320[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1324 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1324 (Batch (None, 17, 17, 64)   192         conv2d_1324[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1324 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1324[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1322 (Conv2D)            (None, 17, 17, 48)   9216        max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1325 (Conv2D)            (None, 17, 17, 96)   55296       activation_1324[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1322 (Batch (None, 17, 17, 48)   144         conv2d_1322[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1325 (Batch (None, 17, 17, 96)   288         conv2d_1325[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1322 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1322[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1325 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1325[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_126 (AverageP (None, 17, 17, 192)  0           max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1321 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1323 (Conv2D)            (None, 17, 17, 64)   76800       activation_1322[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1326 (Conv2D)            (None, 17, 17, 96)   82944       activation_1325[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1327 (Conv2D)            (None, 17, 17, 32)   6144        average_pooling2d_126[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1321 (Batch (None, 17, 17, 64)   192         conv2d_1321[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1323 (Batch (None, 17, 17, 64)   192         conv2d_1323[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1326 (Batch (None, 17, 17, 96)   288         conv2d_1326[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1327 (Batch (None, 17, 17, 32)   96          conv2d_1327[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1321 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1321[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1323 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1323[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1326 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1326[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1327 (Activation)    (None, 17, 17, 32)   0           batch_normalization_1327[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_1321[0][0]            \n",
      "                                                                 activation_1323[0][0]            \n",
      "                                                                 activation_1326[0][0]            \n",
      "                                                                 activation_1327[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1331 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1331 (Batch (None, 17, 17, 64)   192         conv2d_1331[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1331 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1331[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1329 (Conv2D)            (None, 17, 17, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1332 (Conv2D)            (None, 17, 17, 96)   55296       activation_1331[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1329 (Batch (None, 17, 17, 48)   144         conv2d_1329[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1332 (Batch (None, 17, 17, 96)   288         conv2d_1332[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1329 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1329[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1332 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1332[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_127 (AverageP (None, 17, 17, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1328 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1330 (Conv2D)            (None, 17, 17, 64)   76800       activation_1329[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1333 (Conv2D)            (None, 17, 17, 96)   82944       activation_1332[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1334 (Conv2D)            (None, 17, 17, 64)   16384       average_pooling2d_127[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1328 (Batch (None, 17, 17, 64)   192         conv2d_1328[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1330 (Batch (None, 17, 17, 64)   192         conv2d_1330[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1333 (Batch (None, 17, 17, 96)   288         conv2d_1333[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1334 (Batch (None, 17, 17, 64)   192         conv2d_1334[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1328 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1328[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1330 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1330[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1333 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1333[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1334 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1334[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_1328[0][0]            \n",
      "                                                                 activation_1330[0][0]            \n",
      "                                                                 activation_1333[0][0]            \n",
      "                                                                 activation_1334[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1338 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1338 (Batch (None, 17, 17, 64)   192         conv2d_1338[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1338 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1338[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1336 (Conv2D)            (None, 17, 17, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1339 (Conv2D)            (None, 17, 17, 96)   55296       activation_1338[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1336 (Batch (None, 17, 17, 48)   144         conv2d_1336[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1339 (Batch (None, 17, 17, 96)   288         conv2d_1339[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1336 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1336[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1339 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1339[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_128 (AverageP (None, 17, 17, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1335 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1337 (Conv2D)            (None, 17, 17, 64)   76800       activation_1336[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1340 (Conv2D)            (None, 17, 17, 96)   82944       activation_1339[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1341 (Conv2D)            (None, 17, 17, 64)   18432       average_pooling2d_128[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1335 (Batch (None, 17, 17, 64)   192         conv2d_1335[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1337 (Batch (None, 17, 17, 64)   192         conv2d_1337[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1340 (Batch (None, 17, 17, 96)   288         conv2d_1340[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1341 (Batch (None, 17, 17, 64)   192         conv2d_1341[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1335 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1335[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1337 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1337[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1340 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1340[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1341 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1341[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_1335[0][0]            \n",
      "                                                                 activation_1337[0][0]            \n",
      "                                                                 activation_1340[0][0]            \n",
      "                                                                 activation_1341[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1343 (Conv2D)            (None, 17, 17, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1343 (Batch (None, 17, 17, 64)   192         conv2d_1343[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1343 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1343[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1344 (Conv2D)            (None, 17, 17, 96)   55296       activation_1343[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1344 (Batch (None, 17, 17, 96)   288         conv2d_1344[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1344 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1344[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1342 (Conv2D)            (None, 8, 8, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1345 (Conv2D)            (None, 8, 8, 96)     82944       activation_1344[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1342 (Batch (None, 8, 8, 384)    1152        conv2d_1342[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1345 (Batch (None, 8, 8, 96)     288         conv2d_1345[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1342 (Activation)    (None, 8, 8, 384)    0           batch_normalization_1342[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1345 (Activation)    (None, 8, 8, 96)     0           batch_normalization_1345[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling2D) (None, 8, 8, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_1342[0][0]            \n",
      "                                                                 activation_1345[0][0]            \n",
      "                                                                 max_pooling2d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1350 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1350 (Batch (None, 8, 8, 128)    384         conv2d_1350[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1350 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1350[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1351 (Conv2D)            (None, 8, 8, 128)    114688      activation_1350[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1351 (Batch (None, 8, 8, 128)    384         conv2d_1351[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1351 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1351[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1347 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1352 (Conv2D)            (None, 8, 8, 128)    114688      activation_1351[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1347 (Batch (None, 8, 8, 128)    384         conv2d_1347[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1352 (Batch (None, 8, 8, 128)    384         conv2d_1352[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1347 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1347[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1352 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1352[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1348 (Conv2D)            (None, 8, 8, 128)    114688      activation_1347[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1353 (Conv2D)            (None, 8, 8, 128)    114688      activation_1352[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1348 (Batch (None, 8, 8, 128)    384         conv2d_1348[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1353 (Batch (None, 8, 8, 128)    384         conv2d_1353[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1348 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1348[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1353 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1353[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_129 (AverageP (None, 8, 8, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1346 (Conv2D)            (None, 8, 8, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1349 (Conv2D)            (None, 8, 8, 192)    172032      activation_1348[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1354 (Conv2D)            (None, 8, 8, 192)    172032      activation_1353[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1355 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_129[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1346 (Batch (None, 8, 8, 192)    576         conv2d_1346[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1349 (Batch (None, 8, 8, 192)    576         conv2d_1349[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1354 (Batch (None, 8, 8, 192)    576         conv2d_1354[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1355 (Batch (None, 8, 8, 192)    576         conv2d_1355[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1346 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1346[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1349 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1349[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1354 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1354[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1355 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1355[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_1346[0][0]            \n",
      "                                                                 activation_1349[0][0]            \n",
      "                                                                 activation_1354[0][0]            \n",
      "                                                                 activation_1355[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1360 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1360 (Batch (None, 8, 8, 160)    480         conv2d_1360[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1360 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1360[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1361 (Conv2D)            (None, 8, 8, 160)    179200      activation_1360[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1361 (Batch (None, 8, 8, 160)    480         conv2d_1361[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1361 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1361[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1357 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1362 (Conv2D)            (None, 8, 8, 160)    179200      activation_1361[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1357 (Batch (None, 8, 8, 160)    480         conv2d_1357[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1362 (Batch (None, 8, 8, 160)    480         conv2d_1362[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1357 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1357[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1362 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1362[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1358 (Conv2D)            (None, 8, 8, 160)    179200      activation_1357[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1363 (Conv2D)            (None, 8, 8, 160)    179200      activation_1362[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1358 (Batch (None, 8, 8, 160)    480         conv2d_1358[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1363 (Batch (None, 8, 8, 160)    480         conv2d_1363[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1358 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1358[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1363 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1363[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_130 (AverageP (None, 8, 8, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1356 (Conv2D)            (None, 8, 8, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1359 (Conv2D)            (None, 8, 8, 192)    215040      activation_1358[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1364 (Conv2D)            (None, 8, 8, 192)    215040      activation_1363[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1365 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_130[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1356 (Batch (None, 8, 8, 192)    576         conv2d_1356[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1359 (Batch (None, 8, 8, 192)    576         conv2d_1359[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1364 (Batch (None, 8, 8, 192)    576         conv2d_1364[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1365 (Batch (None, 8, 8, 192)    576         conv2d_1365[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1356 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1356[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1359 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1359[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1364 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1364[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1365 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1365[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_1356[0][0]            \n",
      "                                                                 activation_1359[0][0]            \n",
      "                                                                 activation_1364[0][0]            \n",
      "                                                                 activation_1365[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1370 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1370 (Batch (None, 8, 8, 160)    480         conv2d_1370[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1370 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1370[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1371 (Conv2D)            (None, 8, 8, 160)    179200      activation_1370[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1371 (Batch (None, 8, 8, 160)    480         conv2d_1371[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1371 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1371[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1367 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1372 (Conv2D)            (None, 8, 8, 160)    179200      activation_1371[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1367 (Batch (None, 8, 8, 160)    480         conv2d_1367[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1372 (Batch (None, 8, 8, 160)    480         conv2d_1372[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1367 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1367[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1372 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1372[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1368 (Conv2D)            (None, 8, 8, 160)    179200      activation_1367[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1373 (Conv2D)            (None, 8, 8, 160)    179200      activation_1372[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1368 (Batch (None, 8, 8, 160)    480         conv2d_1368[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1373 (Batch (None, 8, 8, 160)    480         conv2d_1373[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1368 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1368[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1373 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1373[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_131 (AverageP (None, 8, 8, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1366 (Conv2D)            (None, 8, 8, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1369 (Conv2D)            (None, 8, 8, 192)    215040      activation_1368[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1374 (Conv2D)            (None, 8, 8, 192)    215040      activation_1373[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1375 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_131[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1366 (Batch (None, 8, 8, 192)    576         conv2d_1366[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1369 (Batch (None, 8, 8, 192)    576         conv2d_1369[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1374 (Batch (None, 8, 8, 192)    576         conv2d_1374[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1375 (Batch (None, 8, 8, 192)    576         conv2d_1375[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1366 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1366[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1369 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1369[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1374 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1374[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1375 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1375[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_1366[0][0]            \n",
      "                                                                 activation_1369[0][0]            \n",
      "                                                                 activation_1374[0][0]            \n",
      "                                                                 activation_1375[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1380 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1380 (Batch (None, 8, 8, 192)    576         conv2d_1380[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1380 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1380[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1381 (Conv2D)            (None, 8, 8, 192)    258048      activation_1380[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1381 (Batch (None, 8, 8, 192)    576         conv2d_1381[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1381 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1381[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1377 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1382 (Conv2D)            (None, 8, 8, 192)    258048      activation_1381[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1377 (Batch (None, 8, 8, 192)    576         conv2d_1377[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1382 (Batch (None, 8, 8, 192)    576         conv2d_1382[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1377 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1377[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1382 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1382[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1378 (Conv2D)            (None, 8, 8, 192)    258048      activation_1377[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1383 (Conv2D)            (None, 8, 8, 192)    258048      activation_1382[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1378 (Batch (None, 8, 8, 192)    576         conv2d_1378[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1383 (Batch (None, 8, 8, 192)    576         conv2d_1383[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1378 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1378[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1383 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1383[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_132 (AverageP (None, 8, 8, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1376 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1379 (Conv2D)            (None, 8, 8, 192)    258048      activation_1378[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1384 (Conv2D)            (None, 8, 8, 192)    258048      activation_1383[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1385 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_132[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1376 (Batch (None, 8, 8, 192)    576         conv2d_1376[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1379 (Batch (None, 8, 8, 192)    576         conv2d_1379[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1384 (Batch (None, 8, 8, 192)    576         conv2d_1384[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1385 (Batch (None, 8, 8, 192)    576         conv2d_1385[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1376 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1376[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1379 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1379[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1384 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1384[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1385 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1385[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_1376[0][0]            \n",
      "                                                                 activation_1379[0][0]            \n",
      "                                                                 activation_1384[0][0]            \n",
      "                                                                 activation_1385[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1388 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1388 (Batch (None, 8, 8, 192)    576         conv2d_1388[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1388 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1388[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1389 (Conv2D)            (None, 8, 8, 192)    258048      activation_1388[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1389 (Batch (None, 8, 8, 192)    576         conv2d_1389[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1389 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1389[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1386 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1390 (Conv2D)            (None, 8, 8, 192)    258048      activation_1389[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1386 (Batch (None, 8, 8, 192)    576         conv2d_1386[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1390 (Batch (None, 8, 8, 192)    576         conv2d_1390[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1386 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1386[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1390 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1390[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1387 (Conv2D)            (None, 3, 3, 320)    552960      activation_1386[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1391 (Conv2D)            (None, 3, 3, 192)    331776      activation_1390[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1387 (Batch (None, 3, 3, 320)    960         conv2d_1387[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1391 (Batch (None, 3, 3, 192)    576         conv2d_1391[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1387 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1387[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1391 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1391[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_1387[0][0]            \n",
      "                                                                 activation_1391[0][0]            \n",
      "                                                                 max_pooling2d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1396 (Conv2D)            (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1396 (Batch (None, 3, 3, 448)    1344        conv2d_1396[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1396 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1396[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1393 (Conv2D)            (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1397 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1396[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1393 (Batch (None, 3, 3, 384)    1152        conv2d_1393[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1397 (Batch (None, 3, 3, 384)    1152        conv2d_1397[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1393 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1393[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1397 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1394 (Conv2D)            (None, 3, 3, 384)    442368      activation_1393[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1395 (Conv2D)            (None, 3, 3, 384)    442368      activation_1393[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1398 (Conv2D)            (None, 3, 3, 384)    442368      activation_1397[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1399 (Conv2D)            (None, 3, 3, 384)    442368      activation_1397[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_133 (AverageP (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1392 (Conv2D)            (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1394 (Batch (None, 3, 3, 384)    1152        conv2d_1394[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1395 (Batch (None, 3, 3, 384)    1152        conv2d_1395[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1398 (Batch (None, 3, 3, 384)    1152        conv2d_1398[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1399 (Batch (None, 3, 3, 384)    1152        conv2d_1399[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1400 (Conv2D)            (None, 3, 3, 192)    245760      average_pooling2d_133[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1392 (Batch (None, 3, 3, 320)    960         conv2d_1392[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1394 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1394[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1395 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1395[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1398 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1399 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1399[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1400 (Batch (None, 3, 3, 192)    576         conv2d_1400[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1392 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1392[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_1394[0][0]            \n",
      "                                                                 activation_1395[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 3, 3, 768)    0           activation_1398[0][0]            \n",
      "                                                                 activation_1399[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1400 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_1392[0][0]            \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_28[0][0]             \n",
      "                                                                 activation_1400[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1405 (Conv2D)            (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1405 (Batch (None, 3, 3, 448)    1344        conv2d_1405[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1405 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1405[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1402 (Conv2D)            (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1406 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1405[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1402 (Batch (None, 3, 3, 384)    1152        conv2d_1402[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1406 (Batch (None, 3, 3, 384)    1152        conv2d_1406[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1402 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1402[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1406 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1406[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1403 (Conv2D)            (None, 3, 3, 384)    442368      activation_1402[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1404 (Conv2D)            (None, 3, 3, 384)    442368      activation_1402[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1407 (Conv2D)            (None, 3, 3, 384)    442368      activation_1406[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1408 (Conv2D)            (None, 3, 3, 384)    442368      activation_1406[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_134 (AverageP (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1401 (Conv2D)            (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1403 (Batch (None, 3, 3, 384)    1152        conv2d_1403[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1404 (Batch (None, 3, 3, 384)    1152        conv2d_1404[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1407 (Batch (None, 3, 3, 384)    1152        conv2d_1407[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1408 (Batch (None, 3, 3, 384)    1152        conv2d_1408[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1409 (Conv2D)            (None, 3, 3, 192)    393216      average_pooling2d_134[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1401 (Batch (None, 3, 3, 320)    960         conv2d_1401[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1403 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1403[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1404 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1404[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1407 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1407[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1408 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1408[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1409 (Batch (None, 3, 3, 192)    576         conv2d_1409[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1401 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1401[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_1403[0][0]            \n",
      "                                                                 activation_1404[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 3, 3, 768)    0           activation_1407[0][0]            \n",
      "                                                                 activation_1408[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1409 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1409[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_1401[0][0]            \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_29[0][0]             \n",
      "                                                                 activation_1409[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "188\n",
      "190\n",
      "Epoch 1/250\n",
      "23/23 [==============================] - 14s 326ms/step - loss: 2.3789 - accuracy: 0.2188 - val_loss: 2.3421 - val_accuracy: 0.3719\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 1.5238 - accuracy: 0.4149 - val_loss: 1.4276 - val_accuracy: 0.5518\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 1.1614 - accuracy: 0.5484 - val_loss: 1.0501 - val_accuracy: 0.6649\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.9349 - accuracy: 0.6529 - val_loss: 0.8771 - val_accuracy: 0.7112\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.8171 - accuracy: 0.7002 - val_loss: 0.7957 - val_accuracy: 0.7371\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.7444 - accuracy: 0.7455 - val_loss: 0.7411 - val_accuracy: 0.7480\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.6695 - accuracy: 0.7619 - val_loss: 0.7011 - val_accuracy: 0.7725\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.5991 - accuracy: 0.7846 - val_loss: 0.6623 - val_accuracy: 0.7807\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.5601 - accuracy: 0.8000 - val_loss: 0.6289 - val_accuracy: 0.7956\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.5333 - accuracy: 0.8209 - val_loss: 0.6018 - val_accuracy: 0.8025\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.4819 - accuracy: 0.8318 - val_loss: 0.5823 - val_accuracy: 0.8120\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.4781 - accuracy: 0.8226 - val_loss: 0.5650 - val_accuracy: 0.8161\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.4242 - accuracy: 0.8502 - val_loss: 0.5450 - val_accuracy: 0.8161\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.4209 - accuracy: 0.8491 - val_loss: 0.5286 - val_accuracy: 0.8283\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3842 - accuracy: 0.8653 - val_loss: 0.5200 - val_accuracy: 0.8311\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3700 - accuracy: 0.8736 - val_loss: 0.5148 - val_accuracy: 0.8351\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3521 - accuracy: 0.8891 - val_loss: 0.5058 - val_accuracy: 0.8311\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3377 - accuracy: 0.8732 - val_loss: 0.4972 - val_accuracy: 0.8379\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.3280 - accuracy: 0.8833 - val_loss: 0.4910 - val_accuracy: 0.8379\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2876 - accuracy: 0.9122 - val_loss: 0.4871 - val_accuracy: 0.8433\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2853 - accuracy: 0.9062 - val_loss: 0.4815 - val_accuracy: 0.8460\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.2572 - accuracy: 0.9123 - val_loss: 0.4738 - val_accuracy: 0.8406\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.2581 - accuracy: 0.9143 - val_loss: 0.4696 - val_accuracy: 0.8447\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2356 - accuracy: 0.9239 - val_loss: 0.4675 - val_accuracy: 0.8460\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.2282 - accuracy: 0.9229 - val_loss: 0.4588 - val_accuracy: 0.8460\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2191 - accuracy: 0.9257 - val_loss: 0.4544 - val_accuracy: 0.8488\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2062 - accuracy: 0.9331 - val_loss: 0.4463 - val_accuracy: 0.8529\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1851 - accuracy: 0.9405 - val_loss: 0.4450 - val_accuracy: 0.8542\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1849 - accuracy: 0.9437 - val_loss: 0.4444 - val_accuracy: 0.8488\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1814 - accuracy: 0.9420 - val_loss: 0.4432 - val_accuracy: 0.8501\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.1748 - accuracy: 0.9420 - val_loss: 0.4414 - val_accuracy: 0.8569\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.1544 - accuracy: 0.9513 - val_loss: 0.4387 - val_accuracy: 0.8515\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.1603 - accuracy: 0.9487 - val_loss: 0.4318 - val_accuracy: 0.8542\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1407 - accuracy: 0.9562 - val_loss: 0.4320 - val_accuracy: 0.8529\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.1413 - accuracy: 0.9549 - val_loss: 0.4305 - val_accuracy: 0.8610\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1360 - accuracy: 0.9574 - val_loss: 0.4268 - val_accuracy: 0.8542\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1299 - accuracy: 0.9621 - val_loss: 0.4241 - val_accuracy: 0.8569\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.1259 - accuracy: 0.9593 - val_loss: 0.4253 - val_accuracy: 0.8665\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1140 - accuracy: 0.9653 - val_loss: 0.4281 - val_accuracy: 0.8638\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1199 - accuracy: 0.9641 - val_loss: 0.4250 - val_accuracy: 0.8638\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0982 - accuracy: 0.9709 - val_loss: 0.4249 - val_accuracy: 0.8706\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.1128 - accuracy: 0.9664 - val_loss: 0.4243 - val_accuracy: 0.8719\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0898 - accuracy: 0.9773 - val_loss: 0.4217 - val_accuracy: 0.8692\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0899 - accuracy: 0.9771 - val_loss: 0.4210 - val_accuracy: 0.8706\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0874 - accuracy: 0.9757 - val_loss: 0.4215 - val_accuracy: 0.8692\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0774 - accuracy: 0.9783 - val_loss: 0.4245 - val_accuracy: 0.8706\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0813 - accuracy: 0.9784 - val_loss: 0.4265 - val_accuracy: 0.8733\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0715 - accuracy: 0.9809 - val_loss: 0.4291 - val_accuracy: 0.8692\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0641 - accuracy: 0.9842 - val_loss: 0.4270 - val_accuracy: 0.8719\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0652 - accuracy: 0.9849 - val_loss: 0.4204 - val_accuracy: 0.8747\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0592 - accuracy: 0.9861 - val_loss: 0.4203 - val_accuracy: 0.8747\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0534 - accuracy: 0.9866 - val_loss: 0.4215 - val_accuracy: 0.8760\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0545 - accuracy: 0.9851 - val_loss: 0.4248 - val_accuracy: 0.8774\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0544 - accuracy: 0.9892 - val_loss: 0.4252 - val_accuracy: 0.8747\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 0.4273 - val_accuracy: 0.8733\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0518 - accuracy: 0.9882 - val_loss: 0.4348 - val_accuracy: 0.8719\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0446 - accuracy: 0.9902 - val_loss: 0.4315 - val_accuracy: 0.8733\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0494 - accuracy: 0.9877 - val_loss: 0.4312 - val_accuracy: 0.8801\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0357 - accuracy: 0.9969 - val_loss: 0.4319 - val_accuracy: 0.8787\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0439 - accuracy: 0.9923 - val_loss: 0.4287 - val_accuracy: 0.8815\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0417 - accuracy: 0.9886 - val_loss: 0.4304 - val_accuracy: 0.8774\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 0.4327 - val_accuracy: 0.8774\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0353 - accuracy: 0.9950 - val_loss: 0.4303 - val_accuracy: 0.8842\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0365 - accuracy: 0.9921 - val_loss: 0.4277 - val_accuracy: 0.8815\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0305 - accuracy: 0.9943 - val_loss: 0.4254 - val_accuracy: 0.8842\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 0.4268 - val_accuracy: 0.8828\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0302 - accuracy: 0.9934 - val_loss: 0.4303 - val_accuracy: 0.8815\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.4315 - val_accuracy: 0.8828\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0249 - accuracy: 0.9961 - val_loss: 0.4333 - val_accuracy: 0.8842\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 0.4366 - val_accuracy: 0.8856\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.4410 - val_accuracy: 0.8856\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0242 - accuracy: 0.9954 - val_loss: 0.4398 - val_accuracy: 0.8883\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0231 - accuracy: 0.9968 - val_loss: 0.4413 - val_accuracy: 0.8856\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0166 - accuracy: 0.9991 - val_loss: 0.4418 - val_accuracy: 0.8856\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.4422 - val_accuracy: 0.8828\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0187 - accuracy: 0.9967 - val_loss: 0.4406 - val_accuracy: 0.8815\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.4430 - val_accuracy: 0.8828\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0190 - accuracy: 0.9966 - val_loss: 0.4428 - val_accuracy: 0.8842\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.4403 - val_accuracy: 0.8856\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0186 - accuracy: 0.9967 - val_loss: 0.4403 - val_accuracy: 0.8869\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0175 - accuracy: 0.9979 - val_loss: 0.4378 - val_accuracy: 0.8828\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.4352 - val_accuracy: 0.8815\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0136 - accuracy: 0.9987 - val_loss: 0.4382 - val_accuracy: 0.8842\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0171 - accuracy: 0.9983 - val_loss: 0.4376 - val_accuracy: 0.8828\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 0.4385 - val_accuracy: 0.8896\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 0.4404 - val_accuracy: 0.8883\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0148 - accuracy: 0.9979 - val_loss: 0.4438 - val_accuracy: 0.8896\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 0.4424 - val_accuracy: 0.8856\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.4429 - val_accuracy: 0.8869\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0107 - accuracy: 0.9996 - val_loss: 0.4455 - val_accuracy: 0.8856\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.4430 - val_accuracy: 0.8856\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.4392 - val_accuracy: 0.8869\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.4388 - val_accuracy: 0.8883\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0117 - accuracy: 0.9993 - val_loss: 0.4410 - val_accuracy: 0.8883\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.4478 - val_accuracy: 0.8869\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.4516 - val_accuracy: 0.8869\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.4513 - val_accuracy: 0.8869\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.4495 - val_accuracy: 0.8883\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 0.4528 - val_accuracy: 0.8842\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.4531 - val_accuracy: 0.8869\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.4500 - val_accuracy: 0.8910\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.4491 - val_accuracy: 0.8896\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.4534 - val_accuracy: 0.8896\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.4496 - val_accuracy: 0.8869\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4528 - val_accuracy: 0.8896\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.4531 - val_accuracy: 0.8869\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.4542 - val_accuracy: 0.8883\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.4556 - val_accuracy: 0.8883\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8842\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8842\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.4529 - val_accuracy: 0.8828\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.4548 - val_accuracy: 0.8869\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4574 - val_accuracy: 0.8883\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.4613 - val_accuracy: 0.8869\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.4633 - val_accuracy: 0.8842\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.4615 - val_accuracy: 0.8896\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.4681 - val_accuracy: 0.8896\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.4638 - val_accuracy: 0.8842\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.4645 - val_accuracy: 0.8869\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8883\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8896\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.4736 - val_accuracy: 0.8869\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4752 - val_accuracy: 0.8856\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4733 - val_accuracy: 0.8869\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8896\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.4742 - val_accuracy: 0.8883\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.4733 - val_accuracy: 0.8856\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.4648 - val_accuracy: 0.8896\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.4670 - val_accuracy: 0.8883\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.4702 - val_accuracy: 0.8896\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4728 - val_accuracy: 0.8937\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.4717 - val_accuracy: 0.8896\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.4707 - val_accuracy: 0.8924\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8910\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.8937\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8937\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.4794 - val_accuracy: 0.8924\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4831 - val_accuracy: 0.8910\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4829 - val_accuracy: 0.8924\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8910\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.4833 - val_accuracy: 0.8924\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4859 - val_accuracy: 0.8896\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4846 - val_accuracy: 0.8910\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8924\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.4888 - val_accuracy: 0.8924\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.4883 - val_accuracy: 0.8924\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.8937\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4844 - val_accuracy: 0.8924\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.8951\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.4917 - val_accuracy: 0.8937\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.8951\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.4878 - val_accuracy: 0.8924\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4839 - val_accuracy: 0.8937\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.8951\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8978\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.4946 - val_accuracy: 0.8951\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.4940 - val_accuracy: 0.9005\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8992\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8978\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5032 - val_accuracy: 0.9005\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8978\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.8937\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5041 - val_accuracy: 0.8937\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.5058 - val_accuracy: 0.8896\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5036 - val_accuracy: 0.8896\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.5015 - val_accuracy: 0.8896\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8924\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.5079 - val_accuracy: 0.8951\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8896\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.5010 - val_accuracy: 0.8910\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.8924\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8910\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8937\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8937\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.8910\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8924\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5035 - val_accuracy: 0.8951\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8937\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8937\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 8.6834e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8951\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.8937\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.8951\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.5156 - val_accuracy: 0.8937\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5282 - val_accuracy: 0.8937\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8937\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8937\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8937\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.8896\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8869\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 9.0915e-04 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8896\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.5296 - val_accuracy: 0.8896\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 7.7424e-04 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8910\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 9.3782e-04 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8896\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.8896\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 8.3515e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8883\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 9.8299e-04 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.8910\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 7.1374e-04 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8910\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 9.9280e-04 - accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.8924\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5408 - val_accuracy: 0.8910\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 7.8188e-04 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8937\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 7.3618e-04 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.8937\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 7.7753e-04 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8924\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 8.5886e-04 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8924\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 6.4521e-04 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8924\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5337 - val_accuracy: 0.8937\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 8.5589e-04 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.8937\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 5.7934e-04 - accuracy: 1.0000 - val_loss: 0.5359 - val_accuracy: 0.8910\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 9.7214e-04 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.8910\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 5.7650e-04 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8910\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 6.2991e-04 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8869\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 8.8397e-04 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.8896\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 6.3432e-04 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.8883\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5652 - val_accuracy: 0.8842\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 6.3839e-04 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8856\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.8828\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 8.4497e-04 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8856\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.8869\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 7.9401e-04 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.8896\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 5.4854e-04 - accuracy: 1.0000 - val_loss: 0.5696 - val_accuracy: 0.8856\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 6.0741e-04 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8856\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 6.7422e-04 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.8883\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 4.5457e-04 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8883\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 7.1164e-04 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.8910\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 6.9219e-04 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.8883\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 4.9397e-04 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8896\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 7.3802e-04 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.8896\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 4.1929e-04 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.8924\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 7.0947e-04 - accuracy: 0.9999 - val_loss: 0.5574 - val_accuracy: 0.8951\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5734 - val_accuracy: 0.8951\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.5633 - val_accuracy: 0.8924\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.4112e-04 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8896\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 6.0133e-04 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.8883\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.5569 - val_accuracy: 0.8896\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.7386e-04 - accuracy: 0.9998 - val_loss: 0.5504 - val_accuracy: 0.8924\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.8924\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.5207e-04 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.8965\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.3085e-04 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.8951\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.6536e-04 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.8965\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.3829e-04 - accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.8951\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.3142e-04 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8978\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.8487e-04 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.8978\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.5467 - val_accuracy: 0.8978\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 6.0322e-04 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.8992\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.1110e-04 - accuracy: 1.0000 - val_loss: 0.5471 - val_accuracy: 0.8965\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.1436e-04 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.8965\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.2451e-04 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.8965\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.5273e-04 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8978\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.6895e-04 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8965\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.3874e-04 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.8978\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.9729e-04 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8992\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAHwCAYAAACVNQcNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gc5bX48e9Z9Wpblty7ccfIRdgUQ0xLaLHp4IRiCJBwQ7hASEISAoRcAjfhJrn8AtwQQgvFEBKIAVMCxpgabIMBV3DFcpUlW8VqW87vj3ckr2WVlbzyatfn8zx6tDPzzszZV6M5877TRFUxxhhjTOz4Yh2AMcYYc6izZGyMMcbEmCVjY4wxJsYsGRtjjDExZsnYGGOMiTFLxsYYY0yMWTI2cUlEXhGRy6JdNpZEZIOInNwJy10gIld6n78tIq9HUrYD6xkkIlUiktTRWI05VFkyNgeNt6Nu+AmJSE3Y8LfbsyxVPU1VH4t22a5IRG4WkYXNjM8XkXoROTzSZanqk6r69SjFtc/Bg6p+parZqhqMxvKbWZ+IyDoRWdEZyzcmliwZm4PG21Fnq2o28BXwzbBxTzaUE5Hk2EXZJT0BHCMiQ5uMvwj4XFWXxSCmWDge6AUME5EjD+aKbZs0nc2SsYk5EZkuIsUi8hMR2QY8IiI9ROQlESkRkV3e5wFh84R3vc4WkXdF5B6v7HoROa2DZYeKyEIRqRSRN0TkPhF5ooW4I4nxVyLynre810UkP2z6JSKyUURKReTnLdWPqhYD84FLmky6FHi8rTiaxDxbRN4NGz5FRFaJSLmI/BGQsGnDRWS+F99OEXlSRLp70/4KDAJe9Ho2fiwiQ0REGxKXiPQTkbkiUiYia0TkqrBl3y4iz4rI417dLBeRopbqwHMZ8E9gnvc5/HuNE5F/eevaLiI/88YnicjPRGStt54lIjKwaaxe2abbyXsi8nsRKQVub60+vHkGisg/vL9DqYj8UURSvZjGh5XrJSLVIlLQxvc1hxBLxqar6APkAYOBq3Hb5iPe8CCgBvhjK/NPBVYD+cBvgL+IiHSg7FPAR0BP4Hb2T4DhIonxW8DluBZdKnATgIiMBR7wlt/PW1+zCdTzWHgsIjIKmODF2966alhGPvAP4BZcXawFjg0vAtzlxTcGGIirE1T1Evbt3fhNM6uYAxR7858H/FpETgybPsMr0x2Y21rMIpLpLeNJ7+ciEUn1puUAbwCveus6DHjTm/VGYBZwOpALXAFUt1oxe00F1gG9gTtbqw9x58lfAjYCQ4D+wBxVrfe+48Vhy50FvKmqJRHGYQ4Fqmo/9nPQf4ANwMne5+lAPZDeSvkJwK6w4QXAld7n2cCasGmZgAJ92lMWl8gCQGbY9CeAJyL8Ts3FeEvY8H8Ar3qfb8XtrBumZXl1cHILy84EKoBjvOE7gX92sK7e9T5fCnwYVk5wyfPKFpZ7FvBJc39Db3iIV5fJuEQVBHLCpt8FPOp9vh14I2zaWKCmlbq9GCjxlp0OlANne9NmhcfVZL7VwMxmxjfG2ko9fdXG37uxPoCjG+JrptxU3IGLeMOLgQti+f9nP13vx1rGpqsoUdXahgERyRSRP3nduBXAQqC7tHyl7raGD6ra0PLJbmfZfkBZ2DiATS0FHGGM28I+V4fF1C982aq6ByhtaV1eTH8DLvVa8d8GHm9HHM1pGoOGD4tIbxGZIyKbveU+gWtBR6KhLivDxm3EtRgbNK2bdGn53OxlwLOqGvC2k7+zt6t6IK5V35zWprVln799G/UxENioqoGmC1HVf+O+33QRGY1ruc/tYEwmQVkyNl1F09eH/RAYBUxV1VzcxTsQdk6zE2wF8rwu0QYDWyl/IDFuDV+2t86ebczzGHABcAqQA7x4gHE0jUHY9/v+Gvd3Ge8t9+Imy2ztlW9bcHWZEzZuELC5jZj2453/PhG4WES2ibuu4DzgdK+rfRMwrIXZNwHDmxm/x/sd/rfu06RM0+/XWn1sAga1cjDxmFf+EuC58ANPY8CSsem6cnDnPneLSB5wW2evUFU34roQb/cuvDka+GYnxfgccKaITPPOfd5B2/+P7wC7gQfZez7yQOJ4GRgnIud4SeQ69k1IOUAVUC4i/YEfNZl/Oy0kQVXdBLwP3CUi6SJyBPAdXGuyvS4BvsAdcEzwfkbiutRn4c7V9hWR60UkTURyRGSqN+9DwK9EZIQ4R4hIT3XnazfjEnySiFxB80k7XGv18RHu4OZuEcnyvnP4+fcngLNxCfnxDtSBSXCWjE1X9QcgA9gJfIi7OOdg+Dbu/F8p8F/AM0BdC2U7HKOqLge+j7sAayuwC5dcWptHcTvywey7Q+9QHKq6EzgfuBv3fUcA74UV+SUwCXd+9mXcxV7h7gJuEZHdInJTM6uYhTs3uwV4HrhNVd+IJLYmLgPuV9Vt4T/A/wGXeV3hp+AOnLYBXwInePP+DngWeB13zv0vuLoCuAqXUEuBcbiDh9a0WB/q7q3+Jq4L+ivc3/LCsOmbgI9xLet32l8FJtE1XFBgjGmGiDwDrFLVTm+Zm8QmIg8DW1T1lljHYroeS8bGhBH3MIkyYD3wdeAF4GhV/SSmgZm4JiJDgKXARFVdH9toTFdk3dTG7KsP7haXKuBe4BpLxOZAiMivgGXAby0Rm5ZYy9gYY4yJMWsZG2OMMTFmydgYY4yJsZi9iSQ/P1+HDBkSq9UbY4wxB92SJUt2qup+LwmJWTIeMmQIixcvjtXqjTHGmINORDY2N966qY0xxpgYs2RsjDHGxJglY2OMMSbG2kzGIvKwiOwQkWUtTBcRuVdE1ojIZyIyKfphGmOMMYkrkpbxo8CprUw/DfeA+RHA1cADBx6WMcYYc+hoMxmr6kLcs3pbMhN4XJ0PcS817xutAI0xxphEF41bm/rjXqzdoNgbtzUKyzaHMFXl4692s2hDGaP75DBxUA+6ZaSgqpRU1VG8q4ZAUMnLSqF7Zio+EdbvrGJdyR62ldcyrCCb4b2yyEpNpqLWz46KOnZU1lIfCJGWksTW3bVsq6ihzh+iPhhCgSMH92BIfhYrtlZQvKuGytoA/btn0Ds3jdRkH6lJPgIhZcPOPVTXB0lL9pGekkRaso+0FB8llXVs3l2DT4TUJB+pyT4yUpPITksmMzWZnVV1fLmjimH5WQzMy2TV1gq+KqumbE89ST4hJclHSpKQlpxEeoqv8XdKko9d1X6q6wPkZ6cRDCmle+pITU4iNUmoC4So9Qep9YeoCwRJ9vkoyEkjpEogqOTnpFFTH2RTWTU+n5CR4uLOSEkiPdX9DoWUXdX1lFX7qa4LkJGaRFZqMhmpSeyqrqe8xt/4t/GJkJeVSlZqEtX1QXLSk8lKS2ZTWTV1gRAFOWmoQl2gIaYQgWCIHlmp5KanEFLFHwwRDCmBkFLnD1JdHyTFq7Oa+iAh1cZhn4A/6ObxB0NePbm6Cir4A268T4TMtCRCCvXeOAFSk135ZJ80v621sR22OK3FeVpZXivram3Gjq2rleW1MKmjsXfk0cpRj73VdbW/bgHmXjuN7LTOvwv4oN5nLCJX47qyGTRo0MFctekEoZDy2AcbKN5Vw+nj+zKmbw6ZqXs3qS+2V7Kzso4t5bUs31JOIKikp/iorg/SLSOFSYN68FVZNcW7aigc2I2PN+7iH59sZvLgHozqncPLn2+leFfNPuvsmZVKVV2AukDogOMXgfzstMZkVx8I8fJne48he2alkp2ezKvLtuIP7vvvmprsIzst2UuAQUK6d/yAHu51ufWBEPWBEDX1QarqA6hCWrKPoflZfLS+lFp/iJ5ZqQwvyGZ4QTaKunmCbr6dVYHGZFYfCNE9M4XM1CSWbtpNcpLQMyuV8ho//kCoMXHnZyeTnpJEXSBESWUdST4h2Sd8VrybtGQfg/KyEIFaf5Ca+iAVtX5q6t06RKBHZirdM1Po1y2d6voge+oClJf76ZGVQr9uGYiXy4IhpbSqnh2VdWSlJrN5dy0VNX4G5WXSLSOFkqo6fCKkJyeRk55MfnISKUlC6Z56indVk5Lk8w4+hCSf0C0zlX7dk/AHXeLunZtGkk+8+lBCIfUSqpDs8xEIhbxkq/h8DQc+QiCo1PiD+ES8RC6o0rjcYEgbv8N+2wMtTPC2lfZvX60sr9X5Wpl20NbVsbroyLo6Wu8dWV5HJiV15I/fAdFIxpuBgWHDA7xx+1HVB4EHAYqKiuwNFXFgZ1UdSSL0yEptHLdh5x7W7Kji2cWbeH3FdpJ9wl/edS+j6dctnSumDWXJxl28smxb4zwZKa6FV+sPkZmaRHmNn4CXwVKTfTz8Xohkn3DymN58smkXC78oYdqIAm44eSTHjcxn9bZKlm2uYGPpHrLTkhmYl8mAHhlei7Ge3dVueUN6ZjKsIJveuWms3bGHr8qq2VMfIDc9mYKcdHrnppGWnERNfZBeuWmkpyTt833X73St6rF9c+mWmQJAIBiiojaA30uSPp/QJzedJK+Vpepad7X+IJmpyY3jw6m6JJGa5CPZS/y7q+spyElrdUdqjDk0RPTWJu9dnC+p6uHNTDsDuBY4HZgK3KuqU9paZlFRkdoTuLoOVWVnVT3rd+5hU1k12enJfFa8mwcXriMYUiYN6sGkwT34qrSaV5e7JJvkE35++hjOKxrA26tL2LSrmoVflPDhujJSk3384ITDKBqSR0FOGkPzs/ZJUtX1AT4vLmdAXia9c9JYubWSvOxU+nfPIBAMURsIHZSuIWOMOZhEZImqFu03vq1kLCJPA9OBfGA7cBuQAqCq/yfusP6PuCuuq4HLVbXNLGvJOLaKd1WzbHM5a0v28NH6Mj75ahcVtYH9yp0zsT8DemTw9hclrNxaSVqyj8unDeXE0b0Y2CODntlp+83zeXE53TNTGJiXeTC+ijHGxI0OJ+POYsm4c/mDIXbtqcfnE/IyU1Hg883lzPt8K68s28qmsr3nYkf0yubIoXmM6JXNsIJsBvbIaLw4aUTvnMZy9YEQipKWnNTMGo0xxrSlpWRs/YAJaP3OPcx+5CM2llYDkJ7iI9nno6ouQLJPOH5kAd85digTB/VgWEEWOekpES03Ndke2GaMMZ3BknGCWLm1gv95/QuCoRCfFZejwG3fHItPhE1l1dQGghw5JI/jRxTsczGWMcaY2LNkHMd27annqY++YtW2Sl75fCu5GSn07ZbO4J6Z3HN+IcMKsmMdojHGmAhYMo4zry3fxmvLt3H0sJ7cO/9LinfV0K9bBudOGsBPThtNnrV6jTEm7lgy7uL8wRDVde4JRyVVddz0t0+pqgvwj4830zs3jef/41gmDOwe6zCNMcYcAEvGXVR9IMQdLy3nyX9/hSoMy8+iZ3Yq9YEQ/7rheHZV+zmsINvO/xpjTAKwZNzFvPTZFt5cuYOVWytYta2Si44cyJD8LP62eBOLNuzix6eO4rBeOW0vyBhjTNywZNyFPPHhRm55YRkFOWn0yknjj9+ayJlH9APgymlD+bR4NxMH9ohxlMYYY6LNknGMBEPKO1+WsGB1Ccu3lLN5Vw1byms5cXQvHrh40n4P1khO8jF5cF6MojXGGNOZLBnHwKINZdz47FI2ldWQkZLEuH65HD08n2EFWVx53FB7wpUxxhxiLBkfZC98spkfP/cZ/Xtk8P9mTeQb4/rYk62MMeYQZ8n4ICmv8fM/r6/m8Q82MnVoHn+6ZDLdM+1KaGOMMZaMO9Wf3l7L3E+3sLvaz+bd7sUMVx8/jB99YxQpSdYaNsYY41gy7iRLN+3mrldWccSAbhQN6cG3eg/imOE9mTjIroY2xhizL0vGnSAUUm6fu5yCnDSeuuoostOsmo0xxrQsor5SETlVRFaLyBoRubmZ6YNF5E0R+UxEFojIgOiH2vWpKve9tYZv/vFdlm7azc2njrZEbIwxpk1tJmMRSQLuA04DxgKzRGRsk2L3AI+r6hHAHcBd0Q40HvxtcTG/fW01ack+bjljDGdP7B/rkIwxxsSBSJptU4A1qroOQETmADOBFWFlxgI3ep/fAl6IZpBd2ebdNdzx4nKOG1HAb15dxZShecy56ih8Pol1aMYYY+JEJMm4P7ApbLgYmNqkzKfAOcD/AmcDOSLSU1VLoxJlF/bwu+t5bfl2Xlu+ndRkH3edM94SsTGdJRSC3RuhxxAoWwcv3wgI9JsI/SZA6VpY9RL0nwxF34Feo2MdsYmVPaWwe8Pe4ZrdsO0z6DYQRp8JKel7p9VVQfkmyBsG4oMdK2HrUti+Ak69C6Tz9+nROqF5E/BHEZkNLAQ2A8GmhUTkauBqgEGDBkVp1bFT6w/y94+LOWN8Xy48ciDJScLwguxYh2XMgQkGXMLrOXz/aeXFULEVfEmQPwLSDuClJbUVbj15w6FqOyz7O2T0gG4DYPtyyMqHcedA/R7Y8glsXgyfPbt3nj07XRzdBsD790Io4Jbb5whY8ih89Gc48jtwxIWQnA59xje/U925Br58DUae2vx3Bti1AapK3A689+FuOaEQrJsPmxa5pJ/bH4L1bgdeU+bK1VVC2VroOQLyhgLNrN+X5GJOiuL1JQ3xJiVD/khIzdo7LRSCXeuhusxb93hISoneujtCFTb9G754FYJ+lzCPuAAyW3kEcCjo/s6LH4HuA9133LbMbTdpufDl6xDyNz9vag5kdN+7nMqtgIIvxSXjYJ2bltYNpt0AOb2j+W2bJaraegGRo4HbVfUb3vBPAVS12fPCIpINrFLVVi/iKioq0sWLF3co6K7in0s3859zlvLklVM59rD8WIdjWhMKQeka6NYfELczyh8Z/Z1Q2Tr49BnoPsjtfMXndnapWVC53e3Es3sd2Doqt7v1pKRD3wn7JhhV992S0rzvGiYUgpKVkNN3704uFIKSVS6hJafBxvfh9Vtg+zIYexYUjIYV/9wb8/q3wxYorg77HuES4+6vXHmfD0pWw8ApMPwk2PmFS6Y7VrhED6AhqNrmLcbnhpvjS96bZBEYMg1GfB1Wv+ISzYw/Qo/B4K+FHcshvbtLqHt2wsLfwkcP7l324GPhuB9CSqYbrtgMHz8G6xe64bRcOOlWqC6FLUtd3D2GgL8Gvnp/b0x5w6H3ONi8xC0jGvqMh9N+C4OPdslh66cQqIM9O1yCycyDXmPc3zWzp9u21rwB698BDcKujXvjDdTCxvf2Llt8kN2bxgOBukqor9w7PbsPjDrNHbAApGRA0eVuG965xm27uX3b/g41u13MzSWuUNAlx+3LYdzZLp6S1e7gZdvnsOQRt334kiEpFfzV7ruOOwsmXgz9iwAvYX/8V/fbX+MOevpOcAds/mp3AFS9Eyq3wdiZMPR49/0bvlfvw13drpzrYm3QfbDbjkpWuYOBfhPdT4+hbnuOIhFZoqpF+42PIBknA18AJ+FavIuAb6nq8rAy+UCZqoZE5E4gqKq3trbceE3GlbV+ctJTUFUu+NMHbK+oY8FN061r+kAEA7BztTtSr90Nn85xXUbjz3f/aMnp0H+SO4pvqq4Stn7mdvYhPxx55f6ttVAQnv8efP6s948pbgdWMBqOvtYlkeQ01zpJyYA9Ja6LqmGHHAq6nWGfIyC9m7dQdfOVrYfCC10L7pO/wgf37z2qbpCaA30LvR26wPATvBbTejd96PHw9V9Bbr+982xbBv/+P/e9NOTqYewMt/N64T+gvsqVG/NNOOHnLmFufN/FXVvuredEGHGKW+62z13Ls2ydm69gtKvfL193OzbYm/hy+7tuvI8fczusIdNcvHWVrpXZf5Ibv325i2/b565+egyGHatc3fY8DDa8B/49NCbtPuNd/TboPtgllZLVrv4LZ7n1V2xxiadktdtp5vZ3XdB9joC0dvY8la519Vy2FhbcBTW79p3ebRBMvtTV1YvXu27MhngLRkLZBlfnhRe59VduhaVPud99C139j/yGO9DbU+p23PmjXAt/xwpIzXZdn6Vr3PdqTuVWF1vFZrfM6l1Q/lVYAQGa7KclydVzcoZLXjl9mo/XX+3+PpVb987bkJRy+7lt5bNnYdOHe1fh3+NaiD0Pg+2fe3+rQXDiL1zSLl3jtp+UDFe/G951PyvnukR21DWul6Fii/ufKFntDhDqKlr+Tn0nuAOAw89zf+Ntn7tW76fPuAMHSXLlNeQOuEZ83W0zw09w/3sHoRs5WjqcjL2ZTwf+ACQBD6vqnSJyB7BYVeeKyHm4K6gV1039fVWta3mJ8ZmMl2zcxYV/+oArpg2lT246d7y0gjtmjuPSo4fEOrTYCoVcMs0b5v5BwO2IX7wOhhzn/pE//5vbaTSc20tKdcmuYWceqNm7vMx8N8+Wj/eOyx0Ah5/j5q3c7iXLT2Dnl+zzT53TF4qucDuaZX93LYb0XFf26GvdUb6GXLn3/uASanMtM1+Ka/30Hudirdzm4vRXh62rD2TkwcZ3vREC48+Dk3/pkmXFFrcTWv6C+y5jvukS+4p/uvXnH+Z2Xsv+4dafluOSfd4wWLfAxTpwiouveLFrBYA7Hzr9Z64O3rrTzdvQAu830e3YKre5pNGwUxcfDDzKHTjU7HIty03/dq2s425y8fprXDIYcYpbd9UOr8uwg3cF1Fa4v0/BqPYn0c5Qs8ttcw1Ss1xdNhzkBercucKeww+s+70j6qrg06dh6ZNuG5jwbcgqcNtur3HuIHXnF+5gpXKbS/QDp7qkF+3end2b4F+3uq7u8ee7RPfZM+5/qEF6d3eaonjR3uHDz3UHxB8/vrdc98EwbLo70Bs23R3Iff6cq+s+h7teiuxe7v+sOfV73P/Clk9cQu43EYZ9bd+DujhzQMm4M8RjMp79yEcs/KKEkFdlp4ztzYOXTEbi6KgsIg3nlOqr3NF1c9/v0zmw4G7XGtq10ZXPGw7Tf+qO2F+60e1Iana5hDTwKJeotyyFunK3jJQst/NvSNA5fbyEPQmSU92OvHKbO5/4yROw4Z29XZY5ffd2JfWd4Obf/RW8evPeHUTuADd+55euq+vY6/b9Dv4aN63nYa410dBtlp4LBWNcDJFY86ZrUY07x9VHe5Wth8V/cV2te3a4c45Dj3MtkYbu5KDfJdCKzTD58r0Xn2z8wJ1LHXuWO2/WVOU2d1BQMGrf84bgdrYZee77GtOaUNAl5N3eRU6rX3b/O4ef67qDw7tzd65xLfHUTOg7MerdvPHOkvEB+ry4nG/+8V1+9I1RlO2pZ9GGMv56xVS6Zcb4wof28te48yJ9Ct0/SaAeVr0Ia99y/3Dlm9w5lYYupYIxMOZML+FNdDv0Zc/Byze5ri6fz51rG3kqLH7YdQeCu2Bl9ssuodVW7E1Sqq6rNBRwSbC5rucWY691rYPsXi5xt6S23CXmXmPbt3xjjOlkLSVjezxUhO6d/yW56clcevRgctK7YAL218Abv3Stx+oy16Wb2991H/cY4lpAm5fAihdcsuo/GQYf41q4e0rc9NQs1zU2/nyXeDXoWqTv/M59Djf0eJj1jDv6bTDlKteVqyHX7dTQEssIex63SMtXrLYlJd1dLNSW9G6uy9YYY+KEJeMI/HtdKf9asZ0fnjKyayRiVXelaHo377aNNHh6lju3MvxEd7713//nWp/p3d35JnAXEo38ursy8d3fw5b73QUZky938zXXnTR5NtRXu6trt3ziuq77TnDJuOm5quQ0GLDfAZ8xxpg2WDd1G0IhZcZ971JaVc/8H04nIzUG3Z47v3QXlDR0zX70Z5h3U5NCAmfdDxO+5Qb3lLqLKXL67L1KufuQvQm3vtqdy23tPj5jjDFRZd3UHVAfCPHfr65i2eYK/nDhhM5NxP4ad8XskGn7XjC19TN4+BvuvOzsl91l/q/f4u7fPOkX8MXrrgU8cCqMOHnvfFk9937OzNs/6aZm7tvFbIwxJmYsGTejqi7AC59s5okPN7JqWyXfmjqIGYX92p4xEhs/gLXz3RWux/6nuzewvhqevtA9fGDsWa7reeWL7kkyy/7hupqD9fCn4909gFkFcNYD7ub6fhOjE5cxxpiYsWTcjJ889xkvf76Vw3pl86dLJvONca1cuRupnWtg/h3uHlPxuQdZrPinu+hp3Vvulp8jLnT34654wSVgf7UrN/sld9/raz919+1OuvTAn+JkjDGmy7Bk3EQopCz8soTzJg/gt+cdEdk9xDvXuKcVpWS4x+3VVbqn2mz5xD2arbbcXcmcnAEn3gJH/Yc7j/vMxfDu79w9euf8GY44H6Z+1z3UYsQp7kItDe69wf3Sf3bulzfGGBMTloybWFNSRWVtgKOG9Ww7EYdCsODX7srmhkcJrn7F3eNau9vdWpTT1z3I4sRfwMRL9j63NTULrl7grk4Of9pP/8md9dWMMcZ0UZaMm1i8wT27dvLgHvtOCNS7B0j4ktxjFhc/4h4ov2OFe3TdSbe5Zw+/8H33yLfTfgO9x7a+MpGD/9g9Y4wxXY4l4yaWbNxFz6xUhvT0rjRWdc9Sff3nrjU79ix3j27P4a7Ve+bv3X26Iu5tJKNOdy3hRHtEpjHGmE5jydjz8Ve7GNgjkyUby5g0uId72djih+HDB9wjGPtNdOeC3/2de+D5rDnNP6y84UUJxhhjTIQsGQMvfrqF6+Z8Qs+sVHZW1TNryiD3armXbnDncM9+0L2NJxRw7xAdfmJcvzXEGGNM13LIJ+N/ryvlxmeXMnFgd8r21LOzqp6iQTkw71b3dpLLX9379h5fEow+I7YBG2OMSTiHfDK+b8FaCrLTeOTyKUjFZna8+xjDl851bza64PHIX6NnjDHGdFBEyVhETgX+F0gCHlLVu5tMHwQ8BnT3ytysqvOiHGvU7akL8OHaUi47ZjDdPv0LvPlLchteHj/qDBgzI7YBGmOMOSS0mYxFJAm4DzgFKAYWichcVV0RVuwW4FlVfUBExgLzgCGdEG9UvfPlTuqDIc7L/ARe/QmM+Dqcfo976xHYFdHGGGMOikhaxlOANaq6DkBE5gAzgfBkrECu97kbsCWaQXaW+au2Mzy9gpEf/dxdLX3RU/u/FtAYY4zpZJEk4/7AprDhYmBqkzK3A6+LyA+ALOBkurhQSFm0cj2Ppf0OCdTBOQ9ZIjbGGBMTzbxNvkNmAY+q6gDgdKOzaXUAACAASURBVOCvIrLfskXkahFZLCKLS0pKorTqjlm2YSt/8P+S/v71cP6jkH9YTOMxxhhz6IokGW8GBoYND/DGhfsO8CyAqn4ApAP5TRekqg+qapGqFhUUFHQs4igpW/gnCn3rqJnxEIz8RkxjMcYYc2iLJBkvAkaIyFARSQUuAuY2KfMVcBKAiIzBJePYNn1bEwww5qunWJFyONkTzop1NMYYYw5xbSZjVQ0A1wKvAStxV00vF5E7RKTh3p8fAleJyKfA08BsVdXOCvpA7VryN3qHdrBx9HdiHYoxxhgT2X3G3j3D85qMuzXs8wrg2OiG1knqq5GF97A21JcR086NdTTGGGNM1C7gig+q8M/vk1u1lj9lfIfhvXLbnscYY4zpZIdWMv7kCVj+D+4JziJn/BmIPdTDGGNMF3BoJeMV/6Qiawj3+89g5oR+sY7GGGOMAQ6lZOyvhQ3v8h5HMCw/m/H9u8U6ImOMMQY4lJLxVx9AoIa/7R7FzAn9rYvaGGNMl3HoJOO18wlKMh8Gx1gXtTHGmC7lkEnGuvZNPvONYczgvgzJz4p1OMYYY0yjQyMZl6xGti/n9dpxXFA0INbRGGOMMfuI6KEfcU0VXrqR6qQc5gZP5LUjrIvaGGNM15L4LeOlT8HGd/nvwCyOGj+a7LTEP/4wxhgTXxI/GX94P9X543m87nhOGds71tEYY4wx+0nsZFxVAtuXsabniSg+xvTNiXVExhhjzH4SOxlvWAjAIhlPeoqPgT0yYxyQMcYYs7/EPoG67m1Iy+Xtyv6M7B3C57MHfRhjjOl6ErtlvH4hDJnGyh3VjOxtXdTGGGO6psRNxru/gl3r2dP/WEoq6xjdx5KxMcaYrimiZCwip4rIahFZIyI3NzP99yKy1Pv5QkR2Rz/Udtr4PgBrMicCWMvYGGNMl9XmOWMRSQLuA04BioFFIjJXVVc0lFHVG8LK/wCY2Amxts/OL0CS+LS2F7CbUdYyNsYY00VF0jKeAqxR1XWqWg/MAWa2Un4W8HQ0gjsgpWugx2BWldTSLSOFXjlpsY7IGGOMaVYkybg/sClsuNgbtx8RGQwMBea3MP1qEVksIotLSkraG2v7lK6Dnofx5fZKRvbOtlcmGmOM6bKifQHXRcBzqhpsbqKqPqiqRapaVFBQEOVV77MiKFsHecNZW7KHw3pld966jDHGmAMUSTLeDAwMGx7gjWvORXSFLurKbeDfw56cIZTtqWd4gSVjY4wxXVckyXgRMEJEhopIKi7hzm1aSERGAz2AD6IbYgeUrgFgs68vgCVjY4wxXVqbyVhVA8C1wGvASuBZVV0uIneIyIywohcBc1RVOyfUdihbC8AXfvdiiGEFWbGMxhhjjGlVRI/DVNV5wLwm425tMnx79MI6QKVrISmNZVXZpCbtYoA9k9oYY0wXlphP4CpdC3lDWbOzhqH5WSTZM6mNMcZ0YYmZjMvWQs/DWFeyx7qojTHGdHmJl4xVoWw9we5D2FhWbRdvGWOM6fISLxnXV0Gwjl3SnWBIGd7LWsbGGGO6tsRLxrUVAGyrc4+/HJZvLWNjjDFdWwIm43IASoMuGffrnhHLaIwxxpg2JV4yrnMt49KAS8I9MlNiGY0xxhjTpsRLxl439U5/Gt0yUkhOSryvaIwxJrEkXqbyWsY76tPIy0qNcTDGGGNM2xIvGdfuBmBrXRrdrYvaGGNMHEjAZOxaxptrUsjLtJaxMcaYri/xknFdBfhS2F4NPayb2hhjTBxIvGRcWw7puZRV++2csTHGmLiQgMm4glBaN+oCIXpYN7Uxxpg4kHjJuK6CQIp76lZell3AZYwxpuuLKBmLyKkislpE1ojIzS2UuUBEVojIchF5KrphtkNtOfXJLhlby9gYY0w8SG6rgIgkAfcBpwDFwCIRmauqK8LKjAB+ChyrqrtEpFdnBdym2gpq0wYC2DljY4wxcSGSlvEUYI2qrlPVemAOMLNJmauA+1R1F4Cq7ohumO1QV8Een3tTk11NbYwxJh5Ekoz7A5vChou9ceFGAiNF5D0R+VBETm1uQSJytYgsFpHFJSUlHYu4LbXlVJEJYPcZG2OMiQvRuoArGRgBTAdmAX8Wke5NC6nqg6papKpFBQUFUVp1mFAQ6quoCGUgArkZdgGXMcaYri+SZLwZGBg2PMAbF64YmKuqflVdD3yBS84Hl/dc6rJQJt0zUkjyyUEPwRhjjGmvSJLxImCEiAwVkVTgImBukzIv4FrFiEg+rtt6XRTjjIz3KMyyYLqdLzbGGBM32kzGqhoArgVeA1YCz6rqchG5Q0RmeMVeA0pFZAXwFvAjVS3trKBbVFsOuNcn2vliY4wx8aLNW5sAVHUeMK/JuFvDPitwo/cTO1439fa6NHp0t2RsjDEmPiTWE7i8buqtdanWMjbGGBM3EiwZu27qzTWpdLdHYRpjjIkTiZWM6/ZewNXNbmsyxhgTJxIrGXvd1JVkkpNuydgYY0x8SLBkvJtQcjp+kslJi+jaNGOMMSbmEisZ11UQTMkBICfdkrExxpj4kFjJuH4PgWT3XGrrpjbGGBMvEisZ+2vw+zIAyLZuamOMMXEi4ZJxvaQB1k1tjDEmflgyNsYYY2IssZJxoIY63JO3rJvaGGNMvEisZOyvoYZUMlKSSE5KrK9mjDEmcSVWxvLXUKOp1kVtjDEmriRcMq7WVLItGRtjjIkjCZeMq0Ipdo+xMcaYuBJRMhaRU0VktYisEZGbm5k+W0RKRGSp93Nl9ENtgyoEaqgKptijMI0xxsSVNrOWiCQB9wGnAMXAIhGZq6ormhR9RlWv7YQYIxOsBw1RGUy2c8bGGGPiSiQt4ynAGlVdp6r1wBxgZueG1QH+agAqAil2W5Mxxpi4Ekky7g9sChsu9sY1da6IfCYiz4nIwOYWJCJXi8hiEVlcUlLSgXBb4a8FYHfAzhkbY4yJL9G6gOtFYIiqHgH8C3isuUKq+qCqFqlqUUFBQZRW7fFaxuX+JLua2hhjTFyJJBlvBsJbugO8cY1UtVRV67zBh4DJ0QmvHQKuZVxDGrmWjI0xxsSRSJLxImCEiAwVkVTgImBueAER6Rs2OANYGb0QI+SvAaAWO2dsjDEmvrSZtVQ1ICLXAq8BScDDqrpcRO4AFqvqXOA6EZkBBIAyYHYnxtw8r5u6ljQ7Z2yMMSauRNSEVNV5wLwm424N+/xT4KfRDa2dvAu4auwJXMYYY+JM4jyBq7FlbM+mNsYYE18SKBm7c8Y1pNkTuIwxxsSVxEnGAS8Za6qdMzbGGBNXEicZey3jOuycsTHGmPiScMm4VtLISk2KcTDGGGNM5BIqGYdIIi0tDRGJdTTGGGNMxBKnP9dfQ70vlZwUO19sjDEmviROyzhQQ72kk25d1MYYY+JM4iRjfw31pJKebMnYGGNMfEmoZFwnaaSnJM5XMsYYc2hInMzlr6GGNNJTrGVsjDEmviRQMq6mlhRLxsYYY+JO4iTjQC21at3Uxhhj4k/iZC5/DdVqF3AZY4yJPwmWjFNIs25qY4wxcSaiZCwip4rIahFZIyI3t1LuXBFRESmKXogR8tewJ5Rq3dTGGGPiTpuZS0SSgPuA04CxwCwRGdtMuRzgP4F/RzvIiPir2RNKJs26qY0xxsSZSJqRU4A1qrpOVeuBOcDMZsr9CvhvoDaK8UVMA7VU2wVcxhhj4lAkmas/sClsuNgb10hEJgEDVfXlKMYWuVAICdRSo6l2a5Mxxpi4c8DNSBHxAb8DfhhB2atFZLGILC4pKTnQVe8V8F6fSCrpydYyNsYYE18iyVybgYFhwwO8cQ1ygMOBBSKyATgKmNvcRVyq+qCqFqlqUUFBQcejbsrvesZrsJaxMcaY+BNJMl4EjBCRoSKSClwEzG2YqKrlqpqvqkNUdQjwITBDVRd3SsTN8VcD2OMwjTHGxKU2k7GqBoBrgdeAlcCzqrpcRO4QkRmdHWBEAq5lXKd2a5Mxxpj4kxxJIVWdB8xrMu7WFspOP/Cw2qmxZZxqD/0wxhgTdxKjGel3F3DVkGaPwzTGGBN3ImoZd3leMq7VFNKsm9oYcxD5/X6Ki4uprY3JIxZMF5Wens6AAQNISUmJqHxiJOPBxzL/9Lf57B8brGVsjDmoiouLycnJYciQIYhIrMMxXYCqUlpaSnFxMUOHDo1onsRoRianUp6STz0pdgGXMeagqq2tpWfPnpaITSMRoWfPnu3qLUmYzFXrDwHYrU3GmIPOErFpqr3bRMIk4zp/ELBkbIw5tJSWljJhwgQmTJhAnz596N+/f+NwfX19q/MuXryY6667rs11HHPMMdEKF4Drr7+e/v37EwqForrceJYY54yB2kBDyzhhji+MMaZNPXv2ZOnSpQDcfvvtZGdnc9NNNzVODwQCJCc3v6svKiqiqKjtN96+//770QkWCIVCPP/88wwcOJC3336bE044IWrLDtfa9+6KEiZz1Ta0jO0CLmPMIW727Nl873vfY+rUqfz4xz/mo48+4uijj2bixIkcc8wxrF69GoAFCxZw5plnAi6RX3HFFUyfPp1hw4Zx7733Ni4vOzu7sfz06dM577zzGD16NN/+9rdRVQDmzZvH6NGjmTx5Mtddd13jcptasGAB48aN45prruHpp59uHL99+3bOPvtsCgsLKSwsbDwAePzxxzniiCMoLCzkkksuafx+zz33XLPxHXfcccyYMYOxY92bfs866ywmT57MuHHjePDBBxvnefXVV5k0aRKFhYWcdNJJhEIhRowYQcN7E0KhEIcddhhRfY9CK+LnsKENtf4QqUk+fD47d2OMiY1fvricFVsqorrMsf1yue2b49o9X3FxMe+//z5JSUlUVFTwzjvvkJyczBtvvMHPfvYz/v73v+83z6pVq3jrrbeorKxk1KhRXHPNNfvdmvPJJ5+wfPly+vXrx7HHHst7771HUVER3/3ud1m4cCFDhw5l1qxZLcb19NNPM2vWLGbOnMnPfvYz/H4/KSkpXHfddXzta1/j+eefJxgMUlVVxfLly/mv//ov3n//ffLz8ykrK2vze3/88ccsW7as8Srmhx9+mLy8PGpqajjyyCM599xzCYVCXHXVVY3xlpWV4fP5uPjii3nyySe5/vrreeONNygsLCSq71FoRUK1jO0eY2OMcc4//3ySklxPYXl5Oeeffz6HH344N9xwA8uXL292njPOOIO0tDTy8/Pp1asX27dv36/MlClTGDBgAD6fjwkTJrBhwwZWrVrFsGHDGhNgS8m4vr6eefPmcdZZZ5Gbm8vUqVN57bXXAJg/fz7XXHMNAElJSXTr1o358+dz/vnnk5+fD0BeXl6b33vKlCn73E507733UlhYyFFHHcWmTZv48ssv+fDDDzn++OMbyzUs94orruDxxx8HXBK//PLL21xftCRMy7guECTNuqiNMTHUkRZsZ8nKymr8/Itf/IITTjiB559/ng0bNjB9+vRm50lLS2v8nJSURCAQ6FCZlrz22mvs3r2b8ePHA1BdXU1GRkaLXdotSU5Obrz4KxQK7XOhWvj3XrBgAW+88QYffPABmZmZTJ8+vdXbjQYOHEjv3r2ZP38+H330EU8++WS74joQCdOUrPWH7OItY4xpRnl5Of379wfg0UcfjfryR40axbp169iwYQMAzzzzTLPlnn76aR566CE2bNjAhg0bWL9+Pf/617+orq7mpJNO4oEHHgAgGAxSXl7OiSeeyN/+9jdKS0sBGruphwwZwpIlSwCYO3cufr+/2fWVl5fTo0cPMjMzWbVqFR9++CEARx11FAsXLmT9+vX7LBfgyiuv5OKLL96nZ+FgSJjsVesP2m1NxhjTjB//+Mf89Kc/ZeLEie1qyUYqIyOD+++/n1NPPZXJkyeTk5NDt27d9ilTXV3Nq6++yhlnnNE4Lisri2nTpvHiiy/yv//7v7z11luMHz+eyZMns2LFCsaNG8fPf/5zvva1r1FYWMiNN94IwFVXXcXbb79NYWEhH3zwwT6t4XCnnnoqgUCAMWPGcPPNN3PUUUcBUFBQwIMPPsg555xDYWEhF154YeM8M2bMoKqq6qB2UQNIw5VwB1tRUZEuXhy9Vx5f8egidlTW8tIPjovaMo0xpi0rV65kzJgxsQ4j5qqqqsjOzkZV+f73v8+IESO44YYbYh1Wuy1evJgbbriBd95554CX1dy2ISJLVHW/+8kSq2Vs54yNMSYm/vznPzNhwgTGjRtHeXk53/3ud2MdUrvdfffdnHvuudx1110Hfd0RJWMROVVEVovIGhG5uZnp3xORz0VkqYi8KyJjox9q66yb2hhjYueGG25g6dKlrFixgieffJLMzMxYh9RuN998Mxs3bmTatGkHfd1tJmMRSQLuA04DxgKzmkm2T6nqeFWdAPwG+F3UI22DXcBljDEmXkWSvaYAa1R1narWA3OAmeEFVDX8Lvcs4KCfiK4NBEmzlrExxpg4FMl9xv2BTWHDxcDUpoVE5PvAjUAqcGJUomuHOn+ItGRrGRtjjIk/Ucteqnqfqg4HfgLc0lwZEblaRBaLyOJoP+/TzhkbY4yJV5Ek483AwLDhAd64lswBzmpugqo+qKpFqloU7ed92tXUxphD0QknnND4SMkGf/jDHxofLdmc6dOn03Br6emnn87u3bv3K3P77bdzzz33tLruF154gRUrVjQO33rrrbzxxhvtCb9Vh9KrFiNJxouAESIyVERSgYuAueEFRGRE2OAZwJfRCzEydQG7gMsYc+iZNWsWc+bM2WfcnDlzWn1ZQ7h58+bRvXv3Dq27aTK+4447OPnkkzu0rKaavmqxs3TGQ1A6os3spaoB4FrgNWAl8KyqLheRO0RkhlfsWhFZLiJLceeNL+u0iJsRCIYIhNS6qY0xh5zzzjuPl19+ufH5zBs2bGDLli0cd9xxXHPNNRQVFTFu3Dhuu+22ZucfMmQIO3fuBODOO+9k5MiRTJs2rfE1i+DuIT7yyCMpLCzk3HPPpbq6mvfff5+5c+fyox/9iAkTJrB27dp9Xm345ptvMnHiRMaPH88VV1xBXV1d4/puu+02Jk2axPjx41m1alWzcR1qr1qM6EURqjoPmNdk3K1hn//zgKI4QLUB14VhLWNjTEy9cjNs+zy6y+wzHk67u8XJeXl5TJkyhVdeeYWZM2cyZ84cLrjgAkSEO++8k7y8PILBICeddBKfffYZRxxxRLPLWbJkCXPmzGHp0qUEAgEmTZrE5MmTATjnnHO46qqrALjlllv4y1/+wg9+8ANmzJjBmWeeyXnnnbfPsmpra5k9ezZvvvkmI0eO5NJLL+WBBx7g+uuvByA/P5+PP/6Y+++/n3vuuYeHHnpov3gOtVctJkT2qvUHAaxlbIw5JIV3VYd3UT/77LNMmjSJiRMnsnz58n26lJt65513OPvss8nMzCQ3N5cZM2Y0Tlu2bBnHHXcc48eP58knn2zxFYwNVq9ezdChQxk5ciQAl112GQsXLmycfs455wAwefLkxpdLhDsUX7WYEK9QbEzGdgGXMSaWWmnBdqaZM2dyww038PHHH1NdXc3kyZNZv34999xzD4sWLaJHjx7Mnj271dcHtmb27Nm88MILFBYW8uijj7JgwYIDirfhNYwtvYLxUHzVYoK0jF1lp1k3tTHmEJSdnc0JJ5zAFVdc0dgqrqioICsri27durF9+3ZeeeWVVpdx/PHH88ILL1BTU0NlZSUvvvhi47TKykr69u2L3+/fJ/Hk5ORQWVm537JGjRrFhg0bWLNmDQB//etf+drXvhbx9zkUX7WYENmroWWcZi1jY8whatasWXz66aeNybiwsJCJEycyevRovvWtb3Hssce2Ov+kSZO48MILKSws5LTTTuPII49snParX/2KqVOncuyxxzJ69OjG8RdddBG//e1vmThxImvXrm0cn56eziOPPML555/P+PHj8fl8fO9734voexyqr1pMiFcoLtlYxrkPfMCjlx/J9FG9orJMY4yJhL1C8dAUyasW2/MKxQQ5Z9xwNbW1jI0xxnSuu+++mwceeCAq54obJEQ39Yhe2fz+wkIO65Ud61CMMcYkuM541WJCtIx75aZz9sQBsQ7DGGOM6ZCEaBkbY0wsxeraG9N1tXebsGRsjDEHID09ndLSUkvIppGqUlpaSnp6esTzJEQ3tTHGxMqAAQMoLi4+4GcTm8SSnp7OgAGRnz61ZGyMMQcgJSVln8cqGtMR1k1tjDHGxJglY2OMMSbGLBkbY4wxMRazx2GKSAmwMYqLzAd2RnF5hyqrxwNndRgdVo8HzuowOqJZj4NVdb+XH8csGUebiCxu7nmfpn2sHg+c1WF0WD0eOKvD6DgY9Wjd1MYYY0yMWTI2xhhjYiyRkvGDsQ4gQVg9Hjirw+iwejxwVofR0en1mDDnjI0xxph4lUgtY2OMMSYuJUQyFpFTRWS1iKwRkZtjHU+8EJENIvK5iCwVkcXeuDwR+ZeIfOn97hHrOLsaEXlYRHaIyLKwcc3Wmzj3etvmZyIyKXaRdy0t1OPtIrLZ2yaXisjpYdN+6tXjahH5Rmyi7lpEZKCIvCUiK0RkuYj8pzfetscItVKHB3VbjPtkLCJJwH3AacBYYJaIjI1tVHHlBFWdEHbZ/s3Am6o6AnjTGzb7ehQ4tcm4lurtNGCE93M18MBBijEePMr+9Qjwe2+bnKCq8wC8/+mLgHHePPd7//uHugDwQ1UdCxwFfN+rK9seI9dSHcJB3BbjPhkDU4A1qrpOVeuBOcDMGMcUz2YCj3mfHwPOimEsXZKqLgTKmoxuqd5mAo+r8yHQXUT6HpxIu7YW6rElM4E5qlqnquuBNbj//UOaqm5V1Y+9z5XASqA/tj1GrJU6bEmnbIuJkIz7A5vChotpvSLNXgq8LiJLRORqb1xvVd3qfd4G9I5NaHGnpXqz7bP9rvW6UB8OO01i9dgGERkCTAT+jW2PHdKkDuEgbouJkIxNx01T1Um4rqvvi8jx4RPVXWpvl9u3k9XbAXkAGA5MALYC/xPbcOKDiGQDfweuV9WK8Gm2PUammTo8qNtiIiTjzcDAsOEB3jjTBlXd7P3eATyP62rZ3tBt5f3eEbsI40pL9WbbZzuo6nZVDapqCPgze7v/rB5bICIpuCTypKr+wxtt22M7NFeHB3tbTIRkvAgYISJDRSQVd2J9boxj6vJEJEtEcho+A18HluHq7jKv2GXAP2MTYdxpqd7mApd6V7EeBZSHdR+aJpqcvzwbt02Cq8eLRCRNRIbiLkD66GDH19WIiAB/AVaq6u/CJtn2GKGW6vBgb4vJB7qAWFPVgIhcC7wGJAEPq+ryGIcVD3oDz7vtkGTgKVV9VUQWAc+KyHdwb9W6IIYxdkki8jQwHcgXkWLgNuBumq+3ecDpuIs8qoHLD3rAXVQL9ThdRCbgulU3AN8FUNXlIvIssAJ39ev3VTUYi7i7mGOBS4DPRWSpN+5n2PbYHi3V4ayDuS3aE7iMMcaYGEuEbmpjjDEmrlkyNsYYY2LMkrExxhgTY5aMjTHGmBizZGyMMcbEmCVjY4wxJsYsGRtjjDExZsnYHFJE5BURuaztku0rG0vi3kt9cicsd4GIXOl9/raIvB5J2Q6sZ5CIVNkrEc2hzJKx6fK8HXXDT0hEasKGv92eZanqaar6WNsl21e2KxKRm0VkYTPj80WkXkQOj3RZqvqkqn49SnHtc/Cgql+panZnPFFLRFREDov2co2JNkvGpsvzdtTZqpoNfAV8M2zckw3lRCTuH+8aZU8Ax3jPzw13EfC5qi5rZh5jTAxYMjZxS0Smi0ixiPxERLYBj4hIDxF5SURKRGSX93lA2DzhXa+zReRdEbnHK7teRE7rYNmhIrJQRCpF5A0RuU9Enmgh7khi/JWIvOct73URyQ+bfomIbBSRUhH5eUv1o6rFwHzcc3fDXQo83lYcTWKeLSLvhg2fIiKrRKRcRP4ISNi04SIy34tvp4g8KSLdvWl/BQYBL3o9Gz8WkSFeCzbZK9NPROaKSJmIrBGRq8KWfbuIPCsij3t1s1xEilqqg5aISDdvGSVeXd4iIj5v2mEi8rb33XaKyDPeeBGR34vIDhGpEJHP29O7YExrLBmbeNcHyAMGA1fjtulHvOFBQA3wx1bmnwqsBvKB3wB/ERHpQNmncG9u6Qnczv4JMFwkMX4L9xD/XkAqcBOAiIzFvWf1EqCft75mE6jnsfBYRGQU7v2sT0UYx368A4N/ALfg6mIt7mH7jUWAu7z4xuBeN3c7gKpewr69G79pZhVzcC9s7wecB/xaRE4Mmz7DK9Md9wadNmNuxv8DugHDgK/hDlAaXprwK+B1oAeubv+fN/7rwPHASG/eC4DSDqzbmP1YMjbxLgTcpqp1qlqjqqWq+ndVrVbVSuBO3M62JRtV9c/e+crHgL64N1pFXFZEBgFHAreqar2qvksrr/GMMMZHVPULVa0BnsUlUHDJ6SVVXaiqdcAvvDpoyfNejMd4w5cCr6hqSQfqqsHpwHJVfU5V/cAfgG1h32+Nqv7L+5uUAL+LcLmIyEBcYv+Jqtaq6lLgIS/uBu+q6jzv7/BXoDCSZYetIwnXVf9TVa1U1Q24F8c3HLT4cQco/bwY3g0bnwOMxr1kZ+Wh/vpBEz2WjE28K1HV2oYBEckUkT95XY8VwEKgu7R8pW54Eqn2Pma3s2w/oCxsHMCmlgKOMMZtYZ+rw2LqF75sVd1DK60zL6a/4b3DFvg28Hg74mhO0xg0fFhEeovIHBHZ7C33CVwLOhINdVkZNm4j0D9suGndpEv7rhfIB1K85Ta3jh/jWvcfed3gVwCo6nxcK/w+YIeIPCgiue1YrzEtsmRs4l3Td4D+EBgFTFXVXFy3IoSd0+wEW4E8EckMGzewlfIHEuPW8GV76+zZxjyP4bpUT8G17F48wDiaxiDs+31/jfu7jPeWe3GTZbb23tYtuLrM/O6WPQAAIABJREFUCRs3CNjcRkztsZO9rd/91qGq21T1KlXth3uH7f3iXZGtqveq6mRgLK67+kdRjMscwiwZm0STgzv3uVtE8nAvrO9UqroRWAzcLiKpInI08M1OivE54EwRmSYiqcAdtP1//A6wG3gQmKOq9QcYx8vAOBE5x2uRXoc7d98gB6gCykWkP/snrO24c7X7UdX/396dx0lV3vke//xq6a7eaBqaZkcQEFxAUBZFY2DiGCKOaOLGqBFNYuK4TLyTSWJujF4Tr96rmSS+YjQmOpqMVzSJcTSSGEWjRmJkkV1URJRm33rfannuH0/1AvYKTVdX9ff9evWrqk6dOvWrQ1Hf8zznOedsBZYCd5lZxMwmA1/Ct64PV1ZyWREziySnPQXcaWYFZnYM8D8a38PMLm4xkO0AfuMhYWbTzWymmYWBaqCO9ncRiHSawlgyzY+BHHzr503gTz30vpcDp+O7jH8APAnUtzHvYdfonFsPXI8fgLUDHxalHbzG4bumj0neHlEdzrm9wMXA3fjPOx54o8Us/ws4BSjHB/fThyziLuC7ZlZmZt9o5S0WAKPxreTf48cEvNSZ2tqwHr/R0fh3NXAjPlA3A3/Fr89HkvNPB/5uZlX4ff//6pzbDPQDfoFf5x/hP/s9R1CXSBPz/09FpDslD4fZ6Jw76i1zEUl/ahmLdINkF+ZYMwuY2VxgPvBMqusSkfSgMxaJdI8h+O7Ygfhu4+ucc2+ntiQRSRfqphYREUkxdVOLiIikmMJYREQkxVK2z7i4uNiNHj06VW8vIiLS41asWLHXOTfo0OkpC+PRo0ezfPnyVL29iIhIjzOzj1qbrm5qERGRFFMYi4iIpJjCWEREJMV00g8RkV4sGo1SWlpKXV1dxzNLrxGJRBgxYgThcLhT8yuMRUR6sdLSUgoKChg9ejT+apXS2znn2LdvH6WlpYwZM6ZTr1E3tYhIL1ZXV8fAgQMVxGnEzBg4cGCXejMyI4x3bYDffQX2vp/qSkREup2COP109d8sM8K4Zi+sfQqqdqW6EhGRjLJv3z6mTJnClClTGDJkCMOHD2963NDQ0O5rly9fzk033dThe8yaNatbav3LX/7Ceeed1y3L6mmZsc84mOVv4+1/MUREpGsGDhzIqlWrALj99tvJz8/nG9/4RtPzsViMUKj1KJk2bRrTpk3r8D2WLl3aPcWmscxoGQeTo9Xi0dTWISLSByxcuJCvfe1rzJw5k29+85u89dZbnH766UydOpVZs2bx7rvvAge3VG+//XauueYaZs+ezbHHHst9993XtLz8/Pym+WfPns1FF13ExIkTufzyy2m8suDixYuZOHEip556KjfddFOXWsBPPPEEkyZN4qSTTuJb3/oWAPF4nIULF3LSSScxadIkfvSjHwFw3333ccIJJzB58mQuu+yyI19ZnaSWsYiIdFlpaSlLly4lGAxSUVHB66+/TigU4qWXXuI73/kOv/vd7z7xmo0bN/LKK69QWVnJhAkTuO666z5x6M/bb7/N+vXrGTZsGGeccQZvvPEG06ZN46tf/SqvvfYaY8aMYcGCBZ2uc/v27XzrW99ixYoVFBUVcc455/DMM88wcuRItm3bxrp16wAoKysD4O677+bDDz8kOzu7aVpPUBiLiKSJ//XcejZsr+jWZZ4wrB+3/dOJXX7dxRdfTDAYBKC8vJyrrrqK999/HzMjGm29l3LevHlkZ2eTnZ1NSUkJu3btYsSIEQfNM2PGjKZpU6ZMYcuWLeTn53Psscc2HSa0YMECHnrooU7VuWzZMmbPns2gQf7aDJdffjmvvfYat956K5s3b+bGG29k3rx5nHPOOQBMnjyZyy+/nAsuuIALLrigy+vlcKmbWkREuiwvL6/p/q233sqcOXNYt24dzz33XJuH9GRnZzfdDwaDxGKxw5qnOxQVFbF69Wpmz57Ngw8+yJe//GUAnn/+ea6//npWrlzJ9OnTj9r7H0otYxGRNHE4LdieUF5ezvDhwwF49NFHu335EyZMYPPmzWzZsoXRo0fz5JNPdvq1M2bM4KabbmLv3r0UFRXxxBNPcOONN7J3716ysrL4whe+wIQJE7jiiitIJBJs3bqVOXPmcOaZZ7Jo0SKqqqro379/t3+mQymMRUTkiHzzm9/kqquu4gc/+AHz5s3r9uXn5OTws5/9jLlz55KXl8f06dPbnHfJkiUHdX3/5je/4e6772bOnDk455g3bx7z589n9erVXH311SQSCQDuuusu4vE4V1xxBeXl5TjnuOmmm3okiAGscaRaT5s2bZrrtusZ1x6A/zMa5t4Np13XPcsUEekF3nnnHY4//vhUl5FyVVVV5Ofn45zj+uuvZ/z48dx8882pLqtdrf3bmdkK59wnjvfKkH3GahmLiGSyX/ziF0yZMoUTTzyR8vJyvvrVr6a6pG6lbmoREen1br755l7fEj4SmdEyDiS3KTSaWkRE0lBmhLGZbx2rZSwiImkoM8IYIBBWy1hERNJS5oRxMKyWsYiIpKWMCONlW/azrw72lVeluhQRkYwyZ84cXnjhhYOm/fjHP+a669o+jHT27Nk0Hrp67rnntnqO59tvv51777233fd+5pln2LBhQ9Pj733ve7z00ktdKb9VvfFSixkRxomEo84FiUfrU12KiEhGWbBgAYsWLTpo2qJFizp9sYbFixcf9okzDg3jO+64g7PPPvuwltXbZUQYZ4UCRF2IhLqpRUS61UUXXcTzzz9PQ4P/fd2yZQvbt2/nU5/6FNdddx3Tpk3jxBNP5Lbbbmv19aNHj2bv3r0A3HnnnRx33HGceeaZTZdZBH8M8fTp0zn55JP5whe+QE1NDUuXLuXZZ5/l3//935kyZQoffPABCxcu5Le//S3gz7Q1depUJk2axDXXXEN9fX3T+912222ccsopTJo0iY0bN3b6s6byUosZEcbZoSBRQhBTGIuIdKcBAwYwY8YM/vjHPwK+VXzJJZdgZtx5550sX76cNWvW8Oqrr7JmzZo2l7NixQoWLVrEqlWrWLx4McuWLWt67vOf/zzLli1j9erVHH/88Tz88MPMmjWL888/n3vuuYdVq1YxduzYpvnr6upYuHAhTz75JGvXriUWi/HAAw80PV9cXMzKlSu57rrrOuwKb9R4qcWXX36ZVatWsWzZMp555hlWrVrVdKnFtWvXcvXVVwP+Uotvv/02a9as4cEHH+zSOm1NRpz0IzscoJ4QTqOpRSST/fHbsHNt9y5zyCT43N3tztLYVT1//nwWLVrEww8/DMBTTz3FQw89RCwWY8eOHWzYsIHJkye3uozXX3+dCy+8kNzcXADOP//8pufWrVvHd7/7XcrKyqiqquKzn/1su/W8++67jBkzhuOOOw6Aq666ivvvv5+vf/3rgA93gFNPPZWnn366Eysh9ZdazIiWcVYwQANBHdokInIUzJ8/nyVLlrBy5Upqamo49dRT+fDDD7n33ntZsmQJa9asYd68eW1eOrEjCxcu5Kc//Slr167ltttuO+zlNGq8DGN3XIKxpy61mDEt4yghSKibWkQyWAct2KMlPz+fOXPmcM011zQN3KqoqCAvL4/CwkJ27drFH//4R2bPnt3mMs466ywWLlzILbfcQiwW47nnnms6v3RlZSVDhw4lGo3y+OOPN12OsaCggMrKyk8sa8KECWzZsoVNmzYxbtw4fv3rX/PpT3/6iD5jqi+1mBlhHAoSdSFMLWMRkaNiwYIFXHjhhU0jq08++WSmTp3KxIkTGTlyJGeccUa7rz/llFO49NJLOfnkkykpKTnoMojf//73mTlzJoMGDWLmzJlNAXzZZZfxla98hfvuu69p4BZAJBLhP//zP7n44ouJxWJMnz6dr33ta136PL3tUosdXkLRzEYCvwIGAw54yDn3k0PmMeAnwLlADbDQObeyveV25yUU66Jx/n7HbCb0TzDk397olmWKiPQGuoRi+urKJRQ70zKOAf/mnFtpZgXACjN70Tm3ocU8nwPGJ/9mAg8kb3uE32ccwhLVPfWWIiIi3abDAVzOuR2NrVznXCXwDjD8kNnmA79y3ptAfzMb2u3VtiEQMOIWIpBQN7WIiKSfLo2mNrPRwFTg74c8NRzY2uJxKZ8MbMzsWjNbbmbL9+zZ07VKOxC3sMJYRETSUqfD2Mzygd8BX3fOVRzOmznnHnLOTXPOTWs8lqu7JAIKYxHJTB2N7ZHep6v/Zp0KYzML44P4cedca0dQbwNGtng8IjmtxyQsTMApjEUks0QiEfbt26dATiPOOfbt20ckEun0azocwJUcKf0w8I5z7j/amO1Z4AYzW4QfuFXunNvR6Sq6QSIQJqgwFpEMM2LECEpLS+nuXXtydEUikYMOnepIZ0ZTnwFcCaw1s1XJad8BRgE45x4EFuMPa9qEP7Tp6i7U3C0SgTDB6JGdAUVEpLcJh8OMGTMm1WXIUdZhGDvn/gpYB/M44PruKupwuGCYUINaxiIikn4y4tzUAC4QJkgMtF9FRETSTMaEMcEwARwk4qmuREREpEsyKIyz/G1cF4sQEZH0kjlhHAj7W4WxiIikmcwJ41Bjy1iDuEREJL1kThgH1E0tIiLpKWPCOBBWGIuISHrKmDC2xgFcCZ34Q0RE0kvmhHFILWMREUlPGRPGgWQYx6MKYxERSS8ZE8bBcDYAsYa6FFciIiLSNRkTxoGQD+NoQ32KKxEREemajAnjYHI0dTSqMBYRkfSScWEcU8tYRETSTAaFcXKfsVrGIiKSZjImjEPhCACxqAZwiYhIesmcMM7SoU0iIpKeMiaMw8lu6ri6qUVEJM1kThhnJ8M4ppaxiIikl8wJ4yy/zzihbmoREUkzGRTGvmWciKmbWkRE0kvGhHFWYxirZSwiImkmY8I4O9lN7XTVJhERSTMZE8ZZ4SANLojTAC4REUkzGRPG2aEAUUJqGYuISNrJuDBGLWMREUkzGRPGoWAyjOPRVJciIiLSJRkTxoAP44RaxiIikl4yKoxjppaxiIiknw7D2MweMbPdZraujednm1m5ma1K/n2v+8vsnBhhLKEwFhGR9BLqxDyPAj8FftXOPK87587rloqOQNxCmFrGIiKSZjpsGTvnXgP290AtRyxuYQJqGYuISJrprn3Gp5vZajP7o5md2E3L7LK4hTEN4BIRkTTTmW7qjqwEjnHOVZnZucAzwPjWZjSza4FrAUaNGtUNb32wRCBE2KllLCIi6eWIW8bOuQrnXFXy/mIgbGbFbcz7kHNumnNu2qBBg470rT8hHggTSMS6fbkiIiJH0xGHsZkNMTNL3p+RXOa+I13u4UgEwgTVMhYRkTTTYTe1mT0BzAaKzawUuA0IAzjnHgQuAq4zsxhQC1zmnHNHreJ2uECYoAZwiYhImukwjJ1zCzp4/qf4Q59SzreM1U0tIiLpJaPOwEUwmyxXn+oqREREuiSjwjiRVUCuq0l1GSIiIl2SUWHssgvIo45YTF3VIiKSPjIqjIORfgTMUVFZkepSREREOi2zwji3EIDq8pQcWSUiInJYMiqMwznJMK44kOJKREREOi+jwjg7vz8AddVlKa5ERESk8zIsjIsAqK9SGIuISPrIqDDOK/At44bq8hRXIiIi0nkZFcb5hQMAiNcojEVEJH1kVBhn5/kBXPE6HdokIiLpI6PC2LILAHAKYxERSSMZFcYEglSTQ6ChMtWViIiIdFpmhTFQG8glGFUYi4hI+si4MK4P5hOKVqW6DBERkU7LuDBuCOaRFVMYi4hI+si4MI6F88lO6DKKIiKSPjIujONZBeS6apxzqS5FRESkUzIujMkqIJ9aqhviqa5ERESkUzIvjCP9yKeW8tpoqisRERHplIwL42CkH/lWR0V1XapLERER6ZSMC+NQrr9YRFWlrtwkIiLpIePCOJw8P3Vt5YEUVyIiItI5GRfGkTzfMlYYi4hIusi4MM4pKAJ0TWMREUkfmRfG+b5lXF+tlrGIiKSHjAvjQI7fZ1xToQFcIiKSHjIujEle07iuWmEsIiLpIWPDOFajMBYRkfTQYRib2SNmttvM1rXxvJnZfWa2yczWmNkp3V9mF2TlEbMwwboDxBM6P7WIiPR+nWkZPwrMbef5zwHjk3/XAg8ceVlHwIyanKEMYw97KutTWoqIiEhndBjGzrnXgP3tzDIf+JXz3gT6m9nQ7irwcMQKRjDc9rKtrDaVZYiIiHRKd+wzHg5sbfG4NDktZYJFoxihMBYRkTTRowO4zOxaM1tuZsv37Nlz1N4nMmgMJVbGrn0axCUiIr1fd4TxNmBki8cjktM+wTn3kHNumnNu2qBBg7rhrVuXXTwagJo9W47ae4iIiHSX7gjjZ4EvJkdVnwaUO+d2dMNyD1+h3zaI7f84pWWIiIh0RqijGczsCWA2UGxmpcBtQBjAOfcgsBg4F9gE1ABXH61iO63/KACCFVs7mFFERCT1Ogxj59yCDp53wPXdVlF3KBhKnCC5tdtTXYmIiEiHMu8MXADBEDWREorju6msi6a6GhERkXZlZhgD0fyRjLA9bNpdlepSRERE2pWxYZwzaDTDbS+rturwJhER6d0yN4xLxjDEDrDm472pLkVERKRdGRvG9D+GIAn2fbwx1ZWIiIi0K3PDeNRpAIysWMmB6oYUFyMiItK2zA3jAcdSnzuUWYF1rCrVfmMREem9MjeMzQiM/TSnBzaw6qP2LjolIiKSWpkbxkB43BwGWBX7N69MdSkiIiJtyugwZsynASjY/gb1sXiKixEREWldZodxv6FUFxzLaW41y7ccSHU1IiIircrsMAbCky7gjMA63l63PtWliIiItCrjwzhr2hcJmqNg41OpLkVERKRVGR/GDBhDaf/pzKl5gd3lNamuRkRE5BMyP4wBN/VKRgX28M7S51JdioiIyCf0iTAeMesSdjOAEat/DM6luhwREZGD9IkwtnAOb4z4CmPrNtCwXq1jERHpXfpEGAMUzVrIpsQwon++DeKxVJcjIiLSpM+E8WnjB/Nj98/kVWyGVY+nuhwREZEmfSaMI+Eg0fFzWWMTcH+5Cxo0slpERHqHPhPGAJ+bNIzv112KVe6AN3+W6nJERESAPhbGc08awsbsk1hTcBa8di/s/zDVJYmIiPStMI6Eg/zTycO4oewyXCAIf7hZhzqJiEjK9akwBrhk2kg+jvZn+bh/hc2vwLJfprokERHp4/pcGJ88opDjBufzv3efDsfNhT99Gz7+e6rLEhGRPqzPhbGZccm0kbxdWsGmM38IhSPhycthx5pUlyYiIn1UnwtjgAumDicUMJ5cWwGX/waC2fDoPNj8aqpLExGRPiiU6gJSoTg/m88cX8Lv397GN+d+hvCXXoD/+gL8+kL43P+BGV9JdYkiIr1LeSmsXgQfvgqDT4Ljz4eRMyEQgNoD8MErsGsd1OyHUAQKBsOQSTBiBkT6de496ipg8TfgwBY4/QYYcxZECsHsqH603qBPhjH4gVwvrN/Fb1eUsmDGKPjSi/D0tf6LUF4KZ9/eJ74AIiId2v0OPHoe1OyFkhNg2cP+XA35gyGc68MTBxaEnCKI1UNDpX9tbjHM+yGMmAYV22HbSqivhKw8GDoZio/zYf7ha/C3+6HsY+g3DJ660r8+lAMFQ/xfv2Ew6nQYdzYMGNNcX8UOqCuHQRM6/7tde8DXkTvQ13KoeAwqt0P/UUey5jqtz4bxnAklzBgzgLsWv8NnJpZQ0q8fXPa4D+M3fgy1++HceyGUnepSRUTalkj4kCzbCuUfQ7TWh1bNPh9sWfkQCEG0BvoN963VojG+RdsoWuvnr9nnW7Ytb2sPwPqn/TL+5e9QMtGH2HsvwMbnwSVgyj/DmE/D8FMhmIyVunIoXQ5L7oDfXNW5zzLoeFj4B9+a3vQi7NsElTv9X9Uu2LoM1v3OzztwnP+c1Xth9wY/La8EsvN9TcNP9RsH21ZAPArhiN94aKiC/Zt9fY1COX4jwgKAg0QcqveAi8Mt2/wyjzJznTjO1szmAj8BgsAvnXN3H/L8QuAeYFty0k+dc+0eMzRt2jS3fPnyw6m522zeU8Xcn7zOPx4/mPsvP8VPdA5e/gG8fi8Mnwbz7oVhU1Nap4hkgHjMh9rONdBQDSfMh8GToHwr1JX5gKuv9K3Hyh0+GLLyfYAkYn7a9rd9z12szv9F6yBe3/VawrmQV+xrqivzQd2WSCEUjYbP/xIGHXcYnzsK656GWK0Py2FTIG8Q1Jb5oCz72L/HsCm+ZduRfR/A+y/CB0t8t3Z2AYw+w7dwt7zh11UiBlvf8qE8YpqfJ1oDVbt9F/qAY33LOlLoNziq9/r10BiHZn69Fx0DJ32h9ZbzYTKzFc65aZ+Y3lEYm1kQeA/4R6AUWAYscM5taDHPQmCac+6GzhbUG8IY4D9efI/7lrzPizefxfjBBc1PbHgW/vt6qK/w/2GO/TRMOBeOmaXuaxHpWCIB9eVQucuH6N9+6vepBrMhGPYttLZE+gMO6qt86wz864ZMgoFjfaCEc3zPXSjHB1H/kf7okHAOVGzzyyga7Vu9iZifXvYR7Fzn66gt863dnP6QO8Av49C/SP/mlq50i7bCuDNreQawyTm3ObmgRcB8YEO7r0oTV51+DD9/9QMeeWMLd31+UvMTJ5zvBw+seQrW/x7eesj/Zxp0PEz/Eky+tPODEkTk6Is1+JbWx0shu58PmOp9vruxerdvASXivsVTMNQ/31ANe971r8sd4Ftmgyb6sDuoyzb511DluzMDYd9922+Ybz3VV/rHNfv9be1+H3a0aOwUjoSLH/MDn+INsPEPvqXWf5R/7+yCZEu4pLkllkj4ZQXDkFVwcNdyewaObb7f8ncqd4B6+nqpzrSMLwLmOue+nHx8JTCzZSs42TK+C9iDb0Xf7Jzb2sqyrgWuBRg1atSpH330UTd9jCPz7d+t4fdvb+PNWz5DUV5W6zM1VPuulmW/hB2r/FbqmE/5wQRDT/ajChXOIl4i7vfz1R7w+9ti9c37/eorIJjlW135gyF/kN89dGCLb0HuWue7anOLYfzZfndR7kDY8w7s2uAHE+19z+8ndQn/2lid72qkld8zCyRbesX+ftVOH6yNcgf6fZR15f49ag80P5eVf3CrMSvPPx+P+RZl2VbfzRwp9CGdO8Df5hRBTvJ+XrFv0RYfB4Hg0V7z0ssdSTd1Z8J4IFDlnKs3s68Clzrn/qG95faWbmqA93ZVcs6PXmN8ST7nThrKDf8wjnCwnS3Q0hV+EMH7f4Z97/tpFoRRp8HkS+DYOX5rV93ZkiqJBOxc7fcvRmt9MOQV+wCp2uP3j4Vz/CEqOf2bX+ecD7XqPf75rHx/6+K+y7Rqp+92rdjmB83sWu/DsaEqeZ73bjjXe9EYKBwBBz7yA5IOlT8Eisf71m0g6AM2EPKPS473PVqxeh+aecU+RA8NwVhDch3k+oBt/L/a+PkTMR+sGsAp3exIwvh04Hbn3GeTj28BcM7d1cb8QWC/c66wveX2pjAGWPTWx/x2RSnLPzrAfQumcv7Jwzr3wrpy2L7KD8t/51m/xQ6+S6nfMD+ib9rVfuu+s11MIo2c863E3Rv8bWM36e4N8NFS6H+M7yaN1vrnGmr87Y41Pjg7EorA+H/0ry/72Lf0YrWdqy27EAaf6P+aAj0Zahbw3a15xb4LN5QcyZo/2PcgxRt8WFbt9n/gP8fgE/3na/zs+z7wGxU1+33QlpzgQ1IkTR1JGIfwXc+fwY+WXgb8s3NufYt5hjrndiTvXwh8yzl3WnvL7W1hDJBIOM665xVGFuXyxLXtlt8652DnWti2HHZv9K2Hza/64+2y+8HIGTD5MjjmdP+DE85V67m3SCR8SylS2HpXYjwGpctgx2rfLQm+1Rgp9I8rdyRbU8V+pGZ2vg+QXet9y6zfMB92NXt9qy1a60d31pUDBlm5za3QUMRPr9jmu3ZbG+kaCPsNvYpt/r3Deb6Fl5Xnl1U0BibO8/tAw7m+luo9PgDzS3xLub7cH5ry/ovJAUCjmv/yBiWPFa3y7x8I+eUUDEnucx3iW6L6/op0yWEP4HLOxczsBuAF/KFNjzjn1pvZHcBy59yzwE1mdj4QA/YDC7u1+h4SCBgLZozinhfe5cO91Ywp7uJwdjN/EPvQyc3T6ivhnT/4H/L3X4Snv9z8XDC7xf6lxv1N/aF4gv8hzS/x3d/hnN7xo1e+zf/4Dxzng8PF/T67UKQ5wBpDLRj2A1LaE6314VC5w4fWrvW+ZyGY1XxcZEO1b+0losmRn0V+YEz1Hr9Osgv8sZOhbF9H4Qj/lzfI11p7wK/naLV/XV2Z77rdtzk5KCbXB23NPn+IiAWaB/j0G+bfr3ovlL7VvJ8xnJusPxmSoRwoHO7rq3zdv0ej/qOg5oDfIMsp8l2s4Yh/TaR/8wkFGmr88mr2+/2fkUIYOgUmDPMjYgef6AcANe6zzCv28xypcWcf+TJE5Ih16jjjo6E3towBdlfUcfrdL/P5qcP57nknUJgT7r6FJxJ+pOe+D5KjLQ+0GIFZ5qfV7P9k92IwywfDwPE+CPMG+pAv3+ZbWoUjfIAEQr7FFE6GQ6QweRC7+R/4so99EJVvTR6rWO9bOCNnwJjZvhs91uBD4cCHvls03uBr2rcJPn6TVvcJBrN8UMTqfJdjIuqnZxf6OgpH+Ppdwgfb3veaj5VsKZzn9wW6hG9lNrb0wrk+OBv380UKfdiCf1yx3R/LGK3x66RlN2sg5JcVivjwy+nvP/PAcX6QUbTGr7PcZFDWHkieZGC7P6tP7QH/XiUTYeJ5flxA/mC/IRCP+uMcc4oO3gVRV+7DNZzj3885/++lAX4ifd5hd1MfLb01jAG+8ZvV/HZFKaGAceeFJ3Hp9J45HVqTA1tg00vNxwfWHvD78vZt8kEerfYB0m+YbyGVbfWttsbjEdsTCCcDcqRvTZZv8yNIW2U+aHPv8EEIAAAQWklEQVT6+9bncXN9q3/fBz5IGwfP1Oz3NTcelpFf4oO+Ylsy/Et9YAaCvjt04LjmwzlyipJhd8Inzwp0OJzz66JqN/Qb6pefSGh/vYj0CgrjLkgkHG9vLeOHf36Xtz7cz+NfnsnMYwemuizPOd9abW2Up0uexq2h0gdgfRXgfEszmN2iBX1IMFVs98dZBkI+fEPZfmBQv+EKMRGRbqQwPgzltVEu/NkblNVE+fWXZnDisG7YRyciIn1WW2GsZk87CnPCPHLVdCKhAJf9/E3e+nB/qksSEZEMpDDuwOjiPH573SxK+mVzzaPLWLetvOMXiYiIdIHCuBOG9c/h8S+fRmFOmIX/uYyNOytSXZKIiGQQhXEnDSmM8Ng1MwgYXHj/Uv571baOXyQiItIJCuMuGFeSzx9uPJMThvXjXxet4suPLWNneV3HLxQREWmHwriLSvpFWHTtaXzn3Im8sWkfX3zk71TXx1JdloiIpDGF8WEIBwNce9ZYfvHFaWzaXcW/PbWabWW1pOowMRERSW8K4yNw5vhibvnc8fxp/U7OuPtlLvn536hpUCtZRES6RmF8hL5y1rH84cYz+ebcCaz46ABfX7SKeEItZBER6TyFcTc4aXgh/zJ7HLeedwJ/3rCLKx/+O+/urEx1WSIikiYUxt1o4azRfP+Ck1i/vYJz73ud+5a8TyyeSHVZIiLSyymMu5GZceVpx/CXb8zmvMlD+Y8X3+OzP36Nx5ZuobahE1dUEhGRPklhfBQU5WXxk8um8sDlp5CfHeK2Z9dz1j2v8MvXN7OtrLbjBYiISJ+iqzb1gGVb9nPPC+82XWhiwYyR3HnBJAIBS3FlIiLSk9q6alMoFcX0NdNHD+DJa0/jgz3V/NebH/Ho0i0EA8asscXkZAWZNXYg2aFgqssUEZEUURj3EDNjXEk+t/3TCQTMeOSND/mvNz8GoF8kxOljB3LasQO54rRjCAe190BEpC9RGPcwM+PW847ngqnDyAoF2FFWx/Nrd7Bsy35eWL+Llzfu5oeXnEw4EKB/bhgzdWWLiGQ67TPuRRa99TH/85l1TScNOWPcQL5xzgSmjOyvUBYRyQDaZ5wGLpsxivGDC1j50QGqG2I8tnQLF/5sKSOKcjhxWD8G5GVz9vElfPq4QYTUlS0ikjHUMu7FKuqiPL9mB0ve2c3W/TXsKK+loi5Gv0iIU44p4oqZx3D2CYNTXaaIiHRSWy1jhXEaicYTvLJxN6+8u5u/btrL1v21/MPEEiLhACOKcrl+9jgKc8M459StLSLSCymMM0xDLMEDf/mAX7/5EQWREB/tq6ZfTpjsUIBY3HHH/JOYN3loqssUEZEWFMYZbv32cu5/ZRORcJAPdlexurSccSX5ZAUDDMjLYuSAXE4fO5DxJfmUFGQzMD871SWLiPQ5CuM+JBpP8OBfPmDttnLiCcf+mgY27a6isq75WsunjOrP2ScMZuygfMYOymPUgDyyQhoUJiJyNGk0dR8SDga48TPjD5oWiydYv72CbWW1bN5TxXOrd/B///Rui9cYJw0vZNoxRZwyqojC3DCFOWHGlxQ0hXR5bRQz6BcJ9+jnERHJdGoZ92HltVG27K3mw73VvLOzgpUfHWB1aTkNsebLPmaFAhTmhKmLxqmsixEwmDZ6ADNGD2DSiEI+Nb6Y3Kzmbbqq+hjLPtzPwPwsJg0v1EAyEZEWjqib2szmAj8BgsAvnXN3H/J8NvAr4FRgH3Cpc25Le8tUGPdO9bE47+2soqo+xt6qetZuK6eyLkZ2KMDQwgiVdTFe3ribd3dVEk84IuEAQ/pF2F5WhxnEEq7ppCUThxQwpjiPwf0iTB5RyNhB+QwpjFCcn+3fZ1cV4aCRnx2isi5GcX42QwojJBKOaCKh83WLSMY57DA2syDwHvCPQCmwDFjgnNvQYp5/ASY7575mZpcBFzrnLm1vuQrj9FYXjfP2x2UsXruD/dUNDC/KwfAt6ZljBvLh3iqeW+Of215WS02L6zkHA4ZzjkQrX70h/SIcqGkg4RxTR/ku89EDc9le5o+xLsrNIhQ0QgFjSGGEcDBAeW2UgPn3zgoGGVKYzbiSAvKzQ+yrrmfdtnIKc8IcN7iAgmQXeyLhdNUsEelxRxLGpwO3O+c+m3x8C4Bz7q4W87yQnOdvZhYCdgKDXDsLVxj3HfGEY9PuKn/ikoo6dpbXEg4GOH5oP5xzVNbFKIiEKD1Qy7pt5QwqyMbM+NsH+9i4s4Jo3BEwyM0KUVUf6/gN2xEJBwiYUdMQZ2hhhJEDcnHOHdSibzQwL4uB+dnsKK+lvDbaND0UCFCcn01BJIQZBM0IBoxAwJrvmxEwv+FhZjgcNfVxskMBhhRGqIvGqW7wj7NDQSLhAJFwkOyQv004RyzuaIgnSCTr6pcTJjcrSEVdjHgiQSgQIBQwQsFA0wZKKODvN8QSlNdGyQkHm+ps+b+x8e6h/0ODAQi0+AwACefXjb+lxX1H3DlccnrAoKQgQkEkhAOcc8nb5ndsfL+D1lXyfuO2UcKBw2+sNR4zb9C0TjF/v3maJaf5c78Hks+TfL4hnqCmIeY/lxnBYPN7BwNGPOGoTW4sBpLTWj4faLHumteb49AfN4OmWhv3zvT13TSNEdDX10NLRzKAaziwtcXjUmBmW/M452JmVg4MBPYeXrmSSYIBY8KQAiYMKejyaxtiCXaW1zG4MJvsUJBoPEHCOaJxx87yWmIJR2FOmITz89bH4mzd7wep1UUT5GUHmTyiPxW1UTbtqWJfVT0JB7lZQUoP1LKtzG8YRML+h7fxJ8MBuyvr2bCjgqGFOZQURJqea4gnKD1QQ3VDjETi0LBqvH/wdMPIzQ5S2xCnPrlPPhw0ovHUjNmQnnU4WdT4ksYga37c+LwdPGPTBoP7xEbWQa9p8TK/HdNcXMvXuuaJTc+B3zBpuVHSqHHDyBo3lsz3oCUcTRutjRtObX3W1mo+eL5PTmx9vtaW18prW5nv0IlvfPsfemTQao+Opjaza4FrAUaNGtWTby1pKisUYNTA3KbHjZeXzA7BuJLWw33ikH7AJ08TenYr03qac46ymig5WUHfAk446mMJ6qLxptu6WJyAGeGgb/kGk03G8tooNQ0x+kXChIIB4okE0bhvQUcTCeIJfz+ecISCdtDAu0Ytf48af9gapzkHcedIJJpbvY2tz4NasIHWewNiCceuijqq62NNP/ItW4gtf+MO3nDxGy/xhGt6XVPr1oDkho1Lvi6RbG43tpwTyXDw932YNLaunYOsYIBIVhBa9IA0fr543O+uyM3y4xNa9gA09k4knDsotOyQMGtcd67p9pDQOoxBsof2XLhDehZaPu9wHdbW+JqDlndIqB4U+ocEfsvlNj5u+VxjHY0boYmEX/eRcJBgwFpsmLb2WVud2JlJtNb52trqbv21naslq4euA9CZMN4GjGzxeERyWmvzlCa7qQvxA7kO4px7CHgIfDf14RQsks7MjKK8rKbHgYCRkxUkJ6vjwWrD+ucczdJEJIU6E/nLgPFmNsbMsoDLgGcPmedZ4Krk/YuAl9vbXywiIiLNOmwZJ/cB3wC8gD+06RHn3HozuwNY7px7FngY+LWZbQL24wNbREREOqFT+4ydc4uBxYdM+16L+3XAxd1bmoiISN+gkxGLiIikmMJYREQkxRTGIiIiKaYwFhERSbGUXbXJzPYAH3XjIovRGb+6g9bjkdM67B5aj0dO67B7dOd6PMY5N+jQiSkL4+5mZstbO9+ndI3W45HTOuweWo9HTuuwe/TEelQ3tYiISIopjEVERFIsk8L4oVQXkCG0Ho+c1mH30Ho8clqH3eOor8eM2WcsIiKSrjKpZSwiIpKWMiKMzWyumb1rZpvM7NupriddmNkWM1trZqvMbHly2gAze9HM3k/eFqW6zt7GzB4xs91mtq7FtFbXm3n3Jb+ba8zslNRV3ru0sR5vN7Ntye/kKjM7t8VztyTX47tm9tnUVN27mNlIM3vFzDaY2Xoz+9fkdH0fO6mdddij38W0D2MzCwL3A58DTgAWmNkJqa0qrcxxzk1pMWz/28AS59x4YEnysRzsUWDuIdPaWm+fA8Yn/64FHuihGtPBo3xyPQL8KPmdnJK8SA3J/9OXAScmX/Oz5P/9vi4G/Jtz7gTgNOD65LrS97Hz2lqH0IPfxbQPY2AGsMk5t9k51wAsAuanuKZ0Nh94LHn/MeCCFNbSKznnXsNfKrSlttbbfOBXznsT6G9mQ3um0t6tjfXYlvnAIudcvXPuQ2AT/v9+n+ac2+GcW5m8Xwm8AwxH38dOa2cdtuWofBczIYyHA1tbPC6l/RUpzRzwZzNbYWbXJqcNds7tSN7fCQxOTWlpp631pu9n192Q7EJ9pMVuEq3HDpjZaGAq8Hf0fTwsh6xD6MHvYiaEsRy+M51zp+C7rq43s7NaPun8UHsNt+8irbcj8gAwFpgC7AB+mNpy0oOZ5QO/A77unKto+Zy+j53Tyjrs0e9iJoTxNmBki8cjktOkA865bcnb3cDv8V0tuxq7rZK3u1NXYVppa73p+9kFzrldzrm4cy4B/ILm7j+txzaYWRgfIo87555OTtb3sQtaW4c9/V3MhDBeBow3szFmloXfsf5simvq9cwsz8wKGu8D5wDr8OvuquRsVwH/nZoK005b6+1Z4IvJUaynAeUtug/lEIfsv7wQ/50Evx4vM7NsMxuDH4D0Vk/X19uYmQEPA+845/6jxVP6PnZSW+uwp7+LoSNdQKo552JmdgPwAhAEHnHOrU9xWelgMPB7/z0kBPw/59yfzGwZ8JSZfQl/Va1LUlhjr2RmTwCzgWIzKwVuA+6m9fW2GDgXP8ijBri6xwvupdpYj7PNbAq+W3UL8FUA59x6M3sK2IAf/Xq9cy6eirp7mTOAK4G1ZrYqOe076PvYFW2twwU9+V3UGbhERERSLBO6qUVERNKawlhERCTFFMYiIiIppjAWERFJMYWxiIhIiimMReQTzGy2mf0h1XWI9BUKYxERkRRTGIukMTO7wszeSl5v9edmFjSzKjP7UfLarEvMbFBy3ilm9mbyxPe/b3GN23Fm9pKZrTazlWY2Nrn4fDP7rZltNLPHk2cqEpGjQGEskqbM7HjgUuAM59wUIA5cDuQBy51zJwKv4s9sBfAr4FvOucnA2hbTHwfud86dDMzCnxQf/NVrvo6/Tvix+DMVichRkPanwxTpwz4DnAosSzZac/AXBEgATybn+S/gaTMrBPo7515NTn8M+E3y/OTDnXO/B3DO1QEkl/eWc640+XgVMBr469H/WCJ9j8JYJH0Z8Jhz7paDJprdesh8h3vO2/oW9+Po90LkqFE3tUj6WgJcZGYlAGY2wMyOwf+/vig5zz8Df3XOlQMHzOxTyelXAq865yqBUjO7ILmMbDPL7dFPISLa0hVJV865DWb2XeDPZhYAosD1QDUwI/ncbvx+ZfCX0nswGbabab5iz5XAz83sjuQyLu7BjyEi6KpNIhnHzKqcc/mprkNEOk/d1CIiIimmlrGIiEiKqWUsIiKSYgpjERGRFFMYi4iIpJjCWEREJMUUxiIiIimmMBYREUmx/w8P6nvjC9kLQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gmp\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "global_max = tf.keras.layers.GlobalMaxPool2D()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = global_max(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(len(base_model.trainable_variables))\n",
    "print(len(model.trainable_variables))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5613197,
     "status": "ok",
     "timestamp": 1614247238604,
     "user": {
      "displayName": "Quang Vinh",
      "photoUrl": "",
      "userId": "10640784768073460440"
     },
     "user_tz": -420
    },
    "id": "qxsJPiJEsFaK",
    "outputId": "48114db3-2981-4569-e645-71fd173dd8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1410 (Conv2D)            (None, 79, 79, 32)   864         input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1410 (Batch (None, 79, 79, 32)   96          conv2d_1410[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1410 (Activation)    (None, 79, 79, 32)   0           batch_normalization_1410[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1411 (Conv2D)            (None, 77, 77, 32)   9216        activation_1410[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1411 (Batch (None, 77, 77, 32)   96          conv2d_1411[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1411 (Activation)    (None, 77, 77, 32)   0           batch_normalization_1411[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1412 (Conv2D)            (None, 77, 77, 64)   18432       activation_1411[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1412 (Batch (None, 77, 77, 64)   192         conv2d_1412[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1412 (Activation)    (None, 77, 77, 64)   0           batch_normalization_1412[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling2D) (None, 38, 38, 64)   0           activation_1412[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1413 (Conv2D)            (None, 38, 38, 80)   5120        max_pooling2d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1413 (Batch (None, 38, 38, 80)   240         conv2d_1413[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1413 (Activation)    (None, 38, 38, 80)   0           batch_normalization_1413[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1414 (Conv2D)            (None, 36, 36, 192)  138240      activation_1413[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1414 (Batch (None, 36, 36, 192)  576         conv2d_1414[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1414 (Activation)    (None, 36, 36, 192)  0           batch_normalization_1414[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling2D) (None, 17, 17, 192)  0           activation_1414[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1418 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1418 (Batch (None, 17, 17, 64)   192         conv2d_1418[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1418 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1418[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1416 (Conv2D)            (None, 17, 17, 48)   9216        max_pooling2d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1419 (Conv2D)            (None, 17, 17, 96)   55296       activation_1418[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1416 (Batch (None, 17, 17, 48)   144         conv2d_1416[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1419 (Batch (None, 17, 17, 96)   288         conv2d_1419[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1416 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1416[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1419 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1419[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_135 (AverageP (None, 17, 17, 192)  0           max_pooling2d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1415 (Conv2D)            (None, 17, 17, 64)   12288       max_pooling2d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1417 (Conv2D)            (None, 17, 17, 64)   76800       activation_1416[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1420 (Conv2D)            (None, 17, 17, 96)   82944       activation_1419[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1421 (Conv2D)            (None, 17, 17, 32)   6144        average_pooling2d_135[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1415 (Batch (None, 17, 17, 64)   192         conv2d_1415[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1417 (Batch (None, 17, 17, 64)   192         conv2d_1417[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1420 (Batch (None, 17, 17, 96)   288         conv2d_1420[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1421 (Batch (None, 17, 17, 32)   96          conv2d_1421[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1415 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1415[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1417 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1417[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1420 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1420[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1421 (Activation)    (None, 17, 17, 32)   0           batch_normalization_1421[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_1415[0][0]            \n",
      "                                                                 activation_1417[0][0]            \n",
      "                                                                 activation_1420[0][0]            \n",
      "                                                                 activation_1421[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1425 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1425 (Batch (None, 17, 17, 64)   192         conv2d_1425[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1425 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1425[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1423 (Conv2D)            (None, 17, 17, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1426 (Conv2D)            (None, 17, 17, 96)   55296       activation_1425[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1423 (Batch (None, 17, 17, 48)   144         conv2d_1423[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1426 (Batch (None, 17, 17, 96)   288         conv2d_1426[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1423 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1423[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1426 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1426[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_136 (AverageP (None, 17, 17, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1422 (Conv2D)            (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1424 (Conv2D)            (None, 17, 17, 64)   76800       activation_1423[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1427 (Conv2D)            (None, 17, 17, 96)   82944       activation_1426[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1428 (Conv2D)            (None, 17, 17, 64)   16384       average_pooling2d_136[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1422 (Batch (None, 17, 17, 64)   192         conv2d_1422[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1424 (Batch (None, 17, 17, 64)   192         conv2d_1424[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1427 (Batch (None, 17, 17, 96)   288         conv2d_1427[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1428 (Batch (None, 17, 17, 64)   192         conv2d_1428[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1422 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1422[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1424 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1424[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1427 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1427[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1428 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1428[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_1422[0][0]            \n",
      "                                                                 activation_1424[0][0]            \n",
      "                                                                 activation_1427[0][0]            \n",
      "                                                                 activation_1428[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1432 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1432 (Batch (None, 17, 17, 64)   192         conv2d_1432[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1432 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1432[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1430 (Conv2D)            (None, 17, 17, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1433 (Conv2D)            (None, 17, 17, 96)   55296       activation_1432[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1430 (Batch (None, 17, 17, 48)   144         conv2d_1430[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1433 (Batch (None, 17, 17, 96)   288         conv2d_1433[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1430 (Activation)    (None, 17, 17, 48)   0           batch_normalization_1430[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1433 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1433[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_137 (AverageP (None, 17, 17, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1429 (Conv2D)            (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1431 (Conv2D)            (None, 17, 17, 64)   76800       activation_1430[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1434 (Conv2D)            (None, 17, 17, 96)   82944       activation_1433[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1435 (Conv2D)            (None, 17, 17, 64)   18432       average_pooling2d_137[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1429 (Batch (None, 17, 17, 64)   192         conv2d_1429[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1431 (Batch (None, 17, 17, 64)   192         conv2d_1431[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1434 (Batch (None, 17, 17, 96)   288         conv2d_1434[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1435 (Batch (None, 17, 17, 64)   192         conv2d_1435[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1429 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1429[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1431 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1431[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1434 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1434[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1435 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1435[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_1429[0][0]            \n",
      "                                                                 activation_1431[0][0]            \n",
      "                                                                 activation_1434[0][0]            \n",
      "                                                                 activation_1435[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1437 (Conv2D)            (None, 17, 17, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1437 (Batch (None, 17, 17, 64)   192         conv2d_1437[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1437 (Activation)    (None, 17, 17, 64)   0           batch_normalization_1437[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1438 (Conv2D)            (None, 17, 17, 96)   55296       activation_1437[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1438 (Batch (None, 17, 17, 96)   288         conv2d_1438[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1438 (Activation)    (None, 17, 17, 96)   0           batch_normalization_1438[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1436 (Conv2D)            (None, 8, 8, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1439 (Conv2D)            (None, 8, 8, 96)     82944       activation_1438[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1436 (Batch (None, 8, 8, 384)    1152        conv2d_1436[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1439 (Batch (None, 8, 8, 96)     288         conv2d_1439[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1436 (Activation)    (None, 8, 8, 384)    0           batch_normalization_1436[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1439 (Activation)    (None, 8, 8, 96)     0           batch_normalization_1439[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling2D) (None, 8, 8, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_1436[0][0]            \n",
      "                                                                 activation_1439[0][0]            \n",
      "                                                                 max_pooling2d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1444 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1444 (Batch (None, 8, 8, 128)    384         conv2d_1444[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1444 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1444[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1445 (Conv2D)            (None, 8, 8, 128)    114688      activation_1444[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1445 (Batch (None, 8, 8, 128)    384         conv2d_1445[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1445 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1445[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1441 (Conv2D)            (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1446 (Conv2D)            (None, 8, 8, 128)    114688      activation_1445[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1441 (Batch (None, 8, 8, 128)    384         conv2d_1441[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1446 (Batch (None, 8, 8, 128)    384         conv2d_1446[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1441 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1441[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1446 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1446[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1442 (Conv2D)            (None, 8, 8, 128)    114688      activation_1441[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1447 (Conv2D)            (None, 8, 8, 128)    114688      activation_1446[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1442 (Batch (None, 8, 8, 128)    384         conv2d_1442[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1447 (Batch (None, 8, 8, 128)    384         conv2d_1447[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1442 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1442[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1447 (Activation)    (None, 8, 8, 128)    0           batch_normalization_1447[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_138 (AverageP (None, 8, 8, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1440 (Conv2D)            (None, 8, 8, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1443 (Conv2D)            (None, 8, 8, 192)    172032      activation_1442[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1448 (Conv2D)            (None, 8, 8, 192)    172032      activation_1447[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1449 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_138[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1440 (Batch (None, 8, 8, 192)    576         conv2d_1440[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1443 (Batch (None, 8, 8, 192)    576         conv2d_1443[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1448 (Batch (None, 8, 8, 192)    576         conv2d_1448[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1449 (Batch (None, 8, 8, 192)    576         conv2d_1449[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1440 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1440[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1443 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1443[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1448 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1448[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1449 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1449[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_1440[0][0]            \n",
      "                                                                 activation_1443[0][0]            \n",
      "                                                                 activation_1448[0][0]            \n",
      "                                                                 activation_1449[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1454 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1454 (Batch (None, 8, 8, 160)    480         conv2d_1454[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1454 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1454[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1455 (Conv2D)            (None, 8, 8, 160)    179200      activation_1454[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1455 (Batch (None, 8, 8, 160)    480         conv2d_1455[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1455 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1455[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1451 (Conv2D)            (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1456 (Conv2D)            (None, 8, 8, 160)    179200      activation_1455[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1451 (Batch (None, 8, 8, 160)    480         conv2d_1451[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1456 (Batch (None, 8, 8, 160)    480         conv2d_1456[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1451 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1451[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1456 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1456[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1452 (Conv2D)            (None, 8, 8, 160)    179200      activation_1451[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1457 (Conv2D)            (None, 8, 8, 160)    179200      activation_1456[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1452 (Batch (None, 8, 8, 160)    480         conv2d_1452[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1457 (Batch (None, 8, 8, 160)    480         conv2d_1457[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1452 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1452[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1457 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1457[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_139 (AverageP (None, 8, 8, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1450 (Conv2D)            (None, 8, 8, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1453 (Conv2D)            (None, 8, 8, 192)    215040      activation_1452[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1458 (Conv2D)            (None, 8, 8, 192)    215040      activation_1457[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1459 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_139[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1450 (Batch (None, 8, 8, 192)    576         conv2d_1450[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1453 (Batch (None, 8, 8, 192)    576         conv2d_1453[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1458 (Batch (None, 8, 8, 192)    576         conv2d_1458[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1459 (Batch (None, 8, 8, 192)    576         conv2d_1459[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1450 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1450[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1453 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1453[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1458 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1458[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1459 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1459[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_1450[0][0]            \n",
      "                                                                 activation_1453[0][0]            \n",
      "                                                                 activation_1458[0][0]            \n",
      "                                                                 activation_1459[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1464 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1464 (Batch (None, 8, 8, 160)    480         conv2d_1464[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1464 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1464[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1465 (Conv2D)            (None, 8, 8, 160)    179200      activation_1464[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1465 (Batch (None, 8, 8, 160)    480         conv2d_1465[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1465 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1465[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1461 (Conv2D)            (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1466 (Conv2D)            (None, 8, 8, 160)    179200      activation_1465[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1461 (Batch (None, 8, 8, 160)    480         conv2d_1461[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1466 (Batch (None, 8, 8, 160)    480         conv2d_1466[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1461 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1461[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1466 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1466[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1462 (Conv2D)            (None, 8, 8, 160)    179200      activation_1461[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1467 (Conv2D)            (None, 8, 8, 160)    179200      activation_1466[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1462 (Batch (None, 8, 8, 160)    480         conv2d_1462[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1467 (Batch (None, 8, 8, 160)    480         conv2d_1467[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1462 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1462[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1467 (Activation)    (None, 8, 8, 160)    0           batch_normalization_1467[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_140 (AverageP (None, 8, 8, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1460 (Conv2D)            (None, 8, 8, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1463 (Conv2D)            (None, 8, 8, 192)    215040      activation_1462[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1468 (Conv2D)            (None, 8, 8, 192)    215040      activation_1467[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1469 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_140[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1460 (Batch (None, 8, 8, 192)    576         conv2d_1460[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1463 (Batch (None, 8, 8, 192)    576         conv2d_1463[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1468 (Batch (None, 8, 8, 192)    576         conv2d_1468[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1469 (Batch (None, 8, 8, 192)    576         conv2d_1469[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1460 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1460[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1463 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1463[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1468 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1468[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1469 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1469[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_1460[0][0]            \n",
      "                                                                 activation_1463[0][0]            \n",
      "                                                                 activation_1468[0][0]            \n",
      "                                                                 activation_1469[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1474 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1474 (Batch (None, 8, 8, 192)    576         conv2d_1474[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1474 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1474[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1475 (Conv2D)            (None, 8, 8, 192)    258048      activation_1474[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1475 (Batch (None, 8, 8, 192)    576         conv2d_1475[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1475 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1475[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1471 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1476 (Conv2D)            (None, 8, 8, 192)    258048      activation_1475[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1471 (Batch (None, 8, 8, 192)    576         conv2d_1471[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1476 (Batch (None, 8, 8, 192)    576         conv2d_1476[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1471 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1471[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1476 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1476[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1472 (Conv2D)            (None, 8, 8, 192)    258048      activation_1471[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1477 (Conv2D)            (None, 8, 8, 192)    258048      activation_1476[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1472 (Batch (None, 8, 8, 192)    576         conv2d_1472[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1477 (Batch (None, 8, 8, 192)    576         conv2d_1477[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1472 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1472[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1477 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1477[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_141 (AverageP (None, 8, 8, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1470 (Conv2D)            (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1473 (Conv2D)            (None, 8, 8, 192)    258048      activation_1472[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1478 (Conv2D)            (None, 8, 8, 192)    258048      activation_1477[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1479 (Conv2D)            (None, 8, 8, 192)    147456      average_pooling2d_141[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1470 (Batch (None, 8, 8, 192)    576         conv2d_1470[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1473 (Batch (None, 8, 8, 192)    576         conv2d_1473[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1478 (Batch (None, 8, 8, 192)    576         conv2d_1478[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1479 (Batch (None, 8, 8, 192)    576         conv2d_1479[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1470 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1470[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1473 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1473[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1478 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1478[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1479 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1479[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_1470[0][0]            \n",
      "                                                                 activation_1473[0][0]            \n",
      "                                                                 activation_1478[0][0]            \n",
      "                                                                 activation_1479[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1482 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1482 (Batch (None, 8, 8, 192)    576         conv2d_1482[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1482 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1482[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1483 (Conv2D)            (None, 8, 8, 192)    258048      activation_1482[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1483 (Batch (None, 8, 8, 192)    576         conv2d_1483[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1483 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1483[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1480 (Conv2D)            (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1484 (Conv2D)            (None, 8, 8, 192)    258048      activation_1483[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1480 (Batch (None, 8, 8, 192)    576         conv2d_1480[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1484 (Batch (None, 8, 8, 192)    576         conv2d_1484[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1480 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1480[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1484 (Activation)    (None, 8, 8, 192)    0           batch_normalization_1484[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1481 (Conv2D)            (None, 3, 3, 320)    552960      activation_1480[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1485 (Conv2D)            (None, 3, 3, 192)    331776      activation_1484[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1481 (Batch (None, 3, 3, 320)    960         conv2d_1481[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1485 (Batch (None, 3, 3, 192)    576         conv2d_1485[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1481 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1481[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1485 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1485[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_1481[0][0]            \n",
      "                                                                 activation_1485[0][0]            \n",
      "                                                                 max_pooling2d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1490 (Conv2D)            (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1490 (Batch (None, 3, 3, 448)    1344        conv2d_1490[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1490 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1490[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1487 (Conv2D)            (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1491 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1490[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1487 (Batch (None, 3, 3, 384)    1152        conv2d_1487[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1491 (Batch (None, 3, 3, 384)    1152        conv2d_1491[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1487 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1487[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1491 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1491[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1488 (Conv2D)            (None, 3, 3, 384)    442368      activation_1487[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1489 (Conv2D)            (None, 3, 3, 384)    442368      activation_1487[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1492 (Conv2D)            (None, 3, 3, 384)    442368      activation_1491[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1493 (Conv2D)            (None, 3, 3, 384)    442368      activation_1491[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_142 (AverageP (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1486 (Conv2D)            (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1488 (Batch (None, 3, 3, 384)    1152        conv2d_1488[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1489 (Batch (None, 3, 3, 384)    1152        conv2d_1489[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1492 (Batch (None, 3, 3, 384)    1152        conv2d_1492[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1493 (Batch (None, 3, 3, 384)    1152        conv2d_1493[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1494 (Conv2D)            (None, 3, 3, 192)    245760      average_pooling2d_142[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1486 (Batch (None, 3, 3, 320)    960         conv2d_1486[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1488 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1488[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1489 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1489[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1492 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1492[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1493 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1493[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1494 (Batch (None, 3, 3, 192)    576         conv2d_1494[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1486 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1486[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_1488[0][0]            \n",
      "                                                                 activation_1489[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 3, 3, 768)    0           activation_1492[0][0]            \n",
      "                                                                 activation_1493[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1494 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1494[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_1486[0][0]            \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_30[0][0]             \n",
      "                                                                 activation_1494[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1499 (Conv2D)            (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1499 (Batch (None, 3, 3, 448)    1344        conv2d_1499[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1499 (Activation)    (None, 3, 3, 448)    0           batch_normalization_1499[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1496 (Conv2D)            (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1500 (Conv2D)            (None, 3, 3, 384)    1548288     activation_1499[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1496 (Batch (None, 3, 3, 384)    1152        conv2d_1496[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1500 (Batch (None, 3, 3, 384)    1152        conv2d_1500[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1496 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1496[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1500 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1500[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1497 (Conv2D)            (None, 3, 3, 384)    442368      activation_1496[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1498 (Conv2D)            (None, 3, 3, 384)    442368      activation_1496[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1501 (Conv2D)            (None, 3, 3, 384)    442368      activation_1500[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1502 (Conv2D)            (None, 3, 3, 384)    442368      activation_1500[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_143 (AverageP (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1495 (Conv2D)            (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1497 (Batch (None, 3, 3, 384)    1152        conv2d_1497[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1498 (Batch (None, 3, 3, 384)    1152        conv2d_1498[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1501 (Batch (None, 3, 3, 384)    1152        conv2d_1501[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1502 (Batch (None, 3, 3, 384)    1152        conv2d_1502[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1503 (Conv2D)            (None, 3, 3, 192)    393216      average_pooling2d_143[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1495 (Batch (None, 3, 3, 320)    960         conv2d_1495[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1497 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1497[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1498 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1498[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1501 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1501[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1502 (Activation)    (None, 3, 3, 384)    0           batch_normalization_1502[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1503 (Batch (None, 3, 3, 192)    576         conv2d_1503[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1495 (Activation)    (None, 3, 3, 320)    0           batch_normalization_1495[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_1497[0][0]            \n",
      "                                                                 activation_1498[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 3, 3, 768)    0           activation_1501[0][0]            \n",
      "                                                                 activation_1502[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1503 (Activation)    (None, 3, 3, 192)    0           batch_normalization_1503[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_1495[0][0]            \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_31[0][0]             \n",
      "                                                                 activation_1503[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "188\n",
      "190\n",
      "Epoch 1/250\n",
      "23/23 [==============================] - 14s 323ms/step - loss: 1.7242 - accuracy: 0.2297 - val_loss: 1.3800 - val_accuracy: 0.4659\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 1.3158 - accuracy: 0.4797 - val_loss: 1.0215 - val_accuracy: 0.6226\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 1.0733 - accuracy: 0.6174 - val_loss: 0.8334 - val_accuracy: 0.7057\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.9198 - accuracy: 0.6968 - val_loss: 0.7295 - val_accuracy: 0.7371\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.8078 - accuracy: 0.7402 - val_loss: 0.6533 - val_accuracy: 0.7752\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.7059 - accuracy: 0.7803 - val_loss: 0.5995 - val_accuracy: 0.7929\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.6392 - accuracy: 0.7984 - val_loss: 0.5617 - val_accuracy: 0.8079\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.5581 - accuracy: 0.8307 - val_loss: 0.5309 - val_accuracy: 0.8229\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.5268 - accuracy: 0.8355 - val_loss: 0.5074 - val_accuracy: 0.8283\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.4751 - accuracy: 0.8515 - val_loss: 0.4923 - val_accuracy: 0.8351\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.4449 - accuracy: 0.8662 - val_loss: 0.4786 - val_accuracy: 0.8406\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.4220 - accuracy: 0.8689 - val_loss: 0.4606 - val_accuracy: 0.8488\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3825 - accuracy: 0.8786 - val_loss: 0.4481 - val_accuracy: 0.8501\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3511 - accuracy: 0.8966 - val_loss: 0.4360 - val_accuracy: 0.8529\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.3266 - accuracy: 0.8966 - val_loss: 0.4238 - val_accuracy: 0.8515\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.3095 - accuracy: 0.9107 - val_loss: 0.4136 - val_accuracy: 0.8610\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2858 - accuracy: 0.9202 - val_loss: 0.4051 - val_accuracy: 0.8624\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2768 - accuracy: 0.9108 - val_loss: 0.3996 - val_accuracy: 0.8665\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.2433 - accuracy: 0.9275 - val_loss: 0.3908 - val_accuracy: 0.8719\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.2307 - accuracy: 0.9294 - val_loss: 0.3839 - val_accuracy: 0.8719\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.2205 - accuracy: 0.9321 - val_loss: 0.3807 - val_accuracy: 0.8760\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.2026 - accuracy: 0.9418 - val_loss: 0.3732 - val_accuracy: 0.8760\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1911 - accuracy: 0.9395 - val_loss: 0.3692 - val_accuracy: 0.8733\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1861 - accuracy: 0.9398 - val_loss: 0.3633 - val_accuracy: 0.8760\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1702 - accuracy: 0.9504 - val_loss: 0.3568 - val_accuracy: 0.8828\n",
      "Epoch 26/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1668 - accuracy: 0.9488 - val_loss: 0.3512 - val_accuracy: 0.8883\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1489 - accuracy: 0.9589 - val_loss: 0.3528 - val_accuracy: 0.8883\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.1319 - accuracy: 0.9637 - val_loss: 0.3487 - val_accuracy: 0.8910\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1294 - accuracy: 0.9669 - val_loss: 0.3452 - val_accuracy: 0.8910\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1210 - accuracy: 0.9716 - val_loss: 0.3428 - val_accuracy: 0.8978\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1188 - accuracy: 0.9720 - val_loss: 0.3415 - val_accuracy: 0.8937\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.1184 - accuracy: 0.9620 - val_loss: 0.3394 - val_accuracy: 0.8937\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0936 - accuracy: 0.9777 - val_loss: 0.3403 - val_accuracy: 0.8924\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0877 - accuracy: 0.9808 - val_loss: 0.3421 - val_accuracy: 0.8924\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0919 - accuracy: 0.9778 - val_loss: 0.3423 - val_accuracy: 0.8924\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0812 - accuracy: 0.9789 - val_loss: 0.3435 - val_accuracy: 0.8910\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0792 - accuracy: 0.9837 - val_loss: 0.3434 - val_accuracy: 0.8924\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 0.3441 - val_accuracy: 0.8910\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0612 - accuracy: 0.9880 - val_loss: 0.3438 - val_accuracy: 0.8910\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0584 - accuracy: 0.9905 - val_loss: 0.3459 - val_accuracy: 0.8883\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0493 - accuracy: 0.9924 - val_loss: 0.3447 - val_accuracy: 0.8896\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0487 - accuracy: 0.9902 - val_loss: 0.3418 - val_accuracy: 0.8924\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0484 - accuracy: 0.9894 - val_loss: 0.3385 - val_accuracy: 0.8951\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0450 - accuracy: 0.9928 - val_loss: 0.3400 - val_accuracy: 0.8992\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0407 - accuracy: 0.9934 - val_loss: 0.3404 - val_accuracy: 0.9005\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0387 - accuracy: 0.9919 - val_loss: 0.3417 - val_accuracy: 0.9019\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0334 - accuracy: 0.9954 - val_loss: 0.3393 - val_accuracy: 0.9005\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0381 - accuracy: 0.9935 - val_loss: 0.3395 - val_accuracy: 0.8992\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0309 - accuracy: 0.9949 - val_loss: 0.3400 - val_accuracy: 0.8951\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0350 - accuracy: 0.9939 - val_loss: 0.3394 - val_accuracy: 0.8965\n",
      "Epoch 51/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0338 - accuracy: 0.9938 - val_loss: 0.3401 - val_accuracy: 0.8965\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0232 - accuracy: 0.9981 - val_loss: 0.3400 - val_accuracy: 0.8978\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0300 - accuracy: 0.9951 - val_loss: 0.3391 - val_accuracy: 0.8951\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0234 - accuracy: 0.9965 - val_loss: 0.3411 - val_accuracy: 0.8992\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 0.3441 - val_accuracy: 0.8937\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0249 - accuracy: 0.9966 - val_loss: 0.3476 - val_accuracy: 0.8910\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0211 - accuracy: 0.9970 - val_loss: 0.3444 - val_accuracy: 0.8965\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0179 - accuracy: 0.9994 - val_loss: 0.3428 - val_accuracy: 0.8965\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 0.3412 - val_accuracy: 0.8978\n",
      "Epoch 60/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0176 - accuracy: 0.9978 - val_loss: 0.3438 - val_accuracy: 0.8951\n",
      "Epoch 61/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0180 - accuracy: 0.9975 - val_loss: 0.3443 - val_accuracy: 0.8951\n",
      "Epoch 62/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0137 - accuracy: 0.9996 - val_loss: 0.3443 - val_accuracy: 0.8978\n",
      "Epoch 63/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0196 - accuracy: 0.9956 - val_loss: 0.3493 - val_accuracy: 0.8978\n",
      "Epoch 64/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.3546 - val_accuracy: 0.8951\n",
      "Epoch 65/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.3572 - val_accuracy: 0.8951\n",
      "Epoch 66/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 0.3579 - val_accuracy: 0.8951\n",
      "Epoch 67/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0116 - accuracy: 0.9995 - val_loss: 0.3599 - val_accuracy: 0.8992\n",
      "Epoch 68/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.3601 - val_accuracy: 0.8978\n",
      "Epoch 69/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.3566 - val_accuracy: 0.9005\n",
      "Epoch 70/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.3559 - val_accuracy: 0.9046\n",
      "Epoch 71/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0120 - accuracy: 0.9991 - val_loss: 0.3563 - val_accuracy: 0.9019\n",
      "Epoch 72/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9033\n",
      "Epoch 73/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.3576 - val_accuracy: 0.9033\n",
      "Epoch 74/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 0.3600 - val_accuracy: 0.9046\n",
      "Epoch 75/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.3619 - val_accuracy: 0.9046\n",
      "Epoch 76/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.3643 - val_accuracy: 0.9033\n",
      "Epoch 77/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.3641 - val_accuracy: 0.9046\n",
      "Epoch 78/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9060\n",
      "Epoch 79/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9046\n",
      "Epoch 80/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.3612 - val_accuracy: 0.9046\n",
      "Epoch 81/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.3624 - val_accuracy: 0.9046\n",
      "Epoch 82/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9046\n",
      "Epoch 83/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.3643 - val_accuracy: 0.9046\n",
      "Epoch 84/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0073 - accuracy: 0.9999 - val_loss: 0.3664 - val_accuracy: 0.9046\n",
      "Epoch 85/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.3681 - val_accuracy: 0.9046\n",
      "Epoch 86/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9046\n",
      "Epoch 87/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9033\n",
      "Epoch 88/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0056 - accuracy: 0.9999 - val_loss: 0.3734 - val_accuracy: 0.9033\n",
      "Epoch 89/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.3794 - val_accuracy: 0.9033\n",
      "Epoch 90/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9033\n",
      "Epoch 91/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.3810 - val_accuracy: 0.9060\n",
      "Epoch 92/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.3832 - val_accuracy: 0.9046\n",
      "Epoch 93/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.3869 - val_accuracy: 0.9046\n",
      "Epoch 94/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9046\n",
      "Epoch 95/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.3802 - val_accuracy: 0.9046\n",
      "Epoch 96/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.3834 - val_accuracy: 0.9046\n",
      "Epoch 97/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9046\n",
      "Epoch 98/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.3816 - val_accuracy: 0.9033\n",
      "Epoch 99/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.3789 - val_accuracy: 0.9060\n",
      "Epoch 100/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9060\n",
      "Epoch 101/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9087\n",
      "Epoch 102/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.3794 - val_accuracy: 0.9060\n",
      "Epoch 103/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.3826 - val_accuracy: 0.9046\n",
      "Epoch 104/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9046\n",
      "Epoch 105/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.3850 - val_accuracy: 0.9033\n",
      "Epoch 106/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9033\n",
      "Epoch 107/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.3881 - val_accuracy: 0.9046\n",
      "Epoch 108/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9046\n",
      "Epoch 109/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9046\n",
      "Epoch 110/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.3871 - val_accuracy: 0.9033\n",
      "Epoch 111/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9033\n",
      "Epoch 112/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9046\n",
      "Epoch 113/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9019\n",
      "Epoch 114/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.3918 - val_accuracy: 0.9046\n",
      "Epoch 115/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.3890 - val_accuracy: 0.9046\n",
      "Epoch 116/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3896 - val_accuracy: 0.9033\n",
      "Epoch 117/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9033\n",
      "Epoch 118/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9019\n",
      "Epoch 119/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9033\n",
      "Epoch 120/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9033\n",
      "Epoch 121/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3971 - val_accuracy: 0.9019\n",
      "Epoch 122/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.3992 - val_accuracy: 0.9005\n",
      "Epoch 123/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9019\n",
      "Epoch 124/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9019\n",
      "Epoch 125/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9019\n",
      "Epoch 126/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9019\n",
      "Epoch 127/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9019\n",
      "Epoch 128/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9019\n",
      "Epoch 129/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.3999 - val_accuracy: 0.9019\n",
      "Epoch 130/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9046\n",
      "Epoch 131/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9033\n",
      "Epoch 132/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9033\n",
      "Epoch 133/250\n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9019\n",
      "Epoch 134/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9046\n",
      "Epoch 135/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9033\n",
      "Epoch 136/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9019\n",
      "Epoch 137/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9019\n",
      "Epoch 138/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.4049 - val_accuracy: 0.9019\n",
      "Epoch 139/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9033\n",
      "Epoch 140/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9033\n",
      "Epoch 141/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9033\n",
      "Epoch 142/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9019\n",
      "Epoch 143/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9005\n",
      "Epoch 144/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9060\n",
      "Epoch 145/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9046\n",
      "Epoch 146/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9019\n",
      "Epoch 147/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9033\n",
      "Epoch 148/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.4092 - val_accuracy: 0.9019\n",
      "Epoch 149/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9046\n",
      "Epoch 150/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9060\n",
      "Epoch 151/250\n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9033\n",
      "Epoch 152/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9046\n",
      "Epoch 153/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.4226 - val_accuracy: 0.9060\n",
      "Epoch 154/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 8.9568e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9046\n",
      "Epoch 155/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9046\n",
      "Epoch 156/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9046\n",
      "Epoch 157/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9046\n",
      "Epoch 158/250\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 7.7292e-04 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9074\n",
      "Epoch 159/250\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 8.2690e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9074\n",
      "Epoch 160/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 8.6850e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9074\n",
      "Epoch 161/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9087\n",
      "Epoch 162/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9101\n",
      "Epoch 163/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 8.8382e-04 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9074\n",
      "Epoch 164/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9087\n",
      "Epoch 165/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 8.7724e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9046\n",
      "Epoch 166/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 7.6596e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9046\n",
      "Epoch 167/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 9.6546e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9046\n",
      "Epoch 168/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 7.8060e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9060\n",
      "Epoch 169/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 9.5660e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9060\n",
      "Epoch 170/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 7.8262e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9074\n",
      "Epoch 171/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 9.6306e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9046\n",
      "Epoch 172/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.7419e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9046\n",
      "Epoch 173/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.0606e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9046\n",
      "Epoch 174/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 6.9003e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9046\n",
      "Epoch 175/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9046\n",
      "Epoch 176/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.2525e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9074\n",
      "Epoch 177/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 7.0096e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9060\n",
      "Epoch 178/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 6.5353e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9087\n",
      "Epoch 179/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.6439e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9074\n",
      "Epoch 180/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 7.3507e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9087\n",
      "Epoch 181/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.6812e-04 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9087\n",
      "Epoch 182/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.2694e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9074\n",
      "Epoch 183/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.9793e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9060\n",
      "Epoch 184/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.8382e-04 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9074\n",
      "Epoch 185/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.9832e-04 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9074\n",
      "Epoch 186/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.5679e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9060\n",
      "Epoch 187/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 8.3503e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9046\n",
      "Epoch 188/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 6.2252e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9046\n",
      "Epoch 189/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.7044e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9033\n",
      "Epoch 190/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.4247e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9033\n",
      "Epoch 191/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 7.1575e-04 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9046\n",
      "Epoch 192/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.6948e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9046\n",
      "Epoch 193/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.6366e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9033\n",
      "Epoch 194/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 7.7721e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9060\n",
      "Epoch 195/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.3808e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9046\n",
      "Epoch 196/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.8163e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9060\n",
      "Epoch 197/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.9940e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9033\n",
      "Epoch 198/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.8787e-04 - accuracy: 0.9999 - val_loss: 0.4419 - val_accuracy: 0.9060\n",
      "Epoch 199/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.5309e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9046\n",
      "Epoch 200/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.1825e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9046\n",
      "Epoch 201/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.8557e-04 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9033\n",
      "Epoch 202/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.6024e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9033\n",
      "Epoch 203/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.2829e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9033\n",
      "Epoch 204/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.9904e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9019\n",
      "Epoch 205/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 3.5442e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9019\n",
      "Epoch 206/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.8729e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9019\n",
      "Epoch 207/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.6071e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9005\n",
      "Epoch 208/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.7612e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8992\n",
      "Epoch 209/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 3.4509e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9019\n",
      "Epoch 210/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 5.3381e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9046\n",
      "Epoch 211/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.1590e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9060\n",
      "Epoch 212/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.3100e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9046\n",
      "Epoch 213/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.3051e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9033\n",
      "Epoch 214/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.4421e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9033\n",
      "Epoch 215/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.1699e-04 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9046\n",
      "Epoch 216/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.9556e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9046\n",
      "Epoch 217/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.3603e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9060\n",
      "Epoch 218/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.6862e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9046\n",
      "Epoch 219/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.2631e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9046\n",
      "Epoch 220/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.9084e-04 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.9046\n",
      "Epoch 221/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 6.6108e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9033\n",
      "Epoch 222/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.5501e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9046\n",
      "Epoch 223/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.3183e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9046\n",
      "Epoch 224/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.8305e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9033\n",
      "Epoch 225/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.9620e-04 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9046\n",
      "Epoch 226/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.2404e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9046\n",
      "Epoch 227/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 4.0938e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9074\n",
      "Epoch 228/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.0494e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9060\n",
      "Epoch 229/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.6400e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9074\n",
      "Epoch 230/250\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 2.8791e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9074\n",
      "Epoch 231/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.8442e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9087\n",
      "Epoch 232/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 4.5949e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9046\n",
      "Epoch 233/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.0420e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9033\n",
      "Epoch 234/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.9907e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9019\n",
      "Epoch 235/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.5333e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9046\n",
      "Epoch 236/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.1234e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9033\n",
      "Epoch 237/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.4002e-04 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9046\n",
      "Epoch 238/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.0771e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9046\n",
      "Epoch 239/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 3.2265e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9074\n",
      "Epoch 240/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.4041e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9060\n",
      "Epoch 241/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.1151e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9060\n",
      "Epoch 242/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.1957e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9060\n",
      "Epoch 243/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.4178e-04 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9060\n",
      "Epoch 244/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.3919e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9074\n",
      "Epoch 245/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.3398e-04 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9074\n",
      "Epoch 246/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.7221e-04 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9087\n",
      "Epoch 247/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 1.8985e-04 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9101\n",
      "Epoch 248/250\n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.3334e-04 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9074\n",
      "Epoch 249/250\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 2.9832e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9087\n",
      "Epoch 250/250\n",
      "23/23 [==============================] - 6s 270ms/step - loss: 2.3737e-04 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9101\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gap\n",
    "\n",
    "# Create the base model \n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "# process data\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "])\n",
    "\n",
    "# flattening\n",
    "global_average = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "# final layer\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# construct a new network\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = global_average(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(len(base_model.trainable_variables))\n",
    "print(len(model.trainable_variables))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=250,\n",
    "                         validation_data=validation_dataset)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn6ReHHFsFaM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mwmFuwFsFaM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10.Flowers_EfficientNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
