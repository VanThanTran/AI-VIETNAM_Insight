{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex11_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Nm2-oIevrX75",
        "outputId": "7606057f-98d4-4542-8cef-0add197aec34"
      },
      "source": [
        "# !pip install tensorflow==3.2.0\r\n",
        "import tensorflow as tf\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm \r\n",
        "import random, time, os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "if not os.path.isdir(\"/gdrive\"):\r\n",
        "    from google.colab import drive\r\n",
        "    drive.mount(\"/gdrive\")\r\n",
        "\r\n",
        "!test -d data && ls -l data/ || unzip /gdrive/MyDrive/dataset/shopee-code-league-2020-product-detection.zip -d data 1>/dev/null\r\n",
        "\r\n",
        "tf.__version__\r\n",
        "# Tutorial\r\n",
        "# https://www.kaggle.com/fadheladlansyah/product-detection-effnetb5-aug-tta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4604\n",
            "drwxr-xr-x 4 root root    4096 Feb 19 18:38 resized\n",
            "-rw-r--r-- 1 root root  487458 Jun 20  2020 test.csv\n",
            "-rw-r--r-- 1 root root 4215698 Jun 20  2020 train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWt8BpfpIOEX"
      },
      "source": [
        "## 1. Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeeqPsVGrgRZ"
      },
      "source": [
        "def get_data():\r\n",
        "    train =  tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        \"data/resized/train/\",\r\n",
        "        validation_split = .1,\r\n",
        "        subset = \"training\",\r\n",
        "        seed = 1,\r\n",
        "        labels     = \"inferred\",\r\n",
        "        label_mode = \"int\",\r\n",
        "        image_size = (299, 299)\r\n",
        "    )\r\n",
        "\r\n",
        "    validation =  tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        \"data/resized/train/\",\r\n",
        "        validation_split = .1,\r\n",
        "        subset = \"training\",\r\n",
        "        seed = 1,\r\n",
        "        labels     = \"inferred\",\r\n",
        "        label_mode = \"int\",\r\n",
        "        image_size = (299, 299)\r\n",
        "    )\r\n",
        "    return train, validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKaGEgZ0vcC_"
      },
      "source": [
        "## 2. Layers and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR4JxkUsG3PO"
      },
      "source": [
        "### 2.1 Preprocessing input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xHX14IG7L7"
      },
      "source": [
        "class Preprocess(tf.keras.layers.Layer):\r\n",
        "    def __init__(self):\r\n",
        "        super(Preprocess, self).__init__()\r\n",
        "    \r\n",
        "    def call(self, X):\r\n",
        "        X = tf.keras.applications.efficientnet.preprocess_input(X)\r\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfKSQ_DG8i-"
      },
      "source": [
        "### 2.2. Augmentation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhLMRPmDW83d"
      },
      "source": [
        "# # Cutmix\r\n",
        "# def CutMix(self, X, y, lamda=.66):\r\n",
        "#     #N: number of samples within the batch, (W, H) is img size, C is number of img channel (default = 3)\r\n",
        "#     if self.N is None:\r\n",
        "#         self.N, self.W, self.H, _ = X.shape\r\n",
        "\r\n",
        "#     imgs = []; labels=[]\r\n",
        "#     for i in range(self.N):\r\n",
        "#         # select image\r\n",
        "#         k = np.random.randint(0, self.N)\r\n",
        "\r\n",
        "#         r_w, r_h = (1 - self.lamda)**.5 * self.W, (1 - self.lamda)**.5 * self.H\r\n",
        "#         r_w, r_h = int(r_w), int(r_h)\r\n",
        "#         r_x, r_y = np.random.randint(0, self.W - r_w), np.random.randint(0, self.H - r_h)\r\n",
        "\r\n",
        "#         # img\r\n",
        "#         X_i = X[i,:,:,:]\r\n",
        "#         X_k = X[k,:,:,:]\r\n",
        "\r\n",
        "#         y_i = y[i,:]\r\n",
        "#         y_k = y[k,:]\r\n",
        "\r\n",
        "#         # Mask\r\n",
        "#         M = np.ones_like(X_i)\r\n",
        "#         M[r_x:r_x+r_w,r_y:r_y+r_h,:] = 0\r\n",
        "\r\n",
        "#         img = M*X_i + (1-M)*X_k\r\n",
        "#         label = y_i * self.lamda + y_k * (1 - self.lamda)\r\n",
        "\r\n",
        "#         imgs.append(img)\r\n",
        "#         labels.append(label)\r\n",
        "\r\n",
        "#     return imgs, labels\r\n",
        "\r\n",
        "\r\n",
        "# class CutOut(tf.keras.layers.Layer):\r\n",
        "#     def __init__(self, a):\r\n",
        "#         super(CutOut, self).__init__()\r\n",
        "#         self.a = a\r\n",
        "\r\n",
        "#     def call(self, X):\r\n",
        "#         print(X)\r\n",
        "        \r\n",
        "#         _, W, H, _ = X.shape\r\n",
        "\r\n",
        "#         w, h = self.a**.5 * W, self.a**.5 * H\r\n",
        "#         w, h = int(w), int(h)\r\n",
        "#         x, y = np.random.randint(0, W - w), np.random.randint(0, H - h)\r\n",
        "\r\n",
        "#         # Masking\r\n",
        "#         M = np.ones_like(X)\r\n",
        "#         M[:,x:x+w,y:y+h,:] = 0\r\n",
        "        \r\n",
        "#         return M*X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqv4Oo3HHEVU"
      },
      "source": [
        "class Augmentation(tf.keras.layers.Layer):\r\n",
        "    def __init__(self):\r\n",
        "        super(Augmentation, self).__init__()\r\n",
        "        # self.cutout = CutOut(.1)\r\n",
        "    \r\n",
        "    def call(self, X):\r\n",
        "        X = tf.image.random_flip_left_right(X)\r\n",
        "        X = tf.image.random_brightness(X, max_delta=0.5)\r\n",
        "        X = tf.image.random_contrast(X, lower=0.75, upper=1.2)\r\n",
        "        # X = self.cutout(X)\r\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdeb0RVHGEW"
      },
      "source": [
        "### 2.3 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8SfMAb8sllV"
      },
      "source": [
        "def get_model():\r\n",
        "    with tf.device(\"/device:GPU:0\"):\r\n",
        "        # Load efficient net\r\n",
        "        base = tf.keras.applications.efficientnet.EfficientNetB5(\r\n",
        "            include_top = False,\r\n",
        "            weights=\"imagenet\",\r\n",
        "            pooling = None\r\n",
        "        )\r\n",
        "        base.trainable=False\r\n",
        "\r\n",
        "        net = tf.keras.models.Sequential([\r\n",
        "            Preprocess(),\r\n",
        "            Augmentation(),\r\n",
        "            base,\r\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "            tf.keras.layers.Dense(42, activation=\"softmax\")\r\n",
        "        ])\r\n",
        "\r\n",
        "        net.compile(\r\n",
        "            optimizer = tf.keras.optimizers.SGD(learning_rate=.1),\r\n",
        "            loss = \"sparse_categorical_crossentropy\",\r\n",
        "            metrics = \"accuracy\"\r\n",
        "        )\r\n",
        "\r\n",
        "        return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S4OR2RAHQyL"
      },
      "source": [
        "## 3. Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RcukSPzHVNp"
      },
      "source": [
        "### 3.1 Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82wxr-eYvATd"
      },
      "source": [
        "# Reduce learning rate on plateau\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
        "    monitor='val_loss', factor=0.1, patience=2, verbose=1,\r\n",
        "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-5\r\n",
        ")\r\n",
        "\r\n",
        "# save checkspoint\r\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=\"/gdrive/MyDrive/dataset/checkpoints/efficient_net\",\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)\r\n",
        "\r\n",
        "# Early stopping\r\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.002, patience=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js2kelwDHZ-b"
      },
      "source": [
        "### 3.2 Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hY5srZBKgu-"
      },
      "source": [
        "# config\r\n",
        "BATCH_SIZE = 256\r\n",
        "EPOCH = 20\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsPzXGxJ-fDv",
        "outputId": "7f0143b5-3f77-41ae-cf77-556262ee33ad"
      },
      "source": [
        "#input:\r\n",
        "train, validation = get_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 105392 files belonging to 42 classes.\n",
            "Using 94853 files for training.\n",
            "Found 105392 files belonging to 42 classes.\n",
            "Using 94853 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BJlneZXWUXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e768b2-16d4-4fe2-b71d-4a7b2f1435c5"
      },
      "source": [
        "net = get_model()\r\n",
        "\r\n",
        "try: \r\n",
        "    net.load_weights(\"/gdrive/MyDrive/dataset/checkpoints/efficient_net\")\r\n",
        "    print(\"Loaded weight from last check points\")\r\n",
        "\r\n",
        "except Exception as e:\r\n",
        "    print(\"Check point not found\", e)\r\n",
        "\r\n",
        "# Train\r\n",
        "history = net.fit(\r\n",
        "    train,\r\n",
        "    validation_data = validation,\r\n",
        "    epochs= EPOCH,\r\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback],\r\n",
        "    workers=AUTO    \r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
            "115269632/115263384 [==============================] - 1s 0us/step\n",
            "Loaded weight from last check points\n",
            "Epoch 1/20\n",
            "2965/2965 [==============================] - 2431s 813ms/step - loss: 0.6916 - accuracy: 0.8067 - val_loss: 0.6214 - val_accuracy: 0.8262\n",
            "Epoch 2/20\n",
            "2965/2965 [==============================] - 2344s 790ms/step - loss: 0.6838 - accuracy: 0.8080 - val_loss: 0.6115 - val_accuracy: 0.8291\n",
            "Epoch 3/20\n",
            "2965/2965 [==============================] - 2342s 790ms/step - loss: 0.6785 - accuracy: 0.8103 - val_loss: 0.6062 - val_accuracy: 0.8308\n",
            "Epoch 4/20\n",
            "2965/2965 [==============================] - 2351s 793ms/step - loss: 0.6721 - accuracy: 0.8094 - val_loss: 0.5995 - val_accuracy: 0.8331\n",
            "Epoch 5/20\n",
            "1513/2965 [==============>...............] - ETA: 9:44 - loss: 0.6629 - accuracy: 0.8145"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBCgs81QMzXd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}