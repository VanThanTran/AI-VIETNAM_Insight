{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex11_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Nm2-oIevrX75",
        "outputId": "38355ac7-0ca2-4cfe-9278-a2b0e1a55e87"
      },
      "source": [
        "# !pip install tensorflow==3.2.0\r\n",
        "import tensorflow as tf\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm \r\n",
        "import random, time, os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "if not os.path.isdir(\"/gdrive\"):\r\n",
        "    from google.colab import drive\r\n",
        "    drive.mount(\"/gdrive\")\r\n",
        "\r\n",
        "!test -d data && ls -l data/ || unzip /gdrive/MyDrive/dataset/shopee-code-league-2020-product-detection.zip -d data 1>/dev/null\r\n",
        "\r\n",
        "tf.__version__\r\n",
        "# Tutorial\r\n",
        "# https://www.kaggle.com/fadheladlansyah/product-detection-effnetb5-aug-tta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWt8BpfpIOEX"
      },
      "source": [
        "## 1. Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeeqPsVGrgRZ"
      },
      "source": [
        "def get_data():\r\n",
        "    train =  tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        \"data/resized/train/\",\r\n",
        "        validation_split = .1,\r\n",
        "        subset = \"training\",\r\n",
        "        seed = 1,\r\n",
        "        labels     = \"inferred\",\r\n",
        "        label_mode = \"int\",\r\n",
        "        image_size = (299, 299)\r\n",
        "    )\r\n",
        "\r\n",
        "    validation =  tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        \"data/resized/train/\",\r\n",
        "        validation_split = .1,\r\n",
        "        subset = \"training\",\r\n",
        "        seed = 1,\r\n",
        "        labels     = \"inferred\",\r\n",
        "        label_mode = \"int\",\r\n",
        "        image_size = (299, 299)\r\n",
        "    )\r\n",
        "    return train, validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKaGEgZ0vcC_"
      },
      "source": [
        "## 2. Layers and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR4JxkUsG3PO"
      },
      "source": [
        "### 2.1 Preprocessing input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xHX14IG7L7"
      },
      "source": [
        "class Preprocess(tf.keras.layers.Layer):\r\n",
        "    def __init__(self):\r\n",
        "        super(Preprocess, self).__init__()\r\n",
        "    \r\n",
        "    def call(self, X):\r\n",
        "        X = tf.keras.applications.efficientnet.preprocess_input(X)\r\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfKSQ_DG8i-"
      },
      "source": [
        "### 2.2. Augmentation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqv4Oo3HHEVU"
      },
      "source": [
        "class Augmentation(tf.keras.layers.Layer):\r\n",
        "    def __init__(self):\r\n",
        "        super(Augmentation, self).__init__()\r\n",
        "        # self.cutout = CutOut(.1)\r\n",
        "    \r\n",
        "    def call(self, X):\r\n",
        "        X = tf.image.random_flip_left_right(X)\r\n",
        "        X = tf.image.random_brightness(X, max_delta=0.5)\r\n",
        "        X = tf.image.random_contrast(X, lower=0.75, upper=1.2)\r\n",
        "        # X = self.cutout(X)\r\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdeb0RVHGEW"
      },
      "source": [
        "### 2.3 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8SfMAb8sllV"
      },
      "source": [
        "def get_model():\r\n",
        "    with tf.device(\"/device:GPU:0\"):\r\n",
        "        # Load efficient net\r\n",
        "        base = tf.keras.applications.efficientnet.EfficientNetB5(\r\n",
        "            include_top = False,\r\n",
        "            weights=\"imagenet\",\r\n",
        "            pooling = None\r\n",
        "        )\r\n",
        "        for layer in base.layers[:-10]:\r\n",
        "            layer.trainable = False\r\n",
        "\r\n",
        "        net = tf.keras.models.Sequential([\r\n",
        "            Preprocess(),\r\n",
        "            Augmentation(),\r\n",
        "            base,\r\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "            tf.keras.layers.Dense(42, activation=\"softmax\")\r\n",
        "        ])\r\n",
        "\r\n",
        "        net.compile(\r\n",
        "            optimizer = tf.keras.optimizers.SGD(learning_rate=1e-6),\r\n",
        "            loss = \"sparse_categorical_crossentropy\",\r\n",
        "            metrics = \"accuracy\"\r\n",
        "        )\r\n",
        "\r\n",
        "        return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S4OR2RAHQyL"
      },
      "source": [
        "## 3. Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RcukSPzHVNp"
      },
      "source": [
        "### 3.1 Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82wxr-eYvATd"
      },
      "source": [
        "# Reduce learning rate on plateau\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
        "    monitor='val_loss', factor=0.1, patience=2, verbose=1,\r\n",
        "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-5\r\n",
        ")\r\n",
        "\r\n",
        "# save checkspoint\r\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=\"/gdrive/MyDrive/dataset/checkpoints/efficient_net\",\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)\r\n",
        "\r\n",
        "# Early stopping\r\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.002, patience=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js2kelwDHZ-b"
      },
      "source": [
        "### 3.2 Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hY5srZBKgu-"
      },
      "source": [
        "# config\r\n",
        "BATCH_SIZE = 256\r\n",
        "EPOCH = 5\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsPzXGxJ-fDv",
        "outputId": "38a2e98f-17a4-4d37-9891-1ed59a65db4e"
      },
      "source": [
        "#input:\r\n",
        "train, validation = get_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 105392 files belonging to 42 classes.\n",
            "Using 94853 files for training.\n",
            "Found 105392 files belonging to 42 classes.\n",
            "Using 94853 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BJlneZXWUXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44c99af-dd88-4699-9d2f-ea32ae2a3f5b"
      },
      "source": [
        "net = get_model()\r\n",
        "\r\n",
        "try: \r\n",
        "    net.load_weights(\"/gdrive/MyDrive/dataset/checkpoints/efficient_net\")\r\n",
        "    print(\"Loaded weight from last check points\")\r\n",
        "\r\n",
        "except Exception as e:\r\n",
        "    print(\"Check point not found\", e)\r\n",
        "\r\n",
        "# Train\r\n",
        "history = net.fit(\r\n",
        "    train,\r\n",
        "    validation_data = validation,\r\n",
        "    epochs= EPOCH,\r\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback],\r\n",
        "    workers=AUTO    \r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded weight from last check points\n",
            "Epoch 1/5\n",
            "2965/2965 [==============================] - 2460s 825ms/step - loss: 0.8089 - accuracy: 0.7714 - val_loss: 0.4552 - val_accuracy: 0.8682\n",
            "Epoch 2/5\n",
            "2965/2965 [==============================] - 2378s 802ms/step - loss: 0.5520 - accuracy: 0.8402 - val_loss: 0.3053 - val_accuracy: 0.9124\n",
            "Epoch 3/5\n",
            "2965/2965 [==============================] - 2371s 800ms/step - loss: 0.4185 - accuracy: 0.8772 - val_loss: 0.2379 - val_accuracy: 0.9310\n",
            "Epoch 4/5\n",
            "2965/2965 [==============================] - 2370s 799ms/step - loss: 0.3264 - accuracy: 0.9040 - val_loss: 0.1742 - val_accuracy: 0.9525\n",
            "Epoch 5/5\n",
            "2965/2965 [==============================] - 2383s 804ms/step - loss: 0.2577 - accuracy: 0.9256 - val_loss: 0.1122 - val_accuracy: 0.9718\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}